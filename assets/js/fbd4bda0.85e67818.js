"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[2210],{5680:(e,a,n)=>{n.d(a,{xA:()=>d,yg:()=>y});var t=n(6540);function r(e,a,n){return a in e?Object.defineProperty(e,a,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[a]=n,e}function l(e,a){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);a&&(t=t.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),n.push.apply(n,t)}return n}function s(e){for(var a=1;a<arguments.length;a++){var n=null!=arguments[a]?arguments[a]:{};a%2?l(Object(n),!0).forEach((function(a){r(e,a,n[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):l(Object(n)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(n,a))}))}return e}function p(e,a){if(null==e)return{};var n,t,r=function(e,a){if(null==e)return{};var n,t,r={},l=Object.keys(e);for(t=0;t<l.length;t++)n=l[t],a.indexOf(n)>=0||(r[n]=e[n]);return r}(e,a);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(t=0;t<l.length;t++)n=l[t],a.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var i=t.createContext({}),o=function(e){var a=t.useContext(i),n=a;return e&&(n="function"==typeof e?e(a):s(s({},a),e)),n},d=function(e){var a=o(e.components);return t.createElement(i.Provider,{value:a},e.children)},u={inlineCode:"code",wrapper:function(e){var a=e.children;return t.createElement(t.Fragment,{},a)}},m=t.forwardRef((function(e,a){var n=e.components,r=e.mdxType,l=e.originalType,i=e.parentName,d=p(e,["components","mdxType","originalType","parentName"]),m=o(n),y=r,c=m["".concat(i,".").concat(y)]||m[y]||u[y]||l;return n?t.createElement(c,s(s({ref:a},d),{},{components:n})):t.createElement(c,s({ref:a},d))}));function y(e,a){var n=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var l=n.length,s=new Array(l);s[0]=m;var p={};for(var i in a)hasOwnProperty.call(a,i)&&(p[i]=a[i]);p.originalType=e,p.mdxType="string"==typeof e?e:r,s[1]=p;for(var o=2;o<l;o++)s[o]=n[o];return t.createElement.apply(null,s)}return t.createElement.apply(null,n)}m.displayName="MDXCreateElement"},2020:(e,a,n)=>{n.r(a),n.d(a,{contentTitle:()=>s,default:()=>d,frontMatter:()=>l,metadata:()=>p,toc:()=>i});var t=n(8168),r=(n(6540),n(5680));const l={sidebar_label:"utils",title:"automl.spark.utils"},s=void 0,p={unversionedId:"reference/automl/spark/utils",id:"reference/automl/spark/utils",isDocsHomePage:!1,title:"automl.spark.utils",description:"to\\pandas\\on\\_spark",source:"@site/docs/reference/automl/spark/utils.md",sourceDirName:"reference/automl/spark",slug:"/reference/automl/spark/utils",permalink:"/FLAML/docs/reference/automl/spark/utils",editUrl:"https://github.com/microsoft/FLAML/edit/main/website/docs/reference/automl/spark/utils.md",tags:[],version:"current",frontMatter:{sidebar_label:"utils",title:"automl.spark.utils"},sidebar:"referenceSideBar",previous:{title:"metrics",permalink:"/FLAML/docs/reference/automl/spark/metrics"},next:{title:"task",permalink:"/FLAML/docs/reference/automl/task/task"}},i=[{value:"to_pandas_on_spark",id:"to_pandas_on_spark",children:[],level:4},{value:"train_test_split_pyspark",id:"train_test_split_pyspark",children:[],level:4},{value:"unique_pandas_on_spark",id:"unique_pandas_on_spark",children:[],level:4},{value:"len_labels",id:"len_labels",children:[],level:4},{value:"unique_value_first_index",id:"unique_value_first_index",children:[],level:4},{value:"iloc_pandas_on_spark",id:"iloc_pandas_on_spark",children:[],level:4},{value:"spark_kFold",id:"spark_kfold",children:[],level:4}],o={toc:i};function d(e){let{components:a,...n}=e;return(0,r.yg)("wrapper",(0,t.A)({},o,n,{components:a,mdxType:"MDXLayout"}),(0,r.yg)("h4",{id:"to_pandas_on_spark"},"to","_","pandas","_","on","_","spark"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'def to_pandas_on_spark(\n    df: Union[DataFrame, sparkDataFrame, Series, psDataFrame, psSeries],\n    index_col: Optional[str] = None,\n    default_index_type: Optional[str] = "distributed-sequence"\n) -> Union[psDataFrame, psSeries]\n')),(0,r.yg)("p",null,"Convert pandas or pyspark dataframe/series to pandas_on_Spark dataframe/series."),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Arguments"),":"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"df")," - pandas.DataFrame/series or pyspark dataframe | The input dataframe/series."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"index_col")," - str, optional | The column name to use as index, default None."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"default_index_type"),' - str, optional | The default index type, default "distributed-sequence".')),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Returns"),":"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"pyspark.pandas.DataFrame/Series")," - The converted pandas-on-Spark dataframe/series.")),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'import pandas as pd\nfrom flaml.automl.spark.utils import to_pandas_on_spark\n\npdf = DataFrame({"a": [1, 2, 3], "b": [4, 5, 6]})\npsdf = to_pandas_on_spark(pdf)\nprint(psdf)\n\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.getOrCreate()\nsdf = spark.createDataFrame(pdf)\npsdf = to_pandas_on_spark(sdf)\nprint(psdf)\n\npds = Series([1, 2, 3])\npss = to_pandas_on_spark(pds)\nprint(pss)\n')),(0,r.yg)("h4",{id:"train_test_split_pyspark"},"train","_","test","_","split","_","pyspark"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'def train_test_split_pyspark(\n    df: Union[sparkDataFrame, psDataFrame],\n    stratify_column: Optional[str] = None,\n    test_fraction: Optional[float] = 0.2,\n    seed: Optional[int] = 1234,\n    to_pandas_spark: Optional[bool] = True,\n    index_col: Optional[str] = "tmp_index_col"\n) -> Tuple[Union[sparkDataFrame, psDataFrame], Union[sparkDataFrame,\n                                                     psDataFrame]]\n')),(0,r.yg)("p",null,"Split a pyspark dataframe into train and test dataframes."),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Arguments"),":"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"df")," - pyspark.sql.DataFrame | The input dataframe."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"stratify_column")," - str | The column name to stratify the split. Default None."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"test_fraction")," - float | The fraction of the test data. Default 0.2."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"seed")," - int | The random seed. Default 1234."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"to_pandas_spark")," - bool | Whether to convert the output to pandas_on_spark. Default True."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"index_col")," - str | The column name to use as index. Default None.")),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Returns"),":"),(0,r.yg)("p",null,"  pyspark.sql.DataFrame/pandas_on_spark DataFrame | The train dataframe.\npyspark.sql.DataFrame/pandas_on_spark DataFrame | The test dataframe."),(0,r.yg)("h4",{id:"unique_pandas_on_spark"},"unique","_","pandas","_","on","_","spark"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},"def unique_pandas_on_spark(\n        psds: Union[psSeries, psDataFrame]) -> Tuple[np.ndarray, np.ndarray]\n")),(0,r.yg)("p",null,"Get the unique values and counts of a pandas_on_spark series."),(0,r.yg)("h4",{id:"len_labels"},"len","_","labels"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},"def len_labels(y: Union[psSeries, np.ndarray],\n               return_labels=False) -> Union[int, Optional[np.ndarray]]\n")),(0,r.yg)("p",null,"Get the number of unique labels in y."),(0,r.yg)("h4",{id:"unique_value_first_index"},"unique","_","value","_","first","_","index"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},"def unique_value_first_index(\n        y: Union[Series, psSeries,\n                 np.ndarray]) -> Tuple[np.ndarray, np.ndarray]\n")),(0,r.yg)("p",null,"Get the unique values and indices of a pandas series,\npandas_on_spark series or numpy array."),(0,r.yg)("h4",{id:"iloc_pandas_on_spark"},"iloc","_","pandas","_","on","_","spark"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'def iloc_pandas_on_spark(\n    psdf: Union[psDataFrame, psSeries, DataFrame, Series],\n    index: Union[int, slice, list],\n    index_col: Optional[str] = "tmp_index_col"\n) -> Union[psDataFrame, psSeries]\n')),(0,r.yg)("p",null,"Get the rows of a pandas_on_spark dataframe/series by index."),(0,r.yg)("h4",{id:"spark_kfold"},"spark","_","kFold"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'def spark_kFold(\n    dataset: Union[sparkDataFrame, psDataFrame],\n    nFolds: int = 3,\n    foldCol: str = "",\n    seed: int = 42,\n    index_col: Optional[str] = "tmp_index_col"\n) -> List[Tuple[psDataFrame, psDataFrame]]\n')),(0,r.yg)("p",null,"Generate k-fold splits for a Spark DataFrame.\nAdopted from ",(0,r.yg)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/api/python/_modules/pyspark/ml/tuning.html#CrossValidator"},"https://spark.apache.org/docs/latest/api/python/_modules/pyspark/ml/tuning.html#CrossValidator")),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Arguments"),":"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"dataset")," - sparkDataFrame / psDataFrame. | The DataFrame to split."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"nFolds")," - int | The number of folds. Default is 3."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"foldCol"),' - str | The column name to use for fold numbers. If not specified,\nthe DataFrame will be randomly split. Default is "".\nThe same group will not appear in two different folds (the number of\ndistinct groups has to be at least equal to the number of folds).\nThe folds are approximately balanced in the sense that the number of\ndistinct groups is approximately the same in each fold.'),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"seed")," - int | The random seed. Default is 42."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"index_col"),' - str | The name of the index column. Default is "tmp_index_col".')),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Returns"),":"),(0,r.yg)("p",null,"  A list of (train, validation) DataFrames."))}d.isMDXComponent=!0}}]);