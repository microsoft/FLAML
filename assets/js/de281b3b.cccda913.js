"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[3866],{5680(e,a,t){t.d(a,{xA:()=>d,yg:()=>m});var n=t(6540);function r(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function l(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}function o(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?l(Object(t),!0).forEach((function(a){r(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):l(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function i(e,a){if(null==e)return{};var t,n,r=function(e,a){if(null==e)return{};var t,n,r={},l=Object.keys(e);for(n=0;n<l.length;n++)t=l[n],a.indexOf(t)>=0||(r[t]=e[t]);return r}(e,a);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)t=l[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var s=n.createContext({}),p=function(e){var a=n.useContext(s),t=a;return e&&(t="function"==typeof e?e(a):o(o({},a),e)),t},d=function(e){var a=p(e.components);return n.createElement(s.Provider,{value:a},e.children)},u={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},g=n.forwardRef((function(e,a){var t=e.components,r=e.mdxType,l=e.originalType,s=e.parentName,d=i(e,["components","mdxType","originalType","parentName"]),g=p(t),m=r,y=g["".concat(s,".").concat(m)]||g[m]||u[m]||l;return t?n.createElement(y,o(o({ref:a},d),{},{components:t})):n.createElement(y,o({ref:a},d))}));function m(e,a){var t=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var l=t.length,o=new Array(l);o[0]=g;var i={};for(var s in a)hasOwnProperty.call(a,s)&&(i[s]=a[s]);i.originalType=e,i.mdxType="string"==typeof e?e:r,o[1]=i;for(var p=2;p<l;p++)o[p]=t[p];return n.createElement.apply(null,o)}return n.createElement.apply(null,t)}g.displayName="MDXCreateElement"},7355(e,a,t){t.r(a),t.d(a,{contentTitle:()=>o,default:()=>d,frontMatter:()=>l,metadata:()=>i,toc:()=>s});var n=t(8168),r=(t(6540),t(5680));const l={sidebar_label:"data",title:"automl.data"},o=void 0,i={unversionedId:"reference/automl/data",id:"reference/automl/data",isDocsHomePage:!1,title:"automl.data",description:"load\\openml\\dataset",source:"@site/docs/reference/automl/data.md",sourceDirName:"reference/automl",slug:"/reference/automl/data",permalink:"/FLAML/docs/reference/automl/data",editUrl:"https://github.com/microsoft/FLAML/edit/main/website/docs/reference/automl/data.md",tags:[],version:"current",frontMatter:{sidebar_label:"data",title:"automl.data"},sidebar:"referenceSideBar",previous:{title:"automl",permalink:"/FLAML/docs/reference/automl/automl"},next:{title:"logger",permalink:"/FLAML/docs/reference/automl/logger"}},s=[{value:"load_openml_dataset",id:"load_openml_dataset",children:[],level:4},{value:"load_openml_task",id:"load_openml_task",children:[],level:4},{value:"get_output_from_log",id:"get_output_from_log",children:[],level:4},{value:"concat",id:"concat",children:[],level:4},{value:"DataTransformer Objects",id:"datatransformer-objects",children:[{value:"fit_transform",id:"fit_transform",children:[],level:4},{value:"transform",id:"transform",children:[],level:4},{value:"get_random_dataframe",id:"get_random_dataframe",children:[],level:4}],level:2},{value:"Returns",id:"returns",children:[],level:2},{value:"Examples",id:"examples",children:[{value:"auto_convert_dtypes_spark",id:"auto_convert_dtypes_spark",children:[],level:4},{value:"auto_convert_dtypes_pandas",id:"auto_convert_dtypes_pandas",children:[],level:4}],level:2}],p={toc:s};function d(e){let{components:a,...t}=e;return(0,r.yg)("wrapper",(0,n.A)({},p,t,{components:a,mdxType:"MDXLayout"}),(0,r.yg)("h4",{id:"load_openml_dataset"},"load","_","openml","_","dataset"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'def load_openml_dataset(dataset_id,\n                        data_dir=None,\n                        random_state=0,\n                        dataset_format="dataframe")\n')),(0,r.yg)("p",null,"Load dataset from open ML."),(0,r.yg)("p",null,"If the file is not cached locally, download it from open ML."),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Arguments"),":"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"dataset_id")," - An integer of the dataset id in openml."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"data_dir")," - A string of the path to store and load the data."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"random_state")," - An integer of the random seed for splitting data."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"dataset_format")," - A string specifying the format of returned dataset. Default is 'dataframe'.\nCan choose from ","['dataframe', 'array']",".\nIf 'dataframe', the returned dataset will be a Pandas DataFrame.\nIf 'array', the returned dataset will be a NumPy array or a SciPy sparse matrix.")),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Returns"),":"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"X_train")," - Training data."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"X_test")," - Test data."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"y_train")," - A series or array of labels for training data."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"y_test")," - A series or array of labels for test data.")),(0,r.yg)("h4",{id:"load_openml_task"},"load","_","openml","_","task"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},"def load_openml_task(task_id, data_dir)\n")),(0,r.yg)("p",null,"Load task from open ML."),(0,r.yg)("p",null,"Use the first fold of the task.\nIf the file is not cached locally, download it from open ML."),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Arguments"),":"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"task_id")," - An integer of the task id in openml."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"data_dir")," - A string of the path to store and load the data.")),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Returns"),":"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"X_train")," - A dataframe of training data."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"X_test")," - A dataframe of test data."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"y_train")," - A series of labels for training data."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"y_test")," - A series of labels for test data.")),(0,r.yg)("h4",{id:"get_output_from_log"},"get","_","output","_","from","_","log"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},"def get_output_from_log(filename, time_budget)\n")),(0,r.yg)("p",null,"Get output from log file."),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Arguments"),":"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"filename")," - A string of the log file name."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"time_budget")," - A float of the time budget in seconds.")),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Returns"),":"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"search_time_list")," - A list of the finished time of each logged iter."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"best_error_list")," - A list of the best validation error after each logged iter."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"error_list")," - A list of the validation error of each logged iter."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"config_list")," - A list of the estimator, sample size and config of each logged iter."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"logged_metric_list")," - A list of the logged metric of each logged iter.")),(0,r.yg)("h4",{id:"concat"},"concat"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},"def concat(X1, X2)\n")),(0,r.yg)("p",null,"concatenate two matrices vertically."),(0,r.yg)("h2",{id:"datatransformer-objects"},"DataTransformer Objects"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},"class DataTransformer()\n")),(0,r.yg)("p",null,"Transform input training data."),(0,r.yg)("h4",{id:"fit_transform"},"fit","_","transform"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'def fit_transform(X: Union[DataFrame, np.ndarray], y, task: Union[str,\n                                                                  "Task"])\n')),(0,r.yg)("p",null,"Fit transformer and process the input training data according to the task type."),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Arguments"),":"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"X")," - A numpy array or a pandas dataframe of training data."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"y")," - A numpy array or a pandas series of labels."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"task")," - An instance of type Task, or a str such as 'classification', 'regression'.")),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Returns"),":"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"X")," - Processed numpy array or pandas dataframe of training data."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"y")," - Processed numpy array or pandas series of labels.")),(0,r.yg)("h4",{id:"transform"},"transform"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},"def transform(X: Union[DataFrame, np.array])\n")),(0,r.yg)("p",null,"Process data using fit transformer."),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Arguments"),":"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"X")," - A numpy array or a pandas dataframe of training data.")),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Returns"),":"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"X")," - Processed numpy array or pandas dataframe of training data.")),(0,r.yg)("h4",{id:"get_random_dataframe"},"get","_","random","_","dataframe"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},"def get_random_dataframe(n_rows: int = 200,\n                         ratio_none: float = 0.1,\n                         seed: int = 42) -> DataFrame\n")),(0,r.yg)("p",null,"Generate a random pandas DataFrame with various data types for testing.\nThis function creates a DataFrame with multiple column types including:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"Timestamps"),(0,r.yg)("li",{parentName:"ul"},"Integers"),(0,r.yg)("li",{parentName:"ul"},"Floats"),(0,r.yg)("li",{parentName:"ul"},"Categorical values"),(0,r.yg)("li",{parentName:"ul"},"Booleans"),(0,r.yg)("li",{parentName:"ul"},"Lists (tags)"),(0,r.yg)("li",{parentName:"ul"},"Decimal strings"),(0,r.yg)("li",{parentName:"ul"},"UUIDs"),(0,r.yg)("li",{parentName:"ul"},"Binary data (as hex strings)"),(0,r.yg)("li",{parentName:"ul"},"JSON blobs"),(0,r.yg)("li",{parentName:"ul"},"Nullable text fields\nParameters")),(0,r.yg)("hr",null),(0,r.yg)("p",null,"n_rows : int, default=200\nNumber of rows in the generated DataFrame\nratio_none : float, default=0.1\nProbability of generating None values in applicable columns\nseed : int, default=42\nRandom seed for reproducibility"),(0,r.yg)("h2",{id:"returns"},"Returns"),(0,r.yg)("p",null,"pd.DataFrame\nA DataFrame with 14 columns of various data types"),(0,r.yg)("h2",{id:"examples"},"Examples"),(0,r.yg)("blockquote",null,(0,r.yg)("blockquote",{parentName:"blockquote"},(0,r.yg)("blockquote",{parentName:"blockquote"},(0,r.yg)("p",{parentName:"blockquote"},"df = get_random_dataframe(100, 0.05, 123)\ndf.shape\n(100, 14)\ndf.dtypes\ntimestamp       datetime64","[ns]","\nid                       int64\nscore                  float64\nstatus                  object\nflag                    object\ncount                   object\nvalue                   object\ntags                    object\nrating                  object\nuuid                    object\nbinary                  object\njson_blob               object\ncategory              category\nnullable_text           object\ndtype: object")))),(0,r.yg)("h4",{id:"auto_convert_dtypes_spark"},"auto","_","convert","_","dtypes","_","spark"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},"def auto_convert_dtypes_spark(\n        df: psDataFrame,\n        na_values: list = None,\n        category_threshold: float = 0.3,\n        convert_threshold: float = 0.6,\n        sample_ratio: float = 0.1) -> tuple[psDataFrame, dict]\n")),(0,r.yg)("p",null,"Automatically convert data types in a PySpark DataFrame using heuristics."),(0,r.yg)("p",null,"This function analyzes a sample of the DataFrame to infer appropriate data types\nand applies the conversions. It handles timestamps, numeric values, booleans,\nand categorical fields."),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Arguments"),":"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"df")," - A PySpark DataFrame to convert."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"na_values")," - List of strings to be considered as NA/NaN. Defaults to\n","['NA', 'na', 'NULL', 'null', '']","."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"category_threshold")," - Maximum ratio of unique values to total values\nto consider a column categorical. Defaults to 0.3."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"convert_threshold")," - Minimum ratio of successfully converted values required\nto apply a type conversion. Defaults to 0.6."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"sample_ratio")," - Fraction of data to sample for type inference. Defaults to 0.1.")),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Returns"),":"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"tuple")," - (The DataFrame with converted types, A dictionary mapping column names to\ntheir inferred types as strings)")),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Notes"),":"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"'category' in the schema dict is conceptual as PySpark doesn't have a true\ncategory type like pandas"),(0,r.yg)("li",{parentName:"ul"},"The function uses sampling for efficiency with large datasets")),(0,r.yg)("h4",{id:"auto_convert_dtypes_pandas"},"auto","_","convert","_","dtypes","_","pandas"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},"def auto_convert_dtypes_pandas(\n        df: DataFrame,\n        na_values: list = None,\n        category_threshold: float = 0.3,\n        convert_threshold: float = 0.6,\n        sample_ratio: float = 1.0) -> tuple[DataFrame, dict]\n")),(0,r.yg)("p",null,"Automatically convert data types in a pandas DataFrame using heuristics."),(0,r.yg)("p",null,"This function analyzes the DataFrame to infer appropriate data types\nand applies the conversions. It handles timestamps, timedeltas, numeric values,\nand categorical fields."),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Arguments"),":"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"df")," - A pandas DataFrame to convert."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"na_values")," - List of strings to be considered as NA/NaN. Defaults to\n","['NA', 'na', 'NULL', 'null', '']","."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"category_threshold")," - Maximum ratio of unique values to total values\nto consider a column categorical. Defaults to 0.3."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"convert_threshold")," - Minimum ratio of successfully converted values required\nto apply a type conversion. Defaults to 0.6."),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"sample_ratio")," - Fraction of data to sample for type inference. Not used in pandas version\nbut included for API compatibility. Defaults to 1.0.")),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Returns"),":"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"tuple")," - (The DataFrame with converted types, A dictionary mapping column names to\ntheir inferred types as strings)")))}d.isMDXComponent=!0}}]);