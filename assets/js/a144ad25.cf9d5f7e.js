"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[9917],{5680(e,t,n){n.d(t,{xA:()=>g,yg:()=>m});var a=n(6540);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var l=a.createContext({}),c=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},g=function(e){var t=c(e.components);return a.createElement(l.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},p=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,r=e.originalType,l=e.parentName,g=s(e,["components","mdxType","originalType","parentName"]),p=c(n),m=i,d=p["".concat(l,".").concat(m)]||p[m]||u[m]||r;return n?a.createElement(d,o(o({ref:t},g),{},{components:n})):a.createElement(d,o({ref:t},g))}));function m(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=n.length,o=new Array(r);o[0]=p;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:i,o[1]=s;for(var c=2;c<r;c++)o[c]=n[c];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}p.displayName="MDXCreateElement"},902(e,t,n){n.r(t),n.d(t,{contentTitle:()=>o,default:()=>g,frontMatter:()=>r,metadata:()=>s,toc:()=>l});var a=n(8168),i=(n(6540),n(5680));const r={sidebar_label:"assistant_agent",title:"autogen.agentchat.assistant_agent"},o=void 0,s={unversionedId:"reference/autogen/agentchat/assistant_agent",id:"reference/autogen/agentchat/assistant_agent",isDocsHomePage:!1,title:"autogen.agentchat.assistant_agent",description:"AssistantAgent Objects",source:"@site/docs/reference/autogen/agentchat/assistant_agent.md",sourceDirName:"reference/autogen/agentchat",slug:"/reference/autogen/agentchat/assistant_agent",permalink:"/FLAML/docs/reference/autogen/agentchat/assistant_agent",editUrl:"https://github.com/microsoft/FLAML/edit/main/website/docs/reference/autogen/agentchat/assistant_agent.md",tags:[],version:"current",frontMatter:{sidebar_label:"assistant_agent",title:"autogen.agentchat.assistant_agent"},sidebar:"referenceSideBar",previous:{title:"agent",permalink:"/FLAML/docs/reference/autogen/agentchat/agent"},next:{title:"conversable_agent",permalink:"/FLAML/docs/reference/autogen/agentchat/conversable_agent"}},l=[{value:"AssistantAgent Objects",id:"assistantagent-objects",children:[{value:"__init__",id:"__init__",children:[],level:4}],level:2}],c={toc:l};function g(e){let{components:t,...n}=e;return(0,i.yg)("wrapper",(0,a.A)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,i.yg)("h2",{id:"assistantagent-objects"},"AssistantAgent Objects"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-python"},"class AssistantAgent(ConversableAgent)\n")),(0,i.yg)("p",null,"(In preview) Assistant agent, designed to solve tasks with LLM."),(0,i.yg)("p",null,"AssistantAgent is a subclass of ConversableAgent configured with a default system message.\nThe default system message is designed to solve tasks with LLM,\nincluding suggesting Python code blocks and debugging.\n",(0,i.yg)("inlineCode",{parentName:"p"},"human_input_mode"),' defaults to "NEVER"\nand ',(0,i.yg)("inlineCode",{parentName:"p"},"code_execution_config")," defaults to False.\nThis agent doesn't execute code by default and expects the user to execute the code."),(0,i.yg)("h4",{id:"__init__"},"_","_","init","_","_"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-python"},'def __init__(name: str,\n             system_message: Optional[str] = DEFAULT_SYSTEM_MESSAGE,\n             llm_config: Optional[Union[Dict, bool]] = None,\n             is_termination_msg: Optional[Callable[[Dict], bool]] = None,\n             max_consecutive_auto_reply: Optional[int] = None,\n             human_input_mode: Optional[str] = "NEVER",\n             code_execution_config: Optional[Union[Dict, bool]] = False,\n             **kwargs: Dict)\n')),(0,i.yg)("p",null,(0,i.yg)("strong",{parentName:"p"},"Arguments"),":"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"name")," ",(0,i.yg)("em",{parentName:"li"},"str")," - Agent name."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"system_message")," ",(0,i.yg)("em",{parentName:"li"},"Optional","[str]")," - System message for the ChatCompletion inference.\nOverride this attribute if you want to reprogram the agent."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"llm_config")," ",(0,i.yg)("em",{parentName:"li"},"Optional[Union","[Dict, bool]","]")," - LLM inference configuration.\nRefer to ",(0,i.yg)("a",{parentName:"li",href:"/docs/reference/autogen/oai/completion#create"},"autogen.Completion.create"),"\nfor available options."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"is_termination_msg")," ",(0,i.yg)("em",{parentName:"li"},"Optional[Callable[","[Dict]",", bool]]"),' - A function that takes a message in the form of a dictionary\nand returns a boolean value indicating if this received message is a termination message.\nThe dict can contain the following keys: "content", "role", "name", "function_call".'),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"max_consecutive_auto_reply")," ",(0,i.yg)("em",{parentName:"li"},"Optional","[int]"),' - The maximum number of consecutive auto replies.\nDefaults to None (no limit provided, class attribute MAX_CONSECUTIVE_AUTO_REPLY will be used as the limit in this case).\nThe limit only plays a role when human_input_mode is not "ALWAYS".'),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("inlineCode",{parentName:"li"},"**kwargs")," ",(0,i.yg)("em",{parentName:"li"},"Dict")," - Additional keyword arguments. Refer to other kwargs in\n",(0,i.yg)("a",{parentName:"li",href:"conversable_agent#__init__"},"ConversableAgent"),".")))}g.isMDXComponent=!0}}]);