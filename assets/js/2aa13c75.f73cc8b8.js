"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[4848],{5680(e,t,n){n.d(t,{xA:()=>u,yg:()=>c});var r=n(6540);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},i=Object.keys(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=r.createContext({}),p=function(e){var t=r.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},u=function(e){var t=p(e.components);return r.createElement(s.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},g=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),g=p(n),c=a,d=g["".concat(s,".").concat(c)]||g[c]||m[c]||i;return n?r.createElement(d,o(o({ref:t},u),{},{components:n})):r.createElement(d,o({ref:t},u))}));function c(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,o=new Array(i);o[0]=g;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:a,o[1]=l;for(var p=2;p<i;p++)o[p]=n[p];return r.createElement.apply(null,o)}return r.createElement.apply(null,n)}g.displayName="MDXCreateElement"},6741(e,t,n){n.r(t),n.d(t,{contentTitle:()=>o,default:()=>u,frontMatter:()=>i,metadata:()=>l,toc:()=>s});var r=n(8168),a=(n(6540),n(5680));const i={sidebar_label:"retrieve_user_proxy_agent",title:"autogen.agentchat.contrib.retrieve_user_proxy_agent"},o=void 0,l={unversionedId:"reference/autogen/agentchat/contrib/retrieve_user_proxy_agent",id:"reference/autogen/agentchat/contrib/retrieve_user_proxy_agent",isDocsHomePage:!1,title:"autogen.agentchat.contrib.retrieve_user_proxy_agent",description:"RetrieveUserProxyAgent Objects",source:"@site/docs/reference/autogen/agentchat/contrib/retrieve_user_proxy_agent.md",sourceDirName:"reference/autogen/agentchat/contrib",slug:"/reference/autogen/agentchat/contrib/retrieve_user_proxy_agent",permalink:"/FLAML/docs/reference/autogen/agentchat/contrib/retrieve_user_proxy_agent",editUrl:"https://github.com/microsoft/FLAML/edit/main/website/docs/reference/autogen/agentchat/contrib/retrieve_user_proxy_agent.md",tags:[],version:"current",frontMatter:{sidebar_label:"retrieve_user_proxy_agent",title:"autogen.agentchat.contrib.retrieve_user_proxy_agent"},sidebar:"referenceSideBar",previous:{title:"retrieve_assistant_agent",permalink:"/FLAML/docs/reference/autogen/agentchat/contrib/retrieve_assistant_agent"},next:{title:"agent",permalink:"/FLAML/docs/reference/autogen/agentchat/agent"}},s=[{value:"RetrieveUserProxyAgent Objects",id:"retrieveuserproxyagent-objects",children:[{value:"__init__",id:"__init__",children:[],level:4},{value:"generate_init_message",id:"generate_init_message",children:[],level:4}],level:2}],p={toc:s};function u(e){let{components:t,...n}=e;return(0,a.yg)("wrapper",(0,r.A)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("h2",{id:"retrieveuserproxyagent-objects"},"RetrieveUserProxyAgent Objects"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},"class RetrieveUserProxyAgent(UserProxyAgent)\n")),(0,a.yg)("h4",{id:"__init__"},"_","_","init","_","_"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'def __init__(name="RetrieveChatAgent",\n             is_termination_msg: Optional[Callable[\n                 [Dict], bool]] = _is_termination_msg_retrievechat,\n             human_input_mode: Optional[str] = "ALWAYS",\n             retrieve_config: Optional[Dict] = None,\n             **kwargs)\n')),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Arguments"),":"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"name")," ",(0,a.yg)("em",{parentName:"li"},"str")," - name of the agent."),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"human_input_mode")," ",(0,a.yg)("em",{parentName:"li"},"str"),' - whether to ask for human inputs every time a message is received.\nPossible values are "ALWAYS", "TERMINATE", "NEVER".\n(1) When "ALWAYS", the agent prompts for human input every time a message is received.\nUnder this mode, the conversation stops when the human input is "exit",\nor when is_termination_msg is True and there is no human input.\n(2) When "TERMINATE", the agent only prompts for human input only when a termination message is received or\nthe number of auto reply reaches the max_consecutive_auto_reply.\n(3) When "NEVER", the agent will never prompt for human input. Under this mode, the conversation stops\nwhen the number of auto reply reaches the max_consecutive_auto_reply or when is_termination_msg is True.'),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"retrieve_config")," ",(0,a.yg)("em",{parentName:"li"},"dict or None")," - config for the retrieve agent.\nTo use default config, set to None. Otherwise, set to a dictionary with the following keys:",(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},'task (Optional, str): the task of the retrieve chat. Possible values are "code", "qa" and "default". System\nprompt will be different for different tasks. The default value is ',(0,a.yg)("inlineCode",{parentName:"li"},"default"),", which supports both code and qa."),(0,a.yg)("li",{parentName:"ul"},"client (Optional, chromadb.Client): the chromadb client.\nIf key not provided, a default client ",(0,a.yg)("inlineCode",{parentName:"li"},"chromadb.Client()")," will be used."),(0,a.yg)("li",{parentName:"ul"},"docs_path (Optional, str): the path to the docs directory. It can also be the path to a single file,\nor the url to a single file. If key not provided, a default path ",(0,a.yg)("inlineCode",{parentName:"li"},"./docs")," will be used."),(0,a.yg)("li",{parentName:"ul"},"collection_name (Optional, str): the name of the collection.\nIf key not provided, a default name ",(0,a.yg)("inlineCode",{parentName:"li"},"flaml-docs")," will be used."),(0,a.yg)("li",{parentName:"ul"},"model (Optional, str): the model to use for the retrieve chat.\nIf key not provided, a default model ",(0,a.yg)("inlineCode",{parentName:"li"},"gpt-4")," will be used."),(0,a.yg)("li",{parentName:"ul"},"chunk_token_size (Optional, int): the chunk token size for the retrieve chat.\nIf key not provided, a default size ",(0,a.yg)("inlineCode",{parentName:"li"},"max_tokens * 0.4")," will be used."),(0,a.yg)("li",{parentName:"ul"},"context_max_tokens (Optional, int): the context max token size for the retrieve chat.\nIf key not provided, a default size ",(0,a.yg)("inlineCode",{parentName:"li"},"max_tokens * 0.8")," will be used."),(0,a.yg)("li",{parentName:"ul"},'chunk_mode (Optional, str): the chunk mode for the retrieve chat. Possible values are\n"multi_lines" and "one_line". If key not provided, a default mode ',(0,a.yg)("inlineCode",{parentName:"li"},"multi_lines")," will be used."),(0,a.yg)("li",{parentName:"ul"},'must_break_at_empty_line (Optional, bool): chunk will only break at empty line if True. Default is True.\nIf chunk_mode is "one_line", this parameter will be ignored.'),(0,a.yg)("li",{parentName:"ul"},"embedding_model (Optional, str): the embedding model to use for the retrieve chat.\nIf key not provided, a default model ",(0,a.yg)("inlineCode",{parentName:"li"},"all-MiniLM-L6-v2")," will be used. All available models\ncan be found at ",(0,a.yg)("inlineCode",{parentName:"li"},"https://www.sbert.net/docs/pretrained_models.html"),". The default model is a\nfast model. If you want to use a high performance model, ",(0,a.yg)("inlineCode",{parentName:"li"},"all-mpnet-base-v2")," is recommended."),(0,a.yg)("li",{parentName:"ul"},"customized_prompt (Optional, str): the customized prompt for the retrieve chat. Default is None."))),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"**kwargs")," ",(0,a.yg)("em",{parentName:"li"},"dict")," - other kwargs in ",(0,a.yg)("a",{parentName:"li",href:"../user_proxy_agent#__init__"},"UserProxyAgent"),".")),(0,a.yg)("h4",{id:"generate_init_message"},"generate","_","init","_","message"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'def generate_init_message(problem: str,\n                          n_results: int = 20,\n                          search_string: str = "")\n')),(0,a.yg)("p",null,"Generate an initial message with the given problem and prompt."),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Arguments"),":"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"problem")," ",(0,a.yg)("em",{parentName:"li"},"str")," - the problem to be solved."),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"n_results")," ",(0,a.yg)("em",{parentName:"li"},"int")," - the number of results to be retrieved."),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"search_string")," ",(0,a.yg)("em",{parentName:"li"},"str")," - only docs containing this string will be retrieved.")),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Returns"),":"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"str")," - the generated prompt ready to be sent to the assistant agent.")))}u.isMDXComponent=!0}}]);