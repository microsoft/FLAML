"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[9315],{5680:(e,t,a)=>{a.d(t,{xA:()=>p,yg:()=>u});var n=a(6540);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var l=n.createContext({}),m=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},p=function(e){var t=m(e.components);return n.createElement(l.Provider,{value:t},e.children)},g={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},c=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,o=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),c=m(a),u=i,d=c["".concat(l,".").concat(u)]||c[u]||g[u]||o;return a?n.createElement(d,r(r({ref:t},p),{},{components:a})):n.createElement(d,r({ref:t},p))}));function u(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var o=a.length,r=new Array(o);r[0]=c;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:i,r[1]=s;for(var m=2;m<o;m++)r[m]=a[m];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}c.displayName="MDXCreateElement"},6586:(e,t,a)=>{a.r(t),a.d(t,{contentTitle:()=>r,default:()=>p,frontMatter:()=>o,metadata:()=>s,toc:()=>l});var n=a(8168),i=(a(6540),a(5680));const o={},r="Frequently Asked Questions",s={unversionedId:"FAQ",id:"FAQ",isDocsHomePage:!1,title:"Frequently Asked Questions",description:"Guidelines on how to set a hyperparameter search space",source:"@site/docs/FAQ.md",sourceDirName:".",slug:"/FAQ",permalink:"/FLAML/docs/FAQ",editUrl:"https://github.com/microsoft/FLAML/edit/main/website/docs/FAQ.md",tags:[],version:"current",frontMatter:{}},l=[{value:"Guidelines on how to set a hyperparameter search space",id:"guidelines-on-how-to-set-a-hyperparameter-search-space",children:[],level:3},{value:"Guidelines on parallel vs seqential tuning",id:"guidelines-on-parallel-vs-seqential-tuning",children:[],level:3},{value:"Guidelines on creating and tuning a custom estimator",id:"guidelines-on-creating-and-tuning-a-custom-estimator",children:[],level:3},{value:"About <code>low_cost_partial_config</code> in <code>tune</code>.",id:"about-low_cost_partial_config-in-tune",children:[],level:3},{value:"How does FLAML handle missing values?",id:"how-does-flaml-handle-missing-values",children:[],level:3},{value:"How does FLAML handle imbalanced data (unequal distribution of target classes in classification task)?",id:"how-does-flaml-handle-imbalanced-data-unequal-distribution-of-target-classes-in-classification-task",children:[],level:3},{value:"How to interpret model performance? Is it possible for me to visualize feature importance, SHAP values, optimization history?",id:"how-to-interpret-model-performance-is-it-possible-for-me-to-visualize-feature-importance-shap-values-optimization-history",children:[],level:3},{value:"How to resolve out-of-memory error in <code>AutoML.fit()</code>",id:"how-to-resolve-out-of-memory-error-in-automlfit",children:[],level:3},{value:"How to get the best config of an estimator and use it to train the original model outside FLAML?",id:"how-to-get-the-best-config-of-an-estimator-and-use-it-to-train-the-original-model-outside-flaml",children:[],level:3},{value:"How to save and load an AutoML object? (<code>pickle</code> / <code>load_pickle</code>)",id:"how-to-save-and-load-an-automl-object-pickle--load_pickle",children:[],level:3},{value:"How to list all available estimators for a task?",id:"how-to-list-all-available-estimators-for-a-task",children:[],level:3},{value:"How to list supported built-in metrics?",id:"how-to-list-supported-built-in-metrics",children:[],level:3}],m={toc:l};function p(e){let{components:t,...a}=e;return(0,i.yg)("wrapper",(0,n.A)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,i.yg)("h1",{id:"frequently-asked-questions"},"Frequently Asked Questions"),(0,i.yg)("h3",{id:"guidelines-on-how-to-set-a-hyperparameter-search-space"},(0,i.yg)("a",{parentName:"h3",href:"Use-Cases/Tune-User-Defined-Function#details-and-guidelines-on-hyperparameter-search-space"},"Guidelines on how to set a hyperparameter search space")),(0,i.yg)("h3",{id:"guidelines-on-parallel-vs-seqential-tuning"},(0,i.yg)("a",{parentName:"h3",href:"Use-Cases/Task-Oriented-AutoML#guidelines-on-parallel-vs-sequential-tuning"},"Guidelines on parallel vs seqential tuning")),(0,i.yg)("h3",{id:"guidelines-on-creating-and-tuning-a-custom-estimator"},(0,i.yg)("a",{parentName:"h3",href:"Use-Cases/Task-Oriented-AutoML#guidelines-on-tuning-a-custom-estimator"},"Guidelines on creating and tuning a custom estimator")),(0,i.yg)("h3",{id:"about-low_cost_partial_config-in-tune"},"About ",(0,i.yg)("inlineCode",{parentName:"h3"},"low_cost_partial_config")," in ",(0,i.yg)("inlineCode",{parentName:"h3"},"tune"),"."),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("p",{parentName:"li"},"Definition and purpose: The ",(0,i.yg)("inlineCode",{parentName:"p"},"low_cost_partial_config")," is a dictionary of subset of the hyperparameter coordinates whose value corresponds to a configuration with known low-cost (i.e., low computation cost for training the corresponding model). The concept of low/high-cost is meaningful in the case where a subset of the hyperparameters to tune directly affects the computation cost for training the model. For example, ",(0,i.yg)("inlineCode",{parentName:"p"},"n_estimators")," and ",(0,i.yg)("inlineCode",{parentName:"p"},"max_leaves")," are known to affect the training cost of tree-based learners. We call this subset of hyperparameters, ",(0,i.yg)("em",{parentName:"p"},"cost-related hyperparameters"),". In such scenarios, if you are aware of low-cost configurations for the cost-related hyperparameters, you are recommended to set them as the ",(0,i.yg)("inlineCode",{parentName:"p"},"low_cost_partial_config"),". Using the tree-based method example again, since we know that small ",(0,i.yg)("inlineCode",{parentName:"p"},"n_estimators")," and ",(0,i.yg)("inlineCode",{parentName:"p"},"max_leaves")," generally correspond to simpler models and thus lower cost, we set ",(0,i.yg)("inlineCode",{parentName:"p"},"{'n_estimators': 4, 'max_leaves': 4}")," as the ",(0,i.yg)("inlineCode",{parentName:"p"},"low_cost_partial_config")," by default (note that ",(0,i.yg)("inlineCode",{parentName:"p"},"4")," is the lower bound of search space for these two hyperparameters), e.g., in ",(0,i.yg)("a",{parentName:"p",href:"https://github.com/microsoft/FLAML/blob/main/flaml/model.py#L215"},"LGBM"),". Configuring ",(0,i.yg)("inlineCode",{parentName:"p"},"low_cost_partial_config")," helps the search algorithms make more cost-efficient choices.\nIn AutoML, the ",(0,i.yg)("inlineCode",{parentName:"p"},"low_cost_init_value")," in ",(0,i.yg)("inlineCode",{parentName:"p"},"search_space()")," function for each estimator serves the same role.")),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("p",{parentName:"li"},"Usage in practice: It is recommended to configure it if there are cost-related hyperparameters in your tuning task and you happen to know the low-cost values for them, but it is not required (It is fine to leave it the default value, i.e., ",(0,i.yg)("inlineCode",{parentName:"p"},"None"),").")),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("p",{parentName:"li"},"How does it work: ",(0,i.yg)("inlineCode",{parentName:"p"},"low_cost_partial_config")," if configured, will be used as an initial point of the search. It also affects the search trajectory. For more details about how does it play a role in the search algorithms, please refer to the papers about the search algorithms used: Section 2 of ",(0,i.yg)("a",{parentName:"p",href:"https://arxiv.org/pdf/2005.01571.pdf"},"Frugal Optimization for Cost-related Hyperparameters (CFO)")," and Section 3 of ",(0,i.yg)("a",{parentName:"p",href:"https://openreview.net/pdf?id=VbLH04pRA3"},"Economical Hyperparameter Optimization with Blended Search Strategy (BlendSearch)"),"."))),(0,i.yg)("h3",{id:"how-does-flaml-handle-missing-values"},"How does FLAML handle missing values?"),(0,i.yg)("p",null,"FLAML automatically preprocesses missing values in the input data through its ",(0,i.yg)("inlineCode",{parentName:"p"},"DataTransformer")," class (for classification/regression tasks) and ",(0,i.yg)("inlineCode",{parentName:"p"},"DataTransformerTS")," class (for time series tasks). The preprocessing behavior differs based on the column type:"),(0,i.yg)("p",null,(0,i.yg)("strong",{parentName:"p"},"Automatic Missing Value Preprocessing:")),(0,i.yg)("p",null,"FLAML performs the following preprocessing automatically when you call ",(0,i.yg)("inlineCode",{parentName:"p"},"AutoML.fit()"),":"),(0,i.yg)("ol",null,(0,i.yg)("li",{parentName:"ol"},(0,i.yg)("p",{parentName:"li"},(0,i.yg)("strong",{parentName:"p"},"Numerical/Continuous Columns"),": Missing values (NaN) in numerical columns are imputed using ",(0,i.yg)("inlineCode",{parentName:"p"},"sklearn.impute.SimpleImputer")," with the ",(0,i.yg)("strong",{parentName:"p"},"median strategy"),". This preprocessing is applied in the ",(0,i.yg)("inlineCode",{parentName:"p"},"DataTransformer.fit_transform()")," method (see ",(0,i.yg)("inlineCode",{parentName:"p"},"flaml/automl/data.py")," lines 357-369 and ",(0,i.yg)("inlineCode",{parentName:"p"},"flaml/automl/time_series/ts_data.py")," lines 429-440).")),(0,i.yg)("li",{parentName:"ol"},(0,i.yg)("p",{parentName:"li"},(0,i.yg)("strong",{parentName:"p"},"Categorical Columns"),": Missing values in categorical columns (object, category, or string dtypes) are filled with a special placeholder value ",(0,i.yg)("inlineCode",{parentName:"p"},'"__NAN__"'),", which is treated as a distinct category."))),(0,i.yg)("p",null,(0,i.yg)("strong",{parentName:"p"},"Example of automatic preprocessing:")),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-python"},'from flaml import AutoML\nimport pandas as pd\nimport numpy as np\n\n# Data with missing values\nX_train = pd.DataFrame(\n    {\n        "num_feature": [1.0, 2.0, np.nan, 4.0, 5.0],\n        "cat_feature": ["A", "B", None, "A", "B"],\n    }\n)\ny_train = [0, 1, 0, 1, 0]\n\n# FLAML automatically handles missing values\nautoml = AutoML()\nautoml.fit(X_train, y_train, task="classification", time_budget=60)\n# Numerical NaNs are imputed with median, categorical None becomes "__NAN__"\n')),(0,i.yg)("p",null,(0,i.yg)("strong",{parentName:"p"},"Estimator-Specific Native Handling:")),(0,i.yg)("p",null,"After FLAML's preprocessing, some estimators have additional native missing value handling capabilities:"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("strong",{parentName:"li"},(0,i.yg)("inlineCode",{parentName:"strong"},"lgbm"))," (LightGBM): After preprocessing, can still handle any remaining NaN values natively by learning optimal split directions."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("strong",{parentName:"li"},(0,i.yg)("inlineCode",{parentName:"strong"},"xgboost"))," (XGBoost): After preprocessing, can handle remaining NaN values by learning the best direction during training."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("strong",{parentName:"li"},(0,i.yg)("inlineCode",{parentName:"strong"},"xgb_limitdepth"))," (XGBoost with depth limit): Same as ",(0,i.yg)("inlineCode",{parentName:"li"},"xgboost"),"."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("strong",{parentName:"li"},(0,i.yg)("inlineCode",{parentName:"strong"},"catboost"))," (CatBoost): After preprocessing, has additional sophisticated missing value handling strategies. See ",(0,i.yg)("a",{parentName:"li",href:"https://catboost.ai/en/docs/concepts/algorithm-missing-values-processing"},"CatBoost documentation"),"."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("strong",{parentName:"li"},(0,i.yg)("inlineCode",{parentName:"strong"},"histgb"))," (HistGradientBoosting): After preprocessing, can still handle NaN values natively.")),(0,i.yg)("p",null,(0,i.yg)("strong",{parentName:"p"},"Estimators that rely on preprocessing:")),(0,i.yg)("p",null,"These estimators rely on FLAML's automatic preprocessing since they cannot handle missing values directly:"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("strong",{parentName:"li"},(0,i.yg)("inlineCode",{parentName:"strong"},"rf"))," (RandomForest): Requires preprocessing (automatically done by FLAML)."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("strong",{parentName:"li"},(0,i.yg)("inlineCode",{parentName:"strong"},"extra_tree"))," (ExtraTrees): Requires preprocessing (automatically done by FLAML)."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("strong",{parentName:"li"},(0,i.yg)("inlineCode",{parentName:"strong"},"lrl1")),", ",(0,i.yg)("strong",{parentName:"li"},(0,i.yg)("inlineCode",{parentName:"strong"},"lrl2"))," (LogisticRegression): Require preprocessing (automatically done by FLAML)."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("strong",{parentName:"li"},(0,i.yg)("inlineCode",{parentName:"strong"},"kneighbor"))," (KNeighbors): Requires preprocessing (automatically done by FLAML)."),(0,i.yg)("li",{parentName:"ul"},(0,i.yg)("strong",{parentName:"li"},(0,i.yg)("inlineCode",{parentName:"strong"},"sgd"))," (SGDClassifier/Regressor): Require preprocessing (automatically done by FLAML).")),(0,i.yg)("p",null,(0,i.yg)("strong",{parentName:"p"},"Advanced: Customizing Missing Value Handling")),(0,i.yg)("p",null,"In most cases, FLAML's automatic preprocessing (median imputation for numerical, \"",(0,i.yg)("strong",{parentName:"p"},"NAN"),'" for categorical) works well. However, if you need custom preprocessing:'),(0,i.yg)("ol",null,(0,i.yg)("li",{parentName:"ol"},(0,i.yg)("strong",{parentName:"li"},"Skip automatic preprocessing")," using the ",(0,i.yg)("inlineCode",{parentName:"li"},"skip_transform")," parameter:")),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-python"},'from flaml import AutoML\nfrom sklearn.impute import SimpleImputer\nimport numpy as np\n\n# Custom preprocessing with different strategy\nimputer = SimpleImputer(strategy="mean")  # Use mean instead of median\nX_train_preprocessed = imputer.fit_transform(X_train)\nX_test_preprocessed = imputer.transform(X_test)\n\n# Skip FLAML\'s automatic preprocessing\nautoml = AutoML()\nautoml.fit(\n    X_train_preprocessed,\n    y_train,\n    task="classification",\n    time_budget=60,\n    skip_transform=True,  # Skip automatic preprocessing\n)\n')),(0,i.yg)("ol",{start:2},(0,i.yg)("li",{parentName:"ol"},(0,i.yg)("strong",{parentName:"li"},"Use sklearn Pipeline")," for integrated custom preprocessing:")),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-python"},'from flaml import AutoML\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer, KNNImputer\n\n# Custom pipeline with KNN imputation\npipeline = Pipeline(\n    [\n        ("imputer", KNNImputer(n_neighbors=5)),  # Custom imputation strategy\n        ("automl", AutoML()),\n    ]\n)\n\npipeline.fit(X_train, y_train)\n')),(0,i.yg)("p",null,(0,i.yg)("strong",{parentName:"p"},"Note on time series forecasting"),": For time series tasks (",(0,i.yg)("inlineCode",{parentName:"p"},"ts_forecast"),", ",(0,i.yg)("inlineCode",{parentName:"p"},"ts_forecast_panel"),"), the ",(0,i.yg)("inlineCode",{parentName:"p"},"DataTransformerTS"),' class applies the same preprocessing approach (median imputation for numerical columns, "',(0,i.yg)("strong",{parentName:"p"},"NAN"),'" for categorical). Missing values handling in the time dimension may require additional consideration depending on your specific forecasting model.'),(0,i.yg)("h3",{id:"how-does-flaml-handle-imbalanced-data-unequal-distribution-of-target-classes-in-classification-task"},"How does FLAML handle imbalanced data (unequal distribution of target classes in classification task)?"),(0,i.yg)("p",null,"Currently FLAML does several things for imbalanced data."),(0,i.yg)("ol",null,(0,i.yg)("li",{parentName:"ol"},"When a class contains fewer than 20 examples, we repeatedly add these examples to the training data until the count is at least 20."),(0,i.yg)("li",{parentName:"ol"},"We use stratified sampling when doing holdout and kf."),(0,i.yg)("li",{parentName:"ol"},"We make sure no class is empty in both training and holdout data."),(0,i.yg)("li",{parentName:"ol"},"We allow users to pass ",(0,i.yg)("inlineCode",{parentName:"li"},"sample_weight")," to ",(0,i.yg)("inlineCode",{parentName:"li"},"AutoML.fit()"),"."),(0,i.yg)("li",{parentName:"ol"},"User can customize the weight of each class by setting the ",(0,i.yg)("inlineCode",{parentName:"li"},"custom_hp")," or ",(0,i.yg)("inlineCode",{parentName:"li"},"fit_kwargs_by_estimator")," arguments. For example, the following code sets the weight for pos vs. neg as 2:1 for the RandomForest estimator:")),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-python"},'from flaml import AutoML\nfrom sklearn.datasets import load_iris\n\nX_train, y_train = load_iris(return_X_y=True)\nautoml = AutoML()\nautoml_settings = {\n    "time_budget": 2,\n    "task": "classification",\n    "log_file_name": "test/iris.log",\n    "estimator_list": ["rf", "xgboost"],\n}\n\nautoml_settings["custom_hp"] = {\n    "xgboost": {\n        "scale_pos_weight": {\n            "domain": 0.5,\n            "init_value": 0.5,\n        }\n    },\n    "rf": {"class_weight": {"domain": "balanced", "init_value": "balanced"}},\n}\nprint(automl.model)\n')),(0,i.yg)("h3",{id:"how-to-interpret-model-performance-is-it-possible-for-me-to-visualize-feature-importance-shap-values-optimization-history"},"How to interpret model performance? Is it possible for me to visualize feature importance, SHAP values, optimization history?"),(0,i.yg)("p",null,"You can use ",(0,i.yg)("inlineCode",{parentName:"p"},"automl.model.estimator.feature_importances_")," to get the ",(0,i.yg)("inlineCode",{parentName:"p"},"feature_importances_")," for the best model found by automl. See an ",(0,i.yg)("a",{parentName:"p",href:"Examples/AutoML-for-XGBoost#plot-feature-importance"},"example"),"."),(0,i.yg)("p",null,"Packages such as ",(0,i.yg)("inlineCode",{parentName:"p"},"azureml-interpret")," and ",(0,i.yg)("inlineCode",{parentName:"p"},"sklearn.inspection.permutation_importance")," can be used on ",(0,i.yg)("inlineCode",{parentName:"p"},"automl.model.estimator")," to explain the selected model.\nModel explanation is frequently asked and adding a native support may be a good feature. Suggestions/contributions are welcome."),(0,i.yg)("p",null,"Optimization history can be checked from the ",(0,i.yg)("a",{parentName:"p",href:"Use-Cases/Task-Oriented-AutoML#log-the-trials"},"log"),". You can also ",(0,i.yg)("a",{parentName:"p",href:"Use-Cases/Task-Oriented-AutoML#plot-learning-curve"},"retrieve the log and plot the learning curve"),"."),(0,i.yg)("h3",{id:"how-to-resolve-out-of-memory-error-in-automlfit"},"How to resolve out-of-memory error in ",(0,i.yg)("inlineCode",{parentName:"h3"},"AutoML.fit()")),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},"Set ",(0,i.yg)("inlineCode",{parentName:"li"},"free_mem_ratio")," a float between 0 and 1. For example, 0.2 means try to keep free memory above 20% of total memory. Training may be early stopped for memory consumption reason when this is set."),(0,i.yg)("li",{parentName:"ul"},"Set ",(0,i.yg)("inlineCode",{parentName:"li"},"model_history")," False."),(0,i.yg)("li",{parentName:"ul"},"If your data are already preprocessed, set ",(0,i.yg)("inlineCode",{parentName:"li"},"skip_transform")," False. If you can preprocess the data before the fit starts, this setting can save memory needed for preprocessing in ",(0,i.yg)("inlineCode",{parentName:"li"},"fit"),"."),(0,i.yg)("li",{parentName:"ul"},"If the OOM error only happens for some particular trials:",(0,i.yg)("ul",{parentName:"li"},(0,i.yg)("li",{parentName:"ul"},"set ",(0,i.yg)("inlineCode",{parentName:"li"},"use_ray")," True. This will increase the overhead per trial but can keep the AutoML process running when a single trial fails due to OOM error."),(0,i.yg)("li",{parentName:"ul"},"provide a more accurate ",(0,i.yg)("a",{parentName:"li",href:"reference/automl/model#size"},(0,i.yg)("inlineCode",{parentName:"a"},"size"))," function for the memory bytes consumption of each config for the estimator causing this error."),(0,i.yg)("li",{parentName:"ul"},"modify the ",(0,i.yg)("a",{parentName:"li",href:"Use-Cases/Task-Oriented-AutoML#a-shortcut-to-override-the-search-space"},"search space")," for the estimators causing this error."),(0,i.yg)("li",{parentName:"ul"},"or remove this estimator from the ",(0,i.yg)("inlineCode",{parentName:"li"},"estimator_list"),"."))),(0,i.yg)("li",{parentName:"ul"},"If the OOM error happens when ensembling, consider disabling ensemble, or use a cheaper ensemble option. (",(0,i.yg)("a",{parentName:"li",href:"Use-Cases/Task-Oriented-AutoML#ensemble"},"Example"),").")),(0,i.yg)("h3",{id:"how-to-get-the-best-config-of-an-estimator-and-use-it-to-train-the-original-model-outside-flaml"},"How to get the best config of an estimator and use it to train the original model outside FLAML?"),(0,i.yg)("p",null,"When you finished training an AutoML estimator, you may want to use it in other code w/o depending on FLAML. The ",(0,i.yg)("inlineCode",{parentName:"p"},"automl.best_config")," contains FLAML's search space parameters, which may differ from the original model's parameters (e.g., FLAML uses ",(0,i.yg)("inlineCode",{parentName:"p"},"log_max_bin")," for LightGBM instead of ",(0,i.yg)("inlineCode",{parentName:"p"},"max_bin"),"). You need to convert them using the ",(0,i.yg)("inlineCode",{parentName:"p"},"config2params()")," method."),(0,i.yg)("p",null,(0,i.yg)("strong",{parentName:"p"},"Method 1: Using the trained model instance")),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-python"},"from flaml import AutoML\nfrom sklearn.datasets import load_iris\n\nX, y = load_iris(return_X_y=True)\nsettings = {\"time_budget\": 3}\nautoml = AutoML(**settings)\nautoml.fit(X, y)\n\nprint(f\"{automl.best_estimator=}\")\nprint(f\"{automl.best_config=}\")\n# Example: {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20,\n#           'learning_rate': 0.1, 'log_max_bin': 8, ...}\n\n# Convert to original model parameters\nbest_params = automl.model.config2params(automl.best_config)\nprint(f\"params for best estimator: {best_params}\")\n# Example: {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20,\n#           'learning_rate': 0.1, 'max_bin': 255, ...}  # log_max_bin -> max_bin\n")),(0,i.yg)("p",null,(0,i.yg)("strong",{parentName:"p"},"Method 2: Using FLAML estimator classes directly")),(0,i.yg)("p",null,"If the automl instance is not accessible and you only have the ",(0,i.yg)("inlineCode",{parentName:"p"},"best_config"),", you can convert it with below code:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-python"},'from flaml.automl.model import LGBMEstimator\n\nbest_config = {\n    "n_estimators": 4,\n    "num_leaves": 4,\n    "min_child_samples": 20,\n    "learning_rate": 0.1,\n    "log_max_bin": 8,  # FLAML-specific parameter\n    "colsample_bytree": 1.0,\n    "reg_alpha": 0.0009765625,\n    "reg_lambda": 1.0,\n}\n\n# Create FLAML estimator - this automatically converts parameters\nflaml_estimator = LGBMEstimator(task="classification", **best_config)\nbest_params = flaml_estimator.params  # Converted params ready for original model\nprint(f"Converted params: {best_params}")\n# Example: {\'n_estimators\': 4, \'num_leaves\': 4, \'min_child_samples\': 20,\n#           \'learning_rate\': 0.1, \'max_bin\': 255, \'verbose\': -1, ...}\n')),(0,i.yg)("p",null,(0,i.yg)("strong",{parentName:"p"},"Method 3: Using task_factory (for any estimator type)")),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-python"},'from flaml.automl.task.factory import task_factory\n\ntask = "classification"\nbest_estimator = "rf"\nbest_config = {\n    "n_estimators": 15,\n    "max_features": 0.35807183923834934,\n    "max_leaves": 12,\n    "criterion": "gini",\n}\n\nmodel_class = task_factory(task).estimator_class_from_str(best_estimator)(task=task)\nbest_params = model_class.config2params(best_config)\n')),(0,i.yg)("p",null,"Then you can use it to train the sklearn/lightgbm/xgboost estimators directly:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-python"},"from lightgbm import LGBMClassifier\n\n# Using LightGBM directly with converted parameters\nmodel = LGBMClassifier(**best_params)\nmodel.fit(X, y)\n")),(0,i.yg)("p",null,(0,i.yg)("strong",{parentName:"p"},"Using best_config_per_estimator for multiple estimators")),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-python"},'from flaml import AutoML\nfrom flaml.automl.model import LGBMEstimator, XGBoostEstimator\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\n\nautoml = AutoML()\nautoml.fit(\n    X, y, task="classification", time_budget=30, estimator_list=["lgbm", "xgboost"]\n)\n\n# Get configs for all estimators\nconfigs = automl.best_config_per_estimator\n# Example: {\'lgbm\': {\'n_estimators\': 4, \'log_max_bin\': 8, ...},\n#           \'xgboost\': {\'n_estimators\': 4, \'max_leaves\': 4, ...}}\n\n# Convert and use LightGBM config\nif configs.get("lgbm"):\n    lgbm_config = configs["lgbm"].copy()\n    lgbm_config.pop("FLAML_sample_size", None)  # Remove FLAML internal param if present\n    flaml_lgbm = LGBMEstimator(task="classification", **lgbm_config)\n    lgbm_model = LGBMClassifier(**flaml_lgbm.params)\n    lgbm_model.fit(X, y)\n\n# Convert and use XGBoost config\nif configs.get("xgboost"):\n    xgb_config = configs["xgboost"].copy()\n    xgb_config.pop("FLAML_sample_size", None)  # Remove FLAML internal param if present\n    flaml_xgb = XGBoostEstimator(task="classification", **xgb_config)\n    xgb_model = XGBClassifier(**flaml_xgb.params)\n    xgb_model.fit(X, y)\n')),(0,i.yg)("h3",{id:"how-to-save-and-load-an-automl-object-pickle--load_pickle"},"How to save and load an AutoML object? (",(0,i.yg)("inlineCode",{parentName:"h3"},"pickle")," / ",(0,i.yg)("inlineCode",{parentName:"h3"},"load_pickle"),")"),(0,i.yg)("p",null,"FLAML provides ",(0,i.yg)("inlineCode",{parentName:"p"},"AutoML.pickle()")," / ",(0,i.yg)("inlineCode",{parentName:"p"},"AutoML.load_pickle()")," as a convenient and robust way to persist an AutoML run."),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-python"},'from flaml import AutoML\n\nautoml = AutoML()\nautoml.fit(X_train, y_train, task="classification", time_budget=60)\n\n# Save\nautoml.pickle("automl.pkl")\n\n# Load\nautoml_loaded = AutoML.load_pickle("automl.pkl")\npred = automl_loaded.predict(X_test)\n')),(0,i.yg)("p",null,"Notes:"),(0,i.yg)("ul",null,(0,i.yg)("li",{parentName:"ul"},"If you used Spark estimators, ",(0,i.yg)("inlineCode",{parentName:"li"},"AutoML.pickle()")," externalizes Spark ML models into an adjacent artifact folder and keeps\nthe pickle itself lightweight."),(0,i.yg)("li",{parentName:"ul"},"If you want to skip re-loading externalized Spark models (e.g., in an environment without Spark), use:")),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-python"},'automl_loaded = AutoML.load_pickle("automl.pkl", load_spark_models=False)\n')),(0,i.yg)("h3",{id:"how-to-list-all-available-estimators-for-a-task"},"How to list all available estimators for a task?"),(0,i.yg)("p",null,"The available estimator set is task-dependent and can vary with optional dependencies. You can list the estimator keys\nthat FLAML currently has registered in your environment:"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-python"},'from flaml.automl.task.factory import task_factory\n\nprint(sorted(task_factory("classification").estimators.keys()))\nprint(sorted(task_factory("regression").estimators.keys()))\nprint(sorted(task_factory("forecast").estimators.keys()))\nprint(sorted(task_factory("rank").estimators.keys()))\n')),(0,i.yg)("h3",{id:"how-to-list-supported-built-in-metrics"},"How to list supported built-in metrics?"),(0,i.yg)("pre",null,(0,i.yg)("code",{parentName:"pre",className:"language-python"},"from flaml import AutoML\n\nautoml = AutoML()\nsklearn_metrics, hf_metrics, spark_metrics = automl.supported_metrics\nprint(sorted(sklearn_metrics))\nprint(sorted(hf_metrics))\nprint(spark_metrics)\n")))}p.isMDXComponent=!0}}]);