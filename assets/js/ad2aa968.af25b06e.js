"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[9971],{5680:(e,t,a)=>{a.d(t,{xA:()=>u,yg:()=>d});var n=a(6540);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=n.createContext({}),c=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},u=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},p=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),p=c(a),d=r,g=p["".concat(l,".").concat(d)]||p[d]||m[d]||o;return a?n.createElement(g,i(i({ref:t},u),{},{components:a})):n.createElement(g,i({ref:t},u))}));function d(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=a.length,i=new Array(o);i[0]=p;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,i[1]=s;for(var c=2;c<o;c++)i[c]=a[c];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}p.displayName="MDXCreateElement"},454:(e,t,a)=>{a.r(t),a.d(t,{contentTitle:()=>i,default:()=>u,frontMatter:()=>o,metadata:()=>s,toc:()=>l});var n=a(8168),r=(a(6540),a(5680));const o={},i="Getting Started",s={unversionedId:"Getting-Started",id:"Getting-Started",isDocsHomePage:!1,title:"Getting Started",description:"FLAML is a lightweight Python library for efficient automation of machine",source:"@site/docs/Getting-Started.md",sourceDirName:".",slug:"/Getting-Started",permalink:"/FLAML/docs/Getting-Started",editUrl:"https://github.com/microsoft/FLAML/edit/main/website/docs/Getting-Started.md",tags:[],version:"current",frontMatter:{},sidebar:"docsSidebar",next:{title:"Installation",permalink:"/FLAML/docs/Installation"}},l=[{value:"Main Features",id:"main-features",children:[],level:3},{value:"Quickstart",id:"quickstart",children:[{value:"Task-oriented AutoML",id:"task-oriented-automl",children:[],level:4},{value:"Tune user-defined function",id:"tune-user-defined-function",children:[],level:4},{value:"Zero-shot AutoML",id:"zero-shot-automl",children:[],level:4}],level:3},{value:"Where to Go Next?",id:"where-to-go-next",children:[],level:3}],c={toc:l};function u(e){let{components:t,...a}=e;return(0,r.yg)("wrapper",(0,n.A)({},c,a,{components:t,mdxType:"MDXLayout"}),(0,r.yg)("h1",{id:"getting-started"},"Getting Started"),(0,r.yg)("p",null,"FLAML is a lightweight Python library for efficient automation of machine\nlearning and AI operations. It automates workflow based on large language models, machine learning models, etc.\nand optimizes their performance."),(0,r.yg)("h3",{id:"main-features"},"Main Features"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"For common machine learning tasks like classification and regression, it quickly finds quality models for user-provided data with low computational resources. It is easy to customize or extend."),(0,r.yg)("li",{parentName:"ul"},"It supports fast and economical automatic tuning, capable of handling large search space with heterogeneous evaluation cost and complex constraints/guidance/early stopping.")),(0,r.yg)("p",null,"FLAML is powered by a series of ",(0,r.yg)("a",{parentName:"p",href:"/docs/Research"},"research studies")," from Microsoft Research and collaborators such as Penn State University, Stevens Institute of Technology, University of Washington, and University of Waterloo."),(0,r.yg)("h3",{id:"quickstart"},"Quickstart"),(0,r.yg)("p",null,"Install FLAML from pip: ",(0,r.yg)("inlineCode",{parentName:"p"},"pip install flaml")," (",(0,r.yg)("strong",{parentName:"p"},"requires Python >= 3.10"),"). Find more options in ",(0,r.yg)("a",{parentName:"p",href:"/docs/Installation"},"Installation"),"."),(0,r.yg)("p",null,"There are several ways of using flaml:"),(0,r.yg)("h4",{id:"task-oriented-automl"},(0,r.yg)("a",{parentName:"h4",href:"/docs/Use-Cases/task-oriented-automl"},"Task-oriented AutoML")),(0,r.yg)("p",null,"With three lines of code, you can start using this economical and fast AutoML engine as a scikit-learn style estimator."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'from flaml import AutoML\n\nautoml = AutoML()\nautoml.fit(X_train, y_train, task="classification", time_budget=60)\n')),(0,r.yg)("p",null,"It automatically tunes the hyperparameters and selects the best model from default learners such as LightGBM, XGBoost, random forest etc. for the specified time budget 60 seconds. ",(0,r.yg)("a",{parentName:"p",href:"/docs/Use-Cases/task-oriented-automl#customize-automlfit"},"Customizing")," the optimization metrics, learners and search spaces etc. is very easy. For example,"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'automl.add_learner("mylgbm", MyLGBMEstimator)\nautoml.fit(\n    X_train,\n    y_train,\n    task="classification",\n    metric=custom_metric,\n    estimator_list=["mylgbm"],\n    time_budget=60,\n)\n')),(0,r.yg)("h4",{id:"tune-user-defined-function"},(0,r.yg)("a",{parentName:"h4",href:"/docs/Use-Cases/Tune-User-Defined-Function"},"Tune user-defined function")),(0,r.yg)("p",null,"You can run generic hyperparameter tuning for a custom function (machine learning or beyond). For example,"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'from flaml import tune\nfrom flaml.automl.model import LGBMEstimator\n\n\ndef train_lgbm(config: dict) -> dict:\n    # convert config dict to lgbm params\n    params = LGBMEstimator(**config).params\n    # train the model\n    train_set = lightgbm.Dataset(csv_file_name)\n    model = lightgbm.train(params, train_set)\n    # evaluate the model\n    pred = model.predict(X_test)\n    mse = mean_squared_error(y_test, pred)\n    # return eval results as a dictionary\n    return {"mse": mse}\n\n\n# load a built-in search space from flaml\nflaml_lgbm_search_space = LGBMEstimator.search_space(X_train.shape)\n# specify the search space as a dict from hp name to domain; you can define your own search space same way\nconfig_search_space = {\n    hp: space["domain"] for hp, space in flaml_lgbm_search_space.items()\n}\n# give guidance about hp values corresponding to low training cost, i.e., {"n_estimators": 4, "num_leaves": 4}\nlow_cost_partial_config = {\n    hp: space["low_cost_init_value"]\n    for hp, space in flaml_lgbm_search_space.items()\n    if "low_cost_init_value" in space\n}\n# run the tuning, minimizing mse, with total time budget 3 seconds\nanalysis = tune.run(\n    train_lgbm,\n    metric="mse",\n    mode="min",\n    config=config_search_space,\n    low_cost_partial_config=low_cost_partial_config,\n    time_budget_s=3,\n    num_samples=-1,\n)\n')),(0,r.yg)("p",null,"Please see this ",(0,r.yg)("a",{parentName:"p",href:"https://github.com/microsoft/FLAML/blob/main/test/tune_example.py"},"script")," for the complete version of the above example."),(0,r.yg)("h4",{id:"zero-shot-automl"},(0,r.yg)("a",{parentName:"h4",href:"/docs/Use-Cases/Zero-Shot-AutoML"},"Zero-shot AutoML")),(0,r.yg)("p",null,"FLAML offers a unique, seamless and effortless way to leverage AutoML for the commonly used classifiers and regressors such as LightGBM and XGBoost. For example, if you are using ",(0,r.yg)("inlineCode",{parentName:"p"},"lightgbm.LGBMClassifier")," as your current learner, all you need to do is to replace ",(0,r.yg)("inlineCode",{parentName:"p"},"from lightgbm import LGBMClassifier")," by:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},"from flaml.default import LGBMClassifier\n")),(0,r.yg)("p",null,"Then, you can use it just like you use the original ",(0,r.yg)("inlineCode",{parentName:"p"},"LGMBClassifier"),". Your other code can remain unchanged. When you call the ",(0,r.yg)("inlineCode",{parentName:"p"},"fit()")," function from ",(0,r.yg)("inlineCode",{parentName:"p"},"flaml.default.LGBMClassifier"),", it will automatically instantiate a good data-dependent hyperparameter configuration for your dataset, which is expected to work better than the default configuration."),(0,r.yg)("h3",{id:"where-to-go-next"},"Where to Go Next?"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"Understand the use cases for ",(0,r.yg)("a",{parentName:"li",href:"/docs/Use-Cases/Task-Oriented-Automl"},"Task-oriented AutoML"),", ",(0,r.yg)("a",{parentName:"li",href:"/docs/Use-Cases/Tune-User-Defined-Function"},"Tune user-defined function")," and ",(0,r.yg)("a",{parentName:"li",href:"/docs/Use-Cases/Zero-Shot-AutoML"},"Zero-shot AutoML"),"."),(0,r.yg)("li",{parentName:"ul"},'Find code examples under "Examples": from ',(0,r.yg)("a",{parentName:"li",href:"/docs/Examples/AutoML-Classification"},"AutoML - Classification")," to ",(0,r.yg)("a",{parentName:"li",href:"/docs/Examples/Tune-PyTorch"},"Tune - PyTorch"),"."),(0,r.yg)("li",{parentName:"ul"},"Learn about ",(0,r.yg)("a",{parentName:"li",href:"/docs/Research"},"research")," around FLAML and check ",(0,r.yg)("a",{parentName:"li",href:"/blog"},"blogposts"),"."),(0,r.yg)("li",{parentName:"ul"},"Apply practical guidance in ",(0,r.yg)("a",{parentName:"li",href:"/docs/Best-Practices"},"Best Practices"),"."),(0,r.yg)("li",{parentName:"ul"},"Chat on ",(0,r.yg)("a",{parentName:"li",href:"https://discord.gg/Cppx2vSPVP"},"Discord"),".")),(0,r.yg)("p",null,"If you like our project, please give it a ",(0,r.yg)("a",{parentName:"p",href:"https://github.com/microsoft/FLAML/stargazers"},"star")," on GitHub. If you are interested in contributing, please read ",(0,r.yg)("a",{parentName:"p",href:"/docs/Contribute"},"Contributor's Guide"),"."),(0,r.yg)("iframe",{src:"https://ghbtns.com/github-btn.html?user=microsoft&repo=FLAML&type=star&count=true&size=large",frameborder:"0",scrolling:"0",width:"170",height:"30",title:"GitHub"}))}u.isMDXComponent=!0}}]);