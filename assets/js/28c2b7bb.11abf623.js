"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[3751],{5680:(e,a,t)=>{t.d(a,{xA:()=>p,yg:()=>_});var r=t(6540);function l(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function s(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);a&&(r=r.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,r)}return t}function n(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?s(Object(t),!0).forEach((function(a){l(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):s(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function i(e,a){if(null==e)return{};var t,r,l=function(e,a){if(null==e)return{};var t,r,l={},s=Object.keys(e);for(r=0;r<s.length;r++)t=s[r],a.indexOf(t)>=0||(l[t]=e[t]);return l}(e,a);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(r=0;r<s.length;r++)t=s[r],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(l[t]=e[t])}return l}var o=r.createContext({}),m=function(e){var a=r.useContext(o),t=a;return e&&(t="function"==typeof e?e(a):n(n({},a),e)),t},p=function(e){var a=m(e.components);return r.createElement(o.Provider,{value:a},e.children)},d={inlineCode:"code",wrapper:function(e){var a=e.children;return r.createElement(r.Fragment,{},a)}},u=r.forwardRef((function(e,a){var t=e.components,l=e.mdxType,s=e.originalType,o=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),u=m(t),_=l,c=u["".concat(o,".").concat(_)]||u[_]||d[_]||s;return t?r.createElement(c,n(n({ref:a},p),{},{components:t})):r.createElement(c,n({ref:a},p))}));function _(e,a){var t=arguments,l=a&&a.mdxType;if("string"==typeof e||l){var s=t.length,n=new Array(s);n[0]=u;var i={};for(var o in a)hasOwnProperty.call(a,o)&&(i[o]=a[o]);i.originalType=e,i.mdxType="string"==typeof e?e:l,n[1]=i;for(var m=2;m<s;m++)n[m]=t[m];return r.createElement.apply(null,n)}return r.createElement.apply(null,t)}u.displayName="MDXCreateElement"},4038:(e,a,t)=>{t.r(a),t.d(a,{contentTitle:()=>n,default:()=>p,frontMatter:()=>s,metadata:()=>i,toc:()=>o});var r=t(8168),l=(t(6540),t(5680));const s={},n="Default - Flamlized Estimator",i={unversionedId:"Examples/Default-Flamlized",id:"Examples/Default-Flamlized",isDocsHomePage:!1,title:"Default - Flamlized Estimator",description:'Flamlized estimators automatically use data-dependent default hyperparameter configurations for each estimator, offering a unique zero-shot AutoML capability, or "no tuning" AutoML.',source:"@site/docs/Examples/Default-Flamlized.md",sourceDirName:"Examples",slug:"/Examples/Default-Flamlized",permalink:"/FLAML/docs/Examples/Default-Flamlized",editUrl:"https://github.com/microsoft/FLAML/edit/main/website/docs/Examples/Default-Flamlized.md",tags:[],version:"current",frontMatter:{},sidebar:"docsSidebar",previous:{title:"AutoML for XGBoost",permalink:"/FLAML/docs/Examples/AutoML-for-XGBoost"},next:{title:"Integrate - AzureML",permalink:"/FLAML/docs/Examples/Integrate - AzureML"}},o=[{value:"Flamlized LGBMRegressor",id:"flamlized-lgbmregressor",children:[{value:"Prerequisites",id:"prerequisites",children:[],level:3},{value:"Zero-shot AutoML",id:"zero-shot-automl",children:[{value:"Sample output",id:"sample-output",children:[],level:4}],level:3},{value:"Suggest hyperparameters without training",id:"suggest-hyperparameters-without-training",children:[{value:"Sample output",id:"sample-output-1",children:[],level:4}],level:3}],level:2},{value:"Flamlized LGBMClassifier",id:"flamlized-lgbmclassifier",children:[{value:"Prerequisites",id:"prerequisites-1",children:[],level:3},{value:"Zero-shot AutoML",id:"zero-shot-automl-1",children:[{value:"Sample output",id:"sample-output-2",children:[],level:4}],level:3}],level:2},{value:"Flamlized XGBRegressor",id:"flamlized-xgbregressor",children:[{value:"Prerequisites",id:"prerequisites-2",children:[],level:3},{value:"Zero-shot AutoML",id:"zero-shot-automl-2",children:[{value:"Sample output",id:"sample-output-3",children:[],level:4}],level:3}],level:2},{value:"Flamlized XGBClassifier",id:"flamlized-xgbclassifier",children:[{value:"Prerequisites",id:"prerequisites-3",children:[],level:3},{value:"Zero-shot AutoML",id:"zero-shot-automl-3",children:[{value:"Sample output",id:"sample-output-4",children:[],level:4}],level:3}],level:2},{value:"Flamlized RandomForestRegressor",id:"flamlized-randomforestregressor",children:[{value:"Prerequisites",id:"prerequisites-4",children:[],level:3},{value:"Zero-shot AutoML",id:"zero-shot-automl-4",children:[{value:"Sample output",id:"sample-output-5",children:[],level:4}],level:3}],level:2},{value:"Flamlized RandomForestClassifier",id:"flamlized-randomforestclassifier",children:[{value:"Prerequisites",id:"prerequisites-5",children:[],level:3},{value:"Zero-shot AutoML",id:"zero-shot-automl-5",children:[{value:"Sample output",id:"sample-output-6",children:[],level:4}],level:3}],level:2},{value:"Flamlized ExtraTreesRegressor",id:"flamlized-extratreesregressor",children:[{value:"Prerequisites",id:"prerequisites-6",children:[],level:3},{value:"Zero-shot AutoML",id:"zero-shot-automl-6",children:[{value:"Sample output",id:"sample-output-7",children:[],level:4}],level:3}],level:2},{value:"Flamlized ExtraTreesClassifier",id:"flamlized-extratreesclassifier",children:[{value:"Prerequisites",id:"prerequisites-7",children:[],level:3},{value:"Zero-shot AutoML",id:"zero-shot-automl-7",children:[{value:"Sample output",id:"sample-output-8",children:[],level:4}],level:3}],level:2}],m={toc:o};function p(e){let{components:a,...t}=e;return(0,l.yg)("wrapper",(0,r.A)({},m,t,{components:a,mdxType:"MDXLayout"}),(0,l.yg)("h1",{id:"default---flamlized-estimator"},"Default - Flamlized Estimator"),(0,l.yg)("p",null,'Flamlized estimators automatically use data-dependent default hyperparameter configurations for each estimator, offering a unique zero-shot AutoML capability, or "no tuning" AutoML.'),(0,l.yg)("h2",{id:"flamlized-lgbmregressor"},"Flamlized LGBMRegressor"),(0,l.yg)("h3",{id:"prerequisites"},"Prerequisites"),(0,l.yg)("p",null,"This example requires the ","[autozero]"," option."),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-bash"},"pip install flaml[autozero] lightgbm openml\n")),(0,l.yg)("h3",{id:"zero-shot-automl"},"Zero-shot AutoML"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-python"},'from flaml.automl.data import load_openml_dataset\nfrom flaml.default import LGBMRegressor\nfrom flaml.automl.ml import sklearn_metric_loss_score\n\nX_train, X_test, y_train, y_test = load_openml_dataset(dataset_id=537, data_dir="./")\nlgbm = LGBMRegressor()\nlgbm.fit(X_train, y_train)\ny_pred = lgbm.predict(X_test)\nprint("flamlized lgbm r2", "=", 1 - sklearn_metric_loss_score("r2", y_pred, y_test))\nprint(lgbm)\n')),(0,l.yg)("h4",{id:"sample-output"},"Sample output"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre"},"load dataset from ./openml_ds537.pkl\nDataset name: houses\nX_train.shape: (15480, 8), y_train.shape: (15480,);\nX_test.shape: (5160, 8), y_test.shape: (5160,)\nflamlized lgbm r2 = 0.8537444671194614\nLGBMRegressor(colsample_bytree=0.7019911744574896,\n              learning_rate=0.022635758411078528, max_bin=511,\n              min_child_samples=2, n_estimators=4797, num_leaves=122,\n              reg_alpha=0.004252223402511765, reg_lambda=0.11288241427227624,\n              verbose=-1)\n")),(0,l.yg)("h3",{id:"suggest-hyperparameters-without-training"},"Suggest hyperparameters without training"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre"},'from flaml.automl.data import load_openml_dataset\nfrom flaml.default import LGBMRegressor\nfrom flaml.ml import sklearn_metric_loss_score\n\nX_train, X_test, y_train, y_test = load_openml_dataset(dataset_id=537, data_dir="./")\nlgbm = LGBMRegressor()\nhyperparams, estimator_name, X_transformed, y_transformed = lgbm.suggest_hyperparams(X_train, y_train)\nprint(hyperparams)\n')),(0,l.yg)("h4",{id:"sample-output-1"},"Sample output"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre"},"load dataset from ./openml_ds537.pkl\nDataset name: houses\nX_train.shape: (15480, 8), y_train.shape: (15480,);\nX_test.shape: (5160, 8), y_test.shape: (5160,)\n{'n_estimators': 4797, 'num_leaves': 122, 'min_child_samples': 2, 'learning_rate': 0.022635758411078528, 'colsample_bytree': 0.7019911744574896, 'reg_alpha': 0.004252223402511765, 'reg_lambda': 0.11288241427227624, 'max_bin': 511, 'verbose': -1}\n")),(0,l.yg)("p",null,(0,l.yg)("a",{parentName:"p",href:"https://github.com/microsoft/FLAML/blob/main/notebook/zeroshot_lightgbm.ipynb"},"Link to notebook")," | ",(0,l.yg)("a",{parentName:"p",href:"https://colab.research.google.com/github/microsoft/FLAML/blob/main/notebook/zeroshot_lightgbm.ipynb"},"Open in colab")),(0,l.yg)("h2",{id:"flamlized-lgbmclassifier"},"Flamlized LGBMClassifier"),(0,l.yg)("h3",{id:"prerequisites-1"},"Prerequisites"),(0,l.yg)("p",null,"This example requires the ","[autozero]"," option."),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-bash"},"pip install flaml[autozero] lightgbm openml\n")),(0,l.yg)("h3",{id:"zero-shot-automl-1"},"Zero-shot AutoML"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-python"},'from flaml.automl.data import load_openml_dataset\nfrom flaml.default import LGBMClassifier\nfrom flaml.automl.ml import sklearn_metric_loss_score\n\nX_train, X_test, y_train, y_test = load_openml_dataset(dataset_id=1169, data_dir="./")\nlgbm = LGBMClassifier()\nlgbm.fit(X_train, y_train)\ny_pred = lgbm.predict(X_test)\nprint(\n    "flamlized lgbm accuracy",\n    "=",\n    1 - sklearn_metric_loss_score("accuracy", y_pred, y_test),\n)\nprint(lgbm)\n')),(0,l.yg)("h4",{id:"sample-output-2"},"Sample output"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre"},"load dataset from ./openml_ds1169.pkl\nDataset name: airlines\nX_train.shape: (404537, 7), y_train.shape: (404537,);\nX_test.shape: (134846, 7), y_test.shape: (134846,)\nflamlized lgbm accuracy = 0.6745\nLGBMClassifier(colsample_bytree=0.85, learning_rate=0.05, max_bin=255,\n               min_child_samples=20, n_estimators=500, num_leaves=31,\n               reg_alpha=0.01, reg_lambda=0.1, verbose=-1)\n")),(0,l.yg)("h2",{id:"flamlized-xgbregressor"},"Flamlized XGBRegressor"),(0,l.yg)("h3",{id:"prerequisites-2"},"Prerequisites"),(0,l.yg)("p",null,"This example requires xgboost, sklearn, openml==0.10.2."),(0,l.yg)("h3",{id:"zero-shot-automl-2"},"Zero-shot AutoML"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-python"},'from flaml.automl.data import load_openml_dataset\nfrom flaml.default import XGBRegressor\nfrom flaml.automl.ml import sklearn_metric_loss_score\n\nX_train, X_test, y_train, y_test = load_openml_dataset(dataset_id=537, data_dir="./")\nxgb = XGBRegressor()\nxgb.fit(X_train, y_train)\ny_pred = xgb.predict(X_test)\nprint("flamlized xgb r2", "=", 1 - sklearn_metric_loss_score("r2", y_pred, y_test))\nprint(xgb)\n')),(0,l.yg)("h4",{id:"sample-output-3"},"Sample output"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre"},"load dataset from ./openml_ds537.pkl\nDataset name: houses\nX_train.shape: (15480, 8), y_train.shape: (15480,);\nX_test.shape: (5160, 8), y_test.shape: (5160,)\nflamlized xgb r2 = 0.8542\nXGBRegressor(colsample_bylevel=1, colsample_bytree=0.85, learning_rate=0.05,\n             max_depth=6, n_estimators=500, reg_alpha=0.01, reg_lambda=1.0,\n             subsample=0.9)\n")),(0,l.yg)("h2",{id:"flamlized-xgbclassifier"},"Flamlized XGBClassifier"),(0,l.yg)("h3",{id:"prerequisites-3"},"Prerequisites"),(0,l.yg)("p",null,"This example requires xgboost, sklearn, openml==0.10.2."),(0,l.yg)("h3",{id:"zero-shot-automl-3"},"Zero-shot AutoML"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-python"},'from flaml.automl.data import load_openml_dataset\nfrom flaml.default import XGBClassifier\nfrom flaml.automl.ml import sklearn_metric_loss_score\n\nX_train, X_test, y_train, y_test = load_openml_dataset(dataset_id=1169, data_dir="./")\nxgb = XGBClassifier()\nxgb.fit(X_train, y_train)\ny_pred = xgb.predict(X_test)\nprint(\n    "flamlized xgb accuracy",\n    "=",\n    1 - sklearn_metric_loss_score("accuracy", y_pred, y_test),\n)\nprint(xgb)\n')),(0,l.yg)("h4",{id:"sample-output-4"},"Sample output"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre"},"load dataset from ./openml_ds1169.pkl\nDataset name: airlines\nX_train.shape: (404537, 7), y_train.shape: (404537,);\nX_test.shape: (134846, 7), y_test.shape: (134846,)\nflamlized xgb accuracy = 0.6729009388487608\nXGBClassifier(base_score=0.5, booster='gbtree',\n              colsample_bylevel=0.4601573737792679, colsample_bynode=1,\n              colsample_bytree=1.0, gamma=0, gpu_id=-1, grow_policy='lossguide',\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.04039771837785377, max_delta_step=0, max_depth=0,\n              max_leaves=159, min_child_weight=0.3396294979905001, missing=nan,\n              monotone_constraints='()', n_estimators=540, n_jobs=4,\n              num_parallel_tree=1, random_state=0,\n              reg_alpha=0.0012362430984376035, reg_lambda=3.093428791531145,\n              scale_pos_weight=1, subsample=1.0, tree_method='hist',\n              use_label_encoder=False, validate_parameters=1, verbosity=0)\n")),(0,l.yg)("h2",{id:"flamlized-randomforestregressor"},"Flamlized RandomForestRegressor"),(0,l.yg)("h3",{id:"prerequisites-4"},"Prerequisites"),(0,l.yg)("p",null,"This example requires the ","[autozero]"," option."),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-bash"},"pip install flaml[autozero] scikit-learn openml\n")),(0,l.yg)("h3",{id:"zero-shot-automl-4"},"Zero-shot AutoML"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-python"},'from flaml.automl.data import load_openml_dataset\nfrom flaml.default import RandomForestRegressor\nfrom flaml.automl.ml import sklearn_metric_loss_score\n\nX_train, X_test, y_train, y_test = load_openml_dataset(dataset_id=537, data_dir="./")\nrf = RandomForestRegressor()\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)\nprint("flamlized rf r2", "=", 1 - sklearn_metric_loss_score("r2", y_pred, y_test))\nprint(rf)\n')),(0,l.yg)("h4",{id:"sample-output-5"},"Sample output"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre"},"load dataset from ./openml_ds537.pkl\nDataset name: houses\nX_train.shape: (15480, 8), y_train.shape: (15480,);\nX_test.shape: (5160, 8), y_test.shape: (5160,)\nflamlized rf r2 = 0.8521\nRandomForestRegressor(max_features=0.8, min_samples_leaf=2, min_samples_split=5,\n                      n_estimators=500)\n")),(0,l.yg)("h2",{id:"flamlized-randomforestclassifier"},"Flamlized RandomForestClassifier"),(0,l.yg)("h3",{id:"prerequisites-5"},"Prerequisites"),(0,l.yg)("p",null,"This example requires the ","[autozero]"," option."),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-bash"},"pip install flaml[autozero] scikit-learn openml\n")),(0,l.yg)("h3",{id:"zero-shot-automl-5"},"Zero-shot AutoML"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-python"},'from flaml.automl.data import load_openml_dataset\nfrom flaml.default import RandomForestClassifier\nfrom flaml.automl.ml import sklearn_metric_loss_score\n\nX_train, X_test, y_train, y_test = load_openml_dataset(dataset_id=1169, data_dir="./")\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)\nprint(\n    "flamlized rf accuracy",\n    "=",\n    1 - sklearn_metric_loss_score("accuracy", y_pred, y_test),\n)\nprint(rf)\n')),(0,l.yg)("h4",{id:"sample-output-6"},"Sample output"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre"},"load dataset from ./openml_ds1169.pkl\nDataset name: airlines\nX_train.shape: (404537, 7), y_train.shape: (404537,);\nX_test.shape: (134846, 7), y_test.shape: (134846,)\nflamlized rf accuracy = 0.6701\nRandomForestClassifier(max_features=0.7, min_samples_leaf=3, min_samples_split=5,\n                       n_estimators=500)\n")),(0,l.yg)("h2",{id:"flamlized-extratreesregressor"},"Flamlized ExtraTreesRegressor"),(0,l.yg)("h3",{id:"prerequisites-6"},"Prerequisites"),(0,l.yg)("p",null,"This example requires the ","[autozero]"," option."),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-bash"},"pip install flaml[autozero] scikit-learn openml\n")),(0,l.yg)("h3",{id:"zero-shot-automl-6"},"Zero-shot AutoML"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-python"},'from flaml.automl.data import load_openml_dataset\nfrom flaml.default import ExtraTreesRegressor\nfrom flaml.automl.ml import sklearn_metric_loss_score\n\nX_train, X_test, y_train, y_test = load_openml_dataset(dataset_id=537, data_dir="./")\net = ExtraTreesRegressor()\net.fit(X_train, y_train)\ny_pred = et.predict(X_test)\nprint("flamlized et r2", "=", 1 - sklearn_metric_loss_score("r2", y_pred, y_test))\nprint(et)\n')),(0,l.yg)("h4",{id:"sample-output-7"},"Sample output"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre"},"load dataset from ./openml_ds537.pkl\nDataset name: houses\nX_train.shape: (15480, 8), y_train.shape: (15480,);\nX_test.shape: (5160, 8), y_test.shape: (5160,)\nflamlized et r2 = 0.8534\nExtraTreesRegressor(max_features=0.75, min_samples_leaf=2, min_samples_split=5,\n                    n_estimators=500)\n")),(0,l.yg)("h2",{id:"flamlized-extratreesclassifier"},"Flamlized ExtraTreesClassifier"),(0,l.yg)("h3",{id:"prerequisites-7"},"Prerequisites"),(0,l.yg)("p",null,"This example requires the ","[autozero]"," option."),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-bash"},"pip install flaml[autozero] scikit-learn openml\n")),(0,l.yg)("h3",{id:"zero-shot-automl-7"},"Zero-shot AutoML"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre",className:"language-python"},'from flaml.automl.data import load_openml_dataset\nfrom flaml.default import ExtraTreesClassifier\nfrom flaml.automl.ml import sklearn_metric_loss_score\n\nX_train, X_test, y_train, y_test = load_openml_dataset(dataset_id=1169, data_dir="./")\net = ExtraTreesClassifier()\net.fit(X_train, y_train)\ny_pred = et.predict(X_test)\nprint(\n    "flamlized et accuracy",\n    "=",\n    1 - sklearn_metric_loss_score("accuracy", y_pred, y_test),\n)\nprint(et)\n')),(0,l.yg)("h4",{id:"sample-output-8"},"Sample output"),(0,l.yg)("pre",null,(0,l.yg)("code",{parentName:"pre"},"load dataset from ./openml_ds1169.pkl\nDataset name: airlines\nX_train.shape: (404537, 7), y_train.shape: (404537,);\nX_test.shape: (134846, 7), y_test.shape: (134846,)\nflamlized et accuracy = 0.6698\nExtraTreesClassifier(max_features=0.7, min_samples_leaf=3, min_samples_split=5,\n                     n_estimators=500)\n")))}p.isMDXComponent=!0}}]);