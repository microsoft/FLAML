{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved. \n",
        "\n",
        "Licensed under the MIT License.\n",
        "\n",
        "# Use FLAML to Tune OpenAI Models\n",
        "\n",
        "FLAML offers a cost-effective hyperparameter optimization technique [EcoOptiGen](https://arxiv.org/abs/2303.04673) for tuning Large Language Models. Our study finds that tuning hyperparameters can significantly improve the utility of LLMs.\n",
        "\n",
        "In this notebook, we tune OpenAI models for code generation. We use [the HumanEval benchmark](https://huggingface.co/datasets/openai_humaneval) released by OpenAI for synthesizing programs from docstrings. \n",
        "\n",
        "## Requirements\n",
        "\n",
        "FLAML requires `Python>=3.7`. To run this notebook example, please install flaml with the [openai] option:\n",
        "```bash\n",
        "pip install flaml[openai]>=1.1.3\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-24T23:25:36.910966Z",
          "iopub.status.busy": "2023-02-24T23:25:36.910473Z",
          "iopub.status.idle": "2023-02-24T23:25:36.914554Z",
          "shell.execute_reply": "2023-02-24T23:25:36.91403Z"
        },
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-04-10T12:19:42.8919508Z",
              "execution_start_time": "2023-04-10T12:19:40.6162808Z",
              "livy_statement_state": "available",
              "parent_msg_id": "1eb654b0-ad77-4fc5-83b6-311936a1e831",
              "queued_time": "2023-04-10T12:18:09.6772064Z",
              "session_id": "21",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "automl",
              "state": "finished",
              "statement_id": 7
            },
            "text/plain": [
              "StatementMeta(automl, 21, 7, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {},
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting flaml[openai]@ git+https://github.com/microsoft/FLAML.git\n",
            "  Cloning https://github.com/microsoft/FLAML.git to /tmp/pip-install-deiu1ftw/flaml_ef55daf853604154a69c151faab6be07\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/microsoft/FLAML.git /tmp/pip-install-deiu1ftw/flaml_ef55daf853604154a69c151faab6be07\n",
            "  Resolved https://github.com/microsoft/FLAML.git to commit ef5a17cd830cc996bb07e72d07a1d2f3fc0c74c6\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25hCollecting xgboost==1.6.1\n",
            "  Using cached xgboost-1.6.1-py3-none-manylinux2014_x86_64.whl (192.9 MB)\n",
            "Collecting pandas==1.5.1\n",
            "  Using cached pandas-1.5.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "Collecting numpy==1.23.4\n",
            "  Using cached numpy-1.23.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "Collecting datasets\n",
            "  Using cached datasets-2.11.0-py3-none-any.whl (468 kB)\n",
            "Collecting scipy\n",
            "  Using cached scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "Collecting python-dateutil>=2.8.1\n",
            "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "Collecting pytz>=2020.1\n",
            "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "Collecting lightgbm>=2.3.1\n",
            "  Using cached lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "Collecting scikit-learn>=0.24\n",
            "  Using cached scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "Collecting openai==0.27.4\n",
            "  Using cached openai-0.27.4-py3-none-any.whl (70 kB)\n",
            "Collecting diskcache\n",
            "  Using cached diskcache-5.4.0-py3-none-any.whl (44 kB)\n",
            "Collecting optuna==2.8.0\n",
            "  Using cached optuna-2.8.0-py3-none-any.whl (301 kB)\n",
            "Collecting aiohttp\n",
            "  Using cached aiohttp-3.8.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "Collecting requests>=2.20\n",
            "  Using cached requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "Collecting tqdm\n",
            "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "Collecting packaging>=20.0\n",
            "  Using cached packaging-23.0-py3-none-any.whl (42 kB)\n",
            "Collecting colorlog\n",
            "  Using cached colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting sqlalchemy>=1.1.0\n",
            "  Using cached SQLAlchemy-2.0.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "Collecting alembic\n",
            "  Using cached alembic-1.10.3-py3-none-any.whl (212 kB)\n",
            "Collecting cliff\n",
            "  Using cached cliff-4.2.0-py3-none-any.whl (81 kB)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Using cached cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Collecting huggingface-hub<1.0.0,>=0.11.0\n",
            "  Using cached huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "Collecting pyarrow>=8.0.0\n",
            "  Using cached pyarrow-11.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.0 MB)\n",
            "Collecting multiprocess\n",
            "  Using cached multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Using cached PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
            "Collecting responses<0.19\n",
            "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting dill<0.3.7,>=0.3.0\n",
            "  Using cached dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "Collecting fsspec[http]>=2021.11.1\n",
            "  Using cached fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
            "Collecting xxhash\n",
            "  Using cached xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Using cached frozenlist-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "Collecting attrs>=17.3.0\n",
            "  Using cached attrs-22.2.0-py3-none-any.whl (60 kB)\n",
            "Collecting charset-normalizer<4.0,>=2.0\n",
            "  Using cached charset_normalizer-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (195 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Using cached yarl-1.8.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (262 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Using cached multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
            "Collecting typing-extensions>=3.7.4.3\n",
            "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Collecting filelock\n",
            "  Using cached filelock-3.11.0-py3-none-any.whl (10.0 kB)\n",
            "Collecting wheel\n",
            "  Using cached wheel-0.40.0-py3-none-any.whl (64 kB)\n",
            "Collecting six>=1.5\n",
            "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting certifi>=2017.4.17\n",
            "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
            "Collecting idna<4,>=2.5\n",
            "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Using cached urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
            "Collecting joblib>=1.1.1\n",
            "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting greenlet!=0.4.17\n",
            "  Using cached greenlet-2.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (618 kB)\n",
            "Collecting importlib-resources\n",
            "  Using cached importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
            "Collecting importlib-metadata\n",
            "  Using cached importlib_metadata-6.3.0-py3-none-any.whl (22 kB)\n",
            "Collecting Mako\n",
            "  Using cached Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Using cached cmd2-2.4.3-py3-none-any.whl (147 kB)\n",
            "Collecting PrettyTable>=0.7.2\n",
            "  Using cached prettytable-3.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting autopage>=0.4.0\n",
            "  Using cached autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Using cached stevedore-5.0.0-py3-none-any.whl (49 kB)\n",
            "Collecting pyperclip>=1.6\n",
            "  Using cached pyperclip-1.8.2-py3-none-any.whl\n",
            "Collecting wcwidth>=0.1.7\n",
            "  Using cached wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Using cached zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Using cached pbr-5.11.1-py2.py3-none-any.whl (112 kB)\n",
            "Collecting MarkupSafe>=0.9.2\n",
            "  Using cached MarkupSafe-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Building wheels for collected packages: flaml\n",
            "  Building wheel for flaml (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Created wheel for flaml: filename=FLAML-1.2.0-py3-none-any.whl size=250496 sha256=551d50985e20ae3d7c50ad4a615e2eab2aa6252c510f0caa97708fef0b79cdf8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2udxi6t8/wheels/5c/1a/48/c07dfe482b630f96d7258700d361a971759465895f9dd768ee\n",
            "Successfully built flaml\n",
            "Installing collected packages: wcwidth, pytz, pyperclip, zipp, xxhash, wheel, urllib3, typing-extensions, tqdm, threadpoolctl, six, pyyaml, PrettyTable, pbr, packaging, numpy, multidict, MarkupSafe, joblib, idna, greenlet, fsspec, frozenlist, filelock, diskcache, dill, colorlog, charset-normalizer, certifi, autopage, attrs, async-timeout, yarl, stevedore, sqlalchemy, scipy, requests, python-dateutil, pyarrow, multiprocess, Mako, importlib-resources, importlib-metadata, cmd2, cmaes, aiosignal, xgboost, scikit-learn, responses, pandas, huggingface-hub, cliff, alembic, aiohttp, optuna, openai, lightgbm, flaml, datasets\n",
            "  Attempting uninstall: wcwidth\n",
            "    Found existing installation: wcwidth 0.2.5\n",
            "    Not uninstalling wcwidth at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'wcwidth'. No files were found to uninstall.\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2021.1\n",
            "    Not uninstalling pytz at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'pytz'. No files were found to uninstall.\n",
            "  Attempting uninstall: pyperclip\n",
            "    Found existing installation: pyperclip 1.8.2\n",
            "    Not uninstalling pyperclip at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'pyperclip'. No files were found to uninstall.\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.5.0\n",
            "    Not uninstalling zipp at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'zipp'. No files were found to uninstall.\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.36.2\n",
            "    Not uninstalling wheel at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'wheel'. No files were found to uninstall.\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.4\n",
            "    Not uninstalling urllib3 at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'urllib3'. No files were found to uninstall.\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.10.0.0\n",
            "    Not uninstalling typing-extensions at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'typing-extensions'. No files were found to uninstall.\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.61.2\n",
            "    Not uninstalling tqdm at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'tqdm'. No files were found to uninstall.\n",
            "  Attempting uninstall: threadpoolctl\n",
            "    Found existing installation: threadpoolctl 2.1.0\n",
            "    Not uninstalling threadpoolctl at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'threadpoolctl'. No files were found to uninstall.\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Not uninstalling six at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'six'. No files were found to uninstall.\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 5.4.1\n",
            "    Not uninstalling pyyaml at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'PyYAML'. No files were found to uninstall.\n",
            "  Attempting uninstall: PrettyTable\n",
            "    Found existing installation: prettytable 2.4.0\n",
            "    Not uninstalling prettytable at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'prettytable'. No files were found to uninstall.\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 21.0\n",
            "    Not uninstalling packaging at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'packaging'. No files were found to uninstall.\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.4\n",
            "    Not uninstalling numpy at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'numpy'. No files were found to uninstall.\n",
            "  Attempting uninstall: multidict\n",
            "    Found existing installation: multidict 5.1.0\n",
            "    Not uninstalling multidict at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'multidict'. No files were found to uninstall.\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.0.1\n",
            "    Not uninstalling markupsafe at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'MarkupSafe'. No files were found to uninstall.\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.0.1\n",
            "    Not uninstalling joblib at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'joblib'. No files were found to uninstall.\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Not uninstalling idna at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'idna'. No files were found to uninstall.\n",
            "  Attempting uninstall: greenlet\n",
            "    Found existing installation: greenlet 1.1.0\n",
            "    Not uninstalling greenlet at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'greenlet'. No files were found to uninstall.\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2021.6.1\n",
            "    Not uninstalling fsspec at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'fsspec'. No files were found to uninstall.\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.8.0\n",
            "    Not uninstalling filelock at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'filelock'. No files were found to uninstall.\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.4\n",
            "    Not uninstalling dill at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'dill'. No files were found to uninstall.\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2021.5.30\n",
            "    Not uninstalling certifi at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'certifi'. No files were found to uninstall.\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 21.2.0\n",
            "    Not uninstalling attrs at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'attrs'. No files were found to uninstall.\n",
            "  Attempting uninstall: async-timeout\n",
            "    Found existing installation: async-timeout 3.0.1\n",
            "    Not uninstalling async-timeout at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'async-timeout'. No files were found to uninstall.\n",
            "  Attempting uninstall: yarl\n",
            "    Found existing installation: yarl 1.6.3\n",
            "    Not uninstalling yarl at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'yarl'. No files were found to uninstall.\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 1.4.20\n",
            "    Not uninstalling sqlalchemy at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'SQLAlchemy'. No files were found to uninstall.\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.5.3\n",
            "    Not uninstalling scipy at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'scipy'. No files were found to uninstall.\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.25.1\n",
            "    Not uninstalling requests at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'requests'. No files were found to uninstall.\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.1\n",
            "    Not uninstalling python-dateutil at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'python-dateutil'. No files were found to uninstall.\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 3.0.0\n",
            "    Not uninstalling pyarrow at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'pyarrow'. No files were found to uninstall.\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib-resources 5.10.0\n",
            "    Not uninstalling importlib-resources at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'importlib-resources'. No files were found to uninstall.\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.6.1\n",
            "    Not uninstalling importlib-metadata at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'importlib-metadata'. No files were found to uninstall.\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 1.4.0\n",
            "    Not uninstalling xgboost at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'xgboost'. No files were found to uninstall.\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.23.2\n",
            "    Not uninstalling scikit-learn at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'scikit-learn'. No files were found to uninstall.\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.2.3\n",
            "    Not uninstalling pandas at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'pandas'. No files were found to uninstall.\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.7.4.post0\n",
            "    Not uninstalling aiohttp at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'aiohttp'. No files were found to uninstall.\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 3.2.1\n",
            "    Not uninstalling lightgbm at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2\n",
            "    Can't uninstall 'lightgbm'. No files were found to uninstall.\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.4.1 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "tensorflow 2.4.1 requires typing-extensions~=3.7.4, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pmdarima 1.8.2 requires numpy~=1.19.0, but you have numpy 1.23.4 which is incompatible.\n",
            "koalas 1.8.0 requires numpy<1.20.0,>=1.14, but you have numpy 1.23.4 which is incompatible.\n",
            "gevent 21.1.2 requires greenlet<2.0,>=0.4.17; platform_python_implementation == \"CPython\", but you have greenlet 2.0.2 which is incompatible.\n",
            "azureml-dataset-runtime 1.34.0 requires pyarrow<4.0.0,>=0.17.0, but you have pyarrow 11.0.0 which is incompatible.\n",
            "azureml-core 1.34.0 requires urllib3<=1.26.6,>=1.23, but you have urllib3 1.26.15 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.2.4 MarkupSafe-2.1.2 PrettyTable-3.7.0 aiohttp-3.8.4 aiosignal-1.3.1 alembic-1.10.3 async-timeout-4.0.2 attrs-22.2.0 autopage-0.5.1 certifi-2022.12.7 charset-normalizer-3.1.0 cliff-4.2.0 cmaes-0.9.1 cmd2-2.4.3 colorlog-6.7.0 datasets-2.11.0 dill-0.3.6 diskcache-5.4.0 filelock-3.11.0 flaml-1.2.0 frozenlist-1.3.3 fsspec-2023.4.0 greenlet-2.0.2 huggingface-hub-0.13.4 idna-3.4 importlib-metadata-6.3.0 importlib-resources-5.12.0 joblib-1.2.0 lightgbm-3.3.5 multidict-6.0.4 multiprocess-0.70.14 numpy-1.23.4 openai-0.27.4 optuna-2.8.0 packaging-23.0 pandas-1.5.1 pbr-5.11.1 pyarrow-11.0.0 pyperclip-1.8.2 python-dateutil-2.8.2 pytz-2023.3 pyyaml-6.0 requests-2.28.2 responses-0.18.0 scikit-learn-1.2.2 scipy-1.10.1 six-1.16.0 sqlalchemy-2.0.9 stevedore-5.0.0 threadpoolctl-3.1.0 tqdm-4.65.0 typing-extensions-4.5.0 urllib3-1.26.15 wcwidth-0.2.6 wheel-0.40.0 xgboost-1.6.1 xxhash-3.2.0 yarl-1.8.2 zipp-3.15.0\n",
            "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
            "You should consider upgrading via the '/nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "data": {},
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: PySpark kernel has been restarted to use updated packages.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%pip install flaml[synapse]==1.2.1 xgboost==1.6.1 pandas==1.5.1 numpy==1.23.4 datasets --force-reinstall"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set your OpenAI key:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-24T23:25:36.917301Z",
          "iopub.status.busy": "2023-02-24T23:25:36.917011Z",
          "iopub.status.idle": "2023-02-24T23:25:36.923156Z",
          "shell.execute_reply": "2023-02-24T23:25:36.922619Z"
        },
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-04-10T12:19:44.3378567Z",
              "execution_start_time": "2023-04-10T12:19:44.0766121Z",
              "livy_statement_state": "available",
              "parent_msg_id": "f00d29ac-e6c6-400a-8573-0f8af06733a7",
              "queued_time": "2023-04-10T12:18:09.6829834Z",
              "session_id": "21",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "automl",
              "state": "finished",
              "statement_id": 9
            },
            "text/plain": [
              "StatementMeta(automl, 21, 9, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you use Azure OpenAI, uncomment the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-24T23:25:36.925804Z",
          "iopub.status.busy": "2023-02-24T23:25:36.925423Z",
          "iopub.status.idle": "2023-02-24T23:25:36.928191Z",
          "shell.execute_reply": "2023-02-24T23:25:36.927673Z"
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-04-10T12:19:45.3677777Z",
              "execution_start_time": "2023-04-10T12:19:44.5952273Z",
              "livy_statement_state": "available",
              "parent_msg_id": "4e9b924d-f16c-463a-b6cf-c2308ad41432",
              "queued_time": "2023-04-10T12:18:09.976808Z",
              "session_id": "21",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "automl",
              "state": "finished",
              "statement_id": 10
            },
            "text/plain": [
              "StatementMeta(automl, 21, 10, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# import openai\n",
        "# openai.api_type = \"azure\"\n",
        "# openai.api_base = \"YOUR_API_ENDPOINT\"\n",
        "# openai.api_version = \"2022-12-01\"\n",
        "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load dataset\n",
        "\n",
        "First, we load the humaneval dataset. The dataset contains 164 examples. We use the first 20 for tuning the generation hyperparameters and the remaining for evaluation. In each example, the \"prompt\" is the prompt string for eliciting the code generation, \"test\" is the Python code for unit test for the example, and \"entry_point\" is the function name to be tested."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-24T23:25:36.931255Z",
          "iopub.status.busy": "2023-02-24T23:25:36.930838Z",
          "iopub.status.idle": "2023-02-24T23:25:39.148799Z",
          "shell.execute_reply": "2023-02-24T23:25:39.148113Z"
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-04-10T12:19:47.0830761Z",
              "execution_start_time": "2023-04-10T12:19:45.6556329Z",
              "livy_statement_state": "available",
              "parent_msg_id": "c784639c-72ce-4bcb-a0e0-c30130471c44",
              "queued_time": "2023-04-10T12:18:09.9779924Z",
              "session_id": "21",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "automl",
              "state": "finished",
              "statement_id": 11
            },
            "text/plain": [
              "StatementMeta(automl, 21, 11, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found cached dataset openai_humaneval (/home/trusted-service-user/.cache/huggingface/datasets/openai_humaneval/openai_humaneval/1.0.0/2955cebd73602e828fa8c0a424c594e5fab4ec863b316ca98f3d8fdb6a626e75)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7494b46b-140a-4c5f-8fb2-7fccf8c3a8fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading cached shuffled indices for dataset at /home/trusted-service-user/.cache/huggingface/datasets/openai_humaneval/openai_humaneval/1.0.0/2955cebd73602e828fa8c0a424c594e5fab4ec863b316ca98f3d8fdb6a626e75/cache-1e8448101c1b32e8.arrow\n"
          ]
        }
      ],
      "source": [
        "import datasets\n",
        "\n",
        "seed = 41\n",
        "data = datasets.load_dataset(\"openai_humaneval\")[\"test\"].shuffle(seed=seed)\n",
        "n_tune_data = 20\n",
        "tune_data = [\n",
        "    {\n",
        "        \"prompt\": data[x][\"prompt\"],\n",
        "        \"test\": data[x][\"test\"],\n",
        "        \"entry_point\": data[x][\"entry_point\"],\n",
        "    }\n",
        "    for x in range(n_tune_data)\n",
        "]\n",
        "test_data = [\n",
        "    {\n",
        "        \"prompt\": data[x][\"prompt\"],\n",
        "        \"test\": data[x][\"test\"],\n",
        "        \"entry_point\": data[x][\"entry_point\"],\n",
        "    }\n",
        "    for x in range(n_tune_data, len(data))\n",
        "]\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "Check a tuning example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-24T23:25:39.152156Z",
          "iopub.status.busy": "2023-02-24T23:25:39.151531Z",
          "iopub.status.idle": "2023-02-24T23:25:39.155313Z",
          "shell.execute_reply": "2023-02-24T23:25:39.154731Z"
        },
        "slideshow": {
          "slide_type": "subslide"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-04-10T12:19:47.6376145Z",
              "execution_start_time": "2023-04-10T12:19:47.3752342Z",
              "livy_statement_state": "available",
              "parent_msg_id": "cff150be-48f5-44f7-921e-e94758c32c00",
              "queued_time": "2023-04-10T12:18:09.9789669Z",
              "session_id": "21",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "automl",
              "state": "finished",
              "statement_id": 12
            },
            "text/plain": [
              "StatementMeta(automl, 21, 12, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "def compare(game,guess):\n",
            "    \"\"\"I think we all remember that feeling when the result of some long-awaited\n",
            "    event is finally known. The feelings and thoughts you have at that moment are\n",
            "    definitely worth noting down and comparing.\n",
            "    Your task is to determine if a person correctly guessed the results of a number of matches.\n",
            "    You are given two arrays of scores and guesses of equal length, where each index shows a match. \n",
            "    Return an array of the same length denoting how far off each guess was. If they have guessed correctly,\n",
            "    the value is 0, and if not, the value is the absolute difference between the guess and the score.\n",
            "    \n",
            "    \n",
            "    example:\n",
            "\n",
            "    compare([1,2,3,4,5,1],[1,2,3,4,2,-2]) -> [0,0,0,0,3,3]\n",
            "    compare([0,5,0,0,0,4],[4,1,1,0,0,-2]) -> [4,4,1,0,0,6]\n",
            "    \"\"\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(tune_data[1][\"prompt\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is one example of the unit test code for verifying the correctness of the generated code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-24T23:25:39.158398Z",
          "iopub.status.busy": "2023-02-24T23:25:39.157766Z",
          "iopub.status.idle": "2023-02-24T23:25:39.161396Z",
          "shell.execute_reply": "2023-02-24T23:25:39.160797Z"
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-04-10T12:19:48.1365589Z",
              "execution_start_time": "2023-04-10T12:19:47.8737836Z",
              "livy_statement_state": "available",
              "parent_msg_id": "febf0900-33f5-40fb-85f3-394660ca3a60",
              "queued_time": "2023-04-10T12:18:09.9802576Z",
              "session_id": "21",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "automl",
              "state": "finished",
              "statement_id": 13
            },
            "text/plain": [
              "StatementMeta(automl, 21, 13, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "def check(candidate):\n",
            "\n",
            "    # Check some simple cases\n",
            "    assert candidate([1,2,3,4,5,1],[1,2,3,4,2,-2])==[0,0,0,0,3,3], \"This prints if this assert fails 1 (good for debugging!)\"\n",
            "    assert candidate([0,0,0,0,0,0],[0,0,0,0,0,0])==[0,0,0,0,0,0], \"This prints if this assert fails 1 (good for debugging!)\"\n",
            "    assert candidate([1,2,3],[-1,-2,-3])==[2,4,6], \"This prints if this assert fails 1 (good for debugging!)\"\n",
            "    assert candidate([1,2,3,5],[-1,2,3,4])==[2,0,0,1], \"This prints if this assert fails 1 (good for debugging!)\"\n",
            "\n",
            "    # Check some edge cases that are easy to work out by hand.\n",
            "    assert True, \"This prints if this assert fails 2 (also good for debugging!)\"\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(tune_data[1][\"test\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Success Metric\n",
        "\n",
        "Before we start tuning, we need to define the success metric we want to opotimize. For each code generation task, if one of the returned responses can pass the test, we consider the task as successfully solved. Then we can define the mean success rate of a collection of tasks.\n",
        "\n",
        "### Define a code executor\n",
        "\n",
        "First, we write a simple code executor. The code executor takes the generated code and the test code as the input, and execute them with a timer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-24T23:25:39.164187Z",
          "iopub.status.busy": "2023-02-24T23:25:39.163867Z",
          "iopub.status.idle": "2023-02-24T23:25:39.169009Z",
          "shell.execute_reply": "2023-02-24T23:25:39.168427Z"
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-04-10T12:19:48.6408818Z",
              "execution_start_time": "2023-04-10T12:19:48.3747743Z",
              "livy_statement_state": "available",
              "parent_msg_id": "085d2cb3-8470-417d-b9ad-ce67d5481760",
              "queued_time": "2023-04-10T12:18:09.9812212Z",
              "session_id": "21",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "automl",
              "state": "finished",
              "statement_id": 14
            },
            "text/plain": [
              "StatementMeta(automl, 21, 14, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import signal\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def timeout_handler(signum, frame):\n",
        "    raise TimeoutError(\"Timed out!\")\n",
        "\n",
        "signal.signal(signal.SIGALRM, timeout_handler)\n",
        "max_exec_time = 3  # seconds\n",
        "\n",
        "def execute_code(code):\n",
        "    code = code.strip()\n",
        "    with open(\"codetest.py\", \"w\") as fout:\n",
        "        fout.write(code)\n",
        "    try:\n",
        "        signal.alarm(max_exec_time)\n",
        "        result = subprocess.run(\n",
        "            [sys.executable, \"codetest.py\"],\n",
        "            stdout=subprocess.DEVNULL,\n",
        "            stderr=subprocess.PIPE,\n",
        "        )\n",
        "        signal.alarm(0)\n",
        "    except TimeoutError:\n",
        "        return 0\n",
        "    return int(result.returncode == 0)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function will create a temp file \"codetest.py\" and execute it in a separate process. It allows for 3 seconds to finish that code.\n",
        "\n",
        "### Define a function to evaluate the success for a given program synthesis task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-24T23:25:39.171752Z",
          "iopub.status.busy": "2023-02-24T23:25:39.171347Z",
          "iopub.status.idle": "2023-02-24T23:25:39.176343Z",
          "shell.execute_reply": "2023-02-24T23:25:39.17551Z"
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-04-10T12:19:49.1447054Z",
              "execution_start_time": "2023-04-10T12:19:48.8859038Z",
              "livy_statement_state": "available",
              "parent_msg_id": "68ba93f1-9464-44b4-a660-2e1b929137e0",
              "queued_time": "2023-04-10T12:18:09.9827742Z",
              "session_id": "21",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "automl",
              "state": "finished",
              "statement_id": 15
            },
            "text/plain": [
              "StatementMeta(automl, 21, 15, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def success_metrics(responses, prompt, test, entry_point):\n",
        "    \"\"\"Check if the task is successful.\n",
        "\n",
        "    Args:\n",
        "        responses (list): The list of responses.\n",
        "        prompt (str): The input prompt.\n",
        "        test (str): The test code.\n",
        "        entry_point (str): The name of the function.\n",
        "\n",
        "    Returns:\n",
        "        dict: The success metrics.\n",
        "    \"\"\"\n",
        "    success_list = []\n",
        "    n = len(responses)\n",
        "    for i in range(n):\n",
        "        response = responses[i]\n",
        "        code = f\"{prompt}{response}\\n{test}\\ncheck({entry_point})\"\n",
        "        succeed = execute_code(code)\n",
        "        success_list.append(succeed)\n",
        "    return {\n",
        "        \"expected_success\": 1 - pow(1 - sum(success_list) / n, n),\n",
        "        \"success\": any(s for s in success_list),\n",
        "    }\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "## Use the tuning data to find a good configuration\n",
        "\n",
        "### Import the oai and tune subpackages from flaml.\n",
        "\n",
        "FLAML has provided an API for hyperparameter optimization of OpenAI models: `oai.Completion.tune` and to make a request with the tuned config: `oai.Completion.create`. First, we import oai from flaml:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-24T23:25:39.17903Z",
          "iopub.status.busy": "2023-02-24T23:25:39.178624Z",
          "iopub.status.idle": "2023-02-24T23:25:40.58441Z",
          "shell.execute_reply": "2023-02-24T23:25:40.583802Z"
        },
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-04-10T12:19:51.7094028Z",
              "execution_start_time": "2023-04-10T12:19:49.3916438Z",
              "livy_statement_state": "available",
              "parent_msg_id": "a7039604-07a4-47cf-b290-f29e5777c4cc",
              "queued_time": "2023-04-10T12:18:09.9845204Z",
              "session_id": "21",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "automl",
              "state": "finished",
              "statement_id": 16
            },
            "text/plain": [
              "StatementMeta(automl, 21, 16, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages/dask/dataframe/backends.py:187: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
            "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
            "/home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages/dask/dataframe/backends.py:187: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
            "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
            "/home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages/dask/dataframe/backends.py:187: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
            "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (urllib3 1.26.15 (/nfs4/pyenv-b224b66d-ff10-4da7-ad2a-97c4dedd98a2/lib/python3.8/site-packages), Requirement.parse('urllib3<=1.26.6,>=1.23')).\n"
          ]
        }
      ],
      "source": [
        "from flaml import oai, tune"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For (local) reproducibility and cost efficiency, we cache responses from OpenAI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-24T23:25:40.587815Z",
          "iopub.status.busy": "2023-02-24T23:25:40.587283Z",
          "iopub.status.idle": "2023-02-24T23:25:40.590826Z",
          "shell.execute_reply": "2023-02-24T23:25:40.590158Z"
        },
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-04-10T12:19:52.229801Z",
              "execution_start_time": "2023-04-10T12:19:51.9616295Z",
              "livy_statement_state": "available",
              "parent_msg_id": "1163a2b4-b27c-4b8c-b9e0-642fc8c2c045",
              "queued_time": "2023-04-10T12:18:09.9865231Z",
              "session_id": "21",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "automl",
              "state": "finished",
              "statement_id": 17
            },
            "text/plain": [
              "StatementMeta(automl, 21, 17, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "oai.Completion.set_cache(seed)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This will create a disk cache in \".cache/{seed}\". You can change `cache_path` in `set_cache()`. The cache for different seeds are stored separately.\n",
        "\n",
        "### Perform tuning\n",
        "\n",
        "The tuning will take a while to finish, depending on the optimization budget. The tuning will be performed under the specified optimization budgets.\n",
        "\n",
        "* `inference_budget` is the target average inference budget per instance in the benchmark. For example, 0.02 means the target inference budget is 0.02 dollars, which translates to 1000 tokens (input + output combined) if the text Davinci model is used.\n",
        "* `optimization_budget` is the total budget allowed to perform the tuning. For example, 5 means 5 dollars are allowed in total, which translates to 250K tokens for the text Davinci model.\n",
        "* `num_sumples` is the number of different hyperparameter configurations which is allowed to try. The tuning will stop after either num_samples trials or after optimization_budget dollars spent, whichever happens first. -1 means no hard restriction in the number of trials and the actual number is decided by `optimization_budget`.\n",
        "\n",
        "Users can specify tuning data, optimization metric, optimization mode, evaluation function, search spaces etc.. The default search space is:\n",
        "\n",
        "```python\n",
        "default_search_space = {\n",
        "    \"model\": tune.choice([\n",
        "        \"text-ada-001\",\n",
        "        \"text-babbage-001\",\n",
        "        \"text-davinci-003\",\n",
        "        \"gpt-3.5-turbo\",\n",
        "        \"gpt-4\",\n",
        "    ]),\n",
        "    \"temperature_or_top_p\": tune.choice(\n",
        "        [\n",
        "            {\"temperature\": tune.uniform(0, 1)},\n",
        "            {\"top_p\": tune.uniform(0, 1)},\n",
        "        ]\n",
        "    ),\n",
        "    \"max_tokens\": tune.lograndint(50, 1000),\n",
        "    \"n\": tune.randint(1, 100),\n",
        "    \"prompt\": \"{prompt}\",\n",
        "}\n",
        "```\n",
        "\n",
        "The default search space can be overridden by users' input.\n",
        "For example, the following code specifies four choices for the prompt and a fixed list of stop sequences. For hyperparameters which don't appear in users' input, the default search space will be used. If you don't have access to gpt-4 or would like to modify the choice of models, you can provide a different search space for model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-24T23:25:40.593603Z",
          "iopub.status.busy": "2023-02-24T23:25:40.593269Z",
          "iopub.status.idle": "2023-02-24T23:26:38.349191Z",
          "shell.execute_reply": "2023-02-24T23:26:38.348392Z"
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-04-10T12:28:05.881346Z",
              "execution_start_time": "2023-04-10T12:23:12.849894Z",
              "livy_statement_state": "available",
              "parent_msg_id": "397c1c99-0f7b-468d-9938-c0444d860f18",
              "queued_time": "2023-04-10T12:23:12.5926149Z",
              "session_id": "21",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "automl",
              "state": "finished",
              "statement_id": 19
            },
            "text/plain": [
              "StatementMeta(automl, 21, 19, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2023-04-10 12:23:12,833]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
            "\u001b[32m[I 2023-04-10 12:23:12,835]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'. More info can be found at https://microsoft.github.io/FLAML/docs/FAQ#about-low_cost_partial_config-in-tune\n",
            "No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'. More info can be found at https://microsoft.github.io/FLAML/docs/FAQ#about-low_cost_partial_config-in-tune\n",
            "[flaml.tune.tune: 04-10 12:23:12] {832} INFO - trial 1 config: {'prompt': 2, 'stop': 0, 'subspace': {'model': 'text-davinci-002', 'max_tokens': 347, 'temperature_or_top_p': {'temperature': 0.36865945026811975}, 'n': 36}}\n",
            "[flaml.tune.tune: 04-10 12:26:16] {215} INFO - result: {'expected_success': 0.7947565938469873, 'success': 0.8, 'total_cost': 1.0647, 'cost': 1.0647, 'inference_cost': 0.03736, 'training_iteration': 0, 'config': {'prompt': 2, 'stop': 0, 'subspace': {'model': 'text-davinci-002', 'max_tokens': 347, 'temperature_or_top_p': {'temperature': 0.36865945026811975}, 'n': 36}}, 'config/prompt': 2, 'config/stop': 0, 'config/subspace': {'model': 'text-davinci-002', 'max_tokens': 347, 'temperature_or_top_p': {'temperature': 0.36865945026811975}, 'n': 36}, 'experiment_tag': 'exp', 'time_total_s': 183.4394142627716}\n",
            "[flaml.tune.tune: 04-10 12:26:16] {832} INFO - trial 2 config: {'prompt': 2, 'stop': 0, 'subspace': {'model': 'code-cushman-001', 'max_tokens': 347, 'temperature_or_top_p': {'temperature': 0.36865945026811975}, 'n': 36}}\n",
            "[flaml.tune.tune: 04-10 12:26:22] {215} INFO - result: {'expected_success': 0, 'total_cost': 1.1728919999999998, 'cost': 0.108192, 'training_iteration': 0, 'config': {'prompt': 2, 'stop': 0, 'subspace': {'model': 'code-cushman-001', 'max_tokens': 347, 'temperature_or_top_p': {'temperature': 0.36865945026811975}, 'n': 36}}, 'config/prompt': 2, 'config/stop': 0, 'config/subspace': {'model': 'code-cushman-001', 'max_tokens': 347, 'temperature_or_top_p': {'temperature': 0.36865945026811975}, 'n': 36}, 'experiment_tag': 'exp', 'time_total_s': 5.890477418899536}\n",
            "[flaml.tune.tune: 04-10 12:26:22] {832} INFO - trial 3 config: {'prompt': 0, 'stop': 0, 'subspace': {'max_tokens': 90, 'temperature_or_top_p': {'temperature': 0.08833981417401027}, 'n': 68, 'model': 'text-davinci-002'}}\n",
            "[flaml.tune.tune: 04-10 12:26:36] {215} INFO - result: {'expected_success': 0, 'total_cost': 1.5190919999999997, 'cost': 0.34620000000000006, 'training_iteration': 0, 'config': {'prompt': 0, 'stop': 0, 'subspace': {'max_tokens': 90, 'temperature_or_top_p': {'temperature': 0.08833981417401027}, 'n': 68, 'model': 'text-davinci-002'}}, 'config/prompt': 0, 'config/stop': 0, 'config/subspace': {'max_tokens': 90, 'temperature_or_top_p': {'temperature': 0.08833981417401027}, 'n': 68, 'model': 'text-davinci-002'}, 'experiment_tag': 'exp', 'time_total_s': 14.720270872116089}\n",
            "[flaml.tune.tune: 04-10 12:26:36] {832} INFO - trial 4 config: {'prompt': 0, 'stop': 0, 'subspace': {'max_tokens': 119, 'temperature_or_top_p': {'temperature': 0.5425443680112613}, 'n': 15, 'model': 'code-cushman-001'}}\n",
            "[flaml.tune.tune: 04-10 12:27:11] {215} INFO - result: {'expected_success': 0.6068416677725271, 'success': 0.65, 'total_cost': 2.0261879999999994, 'cost': 0.5070960000000001, 'inference_cost': 0.025522800000000002, 'training_iteration': 0, 'config': {'prompt': 0, 'stop': 0, 'subspace': {'max_tokens': 119, 'temperature_or_top_p': {'temperature': 0.5425443680112613}, 'n': 15, 'model': 'code-cushman-001'}}, 'config/prompt': 0, 'config/stop': 0, 'config/subspace': {'max_tokens': 119, 'temperature_or_top_p': {'temperature': 0.5425443680112613}, 'n': 15, 'model': 'code-cushman-001'}, 'experiment_tag': 'exp', 'time_total_s': 34.180718183517456}\n",
            "[flaml.tune.tune: 04-10 12:27:11] {832} INFO - trial 5 config: {'prompt': 1, 'stop': 0, 'subspace': {'max_tokens': 350, 'temperature_or_top_p': {'top_p': 0.5216471523936341}, 'n': 90, 'model': 'text-davinci-002'}}\n",
            "[flaml.tune.tune: 04-10 12:27:35] {215} INFO - result: {'expected_success': 0, 'total_cost': 2.2474879999999993, 'cost': 0.22130000000000002, 'training_iteration': 0, 'config': {'prompt': 1, 'stop': 0, 'subspace': {'max_tokens': 350, 'temperature_or_top_p': {'top_p': 0.5216471523936341}, 'n': 90, 'model': 'text-davinci-002'}}, 'config/prompt': 1, 'config/stop': 0, 'config/subspace': {'max_tokens': 350, 'temperature_or_top_p': {'top_p': 0.5216471523936341}, 'n': 90, 'model': 'text-davinci-002'}, 'experiment_tag': 'exp', 'time_total_s': 24.109977960586548}\n",
            "[flaml.tune.tune: 04-10 12:27:35] {832} INFO - trial 6 config: {'prompt': 0, 'stop': 0, 'subspace': {'max_tokens': 325, 'temperature_or_top_p': {'top_p': 0.1989475396788123}, 'n': 85, 'model': 'text-davinci-002'}}\n",
            "[flaml.tune.tune: 04-10 12:27:35] {215} INFO - result: {'inference_cost': inf, 'expected_success': -inf, 'cost': 0, 'training_iteration': 0, 'config': {'prompt': 0, 'stop': 0, 'subspace': {'max_tokens': 325, 'temperature_or_top_p': {'top_p': 0.1989475396788123}, 'n': 85, 'model': 'text-davinci-002'}}, 'config/prompt': 0, 'config/stop': 0, 'config/subspace': {'max_tokens': 325, 'temperature_or_top_p': {'top_p': 0.1989475396788123}, 'n': 85, 'model': 'text-davinci-002'}, 'experiment_tag': 'exp', 'time_total_s': 0.00047135353088378906}\n",
            "[flaml.tune.tune: 04-10 12:27:35] {832} INFO - trial 7 config: {'prompt': 3, 'stop': 0, 'subspace': {'max_tokens': 161, 'temperature_or_top_p': {'top_p': 0.15115201964256386}, 'n': 39, 'model': 'text-davinci-002'}}\n",
            "[flaml.tune.tune: 04-10 12:28:04] {215} INFO - result: {'expected_success': 0, 'total_cost': 3.0086279999999994, 'cost': 0.76114, 'training_iteration': 0, 'config': {'prompt': 3, 'stop': 0, 'subspace': {'max_tokens': 161, 'temperature_or_top_p': {'top_p': 0.15115201964256386}, 'n': 39, 'model': 'text-davinci-002'}}, 'config/prompt': 3, 'config/stop': 0, 'config/subspace': {'max_tokens': 161, 'temperature_or_top_p': {'top_p': 0.15115201964256386}, 'n': 39, 'model': 'text-davinci-002'}, 'experiment_tag': 'exp', 'time_total_s': 29.699407815933228}\n",
            "[flaml.tune.tune: 04-10 12:28:04] {855} WARNING - fail to sample a trial for 100 times in a row, stopping.\n"
          ]
        }
      ],
      "source": [
        "config, analysis = oai.Completion.tune(\n",
        "    data=tune_data,  # the data for tuning\n",
        "    metric=\"expected_success\",  # the metric to optimize\n",
        "    mode=\"max\",  # the optimization mode\n",
        "    eval_func=success_metrics,  # the evaluation function to return the success metrics\n",
        "    # log_file_name=\"logs/humaneval.log\",  # the log file name\n",
        "    inference_budget=0.05,  # the inference budget (dollar)\n",
        "    optimization_budget=3,  # the optimization budget (dollar)\n",
        "    # num_samples can further limit the number of trials for different hyperparameter configurations;\n",
        "    # -1 means decided by the optimization budget only\n",
        "    num_samples=-1,\n",
        "    model=tune.choice(\n",
        "        [\n",
        "            \"text-davinci-002\",\n",
        "            \"code-cushman-001\",\n",
        "        ]\n",
        "    ),\n",
        "    prompt=[\n",
        "        \"{prompt}\",\n",
        "        \"# Python 3{prompt}\",\n",
        "        \"Complete the following Python function:{prompt}\",\n",
        "        \"Complete the following Python function while including necessary import statements inside the function:{prompt}\",\n",
        "    ],  # the prompt templates to choose from\n",
        "    stop=[\"\\nclass\", \"\\ndef\", \"\\nif\", \"\\nprint\"],  # the stop sequence\n",
        ")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Output tuning results\n",
        "\n",
        "After the tuning, we can print out the config and the result found by FLAML:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-24T23:26:38.35271Z",
          "iopub.status.busy": "2023-02-24T23:26:38.352378Z",
          "iopub.status.idle": "2023-02-24T23:26:38.356939Z",
          "shell.execute_reply": "2023-02-24T23:26:38.356217Z"
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-04-10T12:28:06.5074477Z",
              "execution_start_time": "2023-04-10T12:28:06.2122589Z",
              "livy_statement_state": "available",
              "parent_msg_id": "0b42cf9d-ef91-45d9-84c1-e7d3b3f9e2e2",
              "queued_time": "2023-04-10T12:23:12.6999991Z",
              "session_id": "21",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "automl",
              "state": "finished",
              "statement_id": 20
            },
            "text/plain": [
              "StatementMeta(automl, 21, 20, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "optimized config {'prompt': 'Complete the following Python function:{prompt}', 'stop': ['\\nclass', '\\ndef', '\\nif', '\\nprint'], 'model': 'text-davinci-002', 'max_tokens': 347, 'n': 36, 'temperature': 0.36865945026811975}\n",
            "best result on tuning data {'expected_success': 0.7947565938469873, 'success': 0.8, 'total_cost': 1.0647, 'cost': 1.0647, 'inference_cost': 0.03736, 'training_iteration': 0, 'config': {'prompt': 2, 'stop': 0, 'subspace': {'model': 'text-davinci-002', 'max_tokens': 347, 'temperature_or_top_p': {'temperature': 0.36865945026811975}, 'n': 36}}, 'config/prompt': 2, 'config/stop': 0, 'config/subspace': {'model': 'text-davinci-002', 'max_tokens': 347, 'temperature_or_top_p': {'temperature': 0.36865945026811975}, 'n': 36}, 'experiment_tag': 'exp', 'time_total_s': 183.4394142627716}\n"
          ]
        }
      ],
      "source": [
        "print(\"optimized config\", config)\n",
        "print(\"best result on tuning data\", analysis.best_result)\n",
        "\n",
        "# save results to notebook_output.txt\n",
        "from flaml.version import __version__ as flaml_version\n",
        "import datetime\n",
        "results = {\"optimized config\": config, \"best result on tuning data\": analysis.best_result,}\n",
        "result_info_dict = {\"result_name\": \"integrate_openai.ipynb + optimized config and best result on tuning data\",\n",
        "                    \"flaml_version\": flaml_version, \n",
        "                    \"time\": datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                     \"results\": results}\n",
        "result_info = \"result name: {result_name}, flaml version: {flaml_version}, time: {time}, results: {results}\".format(**result_info_dict)\n",
        "with open(\"notebook_output.txt\", \"a\") as f:\n",
        "    f.write(\"\\n\")\n",
        "    f.write(result_info)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "### Make a request with the tuned config\n",
        "\n",
        "We can apply the tuned config on the request for an example task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-24T23:26:38.359902Z",
          "iopub.status.busy": "2023-02-24T23:26:38.359506Z",
          "iopub.status.idle": "2023-02-24T23:26:39.343921Z",
          "shell.execute_reply": "2023-02-24T23:26:39.343051Z"
        },
        "slideshow": {
          "slide_type": "subslide"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-04-10T12:28:10.2192853Z",
              "execution_start_time": "2023-04-10T12:28:06.7618336Z",
              "livy_statement_state": "available",
              "parent_msg_id": "f2acedb0-8562-4a7b-abfc-7334200f5396",
              "queued_time": "2023-04-10T12:23:12.7903942Z",
              "session_id": "21",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "automl",
              "state": "finished",
              "statement_id": 21
            },
            "text/plain": [
              "StatementMeta(automl, 21, 21, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "response on an example data instance: {\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    # your code here\\n    return [abs(game[i] - guess[i]) for i in range(len(game))]\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 1,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    # your code here\\n    pass\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 2,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    # your code here\\n    return [abs(game[i]-guess[i]) for i in range(len(game))]\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 3,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    # your code here\\n    return [abs(game[i] - guess[i]) for i in range(len(game))]\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 4,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    return [abs(game[i] - guess[i]) for i in range(len(game))]\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 5,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    pass\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 6,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    # your code here\\n    for i in range(len(game)):\\n        if game[i] == guess[i]:\\n            guess[i] = 0\\n        else:\\n            guess[i] = abs(game[i] - guess[i])\\n    return guess\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 7,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    results = []\\n    for i in range(len(game)):\\n        results.append(abs(game[i]-guess[i]))\\n    return results\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 8,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    # your code here\\n    results = []\\n    for i in range(len(game)):\\n        results.append(abs(game[i]-guess[i]))\\n    return results\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 9,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    return [abs(game[i]-guess[i]) for i in range(len(game))]\\n\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 10,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    return [abs(game[i] - guess[i]) for i in range(len(game))]\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 11,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    # your code here\\n    return [abs(game[i] - guess[i]) for i in range(len(game))]\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 12,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    return [abs(game[i]-guess[i]) for i in range(len(game))]\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 13,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    return [abs(game[i]-guess[i]) for i in range(len(game))]\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 14,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    # your code here\\n    return [abs(game[i] - guess[i]) for i in range(len(game))]\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 15,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    # your code here\\n    return [abs(game[i] - guess[i]) for i in range(len(game))]\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 16,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    return [abs(game[i]-guess[i]) for i in range(len(game))]\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 17,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    # your code here\\n    pass\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 18,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    pass\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 19,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    # your code here\\n    return [abs(game[i]-guess[i]) for i in range(len(game))]\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 20,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    return [abs(game[i]-guess[i]) for i in range(len(game))]\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 21,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    return [abs(game[i] - guess[i]) for i in range(len(game))]\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 22,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    pass\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 23,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    diffs = []\\n    for i in range(len(game)):\\n        diffs.append(abs(game[i] - guess[i]))\\n    return diffs\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 24,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    return [abs(game[i]-guess[i]) for i in range(len(game))]\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 25,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    \\n    # your code goes here\\n    results = []\\n    for i in range(len(game)):\\n        if game[i] == guess[i]:\\n            results.append(0)\\n        else:\\n            results.append(abs(game[i] - guess[i]))\\n    return results\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 26,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    \\n    return [abs(game[i]-guess[i]) for i in range(len(game))]\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 27,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    \\n    # your code here\\n    return [abs(game[i]-guess[i]) for i in range(len(game))]\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 28,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    return [abs(game[i] - guess[i]) for i in range(len(game))]\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 29,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    return [abs(game[i]-guess[i]) for i in range(len(game))]\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 30,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    return [abs(game[i]-guess[i]) for i in range(len(game))]\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 31,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    \\n    # your code here\\n    return [abs(game[i] - guess[i]) for i in range(len(game))]\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 32,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    for i in range(len(game)):\\n        if game[i] == guess[i]:\\n            guess[i] = 0\\n        else:\\n            guess[i] = abs(game[i] - guess[i])\\n    return guess\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 33,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    return abs(game - guess)\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 34,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    # your code here\\n    pass\"\n",
            "    },\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 35,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"    return [abs(game[i]-guess[i]) for i in range(len(game))]\"\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1681129686,\n",
            "  \"id\": \"cmpl-73kusgH0NZ6dq8k0GGgC8FsQ5rdvz\",\n",
            "  \"model\": \"text-davinci-002\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 965,\n",
            "    \"prompt_tokens\": 246,\n",
            "    \"total_tokens\": 1211\n",
            "  }\n",
            "}\n",
            "metric_results on the example data instance: {'expected_success': 1.0, 'success': True}\n"
          ]
        }
      ],
      "source": [
        "responses = oai.Completion.create(context=tune_data[1], **config)\n",
        "metric_results = success_metrics([response[\"message\"][\"content\"] if config[\"model\"] in oai.Completion.chat_models else response[\"text\"] for response in responses[\"choices\"]], **tune_data[1])\n",
        "print(\"response on an example data instance:\", responses)\n",
        "print(\"metric_results on the example data instance:\", metric_results)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate the success rate on the test data\n",
        "\n",
        "You can use flaml's `oai.Completion.test` to evaluate the performance of an entire dataset with the tuned config. The following code will take a while to evaluate all the 144 test data instances. The cost is about $7 if you uncomment it and run it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-24T23:26:39.347295Z",
          "iopub.status.busy": "2023-02-24T23:26:39.346994Z",
          "iopub.status.idle": "2023-02-24T23:29:27.160335Z",
          "shell.execute_reply": "2023-02-24T23:29:27.159519Z"
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-04-10T12:41:05.5307913Z",
              "execution_start_time": "2023-04-10T12:28:10.4974665Z",
              "livy_statement_state": "available",
              "parent_msg_id": "8b206eb8-b758-4c95-b8a7-e39ba6de52d4",
              "queued_time": "2023-04-10T12:23:12.9312411Z",
              "session_id": "21",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "automl",
              "state": "finished",
              "statement_id": 22
            },
            "text/plain": [
              "StatementMeta(automl, 21, 22, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "performance on test data with the tuned config: {'expected_success': 0.7388060083964307, 'success': 0.7777777777777778, 'cost': 5.72968, 'inference_cost': 0.03978944444444445}\n"
          ]
        }
      ],
      "source": [
        "result = oai.Completion.test(test_data, config, success_metrics)\n",
        "print(\"performance on test data with the tuned config:\", result)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result will vary with the inference budget and optimization budget.\n"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
