{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tune neural networks with lexicographic preference across objectives\n",
        "This example is to tune neural networks model with two objectives \"error_rate\", \"flops\" on FashionMnist dataset. \n",
        "\n",
        "**Requirements.** This notebook requires:"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": "16",
              "statement_id": -1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-04-10T09:17:54.9444636Z",
              "session_start_time": null,
              "execution_start_time": "2023-04-10T09:23:39.3893128Z",
              "execution_finish_time": "2023-04-10T09:23:39.3896368Z",
              "spark_jobs": null,
              "parent_msg_id": "563a9b66-9e20-4e3c-aae3-b6637097559b"
            },
            "text/plain": "StatementMeta(, 16, -1, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {},
          "execution_count": 1,
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flaml[synapse]==1.1.3\n  Downloading FLAML-1.1.3-py3-none-any.whl (224 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.2/224.2 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting xgboost==1.6.1\n  Downloading xgboost-1.6.1-py3-none-manylinux2014_x86_64.whl (192.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.9/192.9 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting pandas==1.5.1\n  Downloading pandas-1.5.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m166.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting numpy==1.23.4\n  Downloading numpy-1.23.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m144.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting openml\n  Downloading openml-0.13.1.tar.gz (127 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.6/127.6 KB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\n\u001b[?25hCollecting thop\n  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\nCollecting torch\n  Downloading torch-2.0.0-cp38-cp38-manylinux1_x86_64.whl (619.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchvision\n  Downloading torchvision-0.15.1-cp38-cp38-manylinux1_x86_64.whl (33.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m119.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting scikit-learn>=0.24\n  Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m145.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting lightgbm>=2.3.1\n  Downloading lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m174.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting scipy>=1.4.1\n  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m113.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting pyspark>=3.0.0\n  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\n\u001b[?25hCollecting joblibspark>=0.5.0\n  Downloading joblibspark-0.5.1-py3-none-any.whl (15 kB)\nCollecting optuna==2.8.0\n  Downloading optuna-2.8.0-py3-none-any.whl (301 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 KB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pytz>=2020.1\n  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 KB\u001b[0m \u001b[31m121.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting python-dateutil>=2.8.1\n  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 KB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting cliff\n  Downloading cliff-4.2.0-py3-none-any.whl (81 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 KB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tqdm\n  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 KB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting alembic\n  Downloading alembic-1.10.3-py3-none-any.whl (212 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.3/212.3 KB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting colorlog\n  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\nCollecting packaging>=20.0\n  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 KB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting sqlalchemy>=1.1.0\n  Downloading SQLAlchemy-2.0.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m186.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting cmaes>=0.8.2\n  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\nCollecting liac-arff>=2.4.0\n  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\n\u001b[?25hCollecting xmltodict\n  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\nCollecting requests\n  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting minio\n  Downloading minio-7.1.14-py3-none-any.whl (77 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.2/77.2 KB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pyarrow\n  Downloading pyarrow-11.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 KB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting typing-extensions\n  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\nCollecting sympy\n  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m178.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91\n  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting networkx\n  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m169.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101\n  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m165.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m141.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting jinja2\n  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 KB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting triton==2.0.0\n  Downloading triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.2/63.2 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 KB\u001b[0m \u001b[31m154.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting filelock\n  Downloading filelock-3.11.0-py3-none-any.whl (10.0 kB)\nCollecting nvidia-cudnn-cu11==8.5.0.96\n  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting setuptools\n  Downloading setuptools-67.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m155.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting wheel\n  Downloading wheel-0.40.0-py3-none-any.whl (64 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 KB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting lit\n  Downloading lit-16.0.0.tar.gz (144 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 KB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\n\u001b[?25hCollecting cmake\n  Downloading cmake-3.26.1-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m124.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0\n  Downloading Pillow-9.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m171.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting joblib>=0.14\n  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 KB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting py4j==0.10.9.5\n  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting six>=1.5\n  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\nCollecting threadpoolctl>=2.0.0\n  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\nCollecting MarkupSafe>=2.0\n  Downloading MarkupSafe-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nCollecting certifi\n  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 KB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting urllib3\n  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 KB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting idna<4,>=2.5\n  Downloading idna-3.4-py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 KB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting charset-normalizer<4,>=2\n  Downloading charset_normalizer-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (195 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.9/195.9 KB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting mpmath>=0.19\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m126.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting greenlet!=0.4.17\n  Downloading greenlet-2.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (618 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m618.5/618.5 KB\u001b[0m \u001b[31m132.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting Mako\n  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting importlib-resources\n  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\nCollecting importlib-metadata\n  Downloading importlib_metadata-6.3.0-py3-none-any.whl (22 kB)\nCollecting autopage>=0.4.0\n  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\nCollecting PyYAML>=3.12\n  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m701.2/701.2 KB\u001b[0m \u001b[31m140.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting cmd2>=1.0.0\n  Downloading cmd2-2.4.3-py3-none-any.whl (147 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.2/147.2 KB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting stevedore>=2.0.1\n  Downloading stevedore-5.0.0-py3-none-any.whl (49 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 KB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting PrettyTable>=0.7.2\n  Downloading prettytable-3.7.0-py3-none-any.whl (27 kB)\nCollecting attrs>=16.3.0\n  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 KB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting wcwidth>=0.1.7\n  Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\nCollecting pyperclip>=1.6\n  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\n\u001b[?25hCollecting zipp>=0.5\n  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\nCollecting pbr!=2.1.0,>=2.0.0\n  Downloading pbr-5.11.1-py2.py3-none-any.whl (112 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.7/112.7 KB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: openml, liac-arff, pyspark, lit, pyperclip\n  Building wheel for openml (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\n\u001b[?25h  Created wheel for openml: filename=openml-0.13.1-py3-none-any.whl size=142787 sha256=98bf4c15e2a68222fde874fb564d9dea1c586efae90a7a149611b6292f1e8979\n  Stored in directory: /home/trusted-service-user/.cache/pip/wheels/c4/1c/5e/5775d391b42f19ce45a465873d8ce87da9ea56f0cd3af920c4\n  Building wheel for liac-arff (setup.py) ... \u001b[?25l-\b \bdone\n\u001b[?25h  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11731 sha256=99ea2a071c7968c594bdf742f458e26df40b59ca59b39a37999dca56f05f9b91\n  Stored in directory: /home/trusted-service-user/.cache/pip/wheels/a2/de/68/bf3972de3ecb31e32bef59a7f4c75f0687a3674c476b347c14\n  Building wheel for pyspark (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824026 sha256=d7917e6321e931ac0c162efdc4e3bf620b290564c8fb8b020caedde5ca2b7d98\n  Stored in directory: /home/trusted-service-user/.cache/pip/wheels/b1/59/a0/a1a0624b5e865fd389919c1a10f53aec9b12195d6747710baf\n  Building wheel for lit (setup.py) ... \u001b[?25l-\b \bdone\n\u001b[?25h  Created wheel for lit: filename=lit-16.0.0-py3-none-any.whl size=93583 sha256=a088bac4d343ab2c2affdeedfa99f1644de5f132819b40901fc7d86ddf7b432d\n  Stored in directory: /home/trusted-service-user/.cache/pip/wheels/30/c8/c0/9d24f63f30f4879b8efb718a11b2191ef5c8510259d1d6c392\n  Building wheel for pyperclip (setup.py) ... \u001b[?25l-\b \bdone\n\u001b[?25h  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11107 sha256=4662cdd641876927801cb3a1d3485effedb27e1ece7d55668b6b9af2b061889b\n  Stored in directory: /home/trusted-service-user/.cache/pip/wheels/7f/1a/65/84ff8c386bec21fca6d220ea1f5498a0367883a78dd5ba6122\nSuccessfully built openml liac-arff pyspark lit pyperclip\nInstalling collected packages: wcwidth, pytz, pyperclip, py4j, mpmath, lit, cmake, zipp, xmltodict, wheel, urllib3, typing-extensions, tqdm, threadpoolctl, sympy, six, setuptools, PyYAML, pyspark, PrettyTable, pillow, pbr, packaging, nvidia-nccl-cu11, nvidia-cufft-cu11, nvidia-cuda-nvrtc-cu11, numpy, networkx, MarkupSafe, liac-arff, joblib, idna, greenlet, filelock, colorlog, charset-normalizer, certifi, autopage, attrs, stevedore, sqlalchemy, scipy, requests, python-dateutil, pyarrow, nvidia-nvtx-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, minio, Mako, joblibspark, jinja2, importlib-resources, importlib-metadata, cmd2, cmaes, xgboost, scikit-learn, pandas, nvidia-cusolver-cu11, nvidia-cudnn-cu11, cliff, alembic, optuna, openml, lightgbm, flaml, triton, torch, torchvision, thop\n  Attempting uninstall: wcwidth\n    Found existing installation: wcwidth 0.2.5\n    Not uninstalling wcwidth at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'wcwidth'. No files were found to uninstall.\n  Attempting uninstall: pytz\n    Found existing installation: pytz 2021.1\n    Not uninstalling pytz at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'pytz'. No files were found to uninstall.\n  Attempting uninstall: pyperclip\n    Found existing installation: pyperclip 1.8.2\n    Not uninstalling pyperclip at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'pyperclip'. No files were found to uninstall.\n  Attempting uninstall: py4j\n    Found existing installation: py4j 0.10.9.3\n    Not uninstalling py4j at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'py4j'. No files were found to uninstall.\n  Attempting uninstall: zipp\n    Found existing installation: zipp 3.5.0\n    Not uninstalling zipp at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'zipp'. No files were found to uninstall.\n  Attempting uninstall: wheel\n    Found existing installation: wheel 0.36.2\n    Not uninstalling wheel at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'wheel'. No files were found to uninstall.\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.26.4\n    Not uninstalling urllib3 at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'urllib3'. No files were found to uninstall.\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 3.10.0.0\n    Not uninstalling typing-extensions at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'typing-extensions'. No files were found to uninstall.\n  Attempting uninstall: tqdm\n    Found existing installation: tqdm 4.61.2\n    Not uninstalling tqdm at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'tqdm'. No files were found to uninstall.\n  Attempting uninstall: threadpoolctl\n    Found existing installation: threadpoolctl 2.1.0\n    Not uninstalling threadpoolctl at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'threadpoolctl'. No files were found to uninstall.\n  Attempting uninstall: six\n    Found existing installation: six 1.16.0\n    Not uninstalling six at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'six'. No files were found to uninstall.\n  Attempting uninstall: setuptools\n    Found existing installation: setuptools 49.6.0.post20210108\n    Not uninstalling setuptools at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'setuptools'. No files were found to uninstall.\n  Attempting uninstall: PyYAML\n    Found existing installation: PyYAML 5.4.1\n    Not uninstalling pyyaml at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'PyYAML'. No files were found to uninstall.\n  Attempting uninstall: pyspark\n    Found existing installation: pyspark 3.2.1\n    Not uninstalling pyspark at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'pyspark'. No files were found to uninstall.\n  Attempting uninstall: PrettyTable\n    Found existing installation: prettytable 2.4.0\n    Not uninstalling prettytable at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'prettytable'. No files were found to uninstall.\n  Attempting uninstall: pillow\n    Found existing installation: Pillow 8.2.0\n    Not uninstalling pillow at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'Pillow'. No files were found to uninstall.\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.0\n    Not uninstalling packaging at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'packaging'. No files were found to uninstall.\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.19.4\n    Not uninstalling numpy at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'numpy'. No files were found to uninstall.\n  Attempting uninstall: networkx\n    Found existing installation: networkx 2.5.1\n    Not uninstalling networkx at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'networkx'. No files were found to uninstall.\n  Attempting uninstall: MarkupSafe\n    Found existing installation: MarkupSafe 2.0.1\n    Not uninstalling markupsafe at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'MarkupSafe'. No files were found to uninstall.\n  Attempting uninstall: liac-arff\n    Found existing installation: liac-arff 2.5.0\n    Not uninstalling liac-arff at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'liac-arff'. No files were found to uninstall.\n  Attempting uninstall: joblib\n    Found existing installation: joblib 1.0.1\n    Not uninstalling joblib at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'joblib'. No files were found to uninstall.\n  Attempting uninstall: idna\n    Found existing installation: idna 2.10\n    Not uninstalling idna at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'idna'. No files were found to uninstall.\n  Attempting uninstall: greenlet\n    Found existing installation: greenlet 1.1.0\n    Not uninstalling greenlet at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'greenlet'. No files were found to uninstall.\n  Attempting uninstall: filelock\n    Found existing installation: filelock 3.8.0\n    Not uninstalling filelock at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'filelock'. No files were found to uninstall.\n  Attempting uninstall: certifi\n    Found existing installation: certifi 2021.5.30\n    Not uninstalling certifi at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'certifi'. No files were found to uninstall.\n  Attempting uninstall: attrs\n    Found existing installation: attrs 21.2.0\n    Not uninstalling attrs at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'attrs'. No files were found to uninstall.\n  Attempting uninstall: sqlalchemy\n    Found existing installation: SQLAlchemy 1.4.20\n    Not uninstalling sqlalchemy at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'SQLAlchemy'. No files were found to uninstall.\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.5.3\n    Not uninstalling scipy at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'scipy'. No files were found to uninstall.\n  Attempting uninstall: requests\n    Found existing installation: requests 2.25.1\n    Not uninstalling requests at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'requests'. No files were found to uninstall.\n  Attempting uninstall: python-dateutil\n    Found existing installation: python-dateutil 2.8.1\n    Not uninstalling python-dateutil at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'python-dateutil'. No files were found to uninstall.\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 3.0.0\n    Not uninstalling pyarrow at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'pyarrow'. No files were found to uninstall.\n  Attempting uninstall: jinja2\n    Found existing installation: Jinja2 3.0.1\n    Not uninstalling jinja2 at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'Jinja2'. No files were found to uninstall.\n  Attempting uninstall: importlib-resources\n    Found existing installation: importlib-resources 5.10.0\n    Not uninstalling importlib-resources at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'importlib-resources'. No files were found to uninstall.\n  Attempting uninstall: importlib-metadata\n    Found existing installation: importlib-metadata 4.6.1\n    Not uninstalling importlib-metadata at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'importlib-metadata'. No files were found to uninstall.\n  Attempting uninstall: xgboost\n    Found existing installation: xgboost 1.4.0\n    Not uninstalling xgboost at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'xgboost'. No files were found to uninstall.\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 0.23.2\n    Not uninstalling scikit-learn at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'scikit-learn'. No files were found to uninstall.\n  Attempting uninstall: pandas\n    Found existing installation: pandas 1.2.3\n    Not uninstalling pandas at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'pandas'. No files were found to uninstall.\n  Attempting uninstall: lightgbm\n    Found existing installation: lightgbm 3.2.1\n    Not uninstalling lightgbm at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'lightgbm'. No files were found to uninstall.\n  Attempting uninstall: torch\n    Found existing installation: torch 1.8.1\n    Not uninstalling torch at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'torch'. No files were found to uninstall.\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.9.1\n    Not uninstalling torchvision at /home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages, outside environment /nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4\n    Can't uninstall 'torchvision'. No files were found to uninstall.\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.4.1 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\ntensorflow 2.4.1 requires typing-extensions~=3.7.4, but you have typing-extensions 4.5.0 which is incompatible.\npmdarima 1.8.2 requires numpy~=1.19.0, but you have numpy 1.23.4 which is incompatible.\nkoalas 1.8.0 requires numpy<1.20.0,>=1.14, but you have numpy 1.23.4 which is incompatible.\ngevent 21.1.2 requires greenlet<2.0,>=0.4.17; platform_python_implementation == \"CPython\", but you have greenlet 2.0.2 which is incompatible.\nazureml-dataset-runtime 1.34.0 requires pyarrow<4.0.0,>=0.17.0, but you have pyarrow 11.0.0 which is incompatible.\nazureml-core 1.34.0 requires urllib3<=1.26.6,>=1.23, but you have urllib3 1.26.15 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed Mako-1.2.4 MarkupSafe-2.1.2 PrettyTable-3.7.0 PyYAML-6.0 alembic-1.10.3 attrs-22.2.0 autopage-0.5.1 certifi-2022.12.7 charset-normalizer-3.1.0 cliff-4.2.0 cmaes-0.9.1 cmake-3.26.1 cmd2-2.4.3 colorlog-6.7.0 filelock-3.11.0 flaml-1.1.3 greenlet-2.0.2 idna-3.4 importlib-metadata-6.3.0 importlib-resources-5.12.0 jinja2-3.1.2 joblib-1.2.0 joblibspark-0.5.1 liac-arff-2.5.0 lightgbm-3.3.5 lit-16.0.0 minio-7.1.14 mpmath-1.3.0 networkx-3.1 numpy-1.23.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 openml-0.13.1 optuna-2.8.0 packaging-23.0 pandas-1.5.1 pbr-5.11.1 pillow-9.5.0 py4j-0.10.9.5 pyarrow-11.0.0 pyperclip-1.8.2 pyspark-3.3.2 python-dateutil-2.8.2 pytz-2023.3 requests-2.28.2 scikit-learn-1.2.2 scipy-1.10.1 setuptools-67.6.1 six-1.16.0 sqlalchemy-2.0.9 stevedore-5.0.0 sympy-1.11.1 thop-0.1.1.post2209072238 threadpoolctl-3.1.0 torch-2.0.0 torchvision-0.15.1 tqdm-4.65.0 triton-2.0.0 typing-extensions-4.5.0 urllib3-1.26.15 wcwidth-0.2.6 wheel-0.40.0 xgboost-1.6.1 xmltodict-0.13.0 zipp-3.15.0\n\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\nYou should consider upgrading via the '/nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {},
          "execution_count": 1,
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: PySpark kernel has been restarted to use updated packages.\n\n"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "source": [
        "%pip install flaml[synapse]==1.1.3 xgboost==1.6.1 pandas==1.5.1 numpy==1.23.4 openml thop torch torchvision --force-reinstall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "automl",
              "session_id": "16",
              "statement_id": 8,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-04-10T09:17:54.9470438Z",
              "session_start_time": null,
              "execution_start_time": "2023-04-10T09:23:42.011846Z",
              "execution_finish_time": "2023-04-10T09:24:18.7009762Z",
              "spark_jobs": null,
              "parent_msg_id": "fa4a9aac-856d-4121-bc22-deeb0a5af9b3"
            },
            "text/plain": "StatementMeta(automl, 16, 8, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages/dask/dataframe/backends.py:187: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages/dask/dataframe/backends.py:187: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n/home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages/dask/dataframe/backends.py:187: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n100%|██████████| 26421880/26421880 [00:01<00:00, 14417250.55it/s]\n100%|██████████| 29515/29515 [00:00<00:00, 233674.01it/s]\n100%|██████████| 4422102/4422102 [00:00<00:00, 4635054.85it/s]\n100%|██████████| 5148/5148 [00:00<00:00, 22283051.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (urllib3 1.26.15 (/nfs4/pyenv-a9f3cd17-6b27-4a01-9785-88270b24cfc4/lib/python3.8/site-packages), Requirement.parse('urllib3<=1.26.6,>=1.23')).\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1681118400570_0001/container_1681118400570_0001_01_000001/data/FashionMNIST/raw/train-images-idx3-ubyte.gz\nExtracting /mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1681118400570_0001/container_1681118400570_0001_01_000001/data/FashionMNIST/raw/train-images-idx3-ubyte.gz to /mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1681118400570_0001/container_1681118400570_0001_01_000001/data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1681118400570_0001/container_1681118400570_0001_01_000001/data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\nExtracting /mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1681118400570_0001/container_1681118400570_0001_01_000001/data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1681118400570_0001/container_1681118400570_0001_01_000001/data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1681118400570_0001/container_1681118400570_0001_01_000001/data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\nExtracting /mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1681118400570_0001/container_1681118400570_0001_01_000001/data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1681118400570_0001/container_1681118400570_0001_01_000001/data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1681118400570_0001/container_1681118400570_0001_01_000001/data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\nExtracting /mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1681118400570_0001/container_1681118400570_0001_01_000001/data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1681118400570_0001/container_1681118400570_0001_01_000001/data/FashionMNIST/raw\n\n"
          ]
        }
      ],
      "metadata": {},
      "source": [
        "import torch\n",
        "import thop\n",
        "import torch.nn as nn\n",
        "from flaml import tune\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "DEVICE = torch.device(\"cpu\")\n",
        "BATCHSIZE = 128\n",
        "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
        "N_VALID_EXAMPLES = BATCHSIZE * 10\n",
        "data_dir = os.path.abspath(\"data\")\n",
        "\n",
        "train_dataset = torchvision.datasets.FashionMNIST(\n",
        "    data_dir,\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    torch.utils.data.Subset(train_dataset, list(range(N_TRAIN_EXAMPLES))),\n",
        "    batch_size=BATCHSIZE,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "val_dataset = torchvision.datasets.FashionMNIST(\n",
        "    data_dir, train=False, transform=torchvision.transforms.ToTensor()\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    torch.utils.data.Subset(val_dataset, list(range(N_VALID_EXAMPLES))),\n",
        "    batch_size=BATCHSIZE,\n",
        "    shuffle=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Specify the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "automl",
              "session_id": "16",
              "statement_id": 9,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-04-10T09:17:54.9487762Z",
              "session_start_time": null,
              "execution_start_time": "2023-04-10T09:24:18.9489721Z",
              "execution_finish_time": "2023-04-10T09:24:19.2382626Z",
              "spark_jobs": null,
              "parent_msg_id": "5ce8f044-2f28-4e83-b5d6-f61db80bf6e8"
            },
            "text/plain": "StatementMeta(automl, 16, 9, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "def define_model(configuration):\n",
        "    n_layers = configuration[\"n_layers\"]\n",
        "    layers = []\n",
        "    in_features = 28 * 28\n",
        "    for i in range(n_layers):\n",
        "        out_features = configuration[\"n_units_l{}\".format(i)]\n",
        "        layers.append(nn.Linear(in_features, out_features))\n",
        "        layers.append(nn.ReLU())\n",
        "        p = configuration[\"dropout_{}\".format(i)]\n",
        "        layers.append(nn.Dropout(p))\n",
        "        in_features = out_features\n",
        "    layers.append(nn.Linear(in_features, 10))\n",
        "    layers.append(nn.LogSoftmax(dim=1))\n",
        "    return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "automl",
              "session_id": "16",
              "statement_id": 10,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-04-10T09:17:54.9499625Z",
              "session_start_time": null,
              "execution_start_time": "2023-04-10T09:24:19.5326528Z",
              "execution_finish_time": "2023-04-10T09:24:19.8007916Z",
              "spark_jobs": null,
              "parent_msg_id": "159a1c18-166a-4e7c-a773-d282340b785f"
            },
            "text/plain": "StatementMeta(automl, 16, 10, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "def train_model(model, optimizer, train_loader):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.view(-1, 28 * 28).to(DEVICE), target.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        F.nll_loss(model(data), target).backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metrics "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "automl",
              "session_id": "16",
              "statement_id": 11,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-04-10T09:17:54.9518608Z",
              "session_start_time": null,
              "execution_start_time": "2023-04-10T09:24:20.041069Z",
              "execution_finish_time": "2023-04-10T09:24:20.3062406Z",
              "spark_jobs": null,
              "parent_msg_id": "8eb18934-4f05-4289-a277-b35ece10e72c"
            },
            "text/plain": "StatementMeta(automl, 16, 11, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "def eval_model(model, valid_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "            data, target = data.view(-1, 28 * 28).to(DEVICE), target.to(DEVICE)\n",
        "            pred = model(data).argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    accuracy = correct / N_VALID_EXAMPLES\n",
        "    flops, params = thop.profile(\n",
        "        model, inputs=(torch.randn(1, 28 * 28).to(DEVICE),), verbose=False\n",
        "    )\n",
        "    return np.log2(flops), 1 - accuracy, params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "automl",
              "session_id": "16",
              "statement_id": 12,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-04-10T09:17:54.9542632Z",
              "session_start_time": null,
              "execution_start_time": "2023-04-10T09:24:20.5540624Z",
              "execution_finish_time": "2023-04-10T09:24:20.8207369Z",
              "spark_jobs": null,
              "parent_msg_id": "f6108930-7f36-48e4-a7aa-c347dd2dfed7"
            },
            "text/plain": "StatementMeta(automl, 16, 12, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "def evaluate_function(configuration):\n",
        "    model = define_model(configuration).to(DEVICE)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), configuration[\"lr\"])\n",
        "    n_epoch = configuration[\"n_epoch\"]\n",
        "    for epoch in range(n_epoch):\n",
        "        train_model(model, optimizer, train_loader)\n",
        "    flops, error_rate, params = eval_model(model, val_loader)\n",
        "    return {\"error_rate\": error_rate, \"flops\": flops, \"params\": params}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lexicographic information across objectives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "automl",
              "session_id": "16",
              "statement_id": 13,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-04-10T09:17:54.9568833Z",
              "session_start_time": null,
              "execution_start_time": "2023-04-10T09:24:21.0990483Z",
              "execution_finish_time": "2023-04-10T09:24:21.3513794Z",
              "spark_jobs": null,
              "parent_msg_id": "90f87cf2-0b24-411d-b86d-8b3237e8f5b4"
            },
            "text/plain": "StatementMeta(automl, 16, 13, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "lexico_objectives = {}\n",
        "lexico_objectives[\"metrics\"] = [\"error_rate\", \"flops\"]\n",
        "lexico_objectives[\"tolerances\"] = {\"error_rate\": 0.02, \"flops\": 0.0}\n",
        "lexico_objectives[\"targets\"] = {\"error_rate\": 0.0, \"flops\": 0.0}\n",
        "lexico_objectives[\"modes\"] = [\"min\", \"min\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Search space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "automl",
              "session_id": "16",
              "statement_id": 14,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-04-10T09:17:54.9587712Z",
              "session_start_time": null,
              "execution_start_time": "2023-04-10T09:24:21.6065572Z",
              "execution_finish_time": "2023-04-10T09:24:21.9009937Z",
              "spark_jobs": null,
              "parent_msg_id": "c28f6858-25a3-4d53-9d4e-456cecc0040c"
            },
            "text/plain": "StatementMeta(automl, 16, 14, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "search_space = {\n",
        "    \"n_layers\": tune.randint(lower=1, upper=3),\n",
        "    \"n_units_l0\": tune.randint(lower=4, upper=128),\n",
        "    \"n_units_l1\": tune.randint(lower=4, upper=128),\n",
        "    \"n_units_l2\": tune.randint(lower=4, upper=128),\n",
        "    \"dropout_0\": tune.uniform(lower=0.2, upper=0.5),\n",
        "    \"dropout_1\": tune.uniform(lower=0.2, upper=0.5),\n",
        "    \"dropout_2\": tune.uniform(lower=0.2, upper=0.5),\n",
        "    \"lr\": tune.loguniform(lower=1e-5, upper=1e-1),\n",
        "    \"n_epoch\": tune.randint(lower=1, upper=20),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Launch the tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "automl",
              "session_id": "16",
              "statement_id": 15,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-04-10T09:17:54.960942Z",
              "session_start_time": null,
              "execution_start_time": "2023-04-10T09:24:22.1443867Z",
              "execution_finish_time": "2023-04-10T09:26:04.0039282Z",
              "spark_jobs": null,
              "parent_msg_id": "e8a244bb-2872-404a-b4e6-162e7dd5ee80"
            },
            "text/plain": "StatementMeta(automl, 16, 15, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.tune.tune: 04-10 09:24:22] {500} WARNING - If lexico_objectives is not None, search_alg is forced to be CFO\n[flaml.tune.tune: 04-10 09:24:22] {534} INFO - Using search algorithm CFO.\n[flaml.tune.tune: 04-10 09:24:22] {728} INFO - Number of trials: 1/-1, 1 RUNNING, 0 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   14.7s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   14.7s finished\n[flaml.tune.tune: 04-10 09:24:36] {751} INFO - Brief result: {'error_rate': 0.87578125, 'flops': 11.632995197142957, 'params': 3190.0}\n[flaml.tune.tune: 04-10 09:24:36] {728} INFO - Number of trials: 2/-1, 1 RUNNING, 1 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s finished\n[flaml.tune.tune: 04-10 09:24:38] {751} INFO - Brief result: {'error_rate': 0.81953125, 'flops': 11.632995197142957, 'params': 3190.0}\n[flaml.tune.tune: 04-10 09:24:38] {728} INFO - Number of trials: 3/-1, 1 RUNNING, 2 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s finished\n[flaml.tune.tune: 04-10 09:24:39] {751} INFO - Brief result: {'error_rate': 0.846875, 'flops': 11.95492329203032, 'params': 3985.0}\n[flaml.tune.tune: 04-10 09:24:39] {728} INFO - Number of trials: 4/-1, 1 RUNNING, 3 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s finished\n[flaml.tune.tune: 04-10 09:24:41] {751} INFO - Brief result: {'error_rate': 0.73828125, 'flops': 11.632995197142957, 'params': 3190.0}\n[flaml.tune.tune: 04-10 09:24:41] {728} INFO - Number of trials: 5/-1, 1 RUNNING, 4 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.1s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.1s finished\n[flaml.tune.tune: 04-10 09:24:54] {751} INFO - Brief result: {'error_rate': 0.565625, 'flops': 13.33343491528405, 'params': 10345.0}\n[flaml.tune.tune: 04-10 09:24:54] {728} INFO - Number of trials: 6/-1, 1 RUNNING, 5 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s finished\n[flaml.tune.tune: 04-10 09:24:56] {751} INFO - Brief result: {'error_rate': 0.40546875000000004, 'flops': 13.440350119200563, 'params': 11140.0}\n[flaml.tune.tune: 04-10 09:24:56] {728} INFO - Number of trials: 7/-1, 1 RUNNING, 6 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s finished\n[flaml.tune.tune: 04-10 09:24:57] {751} INFO - Brief result: {'error_rate': 0.57890625, 'flops': 13.33343491528405, 'params': 10345.0}\n[flaml.tune.tune: 04-10 09:24:57] {728} INFO - Number of trials: 8/-1, 1 RUNNING, 7 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s finished\n[flaml.tune.tune: 04-10 09:24:59] {751} INFO - Brief result: {'error_rate': 0.46328125, 'flops': 12.80292019858527, 'params': 7165.0}\n[flaml.tune.tune: 04-10 09:24:59] {728} INFO - Number of trials: 9/-1, 1 RUNNING, 8 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s finished\n[flaml.tune.tune: 04-10 09:25:01] {751} INFO - Brief result: {'error_rate': 0.621875, 'flops': 13.880922710586542, 'params': 15115.0}\n[flaml.tune.tune: 04-10 09:25:01] {728} INFO - Number of trials: 10/-1, 1 RUNNING, 9 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.4s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.4s finished\n[flaml.tune.tune: 04-10 09:25:03] {751} INFO - Brief result: {'error_rate': 0.20937499999999998, 'flops': 14.49097619227053, 'params': 23065.0}\n[flaml.tune.tune: 04-10 09:25:03] {728} INFO - Number of trials: 11/-1, 1 RUNNING, 10 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s finished\n[flaml.tune.tune: 04-10 09:25:05] {751} INFO - Brief result: {'error_rate': 0.45625000000000004, 'flops': 13.440350119200563, 'params': 11140.0}\n[flaml.tune.tune: 04-10 09:25:05] {728} INFO - Number of trials: 12/-1, 1 RUNNING, 11 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s finished\n[flaml.tune.tune: 04-10 09:25:07] {751} INFO - Brief result: {'error_rate': 0.19609374999999996, 'flops': 14.217957697864113, 'params': 19090.0}\n[flaml.tune.tune: 04-10 09:25:07] {728} INFO - Number of trials: 13/-1, 1 RUNNING, 12 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s finished\n[flaml.tune.tune: 04-10 09:25:10] {751} INFO - Brief result: {'error_rate': 0.21406250000000004, 'flops': 14.49097619227053, 'params': 23065.0}\n[flaml.tune.tune: 04-10 09:25:10] {728} INFO - Number of trials: 14/-1, 1 RUNNING, 13 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s finished\n[flaml.tune.tune: 04-10 09:25:12] {751} INFO - Brief result: {'error_rate': 0.19062500000000004, 'flops': 14.720458038393296, 'params': 27040.0}\n[flaml.tune.tune: 04-10 09:25:12] {728} INFO - Number of trials: 15/-1, 1 RUNNING, 14 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s finished\n[flaml.tune.tune: 04-10 09:25:15] {751} INFO - Brief result: {'error_rate': 0.24140625000000004, 'flops': 13.440350119200563, 'params': 11140.0}\n[flaml.tune.tune: 04-10 09:25:15] {728} INFO - Number of trials: 16/-1, 1 RUNNING, 15 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s finished\n[flaml.tune.tune: 04-10 09:25:18] {751} INFO - Brief result: {'error_rate': 0.19218749999999996, 'flops': 13.632995197142957, 'params': 12730.0}\n[flaml.tune.tune: 04-10 09:25:18] {728} INFO - Number of trials: 17/-1, 1 RUNNING, 16 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s finished\n[flaml.tune.tune: 04-10 09:25:20] {751} INFO - Brief result: {'error_rate': 0.18593749999999998, 'flops': 14.217957697864113, 'params': 19090.0}\n[flaml.tune.tune: 04-10 09:25:20] {728} INFO - Number of trials: 18/-1, 1 RUNNING, 17 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.1s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.1s finished\n[flaml.tune.tune: 04-10 09:25:24] {751} INFO - Brief result: {'error_rate': 0.26249999999999996, 'flops': 11.95492329203032, 'params': 3985.0}\n[flaml.tune.tune: 04-10 09:25:24] {728} INFO - Number of trials: 19/-1, 1 RUNNING, 18 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.7s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.7s finished\n[flaml.tune.tune: 04-10 09:25:26] {751} INFO - Brief result: {'error_rate': 0.19062500000000004, 'flops': 14.387882699306425, 'params': 21475.0}\n[flaml.tune.tune: 04-10 09:25:26] {728} INFO - Number of trials: 20/-1, 1 RUNNING, 19 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s finished\n[flaml.tune.tune: 04-10 09:25:29] {751} INFO - Brief result: {'error_rate': 0.3515625, 'flops': 11.632995197142957, 'params': 3190.0}\n[flaml.tune.tune: 04-10 09:25:29] {728} INFO - Number of trials: 21/-1, 1 RUNNING, 20 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.2s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.2s finished\n[flaml.tune.tune: 04-10 09:25:32] {751} INFO - Brief result: {'error_rate': 0.17031249999999998, 'flops': 15.059259951845055, 'params': 34195.0}\n[flaml.tune.tune: 04-10 09:25:32] {728} INFO - Number of trials: 22/-1, 1 RUNNING, 21 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.4s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.4s finished\n[flaml.tune.tune: 04-10 09:25:34] {751} INFO - Brief result: {'error_rate': 0.19296875000000002, 'flops': 14.632995197142957, 'params': 25450.0}\n[flaml.tune.tune: 04-10 09:25:34] {728} INFO - Number of trials: 23/-1, 1 RUNNING, 22 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.0s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.0s finished\n[flaml.tune.tune: 04-10 09:25:38] {751} INFO - Brief result: {'error_rate': 0.20859375000000002, 'flops': 15.387882699306425, 'params': 42940.0}\n[flaml.tune.tune: 04-10 09:25:38] {728} INFO - Number of trials: 24/-1, 1 RUNNING, 23 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s finished\n[flaml.tune.tune: 04-10 09:25:42] {751} INFO - Brief result: {'error_rate': 0.18359375, 'flops': 15.49097619227053, 'params': 46120.0}\n[flaml.tune.tune: 04-10 09:25:42] {728} INFO - Number of trials: 25/-1, 1 RUNNING, 24 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s finished\n[flaml.tune.tune: 04-10 09:25:45] {751} INFO - Brief result: {'error_rate': 0.18203124999999998, 'flops': 14.440350119200563, 'params': 22270.0}\n[flaml.tune.tune: 04-10 09:25:45] {728} INFO - Number of trials: 26/-1, 1 RUNNING, 25 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s finished\n[flaml.tune.tune: 04-10 09:25:47] {751} INFO - Brief result: {'error_rate': 0.24375000000000002, 'flops': 13.440350119200563, 'params': 11140.0}\n[flaml.tune.tune: 04-10 09:25:47] {728} INFO - Number of trials: 27/-1, 1 RUNNING, 26 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s finished\n[flaml.tune.tune: 04-10 09:25:50] {751} INFO - Brief result: {'error_rate': 0.18828124999999996, 'flops': 15.025312619921719, 'params': 33400.0}\n[flaml.tune.tune: 04-10 09:25:50] {728} INFO - Number of trials: 28/-1, 1 RUNNING, 27 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.4s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.4s finished\n[flaml.tune.tune: 04-10 09:25:52] {751} INFO - Brief result: {'error_rate': 0.22187500000000004, 'flops': 14.025312619921719, 'params': 16705.0}\n[flaml.tune.tune: 04-10 09:25:52] {728} INFO - Number of trials: 29/-1, 1 RUNNING, 28 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s finished\n[flaml.tune.tune: 04-10 09:25:55] {751} INFO - Brief result: {'error_rate': 0.19140625, 'flops': 14.762278214087925, 'params': 27835.0}\n[flaml.tune.tune: 04-10 09:25:55] {728} INFO - Number of trials: 30/-1, 1 RUNNING, 29 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s finished\n[flaml.tune.tune: 04-10 09:25:58] {751} INFO - Brief result: {'error_rate': 0.17734375000000002, 'flops': 14.440350119200563, 'params': 22270.0}\n[flaml.tune.tune: 04-10 09:25:58] {728} INFO - Number of trials: 31/-1, 1 RUNNING, 30 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s finished\n[flaml.tune.tune: 04-10 09:26:01] {751} INFO - Brief result: {'error_rate': 0.20390624999999996, 'flops': 14.440350119200563, 'params': 22270.0}\n[flaml.tune.tune: 04-10 09:26:01] {728} INFO - Number of trials: 32/-1, 1 RUNNING, 31 TERMINATED\n[Parallel(n_jobs=1)]: Using backend SparkDistributedBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s finished\n[flaml.tune.tune: 04-10 09:26:03] {751} INFO - Brief result: {'error_rate': 0.17031249999999998, 'flops': 15.360915651706158, 'params': 42145.0}\n{'error_rate': 0.18593749999999998, 'flops': 14.217957697864113, 'params': 19090.0, 'training_iteration': 0, 'config': {'n_layers': 1, 'n_units_l0': 24, 'n_units_l1': 4, 'n_units_l2': 15, 'n_epoch': 7, 'dropout_0': 0.20574260667932284, 'dropout_1': 0.27811598975551965, 'dropout_2': 0.2749369760511058, 'lr': 0.004939820852118423}, 'config/n_layers': 1, 'config/n_units_l0': 24, 'config/n_units_l1': 4, 'config/n_units_l2': 15, 'config/n_epoch': 7, 'config/dropout_0': 0.20574260667932284, 'config/dropout_1': 0.27811598975551965, 'config/dropout_2': 0.2749369760511058, 'config/lr': 0.004939820852118423, 'experiment_tag': 'exp', 'time_total_s': 2.58545184135437}\n"
          ]
        }
      ],
      "metadata": {},
      "source": [
        "low_cost_partial_config = {\n",
        "    \"n_layers\": 1,\n",
        "    \"n_units_l0\": 4,\n",
        "    \"n_units_l1\": 4,\n",
        "    \"n_units_l2\": 4,\n",
        "    \"n_epoch\": 1,\n",
        "}\n",
        "\n",
        "analysis = tune.run(\n",
        "    evaluate_function,\n",
        "    num_samples=-1,\n",
        "    time_budget_s=100,\n",
        "    config=search_space,\n",
        "    use_spark=True,\n",
        "    lexico_objectives=lexico_objectives,\n",
        "    low_cost_partial_config=low_cost_partial_config,\n",
        ")\n",
        "result = analysis.best_result\n",
        "print(result)"
      ]
    }
  ]
}
