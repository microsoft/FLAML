{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved. \n",
    "\n",
    "Licensed under the MIT License.\n",
    "\n",
    "# FineTuning NLP Models with FLAML Library\n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "FLAML is a Python library (https://github.com/microsoft/FLAML) designed to automatically produce accurate machine learning models \n",
    "with low computational cost. It is fast and economical. The simple and lightweight design makes it easy to use and extend, such as adding new learners. FLAML can \n",
    "- serve as an economical AutoML engine,\n",
    "- be used as a fast hyperparameter tuning tool, or \n",
    "- be embedded in self-tuning software that requires low latency & resource in repetitive\n",
    "   tuning tasks.\n",
    "\n",
    "In this notebook, we demonstrate how to use the FLAML library to fine tune an NLP language model with hyperparameter search. We have tested this notebook on a server with 4 NVidia V100 GPU (32GB) and 400GB CPU Ram.\n",
    "\n",
    "FLAML requires `Python>=3.6`. To run this notebook example, please install flaml with the `nlp,ray,notebook` and `blendsearch` option:\n",
    "```bash\n",
    "pip install flaml[nlp,ray,notebook,blendsearch];\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flaml[blendsearch,nlp,notebook,ray] in /data/xliu127/projects/hyperopt/FLAML (0.10.0)\n",
      "Collecting NumPy>=1.16.2\n",
      "  Downloading numpy-1.22.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting lightgbm>=2.3.1\n",
      "  Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: xgboost<=1.3.3,>=0.90 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.3.3)\n",
      "Collecting scipy>=1.4.1\n",
      "  Downloading scipy-1.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pandas>=1.1.4\n",
      "  Downloading pandas-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn>=0.24\n",
      "  Downloading scikit_learn-1.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting optuna==2.8.0\n",
      "  Downloading optuna-2.8.0-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 KB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: transformers>=4.14 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (4.17.0)\n",
      "Requirement already satisfied: datasets in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.18.4)\n",
      "Requirement already satisfied: torch in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.11.0)\n",
      "Requirement already satisfied: seqeval in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.2.2)\n",
      "Requirement already satisfied: nltk in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (3.7)\n",
      "Requirement already satisfied: rouge_score in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (0.0.4)\n",
      "Requirement already satisfied: ray[tune]~=1.10 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.11.0)\n",
      "Collecting openml==0.10.2\n",
      "  Downloading openml-0.10.2.tar.gz (158 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.0/159.0 KB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jupyter\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.5.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting rgf-python\n",
      "  Downloading rgf_python-3.12.0-py3-none-manylinux1_x86_64.whl (757 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.8/757.8 KB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting catboost>=0.26\n",
      "  Downloading catboost-1.0.4-cp38-none-manylinux1_x86_64.whl (76.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting liac-arff>=2.4.0\n",
      "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting xmltodict\n",
      "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting requests\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 KB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from openml==0.10.2->flaml[blendsearch,nlp,notebook,ray]) (2.8.2)\n",
      "Requirement already satisfied: tqdm in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (4.63.0)\n",
      "Collecting cmaes>=0.8.2\n",
      "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
      "Collecting cliff\n",
      "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 KB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sqlalchemy>=1.1.0\n",
      "  Downloading SQLAlchemy-1.4.32-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: alembic in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (1.7.6)\n",
      "Collecting packaging>=20.0\n",
      "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 KB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting colorlog\n",
      "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: six in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from catboost>=0.26->flaml[blendsearch,nlp,notebook,ray]) (1.16.0)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.19.1-py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 KB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting plotly\n",
      "  Downloading plotly-5.6.0-py2.py3-none-any.whl (27.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.7/27.7 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from lightgbm>=2.3.1->flaml[blendsearch,nlp,notebook,ray]) (0.37.1)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.5/503.5 KB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf>=3.15.3\n",
      "  Downloading protobuf-3.19.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (8.0.4)\n",
      "Collecting attrs\n",
      "  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 KB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (3.6.0)\n",
      "Collecting redis>=3.5.0\n",
      "  Downloading redis-4.1.4-py3-none-any.whl (175 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.8/175.8 KB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (6.0)\n",
      "Collecting jsonschema\n",
      "  Downloading jsonschema-4.4.0-py3-none-any.whl (72 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.7/72.7 KB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting msgpack<2.0.0,>=1.0.0\n",
      "  Downloading msgpack-1.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 KB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<=1.43.0,>=1.28.1\n",
      "  Downloading grpcio-1.43.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboardX>=1.9\n",
      "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 KB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tabulate\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.0/307.0 KB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m895.2/895.2 KB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2022.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.9/764.9 KB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from transformers>=4.14->flaml[blendsearch,nlp,notebook,ray]) (0.11.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from transformers>=4.14->flaml[blendsearch,nlp,notebook,ray]) (0.4.0)\n",
      "Collecting pyarrow!=4.0.0,>=3.0.0\n",
      "  Downloading pyarrow-7.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.12.2-py38-none-any.whl (128 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.3/128.3 KB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dill\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 KB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
      "  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 KB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: responses<0.19 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from datasets->flaml[blendsearch,nlp,notebook,ray]) (0.18.0)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.1/212.1 KB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting qtconsole\n",
      "  Downloading qtconsole-5.2.2-py3-none-any.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.2/120.2 KB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting notebook\n",
      "  Downloading notebook-6.4.10-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: ipykernel in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter->flaml[blendsearch,nlp,notebook,ray]) (6.9.2)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-7.6.5-py2.py3-none-any.whl (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.8/121.8 KB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nbconvert\n",
      "  Downloading nbconvert-6.4.4-py3-none-any.whl (561 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.4/561.4 KB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jupyter-console\n",
      "  Downloading jupyter_console-6.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.30.0-py3-none-any.whl (898 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.1/898.1 KB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyparsing>=2.2.1\n",
      "  Downloading pyparsing-3.0.7-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.0/98.0 KB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from rouge_score->flaml[blendsearch,nlp,notebook,ray]) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from torch->flaml[blendsearch,nlp,notebook,ray]) (4.1.1)\n",
      "Collecting deprecated>=1.2.3\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 KB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 KB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from requests->openml==0.10.2->flaml[blendsearch,nlp,notebook,ray]) (2021.10.8)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-1.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (156 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.6/156.6 KB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (308 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.6/308.6 KB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.7/158.7 KB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.3/121.3 KB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-resources in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from alembic->optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (5.4.0)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 KB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from alembic->optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (4.11.3)\n",
      "Collecting cmd2>=1.0.0\n",
      "  Downloading cmd2-2.4.0-py3-none-any.whl (150 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 KB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.0/113.0 KB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autopage>=0.4.0\n",
      "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 KB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting PrettyTable>=0.7.2\n",
      "  Downloading prettytable-3.2.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (8.1.1)\n",
      "Requirement already satisfied: traitlets<6.0,>=5.1.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (5.1.1)\n",
      "Requirement already satisfied: psutil in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (5.9.0)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.1.3)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (7.1.2)\n",
      "Requirement already satisfied: nest-asyncio in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (1.5.4)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (1.5.1)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (6.1)\n",
      "Collecting ipython-genutils~=0.2.0\n",
      "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting nbformat>=4.2.0\n",
      "  Downloading nbformat-5.2.0-py3-none-any.whl (74 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 KB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jupyterlab-widgets>=1.0.0\n",
      "  Downloading jupyterlab_widgets-1.0.2-py3-none-any.whl (243 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 KB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting widgetsnbextension~=3.5.0\n",
      "  Downloading widgetsnbextension-3.5.2-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
      "  Downloading pyrsistent-0.18.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (119 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 KB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter-console->jupyter->flaml[blendsearch,nlp,notebook,ray]) (3.0.27)\n",
      "Requirement already satisfied: pygments in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter-console->jupyter->flaml[blendsearch,nlp,notebook,ray]) (2.11.2)\n",
      "Collecting pandocfilters>=1.4.1\n",
      "  Downloading pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting defusedxml\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting jinja2>=2.4\n",
      "  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.6/133.6 KB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: entrypoints>=0.2.2 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.4)\n",
      "Requirement already satisfied: jupyter-core in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (4.9.2)\n",
      "Collecting bleach\n",
      "  Downloading bleach-4.1.0-py2.py3-none-any.whl (157 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.9/157.9 KB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jupyterlab-pygments\n",
      "  Downloading jupyterlab_pygments-0.1.2-py2.py3-none-any.whl (4.6 kB)\n",
      "Collecting testpath\n",
      "  Downloading testpath-0.6.0-py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 KB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nbclient<0.6.0,>=0.5.0\n",
      "  Downloading nbclient-0.5.13-py3-none-any.whl (70 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 KB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.4/97.4 KB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mistune<2,>=0.8.1\n",
      "  Downloading mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: pyzmq>=17 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from notebook->jupyter->flaml[blendsearch,nlp,notebook,ray]) (22.3.0)\n",
      "Collecting argon2-cffi\n",
      "  Downloading argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
      "Collecting prometheus-client\n",
      "  Downloading prometheus_client-0.13.1-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 KB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting Send2Trash>=1.8.0\n",
      "  Downloading Send2Trash-1.8.0-py3-none-any.whl (18 kB)\n",
      "Collecting terminado>=0.8.3\n",
      "  Downloading terminado-0.13.3-py3-none-any.whl (14 kB)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Collecting qtpy\n",
      "  Downloading QtPy-2.0.1-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 KB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.7 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (0.2.5)\n",
      "Collecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting wrapt<2,>=1.10\n",
      "  Downloading wrapt-1.14.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 KB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from importlib-resources->alembic->optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (3.7.0)\n",
      "Requirement already satisfied: backcall in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (60.9.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.18.1)\n",
      "Requirement already satisfied: decorator in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.2.0)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Requirement already satisfied: ptyprocess in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from terminado>=0.8.3->notebook->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.7.0)\n",
      "Collecting argon2-cffi-bindings\n",
      "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.2/86.2 KB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.3.1-py3-none-any.whl (37 kB)\n",
      "Collecting webencodings\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.8.3)\n",
      "Collecting cffi>=1.0.1\n",
      "  Downloading cffi-1.15.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (446 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m446.7/446.7 KB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pure-eval in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.2.2)\n",
      "Requirement already satisfied: executing in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (2.0.5)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 KB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: openml, liac-arff, pyperclip\n",
      "  Building wheel for openml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openml: filename=openml-0.10.2-py3-none-any.whl size=190318 sha256=3b8916c689ebfaab65cb14a3dfe9197cb1c03a87bece4c6696579b0a8c01d489\n",
      "  Stored in directory: /home/xliu127/.cache/pip/wheels/e9/c7/af/50e65ac06e82af181b9ce080c156cd4c76fa2ea8904f28c7cd\n",
      "  Building wheel for liac-arff (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11733 sha256=727533962c2c6c96a22e4a77e5a7ff9ac429001daf3856fa7523c544c159474c\n",
      "  Stored in directory: /home/xliu127/.cache/pip/wheels/a2/de/68/bf3972de3ecb31e32bef59a7f4c75f0687a3674c476b347c14\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=4eff35e840339bea8dd9ef328439d58b7fb783d9269b540da8736c654ea9d7f1\n",
      "  Stored in directory: /home/xliu127/.cache/pip/wheels/7f/1a/65/84ff8c386bec21fca6d220ea1f5498a0367883a78dd5ba6122\n",
      "Successfully built openml liac-arff pyperclip\n",
      "Installing collected packages: webencodings, tabulate, Send2Trash, pytz, pyperclip, msgpack, mistune, ipython-genutils, xxhash, xmltodict, wrapt, urllib3, threadpoolctl, testpath, terminado, tenacity, soupsieve, regex, pyrsistent, pyparsing, pycparser, protobuf, prometheus-client, PrettyTable, pillow, pbr, pandocfilters, NumPy, multidict, MarkupSafe, liac-arff, kiwisolver, jupyterlab-widgets, jupyterlab-pygments, joblib, idna, grpcio, greenlet, graphviz, fsspec, frozenlist, fonttools, dill, defusedxml, cycler, colorlog, charset-normalizer, autopage, attrs, async-timeout, yarl, tensorboardX, stevedore, sqlalchemy, scipy, sacremoses, requests, pyarrow, plotly, pandas, packaging, multiprocess, Mako, jsonschema, jinja2, deprecated, cmd2, cmaes, cffi, beautifulsoup4, aiosignal, scikit-learn, redis, qtpy, nbformat, matplotlib, cliff, bleach, argon2-cffi-bindings, aiohttp, rgf-python, optuna, openml, nbclient, lightgbm, catboost, argon2-cffi, qtconsole, nbconvert, jupyter-console, notebook, widgetsnbextension, ipywidgets, jupyter\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sacrebleu 2.0.0 requires colorama, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Mako-1.2.0 MarkupSafe-2.1.1 NumPy-1.22.3 PrettyTable-3.2.0 Send2Trash-1.8.0 aiohttp-3.8.1 aiosignal-1.2.0 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 async-timeout-4.0.2 attrs-21.4.0 autopage-0.5.0 beautifulsoup4-4.10.0 bleach-4.1.0 catboost-1.0.4 cffi-1.15.0 charset-normalizer-2.0.12 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.0 colorlog-6.6.0 cycler-0.11.0 defusedxml-0.7.1 deprecated-1.2.13 dill-0.3.4 fonttools-4.30.0 frozenlist-1.3.0 fsspec-2022.2.0 graphviz-0.19.1 greenlet-1.1.2 grpcio-1.43.0 idna-3.3 ipython-genutils-0.2.0 ipywidgets-7.6.5 jinja2-3.0.3 joblib-1.1.0 jsonschema-4.4.0 jupyter-1.0.0 jupyter-console-6.4.3 jupyterlab-pygments-0.1.2 jupyterlab-widgets-1.0.2 kiwisolver-1.4.0 liac-arff-2.5.0 lightgbm-3.3.2 matplotlib-3.5.1 mistune-0.8.4 msgpack-1.0.3 multidict-6.0.2 multiprocess-0.70.12.2 nbclient-0.5.13 nbconvert-6.4.4 nbformat-5.2.0 notebook-6.4.10 openml-0.10.2 optuna-2.8.0 packaging-21.3 pandas-1.4.1 pandocfilters-1.5.0 pbr-5.8.1 pillow-9.0.1 plotly-5.6.0 prometheus-client-0.13.1 protobuf-3.19.4 pyarrow-7.0.0 pycparser-2.21 pyparsing-3.0.7 pyperclip-1.8.2 pyrsistent-0.18.1 pytz-2021.3 qtconsole-5.2.2 qtpy-2.0.1 redis-4.1.4 regex-2022.3.2 requests-2.27.1 rgf-python-3.12.0 sacremoses-0.0.49 scikit-learn-1.0.2 scipy-1.8.0 soupsieve-2.3.1 sqlalchemy-1.4.32 stevedore-3.5.0 tabulate-0.8.9 tenacity-8.0.1 tensorboardX-2.5 terminado-0.13.3 testpath-0.6.0 threadpoolctl-3.1.0 urllib3-1.26.8 webencodings-0.5.1 widgetsnbextension-3.5.2 wrapt-1.14.0 xmltodict-0.12.0 xxhash-3.0.0 yarl-1.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install flaml[nlp,ray,notebook,blendsearch];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sentiment Classification Example\n",
    "### Load data and preprocess\n",
    "\n",
    "The Stanford Sentiment treebank (SST-2) dataset is a dataset for sentiment classification. First, let's load this dataset into pandas dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f5fa69e7154cc99684d06f09c96934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/7.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b77dc9cc77444eda943cd803c03df4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset glue/sst2 (download: 7.09 MiB, generated: 4.81 MiB, post-processed: Unknown size, total: 11.90 MiB) to /home/xliu127/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882f8a670c08408980a900295cfeab24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/7.44M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074cea4170ee4aeabe9eea081c79d5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfcd40c81125446f824e40a1f51b1d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f021f2a900fb4e80be0201345dffc3f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/xliu127/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset glue downloaded and prepared to /home/xliu127/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/xliu127/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"glue\", \"sst2\", split=\"train\").to_pandas().iloc[:10000]\n",
    "dev_dataset = load_dataset(\"glue\", \"sst2\", split=\"validation\").to_pandas().iloc[:10000]\n",
    "test_dataset = load_dataset(\"glue\", \"sst2\", split=\"test\").to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the first 5 examples of this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hide new secretions from the parental units</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contains no wit , only labored gags</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that loves its characters and communicates som...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>remains utterly satisfied to remain the same t...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on the worst revenge-of-the-nerds clichés the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label  idx\n",
       "0       hide new secretions from the parental units       0    0\n",
       "1               contains no wit , only labored gags       0    1\n",
       "2  that loves its characters and communicates som...      1    2\n",
       "3  remains utterly satisfied to remain the same t...      0    3\n",
       "4  on the worst revenge-of-the-nerds clichés the ...      0    4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the data into X and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sent_keys = [\"sentence\"]          # specify the column names of the input sentences\n",
    "label_key = \"label\"                                    # specify the column name of the label\n",
    "\n",
    "X_train, y_train = train_dataset[custom_sent_keys], train_dataset[label_key]\n",
    "X_val, y_val = dev_dataset[custom_sent_keys], dev_dataset[label_key]\n",
    "X_test = test_dataset[custom_sent_keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run FLAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "E0305 06:58:57.975986938   49812 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0305 06:58:58.049658638   49812 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "2022-03-05 06:58:58,585\tERROR services.py:1383 -- Failed to start the dashboard: Failed to read dashbord log: [Errno 2] No such file or directory: '/tmp/ray/session_2022-03-05_06-58-56_813199_49812/logs/dashboard.log'\n",
      "E0305 06:58:58.593016246   49812 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0305 06:58:58.624272424   49812 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '155.246.89.124',\n",
       " 'raylet_ip_address': '155.246.89.124',\n",
       " 'redis_address': '155.246.89.124:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2022-03-05_06-58-56_813199_49812/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2022-03-05_06-58-56_813199_49812/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2022-03-05_06-58-56_813199_49812',\n",
       " 'metrics_export_port': 40922,\n",
       " 'gcs_address': '155.246.89.124:35505',\n",
       " 'node_id': 'bee5b455541dbbf7d7f81f71d99e3ea0d96336914fc2a55d0792519f'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/dashboard/agent.py\", line 21, in <module>\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m     import ray.dashboard.utils as dashboard_utils\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/dashboard/utils.py\", line 29, in <module>\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m     from ray.dashboard.optional_deps import (aiohttp, aiosignal, aioredis, hdrs,\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/dashboard/optional_deps.py\", line 3, in <module>\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m     import opencensus  # noqa: F401\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m ModuleNotFoundError: No module named 'opencensus'\n"
     ]
    }
   ],
   "source": [
    "''' import AutoML class from flaml package '''\n",
    "from flaml import AutoML\n",
    "automl = AutoML()\n",
    "\n",
    "import ray\n",
    "ray.init() # you may encounter the ModuleNotFoundError: No module named 'opencensus', which can be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "automl_settings = {\n",
    "        \"time_budget\": 500,                 # setting the time budget\n",
    "        \"task\": \"seq-classification\",       # setting the task as seq-classification\n",
    "        \"hf_args\":\n",
    "            {\"output_dir\": \"data/output/\",  # setting the output directory\n",
    "             \"ckpt_per_epoch\": 1,           # setting the number of checkoints per epoch\n",
    "             \"model_path\": \"google/electra-base-discriminator\",\n",
    "             },\n",
    "        \"gpu_per_trial\": 1,                 # set to 0 if no GPU is available\n",
    "        \"log_file_name\": \"seqclass.log\",    # set the file to save the log for HPO\n",
    "        \"log_type\": \"all\",                  # the log type for checkpoints: all if keeping all checkpoints, best if only keeping the best checkpoints                        # the batch size for validation (inference)\n",
    "        \"use_ray\": True,                     # set whether to use Ray\n",
    "        \"n_concurrent_trials\": 4\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 07:12:00 (running for 00:01:41.29)<br>Memory usage on this node: 27.1/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/96 CPUs, 0/4 GPUs, 0.0/250.43 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Current best trial: 5fc63bdd with val_loss=0.49082568807339455 and parameters={'learning_rate': 0.0009149809294976631, 'num_train_epochs': 0.11641930732714473, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.26555680818499533, 'weight_decay': 0.08699485855077174, 'adam_epsilon': 6.871680478952233e-08, 'seed': 41, 'global_max_steps': 9223372036854775807, 'learner': 'transformer'}<br>Result logdir: /home/xliu127/ray_results/train_2022-03-05_07-10-18<br>Number of trials: 5/1000000 (5 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50403)\u001b[0m {'eval_loss': 0.20583172142505646, 'eval_automl_metric': 0.0745412844036697, 'eval_runtime': 9.5278, 'eval_samples_per_second': 91.522, 'eval_steps_per_second': 91.522, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(train pid=50376)\u001b[0m {'eval_loss': 0.2556954026222229, 'eval_automl_metric': 0.07224770642201839, 'eval_runtime': 9.2868, 'eval_samples_per_second': 93.897, 'eval_steps_per_second': 93.897, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(train pid=50371)\u001b[0m {'eval_loss': 0.27808061242103577, 'eval_automl_metric': 0.09633027522935778, 'eval_runtime': 11.4038, 'eval_samples_per_second': 76.465, 'eval_steps_per_second': 76.465, 'epoch': 0.38}\n",
      "\u001b[2m\u001b[36m(train pid=50403)\u001b[0m {'eval_loss': 0.20583172142505646, 'eval_automl_metric': 0.0745412844036697, 'eval_runtime': 9.0179, 'eval_samples_per_second': 96.697, 'eval_steps_per_second': 96.697, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(train pid=50376)\u001b[0m {'eval_loss': 0.2556954026222229, 'eval_automl_metric': 0.07224770642201839, 'eval_runtime': 9.6653, 'eval_samples_per_second': 90.219, 'eval_steps_per_second': 90.219, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(train pid=50371)\u001b[0m {'train_runtime': 46.1448, 'train_samples_per_second': 81.918, 'train_steps_per_second': 2.579, 'train_loss': 0.45009568158318014, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50371)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=50371)\u001b[0m   Num examples = 872\n",
      "\u001b[2m\u001b[36m(train pid=50371)\u001b[0m   Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50398)\u001b[0m {'eval_loss': 0.40110892057418823, 'eval_automl_metric': 0.11582568807339455, 'eval_runtime': 9.7336, 'eval_samples_per_second': 89.587, 'eval_steps_per_second': 89.587, 'epoch': 0.62}\n",
      "\u001b[2m\u001b[36m(train pid=50403)\u001b[0m {'eval_loss': 0.2070195972919464, 'eval_automl_metric': 0.0745412844036697, 'eval_runtime': 9.1212, 'eval_samples_per_second': 95.602, 'eval_steps_per_second': 95.602, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(train pid=50376)\u001b[0m {'eval_loss': 0.25353941321372986, 'eval_automl_metric': 0.07339449541284404, 'eval_runtime': 9.7712, 'eval_samples_per_second': 89.242, 'eval_steps_per_second': 89.242, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(train pid=50398)\u001b[0m {'eval_loss': 0.40110892057418823, 'eval_automl_metric': 0.11582568807339455, 'eval_runtime': 9.5366, 'eval_samples_per_second': 91.437, 'eval_steps_per_second': 91.437, 'epoch': 0.62}\n",
      "\u001b[2m\u001b[36m(train pid=50403)\u001b[0m {'eval_loss': 0.2070195972919464, 'eval_automl_metric': 0.0745412844036697, 'eval_runtime': 8.864, 'eval_samples_per_second': 98.375, 'eval_steps_per_second': 98.375, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(train pid=50398)\u001b[0m {'train_runtime': 126.5904, 'train_samples_per_second': 433.996, 'train_steps_per_second': 108.5, 'train_loss': 0.49369501294483625, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50398)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=50398)\u001b[0m   Num examples = 872\n",
      "\u001b[2m\u001b[36m(train pid=50398)\u001b[0m   Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50376)\u001b[0m {'eval_loss': 0.25353941321372986, 'eval_automl_metric': 0.07339449541284404, 'eval_runtime': 9.6581, 'eval_samples_per_second': 90.287, 'eval_steps_per_second': 90.287, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(train pid=50403)\u001b[0m {'train_runtime': 131.5202, 'train_samples_per_second': 228.102, 'train_steps_per_second': 7.14, 'train_loss': 0.3094321658546655, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50403)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=50403)\u001b[0m   Num examples = 872\n",
      "\u001b[2m\u001b[36m(train pid=50403)\u001b[0m   Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50376)\u001b[0m {'train_runtime': 133.1484, 'train_samples_per_second': 159.15, 'train_steps_per_second': 4.987, 'train_loss': 0.3239936241122524, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50376)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=50376)\u001b[0m   Num examples = 872\n",
      "\u001b[2m\u001b[36m(train pid=50376)\u001b[0m   Batch size = 1\n",
      "2022-03-05 07:12:57,120\tINFO tune.py:636 -- Total run time: 158.26 seconds (100.73 seconds for the tuning loop).\n",
      "[flaml.automl: 03-05 07:12:57] {2838} INFO - selected model: None\n",
      "\u001b[32m[I 2022-03-05 07:12:57,739]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "\u001b[2m\u001b[36m(bundle_reservation_check_func pid=50369)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(bundle_reservation_check_func pid=50369)\u001b[0m   from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 07:12:59 (running for 00:00:01.86)<br>Memory usage on this node: 12.6/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.43 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-03-05_07-12-57<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_trainable_function_wrapper pid=50369)\u001b[0m E0305 07:12:59.623192723   54605 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 07:13:03 (running for 00:00:05.87)<br>Memory usage on this node: 12.7/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.43 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-03-05_07-12-57<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 07:13:08 (running for 00:00:10.88)<br>Memory usage on this node: 15.3/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.43 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-03-05_07-12-57<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_trainable_function_wrapper pid=50369)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_trainable_function_wrapper pid=50369)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 07:13:13 (running for 00:00:15.89)<br>Memory usage on this node: 16.1/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.43 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-03-05_07-12-57<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_trainable_function_wrapper pid=50369)\u001b[0m {'loss': 0.703, 'learning_rate': 3.388818257398752e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 07:13:18 (running for 00:00:20.89)<br>Memory usage on this node: 16.0/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.43 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-03-05_07-12-57<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_trainable_function_wrapper pid=50369)\u001b[0m {'train_runtime': 10.2122, 'train_samples_per_second': 114.0, 'train_steps_per_second': 3.623, 'train_loss': 0.7030346329147751, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-05 07:13:24,120\tWARNING util.py:163 -- The `fetch_result` operation took 0.790 s, which may be a performance bottleneck.\n",
      "2022-03-05 07:13:24,126\tWARNING util.py:163 -- The `process_trial` operation took 0.796 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial _trainable_function_wrapper_bd5cd0c6 reported train_time=22.88 with parameters={'learning_rate': 0.0009149809294976631, 'num_train_epochs': 0.11641930732714473, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.26555680818499533, 'weight_decay': 0.08699485855077174, 'adam_epsilon': 6.871680478952233e-08, 'seed': 41, 'global_max_steps': 37, 'learner': 'transformer'}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 07:13:24 (running for 00:00:26.36)<br>Memory usage on this node: 17.8/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.43 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Current best trial: bd5cd0c6 with train_time=22.87708592414856 and parameters={'learning_rate': 0.0009149809294976631, 'num_train_epochs': 0.11641930732714473, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.26555680818499533, 'weight_decay': 0.08699485855077174, 'adam_epsilon': 6.871680478952233e-08, 'seed': 41, 'global_max_steps': 37, 'learner': 'transformer'}<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-03-05_07-12-57<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-05 07:13:25,650\tWARNING util.py:163 -- The `fetch_result` operation took 0.775 s, which may be a performance bottleneck.\n",
      "2022-03-05 07:13:25,698\tWARNING util.py:163 -- The `process_trial` operation took 0.823 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial _trainable_function_wrapper_bd5cd0c6 completed. Last result: estimator=<flaml.model.TransformersEstimator object at 0x7fed3cd888b0>,train_time=22.87708592414856\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 07:13:42 (running for 00:00:44.71)<br>Memory usage on this node: 15.4/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/96 CPUs, 0/4 GPUs, 0.0/250.43 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Current best trial: bd5cd0c6 with train_time=22.87708592414856 and parameters={'learning_rate': 0.0009149809294976631, 'num_train_epochs': 0.11641930732714473, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.26555680818499533, 'weight_decay': 0.08699485855077174, 'adam_epsilon': 6.871680478952233e-08, 'seed': 41, 'global_max_steps': 37, 'learner': 'transformer'}<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-03-05_07-12-57<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                          </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  adam_epsilon</th><th style=\"text-align: right;\">  global_max_steps</th><th>learner    </th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  num_train_epochs</th><th style=\"text-align: right;\">  per_device_train_batch_size</th><th style=\"text-align: right;\">  seed</th><th style=\"text-align: right;\">  warmup_ratio</th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>_trainable_function_wrapper_bd5cd0c6</td><td>TERMINATED</td><td>155.246.89.124:50369</td><td style=\"text-align: right;\">   6.87168e-08</td><td style=\"text-align: right;\">                37</td><td>transformer</td><td style=\"text-align: right;\">    0.000914981</td><td style=\"text-align: right;\">          0.116419</td><td style=\"text-align: right;\">                           32</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">      0.265557</td><td style=\"text-align: right;\">     0.0869949</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         22.8774</td><td style=\"text-align: right;\">     22.8771</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-05 07:13:42,592\tINFO tune.py:636 -- Total run time: 44.85 seconds (27.94 seconds for the tuning loop).\n",
      "[flaml.automl: 03-05 07:13:50] {2948} INFO - retrain transformer for 22.9s\n",
      "[flaml.automl: 03-05 07:13:50] {2955} INFO - retrained model: ElectraForSequenceClassification(\n",
      "  (electra): ElectraModel(\n",
      "    (embeddings): ElectraEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): ElectraEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): ElectraClassificationHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "[flaml.automl: 03-05 07:13:50] {2290} INFO - fit succeeded\n",
      "[flaml.automl: 03-05 07:13:50] {2291} INFO - Time taken to find the best model: 53.985883951187134\n"
     ]
    }
   ],
   "source": [
    "'''The main flaml automl API'''\n",
    "automl.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **automl_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ML leaner: transformer\n",
      "Best hyperparmeter config: {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 3.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 71, 'FLAML_sample_size': 10000}\n",
      "Best accuracy on validation data: 0.9541\n",
      "Training duration of best run: 75.44 s\n"
     ]
    }
   ],
   "source": [
    "'''retrieve best config and best learner'''\n",
    "print('Best hyperparmeter config:', automl.best_config)\n",
    "print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
    "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''pickle and save the automl object'''\n",
    "import pickle\n",
    "with open('automl.pkl', 'wb') as f:\n",
    "    pickle.dump(automl, f, pickle.HIGHEST_PROTOCOL)\n",
    "'''load pickled automl object'''\n",
    "with open('automl.pkl', 'rb') as f:\n",
    "    automl = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 03-01 20:01:20] {766} WARNING - No estimator is trained. Please run fit with enough budget.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels None\n"
     ]
    }
   ],
   "source": [
    "'''compute predictions of testing dataset''' \n",
    "y_pred = automl.predict(X_test, **{\"hf_args\": {\"per_gpu_eval_batch_size\": 1}})\n",
    "print('Predicted labels', y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 0.0001683951566733354, 'num_train_epochs': 0.2210193378617947, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.04205307554489066, 'weight_decay': 0.16569345755141265, 'adam_epsilon': 1.6339103068074946e-07, 'seed': 44, 'global_max_steps': 70, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 0.0001683951566733354, 'num_train_epochs': 0.2210193378617947, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.04205307554489066, 'weight_decay': 0.16569345755141265, 'adam_epsilon': 1.6339103068074946e-07, 'seed': 44, 'global_max_steps': 70, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 4.06541243930961e-06, 'num_train_epochs': 0.39160216739720227, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.0005088579635559642, 'weight_decay': 0.15834250683338044, 'adam_epsilon': 1.8072721716293894e-08, 'seed': 43, 'global_max_steps': 245, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 4.06541243930961e-06, 'num_train_epochs': 0.39160216739720227, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.0005088579635559642, 'weight_decay': 0.15834250683338044, 'adam_epsilon': 1.8072721716293894e-08, 'seed': 43, 'global_max_steps': 245, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.084699205980285e-06, 'num_train_epochs': 0.33613850932131845, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.019111274702022462, 'weight_decay': 0.28691064048089554, 'adam_epsilon': 5.346382363277181e-08, 'seed': 40, 'global_max_steps': 421, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.084699205980285e-06, 'num_train_epochs': 0.33613850932131845, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.019111274702022462, 'weight_decay': 0.28691064048089554, 'adam_epsilon': 5.346382363277181e-08, 'seed': 40, 'global_max_steps': 421, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 5.738347095450703e-06, 'num_train_epochs': 0.15715398257485533, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.11022443614360844, 'weight_decay': 0.03419372774239863, 'adam_epsilon': 4.785016539529346e-08, 'seed': 41, 'global_max_steps': 197, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.084699205980285e-06, 'num_train_epochs': 0.33613850932131845, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.019111274702022462, 'weight_decay': 0.28691064048089554, 'adam_epsilon': 5.346382363277181e-08, 'seed': 40, 'global_max_steps': 421, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 2.0473545661471498e-06, 'num_train_epochs': 0.34169313043908095, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.05834925558635486, 'weight_decay': 0.3, 'adam_epsilon': 2.7429849778869072e-08, 'seed': 40, 'global_max_steps': 428, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 2.0473545661471498e-06, 'num_train_epochs': 0.34169313043908095, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.05834925558635486, 'weight_decay': 0.3, 'adam_epsilon': 2.7429849778869072e-08, 'seed': 40, 'global_max_steps': 428, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 3.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 3.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1e-06, 'num_train_epochs': 0.3306741850606283, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.0, 'weight_decay': 0.2578876562560198, 'adam_epsilon': 1.042069300590234e-07, 'seed': 40, 'global_max_steps': 414, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 3.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.4395226763286561e-05, 'num_train_epochs': 0.11016932663769363, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.08045032769233901, 'weight_decay': 0.002015422229971127, 'adam_epsilon': 2.4641023040418407e-08, 'seed': 41, 'global_max_steps': 138, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 3.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 8.003778764416909e-06, 'num_train_epochs': 1.538516331487565, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.025044635819042906, 'weight_decay': 0.040537327679417284, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 3.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 2.3364738960350788e-05, 'num_train_epochs': 1.594510060700272, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 3.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.0436709545680516e-05, 'num_train_epochs': 1.8845967679352, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.025680249011849145, 'adam_epsilon': 8.550666633722979e-07, 'seed': 43, 'global_max_steps': 313, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 3.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.2494098468160911e-05, 'num_train_epochs': 5.849791656938768, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 8.653857539100394e-07, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.2494098468160911e-05, 'num_train_epochs': 5.849791656938768, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 8.653857539100394e-07, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}}\n"
     ]
    }
   ],
   "source": [
    "from flaml.data import get_output_from_log\n",
    "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
    "    get_output_from_log(filename=automl_settings['log_file_name'], time_budget=3000)\n",
    "for config in config_history:\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Wall Clock Time (s)')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "print(len(valid_loss_history))\n",
    "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
    "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Other Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides sequence classification, FLAML currently also supports four other tasks (more tasks are to be supported, which can be found on FLAML's documentation website https://microsoft.github.io/FLAML/docs/Examples/AutoML-NLP):\n",
    "\n",
    "- sequence regression: predicting a float number from the input sequence, e.g., predicting the rating of a hotel review based on the text content;\n",
    "- token classification: predicting the label of each token in a sequence, e.g., named entity recognition;\n",
    "- multiple choice: predicting the best second half of a sentence that comes next to the first part of a sentence based on common sensen reasoning. An example is seen below;\n",
    "- (abstractive) summarization: generating the textual summarization of an input paragraph;\n",
    "\n",
    "For each task, you only have to change the \"Load data and preprocess\" with the corresponding data loading process. For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Multiple Choice Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple choice is a task of predicting the best second half of a sentence that follows the first half based on common sense reasoning. An example of multiple-choice classification problem is:\n",
    "\n",
    "On stage, a woman takes a seat at the piano. She\n",
    "a) sits on a bench as her sister plays with the doll.\n",
    "b) smiles with someone as the music plays.\n",
    "c) is in the crowd, watching the dancers.\n",
    "d) *nervously sets her fingers on the keys*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5cbbd631ce7447f8cacc75a26ad6531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a80f2c021d845b0bedbda2f22617cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: swag/regular\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset swag/regular (download: 41.92 MiB, generated: 44.96 MiB, post-processed: Unknown size, total: 86.88 MiB) to /home/xliu127/.cache/huggingface/datasets/swag/regular/0.0.0/9640de08cdba6a1469ed3834fcab4b8ad8e38caf5d1ba5e7436d8b1fd067ad4c...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1da362a0175402c9f60fe2188dd5f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4ae15df1c04b5fb44477e5fab330e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/6.71M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b23c5433651427c87ad06da67696af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762e679d73e444a19a11d7f704c95373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.21M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f553386e24d3443ea0cd29ad3d90dea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3fb4448237b407c966d94966a6e123a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0699e7ef01d49ddb81dd8917dbd7e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed99508066724806b9cc768cae038854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset swag downloaded and prepared to /home/xliu127/.cache/huggingface/datasets/swag/regular/0.0.0/9640de08cdba6a1469ed3834fcab4b8ad8e38caf5d1ba5e7436d8b1fd067ad4c. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: swag/regular\n",
      "Reusing dataset swag (/home/xliu127/.cache/huggingface/datasets/swag/regular/0.0.0/9640de08cdba6a1469ed3834fcab4b8ad8e38caf5d1ba5e7436d8b1fd067ad4c)\n",
      "No config specified, defaulting to: swag/regular\n",
      "Reusing dataset swag (/home/xliu127/.cache/huggingface/datasets/swag/regular/0.0.0/9640de08cdba6a1469ed3834fcab4b8ad8e38caf5d1ba5e7436d8b1fd067ad4c)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"swag\", split=\"train\").to_pandas().iloc[:10000]\n",
    "dev_dataset = load_dataset(\"swag\", split=\"validation\").to_pandas().iloc[:10000]\n",
    "test_dataset = load_dataset(\"swag\", split=\"test\").to_pandas()\n",
    "\n",
    "custom_sent_keys = [\n",
    "        \"sent1\",\n",
    "        \"sent2\",\n",
    "        \"ending0\",\n",
    "        \"ending1\",\n",
    "        \"ending2\",\n",
    "        \"ending3\",\n",
    "        \"gold-source\",\n",
    "        \"video-id\",\n",
    "        \"startphrase\",\n",
    "        \"fold-ind\",\n",
    "    ]                                                  # specify the column names of the input sentences\n",
    "label_key = \"label\"                                    # specify the column name of the label\n",
    "\n",
    "X_train, y_train = train_dataset[custom_sent_keys], train_dataset[label_key]\n",
    "X_val, y_val = dev_dataset[custom_sent_keys], dev_dataset[label_key]\n",
    "X_test = test_dataset[custom_sent_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Members of the procession walk down the street holding small horn brass instruments.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.iloc[0][\"sent1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 10:49:19 (running for 00:14:14.18)<br>Memory usage on this node: 49.1/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/96 CPUs, 0/4 GPUs, 0.0/250.19 GiB heap, 0.0/111.22 GiB objects (0.0/1.0 accelerator_type:V100)<br>Current best trial: 96e31457 with val_loss=0.18999999999999995 and parameters={'learning_rate': 1.9459272781871782e-05, 'num_train_epochs': 3.8672508737242617, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.3, 'weight_decay': 0.07191806885282034, 'adam_epsilon': 1.401371644431578e-08, 'seed': 44, 'global_max_steps': 9223372036854775807, 'learner': 'transformer'}<br>Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-03-05_10-35-05<br>Number of trials: 21/1000000 (21 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-05 10:49:19,370\tINFO tune.py:636 -- Total run time: 854.36 seconds (500.76 seconds for the tuning loop).\n",
      "[flaml.automl: 03-05 10:51:24] {2844} INFO - selected model: None\n",
      "\u001b[32m[I 2022-03-05 10:51:24,732]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 10:51:24 (running for 00:00:00.13)<br>Memory usage on this node: 32.9/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/96 CPUs, 0/4 GPUs, 0.0/250.19 GiB heap, 0.0/111.22 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-03-05_10-51-24<br>Number of trials: 1/1 (1 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(bundle_reservation_check_func pid=48563)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(bundle_reservation_check_func pid=48563)\u001b[0m   from pandas import MultiIndex, Int64Index\n",
      "\u001b[2m\u001b[36m(_trainable_function_wrapper pid=48563)\u001b[0m E0305 10:51:26.621583546   53454 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 10:51:29 (running for 00:00:05.19)<br>Memory usage on this node: 34.2/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.19 GiB heap, 0.0/111.22 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-03-05_10-51-24<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_trainable_function_wrapper pid=48563)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_trainable_function_wrapper pid=48563)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 10:51:34 (running for 00:00:10.20)<br>Memory usage on this node: 36.9/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.19 GiB heap, 0.0/111.22 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-03-05_10-51-24<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_trainable_function_wrapper pid=48563)\u001b[0m {'loss': 1.3, 'learning_rate': 1.5134989941455831e-05, 'epoch': 1.0}\n",
      "\u001b[2m\u001b[36m(_trainable_function_wrapper pid=48563)\u001b[0m {'loss': 0.8824, 'learning_rate': 1.4338411523484471e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 10:51:39 (running for 00:00:15.20)<br>Memory usage on this node: 36.8/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.19 GiB heap, 0.0/111.22 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-03-05_10-51-24<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_trainable_function_wrapper pid=48563)\u001b[0m {'loss': 0.3826, 'learning_rate': 8.193378013419697e-06, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 10:51:45 (running for 00:00:20.27)<br>Memory usage on this node: 36.8/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.19 GiB heap, 0.0/111.22 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-03-05_10-51-24<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_trainable_function_wrapper pid=48563)\u001b[0m {'loss': 0.2274, 'learning_rate': 2.0483445033549243e-06, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 10:51:50 (running for 00:00:25.28)<br>Memory usage on this node: 36.9/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.19 GiB heap, 0.0/111.22 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-03-05_10-51-24<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 10:51:55 (running for 00:00:30.29)<br>Memory usage on this node: 37.0/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.19 GiB heap, 0.0/111.22 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-03-05_10-51-24<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_trainable_function_wrapper pid=48563)\u001b[0m {'train_runtime': 24.376, 'train_samples_per_second': 15.865, 'train_steps_per_second': 1.149, 'train_loss': 0.6980938911437988, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 10:52:00 (running for 00:00:35.30)<br>Memory usage on this node: 37.3/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.19 GiB heap, 0.0/111.22 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-03-05_10-51-24<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-05 10:52:01,485\tWARNING util.py:163 -- The `fetch_result` operation took 0.519 s, which may be a performance bottleneck.\n",
      "2022-03-05 10:52:01,492\tWARNING util.py:163 -- The `process_trial` operation took 0.527 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial _trainable_function_wrapper_41bb9a64 reported train_time=33.32 with parameters={'learning_rate': 1.9459272781871782e-05, 'num_train_epochs': 3.8672508737242617, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.3, 'weight_decay': 0.07191806885282034, 'adam_epsilon': 1.401371644431578e-08, 'seed': 44, 'global_max_steps': 28, 'learner': 'transformer'}.\n",
      "Trial _trainable_function_wrapper_41bb9a64 completed. Last result: estimator=<flaml.model.TransformersEstimator object at 0x7f3954607d30>,train_time=33.31933665275574\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 10:52:18 (running for 00:00:54.19)<br>Memory usage on this node: 32.9/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/96 CPUs, 0/4 GPUs, 0.0/250.19 GiB heap, 0.0/111.22 GiB objects (0.0/1.0 accelerator_type:V100)<br>Current best trial: 41bb9a64 with train_time=33.31933665275574 and parameters={'learning_rate': 1.9459272781871782e-05, 'num_train_epochs': 3.8672508737242617, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.3, 'weight_decay': 0.07191806885282034, 'adam_epsilon': 1.401371644431578e-08, 'seed': 44, 'global_max_steps': 28, 'learner': 'transformer'}<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-03-05_10-51-24<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                          </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  adam_epsilon</th><th style=\"text-align: right;\">  global_max_steps</th><th>learner    </th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  num_train_epochs</th><th style=\"text-align: right;\">  per_device_train_batch_size</th><th style=\"text-align: right;\">  seed</th><th style=\"text-align: right;\">  warmup_ratio</th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>_trainable_function_wrapper_41bb9a64</td><td>TERMINATED</td><td>155.246.89.124:48563</td><td style=\"text-align: right;\">   1.40137e-08</td><td style=\"text-align: right;\">                28</td><td>transformer</td><td style=\"text-align: right;\">    1.94593e-05</td><td style=\"text-align: right;\">           3.86725</td><td style=\"text-align: right;\">                           16</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">     0.0719181</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         33.3197</td><td style=\"text-align: right;\">     33.3193</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-05 10:52:19,047\tINFO tune.py:636 -- Total run time: 54.31 seconds (38.20 seconds for the tuning loop).\n",
      "[flaml.automl: 03-05 10:52:25] {2954} INFO - retrain transformer for 33.3s\n",
      "[flaml.automl: 03-05 10:52:25] {2961} INFO - retrained model: RobertaForMultipleChoice(\n",
      "  (roberta): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): RobertaPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
      ")\n",
      "[flaml.automl: 03-05 10:52:25] {2292} INFO - fit succeeded\n",
      "[flaml.automl: 03-05 10:52:25] {2293} INFO - Time taken to find the best model: 481.49229097366333\n",
      "[flaml.automl: 03-05 10:52:25] {2304} WARNING - Time taken to find the best model is 96% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
     ]
    }
   ],
   "source": [
    "''' import AutoML class from flaml package '''\n",
    "from flaml import AutoML\n",
    "automl = AutoML()\n",
    "\n",
    "import ray\n",
    "ray.init()\n",
    "\n",
    "automl_settings = {\n",
    "        \"time_budget\": 500,                 # setting the time budget\n",
    "        \"task\": \"multichoice-classification\",       # setting the task as multiplechoice-classification\n",
    "        \"hf_args\":\n",
    "            {\"output_dir\": \"data/output/\",  # setting the output directory\n",
    "             \"ckpt_per_epoch\": 1           # setting the number of checkoints per epoch\n",
    "             },\n",
    "        \"gpu_per_trial\": 1,                 # set to 0 if no GPU is available\n",
    "        \"log_file_name\": \"seqclass.log\",    # set the file to save the log for HPO\n",
    "        \"log_type\": \"all\",                  # the log type for checkpoints: all if keeping all checkpoints, best if only keeping the best checkpoints                        # the batch size for validation (inference)\n",
    "        \"use_ray\": {\"local_dir\": \"data/output/\"},                    # set whether to use Ray\n",
    "        \"n_concurrent_trials\": 4\n",
    "    }\n",
    "\n",
    "'''The main flaml automl API'''\n",
    "automl.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Current Learner': 'transformer', 'Current Sample': 100, 'Current Hyper-parameters': {'learning_rate': 2.756931081948468e-05, 'num_train_epochs': 0.779642815738325, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.22687283276786924, 'weight_decay': 0.29321163598694155, 'adam_epsilon': 3.967681317378338e-08, 'seed': 43, 'global_max_steps': 6, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 2.756931081948468e-05, 'num_train_epochs': 0.779642815738325, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.22687283276786924, 'weight_decay': 0.29321163598694155, 'adam_epsilon': 3.967681317378338e-08, 'seed': 43, 'global_max_steps': 6, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 100, 'Current Hyper-parameters': {'learning_rate': 0.0003745428041684987, 'num_train_epochs': 0.34031242063876355, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.25315902229010456, 'weight_decay': 0.0775263435425649, 'adam_epsilon': 4.3615344471208164e-07, 'seed': 41, 'global_max_steps': 2, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 2.756931081948468e-05, 'num_train_epochs': 0.779642815738325, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.22687283276786924, 'weight_decay': 0.29321163598694155, 'adam_epsilon': 3.967681317378338e-08, 'seed': 43, 'global_max_steps': 6, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 100, 'Current Hyper-parameters': {'learning_rate': 3.408230946566266e-05, 'num_train_epochs': 2.6639246926428695, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.29692259300270796, 'weight_decay': 0.03696272531088296, 'adam_epsilon': 2.3700413247456897e-08, 'seed': 43, 'global_max_steps': 19, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 3.408230946566266e-05, 'num_train_epochs': 2.6639246926428695, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.29692259300270796, 'weight_decay': 0.03696272531088296, 'adam_epsilon': 2.3700413247456897e-08, 'seed': 43, 'global_max_steps': 19, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 100, 'Current Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 3.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 12, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 3.408230946566266e-05, 'num_train_epochs': 2.6639246926428695, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.29692259300270796, 'weight_decay': 0.03696272531088296, 'adam_epsilon': 2.3700413247456897e-08, 'seed': 43, 'global_max_steps': 19, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 100, 'Current Hyper-parameters': {'learning_rate': 0.00014685215729836744, 'num_train_epochs': 0.4296185883795709, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.16500709010162196, 'weight_decay': 0.2752345196630284, 'adam_epsilon': 5.677737668239479e-07, 'seed': 44, 'global_max_steps': 3, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 3.408230946566266e-05, 'num_train_epochs': 2.6639246926428695, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.29692259300270796, 'weight_decay': 0.03696272531088296, 'adam_epsilon': 2.3700413247456897e-08, 'seed': 43, 'global_max_steps': 19, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 100, 'Current Hyper-parameters': {'learning_rate': 9.382526781499879e-05, 'num_train_epochs': 0.4846092544923776, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.11349827798397755, 'weight_decay': 0.0223536181546372, 'adam_epsilon': 1.325624399563435e-07, 'seed': 42, 'global_max_steps': 2, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 3.408230946566266e-05, 'num_train_epochs': 2.6639246926428695, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.29692259300270796, 'weight_decay': 0.03696272531088296, 'adam_epsilon': 2.3700413247456897e-08, 'seed': 43, 'global_max_steps': 19, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 100, 'Current Hyper-parameters': {'learning_rate': 2.2653813604564242e-06, 'num_train_epochs': 5.953693888921684, 'per_device_train_batch_size': 4, 'warmup_ratio': 0.08848850422989044, 'weight_decay': 0.18218716124330445, 'adam_epsilon': 9.590819740273709e-08, 'seed': 41, 'global_max_steps': 149, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 3.408230946566266e-05, 'num_train_epochs': 2.6639246926428695, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.29692259300270796, 'weight_decay': 0.03696272531088296, 'adam_epsilon': 2.3700413247456897e-08, 'seed': 43, 'global_max_steps': 19, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 100, 'Current Hyper-parameters': {'learning_rate': 3.1718766913883246e-05, 'num_train_epochs': 1.242688555979412, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.28879861696027687, 'weight_decay': 0.020291176026743043, 'adam_epsilon': 1.4058514705714036e-08, 'seed': 44, 'global_max_steps': 9, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 3.408230946566266e-05, 'num_train_epochs': 2.6639246926428695, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.29692259300270796, 'weight_decay': 0.03696272531088296, 'adam_epsilon': 2.3700413247456897e-08, 'seed': 43, 'global_max_steps': 19, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 100, 'Current Hyper-parameters': {'learning_rate': 0.00038358448655152153, 'num_train_epochs': 0.46906927146674166, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.07213994595101665, 'weight_decay': 0.02045542217215608, 'adam_epsilon': 1.335493696656059e-08, 'seed': 40, 'global_max_steps': 7, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 3.408230946566266e-05, 'num_train_epochs': 2.6639246926428695, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.29692259300270796, 'weight_decay': 0.03696272531088296, 'adam_epsilon': 2.3700413247456897e-08, 'seed': 43, 'global_max_steps': 19, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 100, 'Current Hyper-parameters': {'learning_rate': 3.66219727793002e-05, 'num_train_epochs': 5.71059798847136, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.3, 'weight_decay': 0.053634274595022874, 'adam_epsilon': 3.9955116159740924e-08, 'seed': 42, 'global_max_steps': 21, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 3.408230946566266e-05, 'num_train_epochs': 2.6639246926428695, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.29692259300270796, 'weight_decay': 0.03696272531088296, 'adam_epsilon': 2.3700413247456897e-08, 'seed': 43, 'global_max_steps': 19, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 100, 'Current Hyper-parameters': {'learning_rate': 7.846976950354034e-06, 'num_train_epochs': 1.3411675653877058, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.12029700459180202, 'weight_decay': 0.26153104245390757, 'adam_epsilon': 1.09997444076099e-08, 'seed': 40, 'global_max_steps': 10, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 3.408230946566266e-05, 'num_train_epochs': 2.6639246926428695, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.29692259300270796, 'weight_decay': 0.03696272531088296, 'adam_epsilon': 2.3700413247456897e-08, 'seed': 43, 'global_max_steps': 19, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 100, 'Current Hyper-parameters': {'learning_rate': 1.0407908566536805e-05, 'num_train_epochs': 4.173332176942938, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.298269523995743, 'weight_decay': 0.02619072036367263, 'adam_epsilon': 3.6112777039938105e-08, 'seed': 44, 'global_max_steps': 30, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 3.408230946566266e-05, 'num_train_epochs': 2.6639246926428695, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.29692259300270796, 'weight_decay': 0.03696272531088296, 'adam_epsilon': 2.3700413247456897e-08, 'seed': 43, 'global_max_steps': 19, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 100, 'Current Hyper-parameters': {'learning_rate': 0.00011160780392017986, 'num_train_epochs': 1.7004385146429333, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.29557566200967283, 'weight_decay': 0.04773473025809329, 'adam_epsilon': 1.555431717364246e-08, 'seed': 42, 'global_max_steps': 7, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 3.408230946566266e-05, 'num_train_epochs': 2.6639246926428695, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.29692259300270796, 'weight_decay': 0.03696272531088296, 'adam_epsilon': 2.3700413247456897e-08, 'seed': 43, 'global_max_steps': 19, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 100, 'Current Hyper-parameters': {'learning_rate': 0.00032894824663391915, 'num_train_epochs': 0.5985869289595176, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.0028526793785428883, 'weight_decay': 0.035866704690217965, 'adam_epsilon': 1.72058056178269e-07, 'seed': 42, 'global_max_steps': 8, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 3.408230946566266e-05, 'num_train_epochs': 2.6639246926428695, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.29692259300270796, 'weight_decay': 0.03696272531088296, 'adam_epsilon': 2.3700413247456897e-08, 'seed': 43, 'global_max_steps': 19, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 100, 'Current Hyper-parameters': {'learning_rate': 0.0002980296735167531, 'num_train_epochs': 0.1518696203741756, 'per_device_train_batch_size': 4, 'warmup_ratio': 0.2726932063588831, 'weight_decay': 0.0922847833891892, 'adam_epsilon': 1.6902286721133343e-07, 'seed': 44, 'global_max_steps': 4, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 3.408230946566266e-05, 'num_train_epochs': 2.6639246926428695, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.29692259300270796, 'weight_decay': 0.03696272531088296, 'adam_epsilon': 2.3700413247456897e-08, 'seed': 43, 'global_max_steps': 19, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 100, 'Current Hyper-parameters': {'learning_rate': 0.00021091530245907213, 'num_train_epochs': 9.349437783022083, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.15776878218603932, 'weight_decay': 0.02671236976077643, 'adam_epsilon': 1.0956631945601741e-08, 'seed': 42, 'global_max_steps': 13, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 3.408230946566266e-05, 'num_train_epochs': 2.6639246926428695, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.29692259300270796, 'weight_decay': 0.03696272531088296, 'adam_epsilon': 2.3700413247456897e-08, 'seed': 43, 'global_max_steps': 19, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 100, 'Current Hyper-parameters': {'learning_rate': 1.9459272781871782e-05, 'num_train_epochs': 3.8672508737242617, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.3, 'weight_decay': 0.07191806885282034, 'adam_epsilon': 1.401371644431578e-08, 'seed': 44, 'global_max_steps': 28, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.9459272781871782e-05, 'num_train_epochs': 3.8672508737242617, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.3, 'weight_decay': 0.07191806885282034, 'adam_epsilon': 1.401371644431578e-08, 'seed': 44, 'global_max_steps': 28, 'learner': 'transformer'}}\n",
      "17\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from flaml.data import get_output_from_log\n",
    "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
    "    get_output_from_log(filename=automl_settings['log_file_name'], time_budget=3000)\n",
    "for config in config_history:\n",
    "    print(config)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Wall Clock Time (s)')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "print(len(valid_loss_history))\n",
    "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
    "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Text Summarization Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text summarization task summarizes a long text into a short sentence. For example:\n",
    "\n",
    "- Document: Army explosives experts were called out to deal with a suspect package at the offices on the Newtownards Road on Friday night. Roads were sealed off and traffic diverted as a controlled explosion was carried out. The premises, used by East Belfast MP Naomi Long, have been targeted a number of times. Most recently, petrol bomb attacks were carried out on the offices on consecutive nights in April and May. The attacks began following a Belfast City Council vote in December 2012 restricting the flying of the union flag at the City Hall. Condemning the latest hoax, Alliance MLA Chris Lyttle said: \"It is a serious incident for the local area, it causes serious disruption, it puts people's lives at risk, it can prevent emergency services reaching the area. \"Ultimately we need people with information to share that with the police in order for them to do their job and bring these people to justice.\n",
    "\n",
    "- Summary: A suspicious package left outside an Alliance Party office in east Belfast has been declared a hoax.\n",
    "\n",
    "In this example, we use FLAML to perform *abstractive summarization* using the t5-small language model, i.e., the summary is generated word-by-word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/dashboard/agent.py\", line 21, in <module>\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m     import ray.dashboard.utils as dashboard_utils\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/dashboard/utils.py\", line 15, in <module>\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m     import aioredis  # noqa: F401\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m ModuleNotFoundError: No module named 'aioredis'\n",
      "Using custom data configuration default\n",
      "Reusing dataset xsum (/home/xliu127/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset xsum (/home/xliu127/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934)\n",
      "Using custom data configuration default\n",
      "Reusing dataset xsum (/home/xliu127/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"xsum\", split=\"train\").to_pandas()\n",
    "print(len(train_dataset))\n",
    "dev_dataset = load_dataset(\"xsum\", split=\"validation\").to_pandas()\n",
    "test_dataset = load_dataset(\"xsum\", split=\"test\").to_pandas()\n",
    "\n",
    "custom_sent_keys = [\"document\"]       # specify the column names of the input sentences\n",
    "label_key = \"summary\"                 # specify the column name of the label                              \n",
    "\n",
    "X_train, y_train = train_dataset[custom_sent_keys], train_dataset[label_key]\n",
    "X_val, y_val = dev_dataset[custom_sent_keys], dev_dataset[label_key]\n",
    "X_test = test_dataset[custom_sent_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The main flaml automl API'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' import AutoML class from flaml package '''\n",
    "from flaml import AutoML\n",
    "automl = AutoML()\n",
    "\n",
    "import ray\n",
    "ray.init()\n",
    "\n",
    "automl_settings = {\n",
    "        \"time_budget\": 500,  # setting the time budget\n",
    "        \"task\": \"summarization\",  # setting the task as multiplechoice-classification\n",
    "        \"hf_args\": {\n",
    "            \"output_dir\": \"data/output/\",  # setting the output directory\n",
    "            \"ckpt_per_epoch\": 1,  # setting the number of checkoints per epoch\n",
    "            \"model_path\": \"t5-small\",\n",
    "            \"per_gpu_eval_batch_size\": 16,\n",
    "        },\n",
    "        \"gpu_per_trial\": 1,  # set to 0 if no GPU is available\n",
    "        \"log_file_name\": \"seqclass.log\",  # set the file to save the log for HPO\n",
    "        \"log_type\": \"all\",\n",
    "        # the log type for checkpoints: all if keeping all checkpoints, best if only keeping the best checkpoints                        # the batch size for validation (inference)\n",
    "        \"use_ray\": {\"local_dir\": \"data/output/\"},  # set whether to use Ray\n",
    "        \"metric\": \"rouge1\",\n",
    "        \"n_concurrent_trials\": 4,\n",
    "    }\n",
    "\n",
    "'''The main flaml automl API'''\n",
    "automl.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 0.00020063808488885728, 'num_train_epochs': 3.031785267961068, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.20061470944619902, 'weight_decay': 0.08235097055507552, 'adam_epsilon': 3.419198285469053e-08, 'seed': 42, 'global_max_steps': 206, 'learner': 'transformer', 'FLAML_sample_size': 10000}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 0.00020063808488885728, 'num_train_epochs': 3.031785267961068, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.20061470944619902, 'weight_decay': 0.08235097055507552, 'adam_epsilon': 3.419198285469053e-08, 'seed': 42, 'global_max_steps': 206, 'learner': 'transformer', 'FLAML_sample_size': 10000}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.9056565817389773e-06, 'num_train_epochs': 0.40927707755155296, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.17228217003792137, 'weight_decay': 0.077077346749664, 'adam_epsilon': 7.198998095723575e-08, 'seed': 40, 'global_max_steps': 126, 'learner': 'transformer', 'FLAML_sample_size': 10000}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 0.00020063808488885728, 'num_train_epochs': 3.031785267961068, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.20061470944619902, 'weight_decay': 0.08235097055507552, 'adam_epsilon': 3.419198285469053e-08, 'seed': 42, 'global_max_steps': 206, 'learner': 'transformer', 'FLAML_sample_size': 10000}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 2.476795107904152e-06, 'num_train_epochs': 0.7666336457913417, 'per_device_train_batch_size': 4, 'warmup_ratio': 0.02209754903572306, 'weight_decay': 0.059885380824711995, 'adam_epsilon': 9.124888202650256e-07, 'seed': 41, 'global_max_steps': 207, 'learner': 'transformer', 'FLAML_sample_size': 10000}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 0.00020063808488885728, 'num_train_epochs': 3.031785267961068, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.20061470944619902, 'weight_decay': 0.08235097055507552, 'adam_epsilon': 3.419198285469053e-08, 'seed': 42, 'global_max_steps': 206, 'learner': 'transformer', 'FLAML_sample_size': 10000}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 1.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 125, 'learner': 'transformer', 'FLAML_sample_size': 10000}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 0.00020063808488885728, 'num_train_epochs': 3.031785267961068, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.20061470944619902, 'weight_decay': 0.08235097055507552, 'adam_epsilon': 3.419198285469053e-08, 'seed': 42, 'global_max_steps': 206, 'learner': 'transformer', 'FLAML_sample_size': 10000}}\n",
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/dashboard/agent.py\", line 21, in <module>\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m     import ray.dashboard.utils as dashboard_utils\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/dashboard/utils.py\", line 15, in <module>\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m     import aioredis  # noqa: F401\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m ModuleNotFoundError: No module named 'aioredis'\n"
     ]
    }
   ],
   "source": [
    "from flaml.data import get_output_from_log\n",
    "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
    "    get_output_from_log(filename=automl_settings['log_file_name'], time_budget=3000)\n",
    "for config in config_history:\n",
    "    print(config)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Wall Clock Time (s)')\n",
    "plt.ylabel('Rouge 1')\n",
    "print(len(valid_loss_history))\n",
    "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
    "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9d36fc5b7c3dd4177ff1b60184dd696c0acc18150a44682abca4d769811bd46"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
