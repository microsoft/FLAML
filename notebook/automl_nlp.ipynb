{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved. \n",
    "\n",
    "Licensed under the MIT License.\n",
    "\n",
    "# FineTuning NLP Models with FLAML Library\n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "FLAML is a Python library (https://github.com/microsoft/FLAML) designed to automatically produce accurate machine learning models \n",
    "with low computational cost. It is fast and economical. The simple and lightweight design makes it easy to use and extend, such as adding new learners. FLAML can \n",
    "- serve as an economical AutoML engine,\n",
    "- be used as a fast hyperparameter tuning tool, or \n",
    "- be embedded in self-tuning software that requires low latency & resource in repetitive\n",
    "   tuning tasks.\n",
    "\n",
    "In this notebook, we demonstrate how to use the FLAML library to fine tune an NLP language model with hyperparameter search. \n",
    "\n",
    "FLAML requires `Python>=3.6`. To run this notebook example, please install flaml with the `nlp,ray,notebook` and `blendsearch` option:\n",
    "```bash\n",
    "pip install flaml[nlp,ray,notebook,blendsearch];\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flaml[blendsearch,nlp,notebook,ray] in /data/xliu127/projects/hyperopt/FLAML (0.9.7)\n",
      "Requirement already satisfied: NumPy>=1.16.2 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.22.2)\n",
      "Requirement already satisfied: lightgbm>=2.3.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (3.3.2)\n",
      "Requirement already satisfied: xgboost<=1.3.3,>=0.90 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.3.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.8.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.0.2)\n",
      "Requirement already satisfied: transformers>=4.14 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (4.16.2)\n",
      "Requirement already satisfied: datasets in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.18.3)\n",
      "Requirement already satisfied: torch in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.10.2)\n",
      "Requirement already satisfied: seqeval in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.2.2)\n",
      "Requirement already satisfied: nltk in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (3.7)\n",
      "Requirement already satisfied: rouge_score in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (0.0.4)\n",
      "Requirement already satisfied: openml==0.10.2 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (0.10.2)\n",
      "Requirement already satisfied: jupyter in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.0.0)\n",
      "Requirement already satisfied: matplotlib in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (3.5.1)\n",
      "Requirement already satisfied: rgf-python in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (3.12.0)\n",
      "Requirement already satisfied: catboost>=0.26 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.0.4)\n",
      "Collecting optuna==2.8.0\n",
      "  Downloading optuna-2.8.0-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 KB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: ray[tune]~=1.10 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.10.0)\n",
      "Requirement already satisfied: liac-arff>=2.4.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from openml==0.10.2->flaml[blendsearch,nlp,notebook,ray]) (2.5.0)\n",
      "Requirement already satisfied: python-dateutil in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from openml==0.10.2->flaml[blendsearch,nlp,notebook,ray]) (2.8.2)\n",
      "Requirement already satisfied: requests in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from openml==0.10.2->flaml[blendsearch,nlp,notebook,ray]) (2.27.1)\n",
      "Requirement already satisfied: xmltodict in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from openml==0.10.2->flaml[blendsearch,nlp,notebook,ray]) (0.12.0)\n",
      "Collecting cmaes>=0.8.2\n",
      "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
      "Collecting sqlalchemy>=1.1.0\n",
      "  Downloading SQLAlchemy-1.4.31-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (21.3)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting cliff\n",
      "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 KB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (4.62.3)\n",
      "Requirement already satisfied: alembic in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (1.7.6)\n",
      "Requirement already satisfied: graphviz in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from catboost>=0.26->flaml[blendsearch,nlp,notebook,ray]) (0.19.1)\n",
      "Requirement already satisfied: plotly in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from catboost>=0.26->flaml[blendsearch,nlp,notebook,ray]) (5.6.0)\n",
      "Requirement already satisfied: six in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from catboost>=0.26->flaml[blendsearch,nlp,notebook,ray]) (1.16.0)\n",
      "Requirement already satisfied: wheel in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from lightgbm>=2.3.1->flaml[blendsearch,nlp,notebook,ray]) (0.37.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from pandas>=1.1.4->flaml[blendsearch,nlp,notebook,ray]) (2021.3)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (1.0.3)\n",
      "Requirement already satisfied: click>=7.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (8.0.3)\n",
      "Requirement already satisfied: pyyaml in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (6.0)\n",
      "Requirement already satisfied: attrs in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (21.4.0)\n",
      "Requirement already satisfied: jsonschema in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (3.2.0)\n",
      "Requirement already satisfied: grpcio>=1.28.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (1.44.0)\n",
      "Requirement already satisfied: protobuf>=3.15.3 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (3.19.4)\n",
      "Requirement already satisfied: redis>=3.5.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (4.1.4)\n",
      "Requirement already satisfied: filelock in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (3.6.0)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (2.5)\n",
      "Requirement already satisfied: tabulate in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (0.8.9)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from scikit-learn>=0.24->flaml[blendsearch,nlp,notebook,ray]) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from scikit-learn>=0.24->flaml[blendsearch,nlp,notebook,ray]) (1.1.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from transformers>=4.14->flaml[blendsearch,nlp,notebook,ray]) (0.11.5)\n",
      "Requirement already satisfied: sacremoses in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from transformers>=4.14->flaml[blendsearch,nlp,notebook,ray]) (0.0.47)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from transformers>=4.14->flaml[blendsearch,nlp,notebook,ray]) (0.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from transformers>=4.14->flaml[blendsearch,nlp,notebook,ray]) (2022.1.18)\n",
      "Requirement already satisfied: multiprocess in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from datasets->flaml[blendsearch,nlp,notebook,ray]) (0.70.12.2)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from datasets->flaml[blendsearch,nlp,notebook,ray]) (2022.2.0)\n",
      "Requirement already satisfied: xxhash in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from datasets->flaml[blendsearch,nlp,notebook,ray]) (3.0.0)\n",
      "Requirement already satisfied: aiohttp in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from datasets->flaml[blendsearch,nlp,notebook,ray]) (3.8.1)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from datasets->flaml[blendsearch,nlp,notebook,ray]) (7.0.0)\n",
      "Requirement already satisfied: dill in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from datasets->flaml[blendsearch,nlp,notebook,ray]) (0.3.4)\n",
      "Requirement already satisfied: qtconsole in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter->flaml[blendsearch,nlp,notebook,ray]) (5.2.2)\n",
      "Requirement already satisfied: nbconvert in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter->flaml[blendsearch,nlp,notebook,ray]) (6.4.2)\n",
      "Requirement already satisfied: ipywidgets in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter->flaml[blendsearch,nlp,notebook,ray]) (7.6.5)\n",
      "Requirement already satisfied: notebook in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter->flaml[blendsearch,nlp,notebook,ray]) (6.4.8)\n",
      "Requirement already satisfied: ipykernel in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter->flaml[blendsearch,nlp,notebook,ray]) (6.9.1)\n",
      "Requirement already satisfied: jupyter-console in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter->flaml[blendsearch,nlp,notebook,ray]) (6.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from matplotlib->flaml[blendsearch,nlp,notebook,ray]) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from matplotlib->flaml[blendsearch,nlp,notebook,ray]) (9.0.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from matplotlib->flaml[blendsearch,nlp,notebook,ray]) (4.29.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from matplotlib->flaml[blendsearch,nlp,notebook,ray]) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from matplotlib->flaml[blendsearch,nlp,notebook,ray]) (3.0.4)\n",
      "Requirement already satisfied: absl-py in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from rouge_score->flaml[blendsearch,nlp,notebook,ray]) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from torch->flaml[blendsearch,nlp,notebook,ray]) (4.1.1)\n",
      "Requirement already satisfied: deprecated>=1.2.3 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from redis>=3.5.0->ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (1.2.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from requests->openml==0.10.2->flaml[blendsearch,nlp,notebook,ray]) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from requests->openml==0.10.2->flaml[blendsearch,nlp,notebook,ray]) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from requests->openml==0.10.2->flaml[blendsearch,nlp,notebook,ray]) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from requests->openml==0.10.2->flaml[blendsearch,nlp,notebook,ray]) (3.3)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-1.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (156 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.6/156.6 KB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: multidict<7.0,>=4.5 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from aiohttp->datasets->flaml[blendsearch,nlp,notebook,ray]) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from aiohttp->datasets->flaml[blendsearch,nlp,notebook,ray]) (1.3.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from aiohttp->datasets->flaml[blendsearch,nlp,notebook,ray]) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from aiohttp->datasets->flaml[blendsearch,nlp,notebook,ray]) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from aiohttp->datasets->flaml[blendsearch,nlp,notebook,ray]) (1.7.2)\n",
      "Requirement already satisfied: importlib-metadata in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from alembic->optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (4.11.1)\n",
      "Requirement already satisfied: importlib-resources in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from alembic->optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (5.4.0)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 KB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.0/113.0 KB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting PrettyTable>=0.7.2\n",
      "  Downloading prettytable-3.1.1-py3-none-any.whl (26 kB)\n",
      "Collecting autopage>=0.4.0\n",
      "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 KB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cmd2>=1.0.0\n",
      "  Downloading cmd2-2.4.0-py3-none-any.whl (150 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 KB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: traitlets<6.0,>=5.1.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (5.1.1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (8.0.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (7.1.2)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (6.1)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (1.5.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.1.3)\n",
      "Requirement already satisfied: nest-asyncio in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (1.5.4)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipywidgets->jupyter->flaml[blendsearch,nlp,notebook,ray]) (5.1.3)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipywidgets->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.2.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipywidgets->jupyter->flaml[blendsearch,nlp,notebook,ray]) (1.0.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipywidgets->jupyter->flaml[blendsearch,nlp,notebook,ray]) (3.5.2)\n",
      "Requirement already satisfied: setuptools in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jsonschema->ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (60.9.3)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jsonschema->ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (0.18.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter-console->jupyter->flaml[blendsearch,nlp,notebook,ray]) (3.0.28)\n",
      "Requirement already satisfied: pygments in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter-console->jupyter->flaml[blendsearch,nlp,notebook,ray]) (2.11.2)\n",
      "Requirement already satisfied: bleach in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (4.1.0)\n",
      "Requirement already satisfied: jinja2>=2.4 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (3.0.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (1.5.0)\n",
      "Requirement already satisfied: defusedxml in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.7.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.8.4)\n",
      "Requirement already satisfied: testpath in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.5.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.5.11)\n",
      "Requirement already satisfied: jupyterlab-pygments in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.1.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.4)\n",
      "Requirement already satisfied: jupyter-core in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (4.9.2)\n",
      "Requirement already satisfied: pyzmq>=17 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from notebook->jupyter->flaml[blendsearch,nlp,notebook,ray]) (22.3.0)\n",
      "Requirement already satisfied: argon2-cffi in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from notebook->jupyter->flaml[blendsearch,nlp,notebook,ray]) (21.3.0)\n",
      "Requirement already satisfied: prometheus-client in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from notebook->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.13.1)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from notebook->jupyter->flaml[blendsearch,nlp,notebook,ray]) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from notebook->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.13.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from plotly->catboost>=0.26->flaml[blendsearch,nlp,notebook,ray]) (8.0.1)\n",
      "Requirement already satisfied: qtpy in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from qtconsole->jupyter->flaml[blendsearch,nlp,notebook,ray]) (2.0.1)\n",
      "Collecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.7 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (0.2.5)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (1.13.3)\n",
      "Requirement already satisfied: pickleshare in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.7.5)\n",
      "Requirement already satisfied: decorator in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.18.1)\n",
      "Requirement already satisfied: black in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (22.1.0)\n",
      "Requirement already satisfied: backcall in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.2.0)\n",
      "Requirement already satisfied: stack-data in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (4.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jinja2>=2.4->nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (2.0.1)\n",
      "Requirement already satisfied: ptyprocess in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from terminado>=0.8.3->notebook->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter->flaml[blendsearch,nlp,notebook,ray]) (21.2.0)\n",
      "Requirement already satisfied: webencodings in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from bleach->nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.5.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from importlib-metadata->alembic->optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (3.7.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.8.3)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->flaml[blendsearch,nlp,notebook,ray]) (1.15.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from black->ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.9.0)\n",
      "Requirement already satisfied: platformdirs>=2 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from black->ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (2.5.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from black->ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (2.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from black->ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.4.3)\n",
      "Requirement already satisfied: executing in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.8.2)\n",
      "Requirement already satisfied: pure-eval in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.2.2)\n",
      "Requirement already satisfied: asttokens in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (2.0.5)\n",
      "Requirement already satisfied: pycparser in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->flaml[blendsearch,nlp,notebook,ray]) (2.21)\n",
      "Building wheels for collected packages: pyperclip\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=48c95a4ac8c1648a27ef72ad1931bdb6e1f886d429a98ff693a24f9a3d2c37c2\n",
      "  Stored in directory: /home/xliu127/.cache/pip/wheels/7f/1a/65/84ff8c386bec21fca6d220ea1f5498a0367883a78dd5ba6122\n",
      "Successfully built pyperclip\n",
      "Installing collected packages: pyperclip, PrettyTable, pbr, Mako, greenlet, colorlog, cmd2, cmaes, autopage, stevedore, sqlalchemy, cliff, optuna\n",
      "Successfully installed Mako-1.1.6 PrettyTable-3.1.1 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.0 colorlog-6.6.0 greenlet-1.1.2 optuna-2.8.0 pbr-5.8.1 pyperclip-1.8.2 sqlalchemy-1.4.31 stevedore-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install flaml[nlp,ray,notebook,blendsearch];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sentiment Classification Example\n",
    "### Load data and preprocess\n",
    "\n",
    "The Stanford Sentiment treebank (SST-2) dataset is a dataset for sentiment classification. First, let's load this dataset into pandas dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f5fa69e7154cc99684d06f09c96934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/7.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b77dc9cc77444eda943cd803c03df4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset glue/sst2 (download: 7.09 MiB, generated: 4.81 MiB, post-processed: Unknown size, total: 11.90 MiB) to /home/xliu127/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882f8a670c08408980a900295cfeab24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/7.44M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074cea4170ee4aeabe9eea081c79d5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfcd40c81125446f824e40a1f51b1d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f021f2a900fb4e80be0201345dffc3f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/xliu127/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset glue downloaded and prepared to /home/xliu127/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/xliu127/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"glue\", \"sst2\", split=\"train\").to_pandas().iloc[:10000]\n",
    "dev_dataset = load_dataset(\"glue\", \"sst2\", split=\"validation\").to_pandas().iloc[:10000]\n",
    "test_dataset = load_dataset(\"glue\", \"sst2\", split=\"test\").to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the first 5 examples of this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hide new secretions from the parental units</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contains no wit , only labored gags</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that loves its characters and communicates som...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>remains utterly satisfied to remain the same t...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on the worst revenge-of-the-nerds clichés the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label  idx\n",
       "0       hide new secretions from the parental units       0    0\n",
       "1               contains no wit , only labored gags       0    1\n",
       "2  that loves its characters and communicates som...      1    2\n",
       "3  remains utterly satisfied to remain the same t...      0    3\n",
       "4  on the worst revenge-of-the-nerds clichés the ...      0    4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the data into X and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sent_keys = [\"sentence\"]          # specify the column names of the input sentences\n",
    "label_key = \"label\"                                    # specify the column name of the label\n",
    "\n",
    "X_train, y_train = train_dataset[custom_sent_keys], train_dataset[label_key]\n",
    "X_val, y_val = dev_dataset[custom_sent_keys], dev_dataset[label_key]\n",
    "X_test = test_dataset[custom_sent_keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run FLAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "E0305 06:58:57.975986938   49812 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0305 06:58:58.049658638   49812 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "2022-03-05 06:58:58,585\tERROR services.py:1383 -- Failed to start the dashboard: Failed to read dashbord log: [Errno 2] No such file or directory: '/tmp/ray/session_2022-03-05_06-58-56_813199_49812/logs/dashboard.log'\n",
      "E0305 06:58:58.593016246   49812 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E0305 06:58:58.624272424   49812 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '155.246.89.124',\n",
       " 'raylet_ip_address': '155.246.89.124',\n",
       " 'redis_address': '155.246.89.124:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2022-03-05_06-58-56_813199_49812/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2022-03-05_06-58-56_813199_49812/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2022-03-05_06-58-56_813199_49812',\n",
       " 'metrics_export_port': 40922,\n",
       " 'gcs_address': '155.246.89.124:35505',\n",
       " 'node_id': 'bee5b455541dbbf7d7f81f71d99e3ea0d96336914fc2a55d0792519f'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/dashboard/agent.py\", line 21, in <module>\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m     import ray.dashboard.utils as dashboard_utils\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/dashboard/utils.py\", line 29, in <module>\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m     from ray.dashboard.optional_deps import (aiohttp, aiosignal, aioredis, hdrs,\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/dashboard/optional_deps.py\", line 3, in <module>\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m     import opencensus  # noqa: F401\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m ModuleNotFoundError: No module named 'opencensus'\n"
     ]
    }
   ],
   "source": [
    "''' import AutoML class from flaml package '''\n",
    "from flaml import AutoML\n",
    "automl = AutoML()\n",
    "\n",
    "import ray\n",
    "ray.init() # you may encounter the ModuleNotFoundError: No module named 'opencensus', which can be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "automl_settings = {\n",
    "        \"time_budget\": 500,                 # setting the time budget\n",
    "        \"task\": \"seq-classification\",       # setting the task as seq-classification\n",
    "        \"hf_args\":\n",
    "            {\"output_dir\": \"data/output/\",  # setting the output directory\n",
    "             \"ckpt_per_epoch\": 1,           # setting the number of checkoints per epoch\n",
    "             \"model_path\": \"google/electra-base-discriminator\",\n",
    "             },\n",
    "        \"gpu_per_trial\": 1,                 # set to 0 if no GPU is available\n",
    "        \"log_file_name\": \"seqclass.log\",    # set the file to save the log for HPO\n",
    "        \"log_type\": \"all\",                  # the log type for checkpoints: all if keeping all checkpoints, best if only keeping the best checkpoints                        # the batch size for validation (inference)\n",
    "        \"use_ray\": True,                     # set whether to use Ray\n",
    "        \"n_concurrent_trials\": 4\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 07:12:00 (running for 00:01:41.29)<br>Memory usage on this node: 27.1/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/96 CPUs, 0/4 GPUs, 0.0/250.43 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Current best trial: 5fc63bdd with val_loss=0.49082568807339455 and parameters={'learning_rate': 0.0009149809294976631, 'num_train_epochs': 0.11641930732714473, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.26555680818499533, 'weight_decay': 0.08699485855077174, 'adam_epsilon': 6.871680478952233e-08, 'seed': 41, 'global_max_steps': 9223372036854775807, 'learner': 'transformer'}<br>Result logdir: /home/xliu127/ray_results/train_2022-03-05_07-10-18<br>Number of trials: 5/1000000 (5 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50403)\u001b[0m {'eval_loss': 0.20583172142505646, 'eval_automl_metric': 0.0745412844036697, 'eval_runtime': 9.5278, 'eval_samples_per_second': 91.522, 'eval_steps_per_second': 91.522, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(train pid=50376)\u001b[0m {'eval_loss': 0.2556954026222229, 'eval_automl_metric': 0.07224770642201839, 'eval_runtime': 9.2868, 'eval_samples_per_second': 93.897, 'eval_steps_per_second': 93.897, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(train pid=50371)\u001b[0m {'eval_loss': 0.27808061242103577, 'eval_automl_metric': 0.09633027522935778, 'eval_runtime': 11.4038, 'eval_samples_per_second': 76.465, 'eval_steps_per_second': 76.465, 'epoch': 0.38}\n",
      "\u001b[2m\u001b[36m(train pid=50403)\u001b[0m {'eval_loss': 0.20583172142505646, 'eval_automl_metric': 0.0745412844036697, 'eval_runtime': 9.0179, 'eval_samples_per_second': 96.697, 'eval_steps_per_second': 96.697, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(train pid=50376)\u001b[0m {'eval_loss': 0.2556954026222229, 'eval_automl_metric': 0.07224770642201839, 'eval_runtime': 9.6653, 'eval_samples_per_second': 90.219, 'eval_steps_per_second': 90.219, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(train pid=50371)\u001b[0m {'train_runtime': 46.1448, 'train_samples_per_second': 81.918, 'train_steps_per_second': 2.579, 'train_loss': 0.45009568158318014, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50371)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=50371)\u001b[0m   Num examples = 872\n",
      "\u001b[2m\u001b[36m(train pid=50371)\u001b[0m   Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50398)\u001b[0m {'eval_loss': 0.40110892057418823, 'eval_automl_metric': 0.11582568807339455, 'eval_runtime': 9.7336, 'eval_samples_per_second': 89.587, 'eval_steps_per_second': 89.587, 'epoch': 0.62}\n",
      "\u001b[2m\u001b[36m(train pid=50403)\u001b[0m {'eval_loss': 0.2070195972919464, 'eval_automl_metric': 0.0745412844036697, 'eval_runtime': 9.1212, 'eval_samples_per_second': 95.602, 'eval_steps_per_second': 95.602, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(train pid=50376)\u001b[0m {'eval_loss': 0.25353941321372986, 'eval_automl_metric': 0.07339449541284404, 'eval_runtime': 9.7712, 'eval_samples_per_second': 89.242, 'eval_steps_per_second': 89.242, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(train pid=50398)\u001b[0m {'eval_loss': 0.40110892057418823, 'eval_automl_metric': 0.11582568807339455, 'eval_runtime': 9.5366, 'eval_samples_per_second': 91.437, 'eval_steps_per_second': 91.437, 'epoch': 0.62}\n",
      "\u001b[2m\u001b[36m(train pid=50403)\u001b[0m {'eval_loss': 0.2070195972919464, 'eval_automl_metric': 0.0745412844036697, 'eval_runtime': 8.864, 'eval_samples_per_second': 98.375, 'eval_steps_per_second': 98.375, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(train pid=50398)\u001b[0m {'train_runtime': 126.5904, 'train_samples_per_second': 433.996, 'train_steps_per_second': 108.5, 'train_loss': 0.49369501294483625, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50398)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=50398)\u001b[0m   Num examples = 872\n",
      "\u001b[2m\u001b[36m(train pid=50398)\u001b[0m   Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50376)\u001b[0m {'eval_loss': 0.25353941321372986, 'eval_automl_metric': 0.07339449541284404, 'eval_runtime': 9.6581, 'eval_samples_per_second': 90.287, 'eval_steps_per_second': 90.287, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(train pid=50403)\u001b[0m {'train_runtime': 131.5202, 'train_samples_per_second': 228.102, 'train_steps_per_second': 7.14, 'train_loss': 0.3094321658546655, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50403)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=50403)\u001b[0m   Num examples = 872\n",
      "\u001b[2m\u001b[36m(train pid=50403)\u001b[0m   Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50376)\u001b[0m {'train_runtime': 133.1484, 'train_samples_per_second': 159.15, 'train_steps_per_second': 4.987, 'train_loss': 0.3239936241122524, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50376)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=50376)\u001b[0m   Num examples = 872\n",
      "\u001b[2m\u001b[36m(train pid=50376)\u001b[0m   Batch size = 1\n",
      "2022-03-05 07:12:57,120\tINFO tune.py:636 -- Total run time: 158.26 seconds (100.73 seconds for the tuning loop).\n",
      "[flaml.automl: 03-05 07:12:57] {2838} INFO - selected model: None\n",
      "\u001b[32m[I 2022-03-05 07:12:57,739]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "\u001b[2m\u001b[36m(bundle_reservation_check_func pid=50369)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\u001b[2m\u001b[36m(bundle_reservation_check_func pid=50369)\u001b[0m   from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 07:12:59 (running for 00:00:01.86)<br>Memory usage on this node: 12.6/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.43 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-03-05_07-12-57<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_trainable_function_wrapper pid=50369)\u001b[0m E0305 07:12:59.623192723   54605 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 07:13:03 (running for 00:00:05.87)<br>Memory usage on this node: 12.7/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.43 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-03-05_07-12-57<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 07:13:08 (running for 00:00:10.88)<br>Memory usage on this node: 15.3/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.43 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-03-05_07-12-57<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_trainable_function_wrapper pid=50369)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_trainable_function_wrapper pid=50369)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 07:13:13 (running for 00:00:15.89)<br>Memory usage on this node: 16.1/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.43 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-03-05_07-12-57<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_trainable_function_wrapper pid=50369)\u001b[0m {'loss': 0.703, 'learning_rate': 3.388818257398752e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 07:13:18 (running for 00:00:20.89)<br>Memory usage on this node: 16.0/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.43 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-03-05_07-12-57<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_trainable_function_wrapper pid=50369)\u001b[0m {'train_runtime': 10.2122, 'train_samples_per_second': 114.0, 'train_steps_per_second': 3.623, 'train_loss': 0.7030346329147751, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-05 07:13:24,120\tWARNING util.py:163 -- The `fetch_result` operation took 0.790 s, which may be a performance bottleneck.\n",
      "2022-03-05 07:13:24,126\tWARNING util.py:163 -- The `process_trial` operation took 0.796 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial _trainable_function_wrapper_bd5cd0c6 reported train_time=22.88 with parameters={'learning_rate': 0.0009149809294976631, 'num_train_epochs': 0.11641930732714473, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.26555680818499533, 'weight_decay': 0.08699485855077174, 'adam_epsilon': 6.871680478952233e-08, 'seed': 41, 'global_max_steps': 37, 'learner': 'transformer'}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 07:13:24 (running for 00:00:26.36)<br>Memory usage on this node: 17.8/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.43 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Current best trial: bd5cd0c6 with train_time=22.87708592414856 and parameters={'learning_rate': 0.0009149809294976631, 'num_train_epochs': 0.11641930732714473, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.26555680818499533, 'weight_decay': 0.08699485855077174, 'adam_epsilon': 6.871680478952233e-08, 'seed': 41, 'global_max_steps': 37, 'learner': 'transformer'}<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-03-05_07-12-57<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-05 07:13:25,650\tWARNING util.py:163 -- The `fetch_result` operation took 0.775 s, which may be a performance bottleneck.\n",
      "2022-03-05 07:13:25,698\tWARNING util.py:163 -- The `process_trial` operation took 0.823 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial _trainable_function_wrapper_bd5cd0c6 completed. Last result: estimator=<flaml.model.TransformersEstimator object at 0x7fed3cd888b0>,train_time=22.87708592414856\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 07:13:42 (running for 00:00:44.71)<br>Memory usage on this node: 15.4/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/96 CPUs, 0/4 GPUs, 0.0/250.43 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Current best trial: bd5cd0c6 with train_time=22.87708592414856 and parameters={'learning_rate': 0.0009149809294976631, 'num_train_epochs': 0.11641930732714473, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.26555680818499533, 'weight_decay': 0.08699485855077174, 'adam_epsilon': 6.871680478952233e-08, 'seed': 41, 'global_max_steps': 37, 'learner': 'transformer'}<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-03-05_07-12-57<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                          </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  adam_epsilon</th><th style=\"text-align: right;\">  global_max_steps</th><th>learner    </th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  num_train_epochs</th><th style=\"text-align: right;\">  per_device_train_batch_size</th><th style=\"text-align: right;\">  seed</th><th style=\"text-align: right;\">  warmup_ratio</th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>_trainable_function_wrapper_bd5cd0c6</td><td>TERMINATED</td><td>155.246.89.124:50369</td><td style=\"text-align: right;\">   6.87168e-08</td><td style=\"text-align: right;\">                37</td><td>transformer</td><td style=\"text-align: right;\">    0.000914981</td><td style=\"text-align: right;\">          0.116419</td><td style=\"text-align: right;\">                           32</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">      0.265557</td><td style=\"text-align: right;\">     0.0869949</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         22.8774</td><td style=\"text-align: right;\">     22.8771</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-05 07:13:42,592\tINFO tune.py:636 -- Total run time: 44.85 seconds (27.94 seconds for the tuning loop).\n",
      "[flaml.automl: 03-05 07:13:50] {2948} INFO - retrain transformer for 22.9s\n",
      "[flaml.automl: 03-05 07:13:50] {2955} INFO - retrained model: ElectraForSequenceClassification(\n",
      "  (electra): ElectraModel(\n",
      "    (embeddings): ElectraEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): ElectraEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): ElectraClassificationHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "[flaml.automl: 03-05 07:13:50] {2290} INFO - fit succeeded\n",
      "[flaml.automl: 03-05 07:13:50] {2291} INFO - Time taken to find the best model: 53.985883951187134\n"
     ]
    }
   ],
   "source": [
    "'''The main flaml automl API'''\n",
    "automl.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **automl_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ML leaner: transformer\n",
      "Best hyperparmeter config: {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 3.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 71, 'FLAML_sample_size': 10000}\n",
      "Best accuracy on validation data: 0.9541\n",
      "Training duration of best run: 75.44 s\n"
     ]
    }
   ],
   "source": [
    "'''retrieve best config and best learner'''\n",
    "print('Best hyperparmeter config:', automl.best_config)\n",
    "print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
    "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''pickle and save the automl object'''\n",
    "import pickle\n",
    "with open('automl.pkl', 'wb') as f:\n",
    "    pickle.dump(automl, f, pickle.HIGHEST_PROTOCOL)\n",
    "'''load pickled automl object'''\n",
    "with open('automl.pkl', 'rb') as f:\n",
    "    automl = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 03-01 20:01:20] {766} WARNING - No estimator is trained. Please run fit with enough budget.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels None\n"
     ]
    }
   ],
   "source": [
    "'''compute predictions of testing dataset''' \n",
    "y_pred = automl.predict(X_test, **{\"hf_args\": {\"per_gpu_eval_batch_size\": 1}})\n",
    "print('Predicted labels', y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 0.0001683951566733354, 'num_train_epochs': 0.2210193378617947, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.04205307554489066, 'weight_decay': 0.16569345755141265, 'adam_epsilon': 1.6339103068074946e-07, 'seed': 44, 'global_max_steps': 70, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 0.0001683951566733354, 'num_train_epochs': 0.2210193378617947, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.04205307554489066, 'weight_decay': 0.16569345755141265, 'adam_epsilon': 1.6339103068074946e-07, 'seed': 44, 'global_max_steps': 70, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 4.06541243930961e-06, 'num_train_epochs': 0.39160216739720227, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.0005088579635559642, 'weight_decay': 0.15834250683338044, 'adam_epsilon': 1.8072721716293894e-08, 'seed': 43, 'global_max_steps': 245, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 4.06541243930961e-06, 'num_train_epochs': 0.39160216739720227, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.0005088579635559642, 'weight_decay': 0.15834250683338044, 'adam_epsilon': 1.8072721716293894e-08, 'seed': 43, 'global_max_steps': 245, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.084699205980285e-06, 'num_train_epochs': 0.33613850932131845, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.019111274702022462, 'weight_decay': 0.28691064048089554, 'adam_epsilon': 5.346382363277181e-08, 'seed': 40, 'global_max_steps': 421, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.084699205980285e-06, 'num_train_epochs': 0.33613850932131845, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.019111274702022462, 'weight_decay': 0.28691064048089554, 'adam_epsilon': 5.346382363277181e-08, 'seed': 40, 'global_max_steps': 421, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 5.738347095450703e-06, 'num_train_epochs': 0.15715398257485533, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.11022443614360844, 'weight_decay': 0.03419372774239863, 'adam_epsilon': 4.785016539529346e-08, 'seed': 41, 'global_max_steps': 197, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.084699205980285e-06, 'num_train_epochs': 0.33613850932131845, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.019111274702022462, 'weight_decay': 0.28691064048089554, 'adam_epsilon': 5.346382363277181e-08, 'seed': 40, 'global_max_steps': 421, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 2.0473545661471498e-06, 'num_train_epochs': 0.34169313043908095, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.05834925558635486, 'weight_decay': 0.3, 'adam_epsilon': 2.7429849778869072e-08, 'seed': 40, 'global_max_steps': 428, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 2.0473545661471498e-06, 'num_train_epochs': 0.34169313043908095, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.05834925558635486, 'weight_decay': 0.3, 'adam_epsilon': 2.7429849778869072e-08, 'seed': 40, 'global_max_steps': 428, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 3.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 3.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1e-06, 'num_train_epochs': 0.3306741850606283, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.0, 'weight_decay': 0.2578876562560198, 'adam_epsilon': 1.042069300590234e-07, 'seed': 40, 'global_max_steps': 414, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 3.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.4395226763286561e-05, 'num_train_epochs': 0.11016932663769363, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.08045032769233901, 'weight_decay': 0.002015422229971127, 'adam_epsilon': 2.4641023040418407e-08, 'seed': 41, 'global_max_steps': 138, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 3.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 8.003778764416909e-06, 'num_train_epochs': 1.538516331487565, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.025044635819042906, 'weight_decay': 0.040537327679417284, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 3.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 2.3364738960350788e-05, 'num_train_epochs': 1.594510060700272, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 3.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.0436709545680516e-05, 'num_train_epochs': 1.8845967679352, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.025680249011849145, 'adam_epsilon': 8.550666633722979e-07, 'seed': 43, 'global_max_steps': 313, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 3.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.2494098468160911e-05, 'num_train_epochs': 5.849791656938768, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 8.653857539100394e-07, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.2494098468160911e-05, 'num_train_epochs': 5.849791656938768, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 8.653857539100394e-07, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}}\n"
     ]
    }
   ],
   "source": [
    "from flaml.data import get_output_from_log\n",
    "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
    "    get_output_from_log(filename=automl_settings['log_file_name'], time_budget=3000)\n",
    "for config in config_history:\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Wall Clock Time (s)')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "print(len(valid_loss_history))\n",
    "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
    "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Other Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides sequence classification, FLAML currently also supports four other tasks (more tasks are to be supported, which can be found on FLAML's documentation website https://microsoft.github.io/FLAML/docs/Examples/AutoML-NLP):\n",
    "\n",
    "- sequence regression: predicting a float number from the input sequence, e.g., predicting the rating of a hotel review based on the text content;\n",
    "- token classification: predicting the label of each token in a sequence, e.g., named entity recognition;\n",
    "- multiple choice: predicting the best second half of a sentence that comes next to the first part of a sentence based on common sensen reasoning. An example is seen below;\n",
    "- (abstractive) summarization: generating the textual summarization of an input paragraph;\n",
    "\n",
    "For each task, you only have to change the \"Load data and preprocess\" with the corresponding data loading process. For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Multiple Choice Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: swag/regular\n",
      "Reusing dataset swag (/home/xliu127/.cache/huggingface/datasets/swag/regular/0.0.0/9640de08cdba6a1469ed3834fcab4b8ad8e38caf5d1ba5e7436d8b1fd067ad4c)\n",
      "No config specified, defaulting to: swag/regular\n",
      "Reusing dataset swag (/home/xliu127/.cache/huggingface/datasets/swag/regular/0.0.0/9640de08cdba6a1469ed3834fcab4b8ad8e38caf5d1ba5e7436d8b1fd067ad4c)\n",
      "No config specified, defaulting to: swag/regular\n",
      "Reusing dataset swag (/home/xliu127/.cache/huggingface/datasets/swag/regular/0.0.0/9640de08cdba6a1469ed3834fcab4b8ad8e38caf5d1ba5e7436d8b1fd067ad4c)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"swag\", split=\"train\").to_pandas().iloc[:100]\n",
    "dev_dataset = load_dataset(\"swag\", split=\"validation\").to_pandas().iloc[:100]\n",
    "test_dataset = load_dataset(\"swag\", split=\"test\").to_pandas().iloc[:100]\n",
    "\n",
    "custom_sent_keys = [\n",
    "        \"sent1\",\n",
    "        \"sent2\",\n",
    "        \"ending0\",\n",
    "        \"ending1\",\n",
    "        \"ending2\",\n",
    "        \"ending3\",\n",
    "        \"gold-source\",\n",
    "        \"video-id\",\n",
    "        \"startphrase\",\n",
    "        \"fold-ind\",\n",
    "    ]                                                  # specify the column names of the input sentences\n",
    "label_key = \"label\"                                    # specify the column name of the label\n",
    "\n",
    "X_train, y_train = train_dataset[custom_sent_keys], train_dataset[label_key]\n",
    "X_val, y_val = dev_dataset[custom_sent_keys], dev_dataset[label_key]\n",
    "X_test = test_dataset[custom_sent_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video-id</th>\n",
       "      <th>fold-ind</th>\n",
       "      <th>startphrase</th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>gold-source</th>\n",
       "      <th>ending0</th>\n",
       "      <th>ending1</th>\n",
       "      <th>ending2</th>\n",
       "      <th>ending3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anetv_jkn6uvmqwh4</td>\n",
       "      <td>3416</td>\n",
       "      <td>Members of the procession walk down the street...</td>\n",
       "      <td>Members of the procession walk down the street...</td>\n",
       "      <td>A drum line</td>\n",
       "      <td>gold</td>\n",
       "      <td>passes by walking down the street playing thei...</td>\n",
       "      <td>has heard approaching them.</td>\n",
       "      <td>arrives and they're outside dancing and asleep.</td>\n",
       "      <td>turns the lead singer watches the performance.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anetv_jkn6uvmqwh4</td>\n",
       "      <td>3417</td>\n",
       "      <td>A drum line passes by walking down the street ...</td>\n",
       "      <td>A drum line passes by walking down the street ...</td>\n",
       "      <td>Members of the procession</td>\n",
       "      <td>gen</td>\n",
       "      <td>are playing ping pong and celebrating one left...</td>\n",
       "      <td>wait slowly towards the cadets.</td>\n",
       "      <td>continues to play as well along the crowd alon...</td>\n",
       "      <td>continue to play marching, interspersed.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            video-id fold-ind  \\\n",
       "0  anetv_jkn6uvmqwh4     3416   \n",
       "1  anetv_jkn6uvmqwh4     3417   \n",
       "\n",
       "                                         startphrase  \\\n",
       "0  Members of the procession walk down the street...   \n",
       "1  A drum line passes by walking down the street ...   \n",
       "\n",
       "                                               sent1  \\\n",
       "0  Members of the procession walk down the street...   \n",
       "1  A drum line passes by walking down the street ...   \n",
       "\n",
       "                       sent2 gold-source  \\\n",
       "0                A drum line        gold   \n",
       "1  Members of the procession         gen   \n",
       "\n",
       "                                             ending0  \\\n",
       "0  passes by walking down the street playing thei...   \n",
       "1  are playing ping pong and celebrating one left...   \n",
       "\n",
       "                           ending1  \\\n",
       "0      has heard approaching them.   \n",
       "1  wait slowly towards the cadets.   \n",
       "\n",
       "                                             ending2  \\\n",
       "0    arrives and they're outside dancing and asleep.   \n",
       "1  continues to play as well along the crowd alon...   \n",
       "\n",
       "                                          ending3  label  \n",
       "0  turns the lead singer watches the performance.      0  \n",
       "1        continue to play marching, interspersed.      3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-05 10:32:27 (running for 00:05:55.59)<br>Memory usage on this node: 25.2/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.25 GiB heap, 0.0/111.24 GiB objects (0.0/1.0 accelerator_type:V100)<br>Current best trial: f2e45f5a with val_loss=0.18999999999999995 and parameters={'learning_rate': 2.5399183759104577e-05, 'num_train_epochs': 10.0, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.060767124594454484, 'weight_decay': 0.08170516786547521, 'adam_epsilon': 5.0930317858296876e-08, 'seed': 40, 'global_max_steps': 9223372036854775807, 'learner': 'transformer'}<br>Result logdir: /home/xliu127/ray_results/train_2022-03-05_10-26-31<br>Number of trials: 33/1000000 (4 RUNNING, 29 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m {'loss': 1.0823, 'learning_rate': 0.0005628621228754496, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m {'loss': 0.9339, 'learning_rate': 0.0001625668236713216, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m {'eval_loss': 1.370664119720459, 'eval_automl_metric': 0.69, 'eval_runtime': 1.1264, 'eval_samples_per_second': 88.779, 'eval_steps_per_second': 88.779, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m 2022-03-05 10:32:30,037\tERROR function_runner.py:268 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/torch/serialization.py\", line 379, in save\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m     _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/torch/serialization.py\", line 499, in _save\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m     zip_file.write_record(name, storage.data_ptr(), num_bytes)\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m OSError: [Errno 28] No space left on device\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 262, in run\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 330, in entrypoint\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m     return self._trainable_func(self.config, self._status_reporter,\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m   File \"/data/xliu127/projects/hyperopt/FLAML/flaml/automl.py\", line 1714, in train\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m     result = states[estimator].training_function(config)\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/utils/trainable.py\", line 353, in _inner\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m     inner(config, checkpoint_dir=None)\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/utils/trainable.py\", line 344, in inner\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m     trainable(config, **fn_kwargs)\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m   File \"/data/xliu127/projects/hyperopt/FLAML/flaml/automl.py\", line 260, in _compute_with_config_base\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m     ) = compute_estimator(\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m   File \"/data/xliu127/projects/hyperopt/FLAML/flaml/ml.py\", line 572, in compute_estimator\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m     val_loss, metric_for_logging, train_time, pred_time = get_val_loss(\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m   File \"/data/xliu127/projects/hyperopt/FLAML/flaml/ml.py\", line 407, in get_val_loss\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m     estimator.fit(X_train, y_train, budget, **fit_kwargs)\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m   File \"/data/xliu127/projects/hyperopt/FLAML/flaml/model.py\", line 602, in fit\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m     self._trainer.train()\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 1440, in train\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m     self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 1569, in _maybe_log_save_evaluate\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m     self._save_checkpoint(model, trial, metrics=metrics)\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 1637, in _save_checkpoint\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m     self.save_model(output_dir, _internal_call=True)\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 2052, in save_model\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m     self._save(output_dir)\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 2104, in _save\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m     self.model.save_pretrained(output_dir, state_dict=state_dict)\n",
      "\u001b[2m\u001b[36m(train pid=41810)\u001b[0m   File \"/data/installation/\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m 2022-03-05 10:32:30,042\tERROR function_runner.py:268 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/torch/serialization.py\", line 379, in save\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m     _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/torch/serialization.py\", line 486, in _save\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m     zip_file.write_record('data.pkl', data_value, len(data_value))\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m OSError: [Errno 28] No space left on device\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/torch/serialization.py\", line 380, in save\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m     return\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/torch/serialization.py\", line 259, in __exit__\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m     self.file_like.write_end_of_file()\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m RuntimeError: [enforce fail at inline_container.cc:300] . unexpected pos 64 vs 0\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 262, in run\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 330, in entrypoint\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m     return self._trainable_func(self.config, self._status_reporter,\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m   File \"/data/xliu127/projects/hyperopt/FLAML/flaml/automl.py\", line 1714, in train\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m     result = states[estimator].training_function(config)\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/utils/trainable.py\", line 353, in _inner\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m     inner(config, checkpoint_dir=None)\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/utils/trainable.py\", line 344, in inner\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m     trainable(config, **fn_kwargs)\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m   File \"/data/xliu127/projects/hyperopt/FLAML/flaml/automl.py\", line 260, in _compute_with_config_base\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m     ) = compute_estimator(\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m   File \"/data/xliu127/projects/hyperopt/FLAML/flaml/ml.py\", line 572, in compute_estimator\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m     val_loss, metric_for_logging, train_time, pred_time = get_val_loss(\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m   File \"/data/xliu127/projects/hyperopt/FLAML/flaml/ml.py\", line 407, in get_val_loss\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m     estimator.fit(X_train, y_train, budget, **fit_kwargs)\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m   File \"/data/xliu127/projects/hyperopt/FLAML/flaml/model.py\", line 602, in fit\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m     self._trainer.train()\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 1440, in train\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m     self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 1569, in _maybe_log_save_evaluate\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m     self._save_checkpoint(model, trial, metrics=metrics)\n",
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packag\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=41847)\u001b[0m {'eval_loss': 0.7794665694236755, 'eval_automl_metric': 0.26, 'eval_runtime': 1.2883, 'eval_samples_per_second': 77.622, 'eval_steps_per_second': 77.622, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-05 10:32:30,526\tERROR trial_runner.py:927 -- Trial train_917ac8a4: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 893, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 707, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/worker.py\", line 1735, in get\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
      "2022-03-05 10:32:30,532\tWARNING worker.py:1257 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff9b266aa435681ddff7b69a2b01000000 Worker ID: b64b3a2bb5a950026bea1e1012943d7a90579bd95341221bf01594cc Node ID: f27b444e55e271781f34ee2461b284ceaca0ae5809b5df5867c2a464 Worker IP address: 155.246.89.124 Worker port: 35625 Worker PID: 41847\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayActorError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_trial\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m             with warn_if_slow(\n",
      "\u001b[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36mfetch_result\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwarn_if_slow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fetch_result\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial_future\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEFAULT_GET_TIMEOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   1734\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRayActorError\u001b[0m: The actor died unexpectedly before finishing this task.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_41519/2884413015.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m'''The main flaml automl API'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mautoml_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/xliu127/projects/hyperopt/FLAML/flaml/automl.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, dataframe, label, metric, task, n_jobs, log_file_name, estimator_list, time_budget, max_iter, sample, ensemble, eval_method, log_type, model_history, split_ratio, n_splits, log_training_metric, mem_thres, pred_time_limit, train_time_limit, X_val, y_val, sample_weight_val, groups_val, groups, verbose, retrain_full, split_type, learner_selector, hpo_method, starting_points, seed, n_concurrent_trials, keep_search_state, early_stop, append_log, auto_augment, min_sample_size, use_ray, **fit_kwargs)\u001b[0m\n\u001b[1;32m   2285\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtraining_log_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_file_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend_log\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msave_helper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2286\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2287\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2288\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2289\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/xliu127/projects/hyperopt/FLAML/flaml/automl.py\u001b[0m in \u001b[0;36m_search\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2832\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_search_sequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2833\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2834\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_search_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2835\u001b[0m         \u001b[0;31m# Add a checkpoint for the current best config to the log.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2836\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_log\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/xliu127/projects/hyperopt/FLAML/flaml/automl.py\u001b[0m in \u001b[0;36m_search_parallel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2415\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"use_ray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2417\u001b[0;31m         analysis = ray.tune.run(\n\u001b[0m\u001b[1;32m   2418\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m             \u001b[0msearch_alg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_alg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, queue_trials, loggers, _remote)\u001b[0m\n\u001b[1;32m    605\u001b[0m     \u001b[0mprogress_reporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_start_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVerbosity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV1_EXPERIMENT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m             \u001b[0m_report_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_reporter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_staging_grace_period\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 self._insufficient_resources_manager.on_no_available_trials(\n",
      "\u001b[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_events\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mwarn_if_slow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"process_trial\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m             \u001b[0;31m# `self._queued_trial_decisions` now contains a final decision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_trial\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_trial_failure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_process_trial_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_trial_failure\u001b[0;34m(self, trial, error_msg)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scheduler_alg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_search_alg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m                 self._callbacks.on_trial_error(\n\u001b[0m\u001b[1;32m   1150\u001b[0m                     \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iteration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                     \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/callback.py\u001b[0m in \u001b[0;36mon_trial_error\u001b[0;34m(self, **info)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_trial_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/logger.py\u001b[0m in \u001b[0;36mon_trial_error\u001b[0;34m(self, iteration, trials, trial, **info)\u001b[0m\n\u001b[1;32m    421\u001b[0m     def on_trial_error(self, iteration: int, trials: List[\"Trial\"],\n\u001b[1;32m    422\u001b[0m                        trial: \"Trial\", **info):\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfailed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/logger.py\u001b[0m in \u001b[0;36mlog_trial_end\u001b[0;34m(self, trial, failed)\u001b[0m\n\u001b[1;32m    677\u001b[0m                 }\n\u001b[1;32m    678\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_log_hparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscrubbed_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_writer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_writer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/tensorboardX/writer.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0;32mreturn\u001b[0m  \u001b[0;31m# ignore double close\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_writers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_writers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/tensorboardX/writer.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mdisk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \"\"\"\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/tensorboardX/event_file_writer.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \"\"\"\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ev_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/tensorboardX/event_file_writer.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outstanding_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_py_recordio_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/tensorboardX/record_writer.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-05 10:32:30,641\tWARNING worker.py:1257 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffbe42a1ae8759326764b2f95201000000 Worker ID: f297aade3e3458821c82ea5b2129d9699d657801ed89cf7be2f8f36f Node ID: f27b444e55e271781f34ee2461b284ceaca0ae5809b5df5867c2a464 Worker IP address: 155.246.89.124 Worker port: 35995 Worker PID: 41810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m {'loss': 1.2776, 'learning_rate': 0.00042857142857142855, 'epoch': 1.0}\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m {'eval_loss': 0.8495630025863647, 'eval_automl_metric': 0.26, 'eval_runtime': 1.0822, 'eval_samples_per_second': 92.406, 'eval_steps_per_second': 92.406, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m 2022-03-05 10:32:31,799\tERROR function_runner.py:268 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m OSError: [Errno 28] No space left on device\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m \n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 262, in run\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 330, in entrypoint\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m     return self._trainable_func(self.config, self._status_reporter,\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m   File \"/data/xliu127/projects/hyperopt/FLAML/flaml/automl.py\", line 1714, in train\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m     result = states[estimator].training_function(config)\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/utils/trainable.py\", line 353, in _inner\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m     inner(config, checkpoint_dir=None)\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/utils/trainable.py\", line 344, in inner\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m     trainable(config, **fn_kwargs)\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m   File \"/data/xliu127/projects/hyperopt/FLAML/flaml/automl.py\", line 260, in _compute_with_config_base\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m     ) = compute_estimator(\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m   File \"/data/xliu127/projects/hyperopt/FLAML/flaml/ml.py\", line 572, in compute_estimator\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m     val_loss, metric_for_logging, train_time, pred_time = get_val_loss(\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m   File \"/data/xliu127/projects/hyperopt/FLAML/flaml/ml.py\", line 407, in get_val_loss\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m     estimator.fit(X_train, y_train, budget, **fit_kwargs)\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m   File \"/data/xliu127/projects/hyperopt/FLAML/flaml/model.py\", line 602, in fit\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m     self._trainer.train()\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 1440, in train\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m     self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 1569, in _maybe_log_save_evaluate\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m     self._save_checkpoint(model, trial, metrics=metrics)\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 1637, in _save_checkpoint\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m     self.save_model(output_dir, _internal_call=True)\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 2052, in save_model\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m     self._save(output_dir)\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 2104, in _save\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m     self.model.save_pretrained(output_dir, state_dict=state_dict)\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/modeling_utils.py\", line 1058, in save_pretrained\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m     model_to_save.config.save_pretrained(save_directory)\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/configuration_utils.py\", line 429, in save_pretrained\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m     self.to_json_file(output_config_file, use_diff=True)\n",
      "\u001b[2m\u001b[36m(train pid=41843)\u001b[0m   File \"/data/installation/anac\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m {'eval_loss': 1.376132845878601, 'eval_automl_metric': 0.61, 'eval_runtime': 1.0596, 'eval_samples_per_second': 94.374, 'eval_steps_per_second': 94.374, 'epoch': 1.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m 2022-03-05 10:32:33,033\tERROR function_runner.py:268 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 262, in run\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 330, in entrypoint\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m     return self._trainable_func(self.config, self._status_reporter,\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m   File \"/data/xliu127/projects/hyperopt/FLAML/flaml/automl.py\", line 1714, in train\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m     result = states[estimator].training_function(config)\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/utils/trainable.py\", line 353, in _inner\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m     inner(config, checkpoint_dir=None)\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/utils/trainable.py\", line 344, in inner\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m     trainable(config, **fn_kwargs)\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m   File \"/data/xliu127/projects/hyperopt/FLAML/flaml/automl.py\", line 260, in _compute_with_config_base\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m     ) = compute_estimator(\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m   File \"/data/xliu127/projects/hyperopt/FLAML/flaml/ml.py\", line 572, in compute_estimator\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m     val_loss, metric_for_logging, train_time, pred_time = get_val_loss(\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m   File \"/data/xliu127/projects/hyperopt/FLAML/flaml/ml.py\", line 407, in get_val_loss\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m     estimator.fit(X_train, y_train, budget, **fit_kwargs)\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m   File \"/data/xliu127/projects/hyperopt/FLAML/flaml/model.py\", line 602, in fit\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m     self._trainer.train()\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 1455, in train\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m     self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 1569, in _maybe_log_save_evaluate\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m     self._save_checkpoint(model, trial, metrics=metrics)\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 1637, in _save_checkpoint\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m     self.save_model(output_dir, _internal_call=True)\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 2052, in save_model\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m     self._save(output_dir)\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 2089, in _save\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m     os.makedirs(output_dir, exist_ok=True)\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/os.py\", line 221, in makedirs\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m     mkdir(name, mode)\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m OSError: [Errno 28] No space left on device: '/home/xliu127/ray_results/train_2022-03-05_10-26-31/train_8de2b164_30_adam_epsilon=1.981e-08,global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.00077843,num_tra_2022-03-05_10-32-04/checkpoint-7'\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(train pid=41829)\u001b[0m     self.run()\n",
      "2022-03-05 10:32:37,572\tERROR worker.py:85 -- Unhandled error (suppress with RAY_IGNORE_UNHANDLED_ERRORS=1): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=41843, ip=155.246.89.124, repr=train)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/trainable.py\", line 315, in train\n",
      "    result = self.step()\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 381, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 531, in _report_thread_runner_error\n",
      "    raise TuneError(\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=41843, ip=155.246.89.124, repr=train)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 262, in run\n",
      "    self._entrypoint()\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 330, in entrypoint\n",
      "    return self._trainable_func(self.config, self._status_reporter,\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/data/xliu127/projects/hyperopt/FLAML/flaml/automl.py\", line 1714, in train\n",
      "    result = states[estimator].training_function(config)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/utils/trainable.py\", line 353, in _inner\n",
      "    inner(config, checkpoint_dir=None)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/utils/trainable.py\", line 344, in inner\n",
      "    trainable(config, **fn_kwargs)\n",
      "  File \"/data/xliu127/projects/hyperopt/FLAML/flaml/automl.py\", line 260, in _compute_with_config_base\n",
      "    ) = compute_estimator(\n",
      "  File \"/data/xliu127/projects/hyperopt/FLAML/flaml/ml.py\", line 572, in compute_estimator\n",
      "    val_loss, metric_for_logging, train_time, pred_time = get_val_loss(\n",
      "  File \"/data/xliu127/projects/hyperopt/FLAML/flaml/ml.py\", line 407, in get_val_loss\n",
      "    estimator.fit(X_train, y_train, budget, **fit_kwargs)\n",
      "  File \"/data/xliu127/projects/hyperopt/FLAML/flaml/model.py\", line 602, in fit\n",
      "    self._trainer.train()\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 1440, in train\n",
      "    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 1569, in _maybe_log_save_evaluate\n",
      "    self._save_checkpoint(model, trial, metrics=metrics)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 1637, in _save_checkpoint\n",
      "    self.save_model(output_dir, _internal_call=True)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 2052, in save_model\n",
      "    self._save(output_dir)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 2104, in _save\n",
      "    self.model.save_pretrained(output_dir, state_dict=state_dict)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/modeling_utils.py\", line 1058, in save_pretrained\n",
      "    model_to_save.config.save_pretrained(save_directory)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/configuration_utils.py\", line 429, in save_pretrained\n",
      "    self.to_json_file(output_config_file, use_diff=True)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/configuration_utils.py\", line 794, in to_json_file\n",
      "    writer.write(self.to_json_string(use_diff=use_diff))\n",
      "OSError: [Errno 28] No space left on device\n",
      "2022-03-05 10:32:38,571\tERROR worker.py:85 -- Unhandled error (suppress with RAY_IGNORE_UNHANDLED_ERRORS=1): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=41829, ip=155.246.89.124, repr=train)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/trainable.py\", line 315, in train\n",
      "    result = self.step()\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 381, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 531, in _report_thread_runner_error\n",
      "    raise TuneError(\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=41829, ip=155.246.89.124, repr=train)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 262, in run\n",
      "    self._entrypoint()\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 330, in entrypoint\n",
      "    return self._trainable_func(self.config, self._status_reporter,\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/data/xliu127/projects/hyperopt/FLAML/flaml/automl.py\", line 1714, in train\n",
      "    result = states[estimator].training_function(config)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/utils/trainable.py\", line 353, in _inner\n",
      "    inner(config, checkpoint_dir=None)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/utils/trainable.py\", line 344, in inner\n",
      "    trainable(config, **fn_kwargs)\n",
      "  File \"/data/xliu127/projects/hyperopt/FLAML/flaml/automl.py\", line 260, in _compute_with_config_base\n",
      "    ) = compute_estimator(\n",
      "  File \"/data/xliu127/projects/hyperopt/FLAML/flaml/ml.py\", line 572, in compute_estimator\n",
      "    val_loss, metric_for_logging, train_time, pred_time = get_val_loss(\n",
      "  File \"/data/xliu127/projects/hyperopt/FLAML/flaml/ml.py\", line 407, in get_val_loss\n",
      "    estimator.fit(X_train, y_train, budget, **fit_kwargs)\n",
      "  File \"/data/xliu127/projects/hyperopt/FLAML/flaml/model.py\", line 602, in fit\n",
      "    self._trainer.train()\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 1455, in train\n",
      "    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 1569, in _maybe_log_save_evaluate\n",
      "    self._save_checkpoint(model, trial, metrics=metrics)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 1637, in _save_checkpoint\n",
      "    self.save_model(output_dir, _internal_call=True)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 2052, in save_model\n",
      "    self._save(output_dir)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 2089, in _save\n",
      "    os.makedirs(output_dir, exist_ok=True)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/os.py\", line 221, in makedirs\n",
      "    mkdir(name, mode)\n",
      "OSError: [Errno 28] No space left on device: '/home/xliu127/ray_results/train_2022-03-05_10-26-31/train_8de2b164_30_adam_epsilon=1.981e-08,global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.00077843,num_tra_2022-03-05_10-32-04/checkpoint-7'\n"
     ]
    }
   ],
   "source": [
    "''' import AutoML class from flaml package '''\n",
    "from flaml import AutoML\n",
    "automl = AutoML()\n",
    "\n",
    "import ray\n",
    "ray.init()\n",
    "\n",
    "automl_settings = {\n",
    "        \"time_budget\": 500,                 # setting the time budget\n",
    "        \"task\": \"multichoice-classification\",       # setting the task as multiplechoice-classification\n",
    "        \"hf_args\":\n",
    "            {\"output_dir\": \"data/output/\",  # setting the output directory\n",
    "             \"ckpt_per_epoch\": 1           # setting the number of checkoints per epoch\n",
    "             },\n",
    "        \"gpu_per_trial\": 1,                 # set to 0 if no GPU is available\n",
    "        \"log_file_name\": \"seqclass.log\",    # set the file to save the log for HPO\n",
    "        \"log_type\": \"all\",                  # the log type for checkpoints: all if keeping all checkpoints, best if only keeping the best checkpoints                        # the batch size for validation (inference)\n",
    "        \"use_ray\": {\"local_dir\": \"data/output/\"},                    # set whether to use Ray\n",
    "        \"n_concurrent_trials\": 4\n",
    "    }\n",
    "\n",
    "'''The main flaml automl API'''\n",
    "automl.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from flaml.data import get_output_from_log\n",
    "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
    "    get_output_from_log(filename=automl_settings['log_file_name'], time_budget=3000)\n",
    "for config in config_history:\n",
    "    print(config)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Wall Clock Time (s)')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "print(len(valid_loss_history))\n",
    "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
    "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9d36fc5b7c3dd4177ff1b60184dd696c0acc18150a44682abca4d769811bd46"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
