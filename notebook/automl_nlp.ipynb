{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved. \n",
    "\n",
    "Licensed under the MIT License.\n",
    "\n",
    "# FineTuning NLP Models with FLAML Library\n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "FLAML is a Python library (https://github.com/microsoft/FLAML) designed to automatically produce accurate machine learning models \n",
    "with low computational cost. It is fast and economical. The simple and lightweight design makes it easy to use and extend, such as adding new learners. FLAML can \n",
    "- serve as an economical AutoML engine,\n",
    "- be used as a fast hyperparameter tuning tool, or \n",
    "- be embedded in self-tuning software that requires low latency & resource in repetitive\n",
    "   tuning tasks.\n",
    "\n",
    "In this notebook, we demonstrate how to use the FLAML library to fine tune an NLP language model with hyperparameter search. We have tested this notebook on a server with 4 NVidia V100 GPU (32GB) and 400GB CPU Ram.\n",
    "\n",
    "FLAML requires `Python>=3.7`. To run this notebook example, please install flaml with the `nlp,ray,notebook` and `blendsearch` option:\n",
    "```bash\n",
    "pip install flaml[nlp,ray,notebook,blendsearch];\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flaml[blendsearch,nlp,notebook,ray] in /data/xliu127/projects/hyperopt/FLAML (0.10.0)\n",
      "Requirement already satisfied: NumPy>=1.16.2 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.22.3)\n",
      "Requirement already satisfied: lightgbm>=2.3.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (3.3.2)\n",
      "Requirement already satisfied: xgboost<=1.3.3,>=0.90 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.3.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.8.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.0.2)\n",
      "Requirement already satisfied: openml==0.10.2 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (0.10.2)\n",
      "Requirement already satisfied: jupyter in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.0.0)\n",
      "Requirement already satisfied: matplotlib in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (3.5.1)\n",
      "Requirement already satisfied: rgf-python in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (3.12.0)\n",
      "Requirement already satisfied: catboost>=0.26 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.0.4)\n",
      "Requirement already satisfied: optuna==2.8.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (2.8.0)\n",
      "Requirement already satisfied: transformers>=4.14 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (4.17.0)\n",
      "Requirement already satisfied: datasets in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.18.4)\n",
      "Requirement already satisfied: torch in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.11.0)\n",
      "Requirement already satisfied: seqeval in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.2.2)\n",
      "Requirement already satisfied: nltk in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (3.7)\n",
      "Requirement already satisfied: rouge_score in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (0.0.4)\n",
      "Requirement already satisfied: ray[tune]~=1.10 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[blendsearch,nlp,notebook,ray]) (1.11.0)\n",
      "Requirement already satisfied: liac-arff>=2.4.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from openml==0.10.2->flaml[blendsearch,nlp,notebook,ray]) (2.5.0)\n",
      "Requirement already satisfied: xmltodict in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from openml==0.10.2->flaml[blendsearch,nlp,notebook,ray]) (0.12.0)\n",
      "Requirement already satisfied: requests in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from openml==0.10.2->flaml[blendsearch,nlp,notebook,ray]) (2.27.1)\n",
      "Requirement already satisfied: python-dateutil in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from openml==0.10.2->flaml[blendsearch,nlp,notebook,ray]) (2.8.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (1.4.32)\n",
      "Requirement already satisfied: packaging>=20.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (21.3)\n",
      "Requirement already satisfied: colorlog in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (6.6.0)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (0.8.2)\n",
      "Requirement already satisfied: alembic in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (1.7.6)\n",
      "Requirement already satisfied: tqdm in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (4.63.0)\n",
      "Requirement already satisfied: cliff in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (3.10.1)\n",
      "Requirement already satisfied: six in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from catboost>=0.26->flaml[blendsearch,nlp,notebook,ray]) (1.16.0)\n",
      "Requirement already satisfied: graphviz in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from catboost>=0.26->flaml[blendsearch,nlp,notebook,ray]) (0.19.1)\n",
      "Requirement already satisfied: plotly in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from catboost>=0.26->flaml[blendsearch,nlp,notebook,ray]) (5.6.0)\n",
      "Requirement already satisfied: wheel in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from lightgbm>=2.3.1->flaml[blendsearch,nlp,notebook,ray]) (0.37.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from pandas>=1.1.4->flaml[blendsearch,nlp,notebook,ray]) (2021.3)\n",
      "Requirement already satisfied: attrs in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (21.4.0)\n",
      "Requirement already satisfied: protobuf>=3.15.3 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (3.19.4)\n",
      "Requirement already satisfied: pyyaml in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (6.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (1.0.3)\n",
      "Requirement already satisfied: grpcio<=1.43.0,>=1.28.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (1.43.0)\n",
      "Requirement already satisfied: click>=7.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (8.0.4)\n",
      "Requirement already satisfied: jsonschema in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (4.4.0)\n",
      "Requirement already satisfied: filelock in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (3.6.0)\n",
      "Requirement already satisfied: redis>=3.5.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (4.1.4)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (2.5)\n",
      "Requirement already satisfied: tabulate in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (0.8.9)\n",
      "Requirement already satisfied: joblib>=0.11 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from scikit-learn>=0.24->flaml[blendsearch,nlp,notebook,ray]) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from scikit-learn>=0.24->flaml[blendsearch,nlp,notebook,ray]) (3.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from transformers>=4.14->flaml[blendsearch,nlp,notebook,ray]) (0.4.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from transformers>=4.14->flaml[blendsearch,nlp,notebook,ray]) (0.11.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from transformers>=4.14->flaml[blendsearch,nlp,notebook,ray]) (2022.3.2)\n",
      "Requirement already satisfied: sacremoses in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from transformers>=4.14->flaml[blendsearch,nlp,notebook,ray]) (0.0.49)\n",
      "Requirement already satisfied: multiprocess in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from datasets->flaml[blendsearch,nlp,notebook,ray]) (0.70.12.2)\n",
      "Requirement already satisfied: xxhash in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from datasets->flaml[blendsearch,nlp,notebook,ray]) (3.0.0)\n",
      "Requirement already satisfied: dill in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from datasets->flaml[blendsearch,nlp,notebook,ray]) (0.3.4)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from datasets->flaml[blendsearch,nlp,notebook,ray]) (7.0.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from datasets->flaml[blendsearch,nlp,notebook,ray]) (2022.2.0)\n",
      "Requirement already satisfied: aiohttp in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from datasets->flaml[blendsearch,nlp,notebook,ray]) (3.8.1)\n",
      "Requirement already satisfied: responses<0.19 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from datasets->flaml[blendsearch,nlp,notebook,ray]) (0.18.0)\n",
      "Requirement already satisfied: nbconvert in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter->flaml[blendsearch,nlp,notebook,ray]) (6.4.4)\n",
      "Requirement already satisfied: ipywidgets in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter->flaml[blendsearch,nlp,notebook,ray]) (7.6.5)\n",
      "Requirement already satisfied: ipykernel in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter->flaml[blendsearch,nlp,notebook,ray]) (6.9.2)\n",
      "Requirement already satisfied: notebook in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter->flaml[blendsearch,nlp,notebook,ray]) (6.4.10)\n",
      "Requirement already satisfied: qtconsole in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter->flaml[blendsearch,nlp,notebook,ray]) (5.2.2)\n",
      "Requirement already satisfied: jupyter-console in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter->flaml[blendsearch,nlp,notebook,ray]) (6.4.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from matplotlib->flaml[blendsearch,nlp,notebook,ray]) (4.30.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from matplotlib->flaml[blendsearch,nlp,notebook,ray]) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from matplotlib->flaml[blendsearch,nlp,notebook,ray]) (1.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from matplotlib->flaml[blendsearch,nlp,notebook,ray]) (3.0.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from matplotlib->flaml[blendsearch,nlp,notebook,ray]) (9.0.1)\n",
      "Requirement already satisfied: absl-py in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from rouge_score->flaml[blendsearch,nlp,notebook,ray]) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from torch->flaml[blendsearch,nlp,notebook,ray]) (4.1.1)\n",
      "Requirement already satisfied: deprecated>=1.2.3 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from redis>=3.5.0->ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (1.2.13)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from requests->openml==0.10.2->flaml[blendsearch,nlp,notebook,ray]) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from requests->openml==0.10.2->flaml[blendsearch,nlp,notebook,ray]) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from requests->openml==0.10.2->flaml[blendsearch,nlp,notebook,ray]) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from requests->openml==0.10.2->flaml[blendsearch,nlp,notebook,ray]) (3.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from sqlalchemy>=1.1.0->optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (1.1.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from aiohttp->datasets->flaml[blendsearch,nlp,notebook,ray]) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from aiohttp->datasets->flaml[blendsearch,nlp,notebook,ray]) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from aiohttp->datasets->flaml[blendsearch,nlp,notebook,ray]) (1.3.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from aiohttp->datasets->flaml[blendsearch,nlp,notebook,ray]) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from aiohttp->datasets->flaml[blendsearch,nlp,notebook,ray]) (1.7.2)\n",
      "Requirement already satisfied: Mako in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from alembic->optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (1.2.0)\n",
      "Requirement already satisfied: importlib-resources in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from alembic->optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (5.4.0)\n",
      "Requirement already satisfied: importlib-metadata in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from alembic->optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (4.11.3)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from cliff->optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (5.8.1)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from cliff->optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (2.4.0)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from cliff->optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (3.2.0)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from cliff->optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (3.5.0)\n",
      "Requirement already satisfied: autopage>=0.4.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from cliff->optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (0.5.0)\n",
      "Requirement already satisfied: traitlets<6.0,>=5.1.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (5.1.1)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (6.1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (8.1.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.1.3)\n",
      "Requirement already satisfied: nest-asyncio in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (1.5.4)\n",
      "Requirement already satisfied: psutil in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (5.9.0)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (1.5.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (7.1.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipywidgets->jupyter->flaml[blendsearch,nlp,notebook,ray]) (3.5.2)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipywidgets->jupyter->flaml[blendsearch,nlp,notebook,ray]) (1.0.2)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipywidgets->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.2.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipywidgets->jupyter->flaml[blendsearch,nlp,notebook,ray]) (5.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jsonschema->ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (0.18.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter-console->jupyter->flaml[blendsearch,nlp,notebook,ray]) (3.0.27)\n",
      "Requirement already satisfied: pygments in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter-console->jupyter->flaml[blendsearch,nlp,notebook,ray]) (2.11.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.1.2)\n",
      "Requirement already satisfied: defusedxml in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.7.1)\n",
      "Requirement already satisfied: testpath in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.6.0)\n",
      "Requirement already satisfied: jinja2>=2.4 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (3.0.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (1.5.0)\n",
      "Requirement already satisfied: jupyter-core in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (4.9.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.4)\n",
      "Requirement already satisfied: bleach in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (4.1.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.5.13)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.8.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (4.10.0)\n",
      "Requirement already satisfied: argon2-cffi in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from notebook->jupyter->flaml[blendsearch,nlp,notebook,ray]) (21.3.0)\n",
      "Requirement already satisfied: prometheus-client in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from notebook->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.13.1)\n",
      "Requirement already satisfied: pyzmq>=17 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from notebook->jupyter->flaml[blendsearch,nlp,notebook,ray]) (22.3.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from notebook->jupyter->flaml[blendsearch,nlp,notebook,ray]) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from notebook->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.13.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from plotly->catboost>=0.26->flaml[blendsearch,nlp,notebook,ray]) (8.0.1)\n",
      "Requirement already satisfied: qtpy in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from qtconsole->jupyter->flaml[blendsearch,nlp,notebook,ray]) (2.0.1)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (0.2.5)\n",
      "Requirement already satisfied: pyperclip>=1.6 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (1.8.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[tune]~=1.10->flaml[blendsearch,nlp,notebook,ray]) (1.14.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from importlib-resources->alembic->optuna==2.8.0->flaml[blendsearch,nlp,notebook,ray]) (3.7.0)\n",
      "Requirement already satisfied: backcall in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (4.8.0)\n",
      "Requirement already satisfied: decorator in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.18.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (60.9.3)\n",
      "Requirement already satisfied: stack-data in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.7.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jinja2>=2.4->nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (2.1.1)\n",
      "Requirement already satisfied: ptyprocess in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from terminado>=0.8.3->notebook->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter->flaml[blendsearch,nlp,notebook,ray]) (21.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from beautifulsoup4->nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (2.3.1)\n",
      "Requirement already satisfied: webencodings in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from bleach->nbconvert->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.8.3)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->flaml[blendsearch,nlp,notebook,ray]) (1.15.0)\n",
      "Requirement already satisfied: pure-eval in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.2.2)\n",
      "Requirement already satisfied: executing in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->flaml[blendsearch,nlp,notebook,ray]) (2.0.5)\n",
      "Requirement already satisfied: pycparser in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->flaml[blendsearch,nlp,notebook,ray]) (2.21)\n"
     ]
    }
   ],
   "source": [
    "%pip install flaml[nlp,ray,notebook,blendsearch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run some examples. \n",
    "\n",
    "Note: throughout this notebook, you may see a few ModuleNotFoundErrors. As long as the cell successfully executes, you can ignore that error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sentiment Classification Example\n",
    "### Load data and preprocess\n",
    "\n",
    "The Stanford Sentiment treebank (SST-2) dataset is a dataset for sentiment classification. First, let's load this dataset into pandas dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/xliu127/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Reusing dataset glue (/home/xliu127/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Reusing dataset glue (/home/xliu127/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"glue\", \"mrpc\", split=\"train\").to_pandas()\n",
    "dev_dataset = load_dataset(\"glue\", \"mrpc\", split=\"validation\").to_pandas()\n",
    "test_dataset = load_dataset(\"glue\", \"mrpc\", split=\"test\").to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the first 5 examples of this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hide new secretions from the parental units</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contains no wit , only labored gags</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that loves its characters and communicates som...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>remains utterly satisfied to remain the same t...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on the worst revenge-of-the-nerds clichés the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label  idx\n",
       "0       hide new secretions from the parental units       0    0\n",
       "1               contains no wit , only labored gags       0    1\n",
       "2  that loves its characters and communicates som...      1    2\n",
       "3  remains utterly satisfied to remain the same t...      0    3\n",
       "4  on the worst revenge-of-the-nerds clichés the ...      0    4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the data into X and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sent_keys = [\"sentence1\", \"sentence2\"]          # specify the column names of the input sentences\n",
    "label_key = \"label\"                                    # specify the column name of the label\n",
    "\n",
    "X_train, y_train = train_dataset[custom_sent_keys], train_dataset[label_key]\n",
    "X_val, y_val = dev_dataset[custom_sent_keys], dev_dataset[label_key]\n",
    "X_test = test_dataset[custom_sent_keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run FLAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' import AutoML class from flaml package '''\n",
    "from flaml import AutoML\n",
    "automl = AutoML()\n",
    "\n",
    "import ray\n",
    "if not ray.is_initialized():\n",
    "    ray.init() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_BUDGET=1200\n",
    "automl_settings = {\n",
    "    \"time_budget\": TIME_BUDGET,                  # setting the time budget\n",
    "    \"task\": \"seq-classification\",       # setting the task as seq-classification\n",
    "    \"fit_kwargs_by_estimator\": {\n",
    "        \"transformer\": {\n",
    "            \"output_dir\": \"data/output/\",   # setting the output directory\n",
    "            \"ckpt_per_epoch\": 1,            # setting the number of checkoints per epoch\n",
    "            \"model_path\": \"bert-base-uncased\",  # if model_path is not set, the default model is facebook/muppet-roberta-base: https://huggingface.co/facebook/muppet-roberta-base\n",
    "        }\n",
    "    },\n",
    "    \"gpu_per_trial\": 1,                 # set to 0 if no GPU is available\n",
    "    \"log_file_name\": \"seqclass.log\",    # set the file to save the log for HPO\n",
    "    \"log_type\": \"all\",                  # the log type for trials: \"all\" if logging all the trials, \"better\" if only keeping the better trials\n",
    "    \"use_ray\": {\"local_dir\": \"data/output/\"},                    # set whether to use Ray\n",
    "    \"n_concurrent_trials\": 4,\n",
    "    \"keep_search_state\": True,          # keeping the search state\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-21 13:27:54 (running for 00:20:14.52)<br>Memory usage on this node: 22.9/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/96 CPUs, 0/4 GPUs, 0.0/252.58 GiB heap, 0.0/112.24 GiB objects (0.0/1.0 accelerator_type:V100)<br>Current best trial: a478b276 with val_loss=0.12009803921568629 and parameters={'learning_rate': 2.1872511767624938e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 4, 'seed': 7, 'global_max_steps': 9223372036854775807, 'learner': 'transformer'}<br>Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_13-07-38<br>Number of trials: 33/1000000 (33 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=59250)\u001b[0m {'loss': 0.3327, 'learning_rate': 1.0295123460382672e-05, 'epoch': 2.18}\n",
      "\u001b[2m\u001b[36m(train pid=59407)\u001b[0m {'loss': 0.4744, 'learning_rate': 3.8483947490148965e-06, 'epoch': 1.64}\n",
      "\u001b[2m\u001b[36m(train pid=58929)\u001b[0m {'loss': 0.1645, 'learning_rate': 4.8933330345560835e-06, 'epoch': 3.27}\n",
      "\u001b[2m\u001b[36m(train pid=59592)\u001b[0m {'loss': 0.5619, 'learning_rate': 1.3544721826857925e-05, 'epoch': 0.55}\n",
      "\u001b[2m\u001b[36m(train pid=59407)\u001b[0m {'eval_loss': 0.5415804386138916, 'eval_automl_metric': 0.13480392156862742, 'eval_runtime': 3.8874, 'eval_samples_per_second': 104.956, 'eval_steps_per_second': 104.956, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(train pid=59407)\u001b[0m {'train_runtime': 133.4439, 'train_samples_per_second': 54.974, 'train_steps_per_second': 13.744, 'train_loss': 0.4956582546754128, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(train pid=59250)\u001b[0m {'loss': 0.2012, 'learning_rate': 7.209055276814724e-06, 'epoch': 2.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=59407)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=59407)\u001b[0m   Num examples = 408\n",
      "\u001b[2m\u001b[36m(train pid=59407)\u001b[0m   Batch size = 1\n",
      "\u001b[2m\u001b[36m(train pid=59407)\u001b[0m Didn't find file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_13-07-38/train_5c51b244_32_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=2,per_device_trai_2022-07-21_13-26-12/checkpoint-1834/added_tokens.json. We won't load it.\n",
      "\u001b[2m\u001b[36m(train pid=59407)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_13-07-38/train_5c51b244_32_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=2,per_device_trai_2022-07-21_13-26-12/checkpoint-1834/vocab.txt\n",
      "\u001b[2m\u001b[36m(train pid=59407)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_13-07-38/train_5c51b244_32_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=2,per_device_trai_2022-07-21_13-26-12/checkpoint-1834/tokenizer.json\n",
      "\u001b[2m\u001b[36m(train pid=59407)\u001b[0m loading file None\n",
      "\u001b[2m\u001b[36m(train pid=59407)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_13-07-38/train_5c51b244_32_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=2,per_device_trai_2022-07-21_13-26-12/checkpoint-1834/special_tokens_map.json\n",
      "\u001b[2m\u001b[36m(train pid=59407)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_13-07-38/train_5c51b244_32_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=2,per_device_trai_2022-07-21_13-26-12/checkpoint-1834/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=59592)\u001b[0m {'eval_loss': 0.5180040001869202, 'eval_automl_metric': 0.15931372549019607, 'eval_runtime': 3.7749, 'eval_samples_per_second': 108.082, 'eval_steps_per_second': 108.082, 'epoch': 1.0}\n",
      "\u001b[2m\u001b[36m(train pid=58929)\u001b[0m {'loss': 0.0951, 'learning_rate': 1.2306586074931466e-06, 'epoch': 3.82}\n",
      "\u001b[2m\u001b[36m(train pid=59592)\u001b[0m {'loss': 0.4703, 'learning_rate': 8.46798950794566e-06, 'epoch': 1.09}\n",
      "\u001b[2m\u001b[36m(train pid=59250)\u001b[0m {'eval_loss': 0.6077207326889038, 'eval_automl_metric': 0.11764705882352944, 'eval_runtime': 3.8401, 'eval_samples_per_second': 106.247, 'eval_steps_per_second': 106.247, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(train pid=58929)\u001b[0m {'eval_loss': 0.806081235408783, 'eval_automl_metric': 0.13480392156862742, 'eval_runtime': 3.7716, 'eval_samples_per_second': 108.177, 'eval_steps_per_second': 108.177, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(train pid=58929)\u001b[0m {'train_runtime': 256.0423, 'train_samples_per_second': 57.303, 'train_steps_per_second': 14.326, 'train_loss': 0.35705690737509027, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=58929)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=58929)\u001b[0m   Num examples = 408\n",
      "\u001b[2m\u001b[36m(train pid=58929)\u001b[0m   Batch size = 1\n",
      "\u001b[2m\u001b[36m(train pid=58929)\u001b[0m Didn't find file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_13-07-38/train_227f7ab0_29_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-21_13-24-35/checkpoint-3668/added_tokens.json. We won't load it.\n",
      "\u001b[2m\u001b[36m(train pid=58929)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_13-07-38/train_227f7ab0_29_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-21_13-24-35/checkpoint-3668/vocab.txt\n",
      "\u001b[2m\u001b[36m(train pid=58929)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_13-07-38/train_227f7ab0_29_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-21_13-24-35/checkpoint-3668/tokenizer.json\n",
      "\u001b[2m\u001b[36m(train pid=58929)\u001b[0m loading file None\n",
      "\u001b[2m\u001b[36m(train pid=58929)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_13-07-38/train_227f7ab0_29_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-21_13-24-35/checkpoint-3668/special_tokens_map.json\n",
      "\u001b[2m\u001b[36m(train pid=58929)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_13-07-38/train_227f7ab0_29_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-21_13-24-35/checkpoint-3668/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=59250)\u001b[0m {'loss': 0.1476, 'learning_rate': 4.122987093246777e-06, 'epoch': 3.27}\n",
      "\u001b[2m\u001b[36m(train pid=59592)\u001b[0m {'loss': 0.3574, 'learning_rate': 3.391257189033394e-06, 'epoch': 1.64}\n",
      "\u001b[2m\u001b[36m(train pid=59592)\u001b[0m {'eval_loss': 0.5781316757202148, 'eval_automl_metric': 0.1421568627450981, 'eval_runtime': 3.7277, 'eval_samples_per_second': 109.45, 'eval_steps_per_second': 109.45, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(train pid=59592)\u001b[0m {'train_runtime': 128.6158, 'train_samples_per_second': 57.038, 'train_steps_per_second': 14.26, 'train_loss': 0.4407762508745932, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=59592)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=59592)\u001b[0m   Num examples = 408\n",
      "\u001b[2m\u001b[36m(train pid=59592)\u001b[0m   Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=59250)\u001b[0m {'loss': 0.1029, 'learning_rate': 1.03691890967883e-06, 'epoch': 3.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=59592)\u001b[0m Didn't find file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_13-07-38/train_89b0b9a7_33_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=2,per_device_trai_2022-07-21_13-27-29/checkpoint-1834/added_tokens.json. We won't load it.\n",
      "\u001b[2m\u001b[36m(train pid=59592)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_13-07-38/train_89b0b9a7_33_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=2,per_device_trai_2022-07-21_13-27-29/checkpoint-1834/vocab.txt\n",
      "\u001b[2m\u001b[36m(train pid=59592)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_13-07-38/train_89b0b9a7_33_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=2,per_device_trai_2022-07-21_13-27-29/checkpoint-1834/tokenizer.json\n",
      "\u001b[2m\u001b[36m(train pid=59592)\u001b[0m loading file None\n",
      "\u001b[2m\u001b[36m(train pid=59592)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_13-07-38/train_89b0b9a7_33_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=2,per_device_trai_2022-07-21_13-27-29/checkpoint-1834/special_tokens_map.json\n",
      "\u001b[2m\u001b[36m(train pid=59592)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_13-07-38/train_89b0b9a7_33_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=2,per_device_trai_2022-07-21_13-27-29/checkpoint-1834/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=59250)\u001b[0m {'eval_loss': 0.7132703065872192, 'eval_automl_metric': 0.12254901960784315, 'eval_runtime': 3.735, 'eval_samples_per_second': 109.237, 'eval_steps_per_second': 109.237, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(train pid=59250)\u001b[0m {'train_runtime': 264.9924, 'train_samples_per_second': 55.368, 'train_steps_per_second': 13.842, 'train_loss': 0.31339427247042223, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=59250)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=59250)\u001b[0m   Num examples = 408\n",
      "\u001b[2m\u001b[36m(train pid=59250)\u001b[0m   Batch size = 1\n",
      "\u001b[2m\u001b[36m(train pid=59250)\u001b[0m Didn't find file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_13-07-38/train_45d8f8ce_31_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-21_13-25-34/checkpoint-2751/added_tokens.json. We won't load it.\n",
      "\u001b[2m\u001b[36m(train pid=59250)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_13-07-38/train_45d8f8ce_31_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-21_13-25-34/checkpoint-2751/vocab.txt\n",
      "\u001b[2m\u001b[36m(train pid=59250)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_13-07-38/train_45d8f8ce_31_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-21_13-25-34/checkpoint-2751/tokenizer.json\n",
      "\u001b[2m\u001b[36m(train pid=59250)\u001b[0m loading file None\n",
      "\u001b[2m\u001b[36m(train pid=59250)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_13-07-38/train_45d8f8ce_31_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-21_13-25-34/checkpoint-2751/special_tokens_map.json\n",
      "\u001b[2m\u001b[36m(train pid=59250)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_13-07-38/train_45d8f8ce_31_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-21_13-25-34/checkpoint-2751/tokenizer_config.json\n",
      "2022-07-21 13:30:17,073\tINFO tune.py:747 -- Total run time: 1358.29 seconds (1204.81 seconds for the tuning loop).\n",
      "[flaml.automl: 07-21 13:30:20] {3314} INFO - selected model: None\n",
      "/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.405, 'learning_rate': 6.02286555920107e-06, 'epoch': 2.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 07-21 13:32:01] {3457} INFO - retrain transformer for 101.3s\n",
      "[flaml.automl: 07-21 13:32:01] {3464} INFO - retrained model: None\n",
      "[flaml.automl: 07-21 13:32:01] {2742} INFO - fit succeeded\n",
      "[flaml.automl: 07-21 13:32:01] {2743} INFO - Time taken to find the best model: 1019.1050026416779\n",
      "[flaml.automl: 07-21 13:32:01] {2754} WARNING - Time taken to find the best model is 85% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 93.2817, 'train_samples_per_second': 117.965, 'train_steps_per_second': 7.397, 'train_loss': 0.3405460468236951, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "'''The main flaml automl API'''\n",
    "automl.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best loss by FLAML: 0.12009803921568629\n"
     ]
    }
   ],
   "source": [
    "print(\"The best loss by FLAML: {}\".format(automl.best_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparmeter config: {'learning_rate': 1.4736175808553141e-05, 'num_train_epochs': 7.623375372739029, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.21605876280261357, 'weight_decay': 0.11938244526496489, 'adam_epsilon': 7.353322403647365e-07, 'seed': 42, 'global_max_steps': 1878, 'learner': 'transformer'}\n",
      "Best accuracy on validation data: 0.9404\n",
      "Training duration of best run: 157.7 s\n"
     ]
    }
   ],
   "source": [
    "'''retrieve best config and best learner'''\n",
    "print('Best hyperparmeter config:', automl.best_config)\n",
    "print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
    "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.528, 'learning_rate': 8.898933352349567e-06, 'epoch': 1.0}\n",
      "{'eval_loss': 0.2549280524253845, 'eval_automl_metric': 0.08600917431192656, 'eval_runtime': 1.0003, 'eval_samples_per_second': 871.751, 'eval_steps_per_second': 54.984, 'epoch': 1.0}\n",
      "{'loss': 0.2278, 'learning_rate': 1.3880017803076292e-05, 'epoch': 2.0}\n",
      "{'eval_loss': 0.24966619908809662, 'eval_automl_metric': 0.06766055045871555, 'eval_runtime': 1.0201, 'eval_samples_per_second': 854.778, 'eval_steps_per_second': 53.914, 'epoch': 2.0}\n",
      "{'loss': 0.1455, 'learning_rate': 1.1410179501562432e-05, 'epoch': 3.0}\n",
      "{'eval_loss': 0.23046882450580597, 'eval_automl_metric': 0.059633027522935755, 'eval_runtime': 1.0097, 'eval_samples_per_second': 863.6, 'eval_steps_per_second': 54.47, 'epoch': 3.0}\n",
      "{'eval_loss': 0.23046882450580597, 'eval_automl_metric': 0.059633027522935755, 'eval_runtime': 0.9726, 'eval_samples_per_second': 896.568, 'eval_steps_per_second': 56.55, 'epoch': 3.0}\n",
      "{'train_runtime': 146.7879, 'train_samples_per_second': 519.346, 'train_steps_per_second': 32.462, 'train_loss': 0.30043953600021217, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 872\n",
      "  Batch size = 64\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "automl.pickle(\"automl.pkl\")\n",
    "\n",
    "with open(\"automl.pkl\", \"rb\") as f:\n",
    "    automl = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1821\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels [0 0 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "'''compute predictions of testing dataset''' \n",
    "y_pred = automl.predict(X_test, **{\"per_device_eval_batch_size\": 1})\n",
    "print('Predicted labels', y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing with Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Transformers, we can tune the hyperparameters using Trainer.hyperparameter_search. The code for tuning sequence classification looks like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/xliu127/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc66235b9f0443f927e0fefcb4fbd3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92317cd4a32d4e9c9a61b2742364b6e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c34b3aab8749e1a03b80dc7aaff7a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0761801ee544d9c98da56770298a386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/xliu127/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/xliu127/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:12:54 (running for 00:00:00.76)\n",
      "Memory usage on this node: 13.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 105/infinite (104 PENDING, 1 RUNNING)\n",
      "+------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------+\n",
      "| Trial name             | status   | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |\n",
      "|------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------|\n",
      "| _objective_69dd6_00000 | RUNNING  | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |\n",
      "| _objective_69dd6_00001 | PENDING  |                      |     1.56207e-05 |                  2 |                            16 |  7.08379 |\n",
      "| _objective_69dd6_00002 | PENDING  |                      |     8.28892e-06 |                  5 |                            16 | 24.4435  |\n",
      "| _objective_69dd6_00003 | PENDING  |                      |     1.09943e-06 |                  2 |                             8 | 29.158   |\n",
      "| _objective_69dd6_00004 | PENDING  |                      |     2.3102e-06  |                  5 |                             8 | 25.0818  |\n",
      "| _objective_69dd6_00005 | PENDING  |                      |     1.12076e-05 |                  4 |                            16 |  1.89943 |\n",
      "| _objective_69dd6_00006 | PENDING  |                      |     1.67381e-05 |                  2 |                            32 |  2.81996 |\n",
      "| _objective_69dd6_00007 | PENDING  |                      |     5.4041e-06  |                  3 |                            32 | 15.916   |\n",
      "| _objective_69dd6_00008 | PENDING  |                      |     1.53049e-05 |                  3 |                            64 | 34.5377  |\n",
      "| _objective_69dd6_00009 | PENDING  |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |\n",
      "| _objective_69dd6_00010 | PENDING  |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |\n",
      "| _objective_69dd6_00011 | PENDING  |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |\n",
      "| _objective_69dd6_00012 | PENDING  |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |\n",
      "| _objective_69dd6_00013 | PENDING  |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |\n",
      "| _objective_69dd6_00014 | PENDING  |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |\n",
      "| _objective_69dd6_00015 | PENDING  |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |\n",
      "| _objective_69dd6_00016 | PENDING  |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |\n",
      "| _objective_69dd6_00017 | PENDING  |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |\n",
      "| _objective_69dd6_00018 | PENDING  |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |\n",
      "| _objective_69dd6_00019 | PENDING  |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |\n",
      "+------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------+\n",
      "... 85 more trials not shown (85 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=14389)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=14389)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=14389)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=14389)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=14389)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=14389)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=14389)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:13:02 (running for 00:00:08.04)\n",
      "Memory usage on this node: 19.0/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 109/infinite (105 PENDING, 4 RUNNING)\n",
      "+------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------+\n",
      "| Trial name             | status   | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |\n",
      "|------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------|\n",
      "| _objective_69dd6_00000 | RUNNING  | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |\n",
      "| _objective_69dd6_00001 | RUNNING  | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |\n",
      "| _objective_69dd6_00002 | RUNNING  | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |\n",
      "| _objective_69dd6_00003 | RUNNING  | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |\n",
      "| _objective_69dd6_00004 | PENDING  |                      |     2.3102e-06  |                  5 |                             8 | 25.0818  |\n",
      "| _objective_69dd6_00005 | PENDING  |                      |     1.12076e-05 |                  4 |                            16 |  1.89943 |\n",
      "| _objective_69dd6_00006 | PENDING  |                      |     1.67381e-05 |                  2 |                            32 |  2.81996 |\n",
      "| _objective_69dd6_00007 | PENDING  |                      |     5.4041e-06  |                  3 |                            32 | 15.916   |\n",
      "| _objective_69dd6_00008 | PENDING  |                      |     1.53049e-05 |                  3 |                            64 | 34.5377  |\n",
      "| _objective_69dd6_00009 | PENDING  |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |\n",
      "| _objective_69dd6_00010 | PENDING  |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |\n",
      "| _objective_69dd6_00011 | PENDING  |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |\n",
      "| _objective_69dd6_00012 | PENDING  |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |\n",
      "| _objective_69dd6_00013 | PENDING  |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |\n",
      "| _objective_69dd6_00014 | PENDING  |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |\n",
      "| _objective_69dd6_00015 | PENDING  |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |\n",
      "| _objective_69dd6_00016 | PENDING  |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |\n",
      "| _objective_69dd6_00017 | PENDING  |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |\n",
      "| _objective_69dd6_00018 | PENDING  |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |\n",
      "| _objective_69dd6_00019 | PENDING  |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |\n",
      "+------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------+\n",
      "... 89 more trials not shown (89 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=14428)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=14428)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=14428)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=14428)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=14428)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=14429)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=14429)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=14429)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=14429)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=14429)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=14430)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=14430)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=14430)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=14430)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=14430)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=14429)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=14429)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_objective pid=14428)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=14428)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_objective pid=14430)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=14430)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:13:07 (running for 00:00:13.06)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 109/infinite (105 PENDING, 4 RUNNING)\n",
      "+------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------+\n",
      "| Trial name             | status   | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |\n",
      "|------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------|\n",
      "| _objective_69dd6_00000 | RUNNING  | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |\n",
      "| _objective_69dd6_00001 | RUNNING  | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |\n",
      "| _objective_69dd6_00002 | RUNNING  | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |\n",
      "| _objective_69dd6_00003 | RUNNING  | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |\n",
      "| _objective_69dd6_00004 | PENDING  |                      |     2.3102e-06  |                  5 |                             8 | 25.0818  |\n",
      "| _objective_69dd6_00005 | PENDING  |                      |     1.12076e-05 |                  4 |                            16 |  1.89943 |\n",
      "| _objective_69dd6_00006 | PENDING  |                      |     1.67381e-05 |                  2 |                            32 |  2.81996 |\n",
      "| _objective_69dd6_00007 | PENDING  |                      |     5.4041e-06  |                  3 |                            32 | 15.916   |\n",
      "| _objective_69dd6_00008 | PENDING  |                      |     1.53049e-05 |                  3 |                            64 | 34.5377  |\n",
      "| _objective_69dd6_00009 | PENDING  |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |\n",
      "| _objective_69dd6_00010 | PENDING  |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |\n",
      "| _objective_69dd6_00011 | PENDING  |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |\n",
      "| _objective_69dd6_00012 | PENDING  |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |\n",
      "| _objective_69dd6_00013 | PENDING  |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |\n",
      "| _objective_69dd6_00014 | PENDING  |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |\n",
      "| _objective_69dd6_00015 | PENDING  |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |\n",
      "| _objective_69dd6_00016 | PENDING  |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |\n",
      "| _objective_69dd6_00017 | PENDING  |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |\n",
      "| _objective_69dd6_00018 | PENDING  |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |\n",
      "| _objective_69dd6_00019 | PENDING  |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |\n",
      "+------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------+\n",
      "... 89 more trials not shown (89 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:13:12 (running for 00:00:18.07)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 109/infinite (105 PENDING, 4 RUNNING)\n",
      "+------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------+\n",
      "| Trial name             | status   | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |\n",
      "|------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------|\n",
      "| _objective_69dd6_00000 | RUNNING  | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |\n",
      "| _objective_69dd6_00001 | RUNNING  | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |\n",
      "| _objective_69dd6_00002 | RUNNING  | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |\n",
      "| _objective_69dd6_00003 | RUNNING  | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |\n",
      "| _objective_69dd6_00004 | PENDING  |                      |     2.3102e-06  |                  5 |                             8 | 25.0818  |\n",
      "| _objective_69dd6_00005 | PENDING  |                      |     1.12076e-05 |                  4 |                            16 |  1.89943 |\n",
      "| _objective_69dd6_00006 | PENDING  |                      |     1.67381e-05 |                  2 |                            32 |  2.81996 |\n",
      "| _objective_69dd6_00007 | PENDING  |                      |     5.4041e-06  |                  3 |                            32 | 15.916   |\n",
      "| _objective_69dd6_00008 | PENDING  |                      |     1.53049e-05 |                  3 |                            64 | 34.5377  |\n",
      "| _objective_69dd6_00009 | PENDING  |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |\n",
      "| _objective_69dd6_00010 | PENDING  |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |\n",
      "| _objective_69dd6_00011 | PENDING  |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |\n",
      "| _objective_69dd6_00012 | PENDING  |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |\n",
      "| _objective_69dd6_00013 | PENDING  |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |\n",
      "| _objective_69dd6_00014 | PENDING  |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |\n",
      "| _objective_69dd6_00015 | PENDING  |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |\n",
      "| _objective_69dd6_00016 | PENDING  |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |\n",
      "| _objective_69dd6_00017 | PENDING  |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |\n",
      "| _objective_69dd6_00018 | PENDING  |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |\n",
      "| _objective_69dd6_00019 | PENDING  |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |\n",
      "+------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------+\n",
      "... 89 more trials not shown (89 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:13:17 (running for 00:00:23.08)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 109/infinite (105 PENDING, 4 RUNNING)\n",
      "+------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------+\n",
      "| Trial name             | status   | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |\n",
      "|------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------|\n",
      "| _objective_69dd6_00000 | RUNNING  | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |\n",
      "| _objective_69dd6_00001 | RUNNING  | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |\n",
      "| _objective_69dd6_00002 | RUNNING  | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |\n",
      "| _objective_69dd6_00003 | RUNNING  | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |\n",
      "| _objective_69dd6_00004 | PENDING  |                      |     2.3102e-06  |                  5 |                             8 | 25.0818  |\n",
      "| _objective_69dd6_00005 | PENDING  |                      |     1.12076e-05 |                  4 |                            16 |  1.89943 |\n",
      "| _objective_69dd6_00006 | PENDING  |                      |     1.67381e-05 |                  2 |                            32 |  2.81996 |\n",
      "| _objective_69dd6_00007 | PENDING  |                      |     5.4041e-06  |                  3 |                            32 | 15.916   |\n",
      "| _objective_69dd6_00008 | PENDING  |                      |     1.53049e-05 |                  3 |                            64 | 34.5377  |\n",
      "| _objective_69dd6_00009 | PENDING  |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |\n",
      "| _objective_69dd6_00010 | PENDING  |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |\n",
      "| _objective_69dd6_00011 | PENDING  |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |\n",
      "| _objective_69dd6_00012 | PENDING  |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |\n",
      "| _objective_69dd6_00013 | PENDING  |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |\n",
      "| _objective_69dd6_00014 | PENDING  |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |\n",
      "| _objective_69dd6_00015 | PENDING  |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |\n",
      "| _objective_69dd6_00016 | PENDING  |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |\n",
      "| _objective_69dd6_00017 | PENDING  |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |\n",
      "| _objective_69dd6_00018 | PENDING  |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |\n",
      "| _objective_69dd6_00019 | PENDING  |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |\n",
      "+------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------+\n",
      "... 89 more trials not shown (89 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:13:22 (running for 00:00:28.10)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 109/infinite (105 PENDING, 4 RUNNING)\n",
      "+------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------+\n",
      "| Trial name             | status   | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |\n",
      "|------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------|\n",
      "| _objective_69dd6_00000 | RUNNING  | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |\n",
      "| _objective_69dd6_00001 | RUNNING  | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |\n",
      "| _objective_69dd6_00002 | RUNNING  | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |\n",
      "| _objective_69dd6_00003 | RUNNING  | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |\n",
      "| _objective_69dd6_00004 | PENDING  |                      |     2.3102e-06  |                  5 |                             8 | 25.0818  |\n",
      "| _objective_69dd6_00005 | PENDING  |                      |     1.12076e-05 |                  4 |                            16 |  1.89943 |\n",
      "| _objective_69dd6_00006 | PENDING  |                      |     1.67381e-05 |                  2 |                            32 |  2.81996 |\n",
      "| _objective_69dd6_00007 | PENDING  |                      |     5.4041e-06  |                  3 |                            32 | 15.916   |\n",
      "| _objective_69dd6_00008 | PENDING  |                      |     1.53049e-05 |                  3 |                            64 | 34.5377  |\n",
      "| _objective_69dd6_00009 | PENDING  |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |\n",
      "| _objective_69dd6_00010 | PENDING  |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |\n",
      "| _objective_69dd6_00011 | PENDING  |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |\n",
      "| _objective_69dd6_00012 | PENDING  |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |\n",
      "| _objective_69dd6_00013 | PENDING  |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |\n",
      "| _objective_69dd6_00014 | PENDING  |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |\n",
      "| _objective_69dd6_00015 | PENDING  |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |\n",
      "| _objective_69dd6_00016 | PENDING  |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |\n",
      "| _objective_69dd6_00017 | PENDING  |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |\n",
      "| _objective_69dd6_00018 | PENDING  |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |\n",
      "| _objective_69dd6_00019 | PENDING  |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |\n",
      "+------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------+\n",
      "... 89 more trials not shown (89 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:13:27 (running for 00:00:33.12)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 109/infinite (105 PENDING, 4 RUNNING)\n",
      "+------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------+\n",
      "| Trial name             | status   | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |\n",
      "|------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------|\n",
      "| _objective_69dd6_00000 | RUNNING  | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |\n",
      "| _objective_69dd6_00001 | RUNNING  | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |\n",
      "| _objective_69dd6_00002 | RUNNING  | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |\n",
      "| _objective_69dd6_00003 | RUNNING  | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |\n",
      "| _objective_69dd6_00004 | PENDING  |                      |     2.3102e-06  |                  5 |                             8 | 25.0818  |\n",
      "| _objective_69dd6_00005 | PENDING  |                      |     1.12076e-05 |                  4 |                            16 |  1.89943 |\n",
      "| _objective_69dd6_00006 | PENDING  |                      |     1.67381e-05 |                  2 |                            32 |  2.81996 |\n",
      "| _objective_69dd6_00007 | PENDING  |                      |     5.4041e-06  |                  3 |                            32 | 15.916   |\n",
      "| _objective_69dd6_00008 | PENDING  |                      |     1.53049e-05 |                  3 |                            64 | 34.5377  |\n",
      "| _objective_69dd6_00009 | PENDING  |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |\n",
      "| _objective_69dd6_00010 | PENDING  |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |\n",
      "| _objective_69dd6_00011 | PENDING  |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |\n",
      "| _objective_69dd6_00012 | PENDING  |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |\n",
      "| _objective_69dd6_00013 | PENDING  |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |\n",
      "| _objective_69dd6_00014 | PENDING  |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |\n",
      "| _objective_69dd6_00015 | PENDING  |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |\n",
      "| _objective_69dd6_00016 | PENDING  |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |\n",
      "| _objective_69dd6_00017 | PENDING  |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |\n",
      "| _objective_69dd6_00018 | PENDING  |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |\n",
      "| _objective_69dd6_00019 | PENDING  |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |\n",
      "+------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------+\n",
      "... 89 more trials not shown (89 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:13:32 (running for 00:00:38.13)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 109/infinite (105 PENDING, 4 RUNNING)\n",
      "+------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------+\n",
      "| Trial name             | status   | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |\n",
      "|------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------|\n",
      "| _objective_69dd6_00000 | RUNNING  | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |\n",
      "| _objective_69dd6_00001 | RUNNING  | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |\n",
      "| _objective_69dd6_00002 | RUNNING  | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |\n",
      "| _objective_69dd6_00003 | RUNNING  | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |\n",
      "| _objective_69dd6_00004 | PENDING  |                      |     2.3102e-06  |                  5 |                             8 | 25.0818  |\n",
      "| _objective_69dd6_00005 | PENDING  |                      |     1.12076e-05 |                  4 |                            16 |  1.89943 |\n",
      "| _objective_69dd6_00006 | PENDING  |                      |     1.67381e-05 |                  2 |                            32 |  2.81996 |\n",
      "| _objective_69dd6_00007 | PENDING  |                      |     5.4041e-06  |                  3 |                            32 | 15.916   |\n",
      "| _objective_69dd6_00008 | PENDING  |                      |     1.53049e-05 |                  3 |                            64 | 34.5377  |\n",
      "| _objective_69dd6_00009 | PENDING  |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |\n",
      "| _objective_69dd6_00010 | PENDING  |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |\n",
      "| _objective_69dd6_00011 | PENDING  |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |\n",
      "| _objective_69dd6_00012 | PENDING  |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |\n",
      "| _objective_69dd6_00013 | PENDING  |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |\n",
      "| _objective_69dd6_00014 | PENDING  |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |\n",
      "| _objective_69dd6_00015 | PENDING  |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |\n",
      "| _objective_69dd6_00016 | PENDING  |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |\n",
      "| _objective_69dd6_00017 | PENDING  |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |\n",
      "| _objective_69dd6_00018 | PENDING  |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |\n",
      "| _objective_69dd6_00019 | PENDING  |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |\n",
      "+------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------+\n",
      "... 89 more trials not shown (89 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:13:37 (running for 00:00:43.15)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 109/infinite (105 PENDING, 4 RUNNING)\n",
      "+------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------+\n",
      "| Trial name             | status   | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |\n",
      "|------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------|\n",
      "| _objective_69dd6_00000 | RUNNING  | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |\n",
      "| _objective_69dd6_00001 | RUNNING  | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |\n",
      "| _objective_69dd6_00002 | RUNNING  | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |\n",
      "| _objective_69dd6_00003 | RUNNING  | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |\n",
      "| _objective_69dd6_00004 | PENDING  |                      |     2.3102e-06  |                  5 |                             8 | 25.0818  |\n",
      "| _objective_69dd6_00005 | PENDING  |                      |     1.12076e-05 |                  4 |                            16 |  1.89943 |\n",
      "| _objective_69dd6_00006 | PENDING  |                      |     1.67381e-05 |                  2 |                            32 |  2.81996 |\n",
      "| _objective_69dd6_00007 | PENDING  |                      |     5.4041e-06  |                  3 |                            32 | 15.916   |\n",
      "| _objective_69dd6_00008 | PENDING  |                      |     1.53049e-05 |                  3 |                            64 | 34.5377  |\n",
      "| _objective_69dd6_00009 | PENDING  |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |\n",
      "| _objective_69dd6_00010 | PENDING  |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |\n",
      "| _objective_69dd6_00011 | PENDING  |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |\n",
      "| _objective_69dd6_00012 | PENDING  |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |\n",
      "| _objective_69dd6_00013 | PENDING  |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |\n",
      "| _objective_69dd6_00014 | PENDING  |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |\n",
      "| _objective_69dd6_00015 | PENDING  |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |\n",
      "| _objective_69dd6_00016 | PENDING  |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |\n",
      "| _objective_69dd6_00017 | PENDING  |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |\n",
      "| _objective_69dd6_00018 | PENDING  |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |\n",
      "| _objective_69dd6_00019 | PENDING  |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |\n",
      "+------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------+\n",
      "... 89 more trials not shown (89 PENDING)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=14428)\u001b[0m {'train_runtime': 35.0903, 'train_samples_per_second': 209.061, 'train_steps_per_second': 6.555, 'train_loss': 0.5120404450789742, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=14428)\u001b[0m {'eval_loss': 0.4491980969905853, 'eval_accuracy': 0.8063725490196079, 'eval_f1': 0.870279146141215, 'eval_runtime': 0.7052, 'eval_samples_per_second': 578.598, 'eval_steps_per_second': 72.325, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=14430)\u001b[0m {'train_runtime': 35.7138, 'train_samples_per_second': 205.411, 'train_steps_per_second': 6.44, 'train_loss': 0.7148748646611752, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=14430)\u001b[0m {'eval_loss': 0.635231614112854, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8104956268221574, 'eval_runtime': 0.7118, 'eval_samples_per_second': 573.166, 'eval_steps_per_second': 71.646, 'epoch': 2.0}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:13:42 (running for 00:00:48.16)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 109/infinite (105 PENDING, 4 RUNNING)\n",
      "+------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------+\n",
      "| Trial name             | status   | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |\n",
      "|------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------|\n",
      "| _objective_69dd6_00000 | RUNNING  | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |\n",
      "| _objective_69dd6_00001 | RUNNING  | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |\n",
      "| _objective_69dd6_00002 | RUNNING  | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |\n",
      "| _objective_69dd6_00003 | RUNNING  | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |\n",
      "| _objective_69dd6_00004 | PENDING  |                      |     2.3102e-06  |                  5 |                             8 | 25.0818  |\n",
      "| _objective_69dd6_00005 | PENDING  |                      |     1.12076e-05 |                  4 |                            16 |  1.89943 |\n",
      "| _objective_69dd6_00006 | PENDING  |                      |     1.67381e-05 |                  2 |                            32 |  2.81996 |\n",
      "| _objective_69dd6_00007 | PENDING  |                      |     5.4041e-06  |                  3 |                            32 | 15.916   |\n",
      "| _objective_69dd6_00008 | PENDING  |                      |     1.53049e-05 |                  3 |                            64 | 34.5377  |\n",
      "| _objective_69dd6_00009 | PENDING  |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |\n",
      "| _objective_69dd6_00010 | PENDING  |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |\n",
      "| _objective_69dd6_00011 | PENDING  |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |\n",
      "| _objective_69dd6_00012 | PENDING  |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |\n",
      "| _objective_69dd6_00013 | PENDING  |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |\n",
      "| _objective_69dd6_00014 | PENDING  |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |\n",
      "| _objective_69dd6_00015 | PENDING  |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |\n",
      "| _objective_69dd6_00016 | PENDING  |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |\n",
      "| _objective_69dd6_00017 | PENDING  |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |\n",
      "| _objective_69dd6_00018 | PENDING  |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |\n",
      "| _objective_69dd6_00019 | PENDING  |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |\n",
      "+------------------------+----------+----------------------+-----------------+--------------------+-------------------------------+----------+\n",
      "... 89 more trials not shown (89 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00001:\n",
      "  date: 2022-07-21_18-13-42\n",
      "  done: true\n",
      "  epoch: 2.0\n",
      "  eval_accuracy: 0.8063725490196079\n",
      "  eval_f1: 0.870279146141215\n",
      "  eval_loss: 0.4491980969905853\n",
      "  eval_runtime: 0.7052\n",
      "  eval_samples_per_second: 578.598\n",
      "  eval_steps_per_second: 72.325\n",
      "  experiment_id: 7c2a760e3cc4425a8f2c3b771f2436a3\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.6766516951608228\n",
      "  pid: 14428\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 42.43034482002258\n",
      "  time_this_iter_s: 42.43034482002258\n",
      "  time_total_s: 42.43034482002258\n",
      "  timestamp: 1658452422\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00001\n",
      "  warmup_time: 0.005004405975341797\n",
      "  \n",
      "Result for _objective_69dd6_00003:\n",
      "  date: 2022-07-21_18-13-43\n",
      "  done: true\n",
      "  epoch: 2.0\n",
      "  eval_accuracy: 0.6813725490196079\n",
      "  eval_f1: 0.8104956268221574\n",
      "  eval_loss: 0.635231614112854\n",
      "  eval_runtime: 0.7118\n",
      "  eval_samples_per_second: 573.166\n",
      "  eval_steps_per_second: 71.646\n",
      "  experiment_id: b885a6f988974afcabdb183864d21fd3\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.4918681758417653\n",
      "  pid: 14430\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 43.5232789516449\n",
      "  time_this_iter_s: 43.5232789516449\n",
      "  time_total_s: 43.5232789516449\n",
      "  timestamp: 1658452423\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00003\n",
      "  warmup_time: 0.004084587097167969\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=14570)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=14570)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=14570)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=14570)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=14570)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=14603)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=14603)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=14603)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=14603)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=14603)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:13:49 (running for 00:00:54.95)\n",
      "Memory usage on this node: 23.2/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 111/infinite (105 PENDING, 4 RUNNING, 2 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00000 | RUNNING    | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |             |\n",
      "| _objective_69dd6_00002 | RUNNING    | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |             |\n",
      "| _objective_69dd6_00004 | RUNNING    | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |             |\n",
      "| _objective_69dd6_00005 | RUNNING    | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |             |\n",
      "| _objective_69dd6_00006 | PENDING    |                      |     1.67381e-05 |                  2 |                            32 |  2.81996 |             |\n",
      "| _objective_69dd6_00007 | PENDING    |                      |     5.4041e-06  |                  3 |                            32 | 15.916   |             |\n",
      "| _objective_69dd6_00008 | PENDING    |                      |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00009 | PENDING    |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |             |\n",
      "| _objective_69dd6_00010 | PENDING    |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |             |\n",
      "| _objective_69dd6_00011 | PENDING    |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | PENDING    |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 91 more trials not shown (91 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=14570)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=14570)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_objective pid=14603)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=14603)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:13:54 (running for 00:00:59.96)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 111/infinite (105 PENDING, 4 RUNNING, 2 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00000 | RUNNING    | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |             |\n",
      "| _objective_69dd6_00002 | RUNNING    | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |             |\n",
      "| _objective_69dd6_00004 | RUNNING    | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |             |\n",
      "| _objective_69dd6_00005 | RUNNING    | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |             |\n",
      "| _objective_69dd6_00006 | PENDING    |                      |     1.67381e-05 |                  2 |                            32 |  2.81996 |             |\n",
      "| _objective_69dd6_00007 | PENDING    |                      |     5.4041e-06  |                  3 |                            32 | 15.916   |             |\n",
      "| _objective_69dd6_00008 | PENDING    |                      |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00009 | PENDING    |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |             |\n",
      "| _objective_69dd6_00010 | PENDING    |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |             |\n",
      "| _objective_69dd6_00011 | PENDING    |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | PENDING    |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 91 more trials not shown (91 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:13:59 (running for 00:01:05.12)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 111/infinite (105 PENDING, 4 RUNNING, 2 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00000 | RUNNING    | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |             |\n",
      "| _objective_69dd6_00002 | RUNNING    | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |             |\n",
      "| _objective_69dd6_00004 | RUNNING    | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |             |\n",
      "| _objective_69dd6_00005 | RUNNING    | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |             |\n",
      "| _objective_69dd6_00006 | PENDING    |                      |     1.67381e-05 |                  2 |                            32 |  2.81996 |             |\n",
      "| _objective_69dd6_00007 | PENDING    |                      |     5.4041e-06  |                  3 |                            32 | 15.916   |             |\n",
      "| _objective_69dd6_00008 | PENDING    |                      |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00009 | PENDING    |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |             |\n",
      "| _objective_69dd6_00010 | PENDING    |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |             |\n",
      "| _objective_69dd6_00011 | PENDING    |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | PENDING    |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 91 more trials not shown (91 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:14:04 (running for 00:01:10.13)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 111/infinite (105 PENDING, 4 RUNNING, 2 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00000 | RUNNING    | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |             |\n",
      "| _objective_69dd6_00002 | RUNNING    | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |             |\n",
      "| _objective_69dd6_00004 | RUNNING    | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |             |\n",
      "| _objective_69dd6_00005 | RUNNING    | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |             |\n",
      "| _objective_69dd6_00006 | PENDING    |                      |     1.67381e-05 |                  2 |                            32 |  2.81996 |             |\n",
      "| _objective_69dd6_00007 | PENDING    |                      |     5.4041e-06  |                  3 |                            32 | 15.916   |             |\n",
      "| _objective_69dd6_00008 | PENDING    |                      |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00009 | PENDING    |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |             |\n",
      "| _objective_69dd6_00010 | PENDING    |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |             |\n",
      "| _objective_69dd6_00011 | PENDING    |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | PENDING    |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 91 more trials not shown (91 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:14:09 (running for 00:01:15.15)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 111/infinite (105 PENDING, 4 RUNNING, 2 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00000 | RUNNING    | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |             |\n",
      "| _objective_69dd6_00002 | RUNNING    | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |             |\n",
      "| _objective_69dd6_00004 | RUNNING    | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |             |\n",
      "| _objective_69dd6_00005 | RUNNING    | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |             |\n",
      "| _objective_69dd6_00006 | PENDING    |                      |     1.67381e-05 |                  2 |                            32 |  2.81996 |             |\n",
      "| _objective_69dd6_00007 | PENDING    |                      |     5.4041e-06  |                  3 |                            32 | 15.916   |             |\n",
      "| _objective_69dd6_00008 | PENDING    |                      |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00009 | PENDING    |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |             |\n",
      "| _objective_69dd6_00010 | PENDING    |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |             |\n",
      "| _objective_69dd6_00011 | PENDING    |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | PENDING    |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 91 more trials not shown (91 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:14:14 (running for 00:01:20.17)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 111/infinite (105 PENDING, 4 RUNNING, 2 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00000 | RUNNING    | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |             |\n",
      "| _objective_69dd6_00002 | RUNNING    | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |             |\n",
      "| _objective_69dd6_00004 | RUNNING    | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |             |\n",
      "| _objective_69dd6_00005 | RUNNING    | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |             |\n",
      "| _objective_69dd6_00006 | PENDING    |                      |     1.67381e-05 |                  2 |                            32 |  2.81996 |             |\n",
      "| _objective_69dd6_00007 | PENDING    |                      |     5.4041e-06  |                  3 |                            32 | 15.916   |             |\n",
      "| _objective_69dd6_00008 | PENDING    |                      |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00009 | PENDING    |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |             |\n",
      "| _objective_69dd6_00010 | PENDING    |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |             |\n",
      "| _objective_69dd6_00011 | PENDING    |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | PENDING    |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 91 more trials not shown (91 PENDING)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=14389)\u001b[0m {'loss': 0.5045, 'learning_rate': 7.319369237392838e-07, 'epoch': 4.35}\n",
      "\u001b[2m\u001b[36m(_objective pid=14389)\u001b[0m {'eval_loss': 0.5054973363876343, 'eval_accuracy': 0.7916666666666666, 'eval_f1': 0.8580968280467446, 'eval_runtime': 0.706, 'eval_samples_per_second': 577.906, 'eval_steps_per_second': 72.238, 'epoch': 4.35}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:14:19 (running for 00:01:25.19)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 111/infinite (105 PENDING, 4 RUNNING, 2 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00000 | RUNNING    | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |             |\n",
      "| _objective_69dd6_00002 | RUNNING    | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |             |\n",
      "| _objective_69dd6_00004 | RUNNING    | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |             |\n",
      "| _objective_69dd6_00005 | RUNNING    | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |             |\n",
      "| _objective_69dd6_00006 | PENDING    |                      |     1.67381e-05 |                  2 |                            32 |  2.81996 |             |\n",
      "| _objective_69dd6_00007 | PENDING    |                      |     5.4041e-06  |                  3 |                            32 | 15.916   |             |\n",
      "| _objective_69dd6_00008 | PENDING    |                      |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00009 | PENDING    |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |             |\n",
      "| _objective_69dd6_00010 | PENDING    |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |             |\n",
      "| _objective_69dd6_00011 | PENDING    |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | PENDING    |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 91 more trials not shown (91 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00000:\n",
      "  date: 2022-07-21_18-14-19\n",
      "  done: false\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.7916666666666666\n",
      "  eval_f1: 0.8580968280467446\n",
      "  eval_loss: 0.5054973363876343\n",
      "  eval_runtime: 0.706\n",
      "  eval_samples_per_second: 577.906\n",
      "  eval_steps_per_second: 72.238\n",
      "  experiment_id: b5f186f010ee444d8bca295599fb50a6\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.6497634947134112\n",
      "  pid: 14389\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 82.90014028549194\n",
      "  time_this_iter_s: 82.90014028549194\n",
      "  time_total_s: 82.90014028549194\n",
      "  timestamp: 1658452459\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00000\n",
      "  warmup_time: 0.003940582275390625\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=14429)\u001b[0m {'loss': 0.4409, 'learning_rate': 1.0811630695937156e-06, 'epoch': 4.35}\n",
      "\u001b[2m\u001b[36m(_objective pid=14429)\u001b[0m {'eval_loss': 0.4387318193912506, 'eval_accuracy': 0.821078431372549, 'eval_f1': 0.8764805414551609, 'eval_runtime': 0.7001, 'eval_samples_per_second': 582.759, 'eval_steps_per_second': 72.845, 'epoch': 4.35}\n",
      "Result for _objective_69dd6_00002:\n",
      "  date: 2022-07-21_18-14-23\n",
      "  done: false\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.821078431372549\n",
      "  eval_f1: 0.8764805414551609\n",
      "  eval_loss: 0.4387318193912506\n",
      "  eval_runtime: 0.7001\n",
      "  eval_samples_per_second: 582.759\n",
      "  eval_steps_per_second: 72.845\n",
      "  experiment_id: 91c5c694ff744f96a9f9d608d5774fef\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.6975589728277098\n",
      "  pid: 14429\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 82.86717343330383\n",
      "  time_this_iter_s: 82.86717343330383\n",
      "  time_total_s: 82.86717343330383\n",
      "  timestamp: 1658452463\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00002\n",
      "  warmup_time: 0.004060983657836914\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:14:28 (running for 00:01:34.09)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 111/infinite (105 PENDING, 4 RUNNING, 2 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00000 | RUNNING    | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00002 | RUNNING    | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00004 | RUNNING    | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |             |\n",
      "| _objective_69dd6_00005 | RUNNING    | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |             |\n",
      "| _objective_69dd6_00006 | PENDING    |                      |     1.67381e-05 |                  2 |                            32 |  2.81996 |             |\n",
      "| _objective_69dd6_00007 | PENDING    |                      |     5.4041e-06  |                  3 |                            32 | 15.916   |             |\n",
      "| _objective_69dd6_00008 | PENDING    |                      |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00009 | PENDING    |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |             |\n",
      "| _objective_69dd6_00010 | PENDING    |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |             |\n",
      "| _objective_69dd6_00011 | PENDING    |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | PENDING    |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 91 more trials not shown (91 PENDING)\n",
      "\n",
      "\n",
      "Result for _objective_69dd6_00000:\n",
      "  date: 2022-07-21_18-14-19\n",
      "  done: true\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.7916666666666666\n",
      "  eval_f1: 0.8580968280467446\n",
      "  eval_loss: 0.5054973363876343\n",
      "  eval_runtime: 0.706\n",
      "  eval_samples_per_second: 577.906\n",
      "  eval_steps_per_second: 72.238\n",
      "  experiment_id: b5f186f010ee444d8bca295599fb50a6\n",
      "  experiment_tag: 0_learning_rate=0.0000,num_train_epochs=5,per_device_train_batch_size=64,seed=8.1540\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.6497634947134112\n",
      "  pid: 14389\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 82.90014028549194\n",
      "  time_this_iter_s: 82.90014028549194\n",
      "  time_total_s: 82.90014028549194\n",
      "  timestamp: 1658452459\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00000\n",
      "  warmup_time: 0.003940582275390625\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=14389)\u001b[0m {'train_runtime': 90.8184, 'train_samples_per_second': 201.941, 'train_steps_per_second': 6.331, 'train_loss': 0.4895707370923913, 'epoch': 5.0}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:14:36 (running for 00:01:42.00)\n",
      "Memory usage on this node: 22.5/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 112/infinite (105 PENDING, 4 RUNNING, 3 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00002 | RUNNING    | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00004 | RUNNING    | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |             |\n",
      "| _objective_69dd6_00005 | RUNNING    | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |             |\n",
      "| _objective_69dd6_00006 | RUNNING    | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |             |\n",
      "| _objective_69dd6_00007 | PENDING    |                      |     5.4041e-06  |                  3 |                            32 | 15.916   |             |\n",
      "| _objective_69dd6_00008 | PENDING    |                      |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00009 | PENDING    |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |             |\n",
      "| _objective_69dd6_00010 | PENDING    |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |             |\n",
      "| _objective_69dd6_00011 | PENDING    |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | PENDING    |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 92 more trials not shown (92 PENDING)\n",
      "\n",
      "\n",
      "Result for _objective_69dd6_00002:\n",
      "  date: 2022-07-21_18-14-23\n",
      "  done: true\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.821078431372549\n",
      "  eval_f1: 0.8764805414551609\n",
      "  eval_loss: 0.4387318193912506\n",
      "  eval_runtime: 0.7001\n",
      "  eval_samples_per_second: 582.759\n",
      "  eval_steps_per_second: 72.845\n",
      "  experiment_id: 91c5c694ff744f96a9f9d608d5774fef\n",
      "  experiment_tag: 2_learning_rate=0.0000,num_train_epochs=5,per_device_train_batch_size=16,seed=24.4435\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.6975589728277098\n",
      "  pid: 14429\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 82.86717343330383\n",
      "  time_this_iter_s: 82.86717343330383\n",
      "  time_total_s: 82.86717343330383\n",
      "  timestamp: 1658452463\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00002\n",
      "  warmup_time: 0.004060983657836914\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=14429)\u001b[0m {'train_runtime': 90.735, 'train_samples_per_second': 202.127, 'train_steps_per_second': 6.337, 'train_loss': 0.4230398294200068, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=14670)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=14670)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=14670)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=14670)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=14670)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=14670)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=14670)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:14:42 (running for 00:01:47.98)\n",
      "Memory usage on this node: 22.9/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 113/infinite (105 PENDING, 4 RUNNING, 4 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00004 | RUNNING    | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |             |\n",
      "| _objective_69dd6_00005 | RUNNING    | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |             |\n",
      "| _objective_69dd6_00006 | RUNNING    | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |             |\n",
      "| _objective_69dd6_00007 | RUNNING    | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |             |\n",
      "| _objective_69dd6_00008 | PENDING    |                      |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00009 | PENDING    |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |             |\n",
      "| _objective_69dd6_00010 | PENDING    |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |             |\n",
      "| _objective_69dd6_00011 | PENDING    |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | PENDING    |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 93 more trials not shown (93 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=14706)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=14706)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=14706)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=14706)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=14706)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=14706)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=14706)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:14:47 (running for 00:01:53.00)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 113/infinite (105 PENDING, 4 RUNNING, 4 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00004 | RUNNING    | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |             |\n",
      "| _objective_69dd6_00005 | RUNNING    | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |             |\n",
      "| _objective_69dd6_00006 | RUNNING    | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |             |\n",
      "| _objective_69dd6_00007 | RUNNING    | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |             |\n",
      "| _objective_69dd6_00008 | PENDING    |                      |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00009 | PENDING    |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |             |\n",
      "| _objective_69dd6_00010 | PENDING    |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |             |\n",
      "| _objective_69dd6_00011 | PENDING    |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | PENDING    |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 93 more trials not shown (93 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:14:52 (running for 00:01:58.02)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 113/infinite (105 PENDING, 4 RUNNING, 4 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00004 | RUNNING    | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |             |\n",
      "| _objective_69dd6_00005 | RUNNING    | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |             |\n",
      "| _objective_69dd6_00006 | RUNNING    | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |             |\n",
      "| _objective_69dd6_00007 | RUNNING    | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |             |\n",
      "| _objective_69dd6_00008 | PENDING    |                      |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00009 | PENDING    |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |             |\n",
      "| _objective_69dd6_00010 | PENDING    |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |             |\n",
      "| _objective_69dd6_00011 | PENDING    |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | PENDING    |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 93 more trials not shown (93 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:14:57 (running for 00:02:03.03)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 113/infinite (105 PENDING, 4 RUNNING, 4 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00004 | RUNNING    | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |             |\n",
      "| _objective_69dd6_00005 | RUNNING    | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |             |\n",
      "| _objective_69dd6_00006 | RUNNING    | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |             |\n",
      "| _objective_69dd6_00007 | RUNNING    | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |             |\n",
      "| _objective_69dd6_00008 | PENDING    |                      |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00009 | PENDING    |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |             |\n",
      "| _objective_69dd6_00010 | PENDING    |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |             |\n",
      "| _objective_69dd6_00011 | PENDING    |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | PENDING    |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 93 more trials not shown (93 PENDING)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=14603)\u001b[0m {'train_runtime': 71.0995, 'train_samples_per_second': 206.359, 'train_steps_per_second': 6.47, 'train_loss': 0.4509672081988791, 'epoch': 4.0}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:15:02 (running for 00:02:08.05)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 113/infinite (105 PENDING, 4 RUNNING, 4 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00004 | RUNNING    | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |             |\n",
      "| _objective_69dd6_00005 | RUNNING    | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |             |\n",
      "| _objective_69dd6_00006 | RUNNING    | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |             |\n",
      "| _objective_69dd6_00007 | RUNNING    | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |             |\n",
      "| _objective_69dd6_00008 | PENDING    |                      |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00009 | PENDING    |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |             |\n",
      "| _objective_69dd6_00010 | PENDING    |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |             |\n",
      "| _objective_69dd6_00011 | PENDING    |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | PENDING    |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 93 more trials not shown (93 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=14603)\u001b[0m {'eval_loss': 0.5211783647537231, 'eval_accuracy': 0.803921568627451, 'eval_f1': 0.8648648648648648, 'eval_runtime': 0.71, 'eval_samples_per_second': 574.667, 'eval_steps_per_second': 71.833, 'epoch': 4.0}\n",
      "Result for _objective_69dd6_00005:\n",
      "  date: 2022-07-21_18-15-04\n",
      "  done: true\n",
      "  epoch: 4.0\n",
      "  eval_accuracy: 0.803921568627451\n",
      "  eval_f1: 0.8648648648648648\n",
      "  eval_loss: 0.5211783647537231\n",
      "  eval_runtime: 0.71\n",
      "  eval_samples_per_second: 574.667\n",
      "  eval_steps_per_second: 71.833\n",
      "  experiment_id: 9bf7cc27d84c4184ae0c7a832ea15043\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.6687864334923157\n",
      "  pid: 14603\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 78.435870885849\n",
      "  time_this_iter_s: 78.435870885849\n",
      "  time_total_s: 78.435870885849\n",
      "  timestamp: 1658452504\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00005\n",
      "  warmup_time: 0.0043048858642578125\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=14570)\u001b[0m {'loss': 0.5994, 'learning_rate': 3.013306810232994e-07, 'epoch': 4.35}\n",
      "\u001b[2m\u001b[36m(_objective pid=14570)\u001b[0m {'eval_loss': 0.5411626696586609, 'eval_accuracy': 0.7009803921568627, 'eval_f1': 0.8189910979228486, 'eval_runtime': 0.7095, 'eval_samples_per_second': 575.02, 'eval_steps_per_second': 71.877, 'epoch': 4.35}\n",
      "Result for _objective_69dd6_00004:\n",
      "  date: 2022-07-21_18-15-08\n",
      "  done: false\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.7009803921568627\n",
      "  eval_f1: 0.8189910979228486\n",
      "  eval_loss: 0.5411626696586609\n",
      "  eval_runtime: 0.7095\n",
      "  eval_samples_per_second: 575.02\n",
      "  eval_steps_per_second: 71.877\n",
      "  experiment_id: 7a1a5102da4a48ba86f5b854e9b6ff5e\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.5199714900797114\n",
      "  pid: 14570\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 83.44735145568848\n",
      "  time_this_iter_s: 83.44735145568848\n",
      "  time_total_s: 83.44735145568848\n",
      "  timestamp: 1658452508\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00004\n",
      "  warmup_time: 0.003969669342041016\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:15:08 (running for 00:02:14.55)\n",
      "Memory usage on this node: 22.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 114/infinite (105 PENDING, 4 RUNNING, 5 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00004 | RUNNING    | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00006 | RUNNING    | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |             |\n",
      "| _objective_69dd6_00007 | RUNNING    | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |             |\n",
      "| _objective_69dd6_00008 | RUNNING    | 155.246.89.124:14759 |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00009 | PENDING    |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |             |\n",
      "| _objective_69dd6_00010 | PENDING    |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |             |\n",
      "| _objective_69dd6_00011 | PENDING    |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | PENDING    |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 94 more trials not shown (94 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=14759)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=14759)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=14759)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=14759)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=14759)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=14759)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=14759)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:15:13 (running for 00:02:19.56)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 114/infinite (105 PENDING, 4 RUNNING, 5 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00004 | RUNNING    | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00006 | RUNNING    | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |             |\n",
      "| _objective_69dd6_00007 | RUNNING    | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |             |\n",
      "| _objective_69dd6_00008 | RUNNING    | 155.246.89.124:14759 |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00009 | PENDING    |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |             |\n",
      "| _objective_69dd6_00010 | PENDING    |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |             |\n",
      "| _objective_69dd6_00011 | PENDING    |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | PENDING    |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 94 more trials not shown (94 PENDING)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=14670)\u001b[0m {'train_runtime': 36.2439, 'train_samples_per_second': 202.406, 'train_steps_per_second': 6.346, 'train_loss': 0.4949451612389606, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=14670)\u001b[0m {'eval_loss': 0.45492023229599, 'eval_accuracy': 0.8137254901960784, 'eval_f1': 0.8733333333333333, 'eval_runtime': 0.7071, 'eval_samples_per_second': 576.976, 'eval_steps_per_second': 72.122, 'epoch': 2.0}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:15:18 (running for 00:02:24.59)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 114/infinite (105 PENDING, 4 RUNNING, 5 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00004 | RUNNING    | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00006 | RUNNING    | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |             |\n",
      "| _objective_69dd6_00007 | RUNNING    | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |             |\n",
      "| _objective_69dd6_00008 | RUNNING    | 155.246.89.124:14759 |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00009 | PENDING    |                      |     7.96157e-06 |                  2 |                            32 | 38.0065  |             |\n",
      "| _objective_69dd6_00010 | PENDING    |                      |     1.33837e-05 |                  2 |                            64 | 12.8799  |             |\n",
      "| _objective_69dd6_00011 | PENDING    |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | PENDING    |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 94 more trials not shown (94 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00006:\n",
      "  date: 2022-07-21_18-15-19\n",
      "  done: true\n",
      "  epoch: 2.0\n",
      "  eval_accuracy: 0.8137254901960784\n",
      "  eval_f1: 0.8733333333333333\n",
      "  eval_loss: 0.45492023229599\n",
      "  eval_runtime: 0.7071\n",
      "  eval_samples_per_second: 576.976\n",
      "  eval_steps_per_second: 72.122\n",
      "  experiment_id: 2be5577acaae432a852888e13f061c21\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.6870588235294117\n",
      "  pid: 14670\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 43.766663789749146\n",
      "  time_this_iter_s: 43.766663789749146\n",
      "  time_total_s: 43.766663789749146\n",
      "  timestamp: 1658452519\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00006\n",
      "  warmup_time: 0.004464387893676758\n",
      "  \n",
      "Result for _objective_69dd6_00004:\n",
      "  date: 2022-07-21_18-15-08\n",
      "  done: true\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.7009803921568627\n",
      "  eval_f1: 0.8189910979228486\n",
      "  eval_loss: 0.5411626696586609\n",
      "  eval_runtime: 0.7095\n",
      "  eval_samples_per_second: 575.02\n",
      "  eval_steps_per_second: 71.877\n",
      "  experiment_id: 7a1a5102da4a48ba86f5b854e9b6ff5e\n",
      "  experiment_tag: 4_learning_rate=0.0000,num_train_epochs=5,per_device_train_batch_size=8,seed=25.0818\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.5199714900797114\n",
      "  pid: 14570\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 83.44735145568848\n",
      "  time_this_iter_s: 83.44735145568848\n",
      "  time_total_s: 83.44735145568848\n",
      "  timestamp: 1658452508\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00004\n",
      "  warmup_time: 0.003969669342041016\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=14570)\u001b[0m {'train_runtime': 91.7497, 'train_samples_per_second': 199.892, 'train_steps_per_second': 6.267, 'train_loss': 0.5912147920028024, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=14807)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=14807)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=14807)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=14807)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=14807)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=14807)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=14807)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_objective pid=14843)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=14843)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=14843)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=14843)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=14843)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:15:27 (running for 00:02:33.02)\n",
      "Memory usage on this node: 23.4/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 116/infinite (105 PENDING, 4 RUNNING, 7 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00007 | RUNNING    | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |             |\n",
      "| _objective_69dd6_00008 | RUNNING    | 155.246.89.124:14759 |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00009 | RUNNING    | 155.246.89.124:14807 |     7.96157e-06 |                  2 |                            32 | 38.0065  |             |\n",
      "| _objective_69dd6_00010 | RUNNING    | 155.246.89.124:14843 |     1.33837e-05 |                  2 |                            64 | 12.8799  |             |\n",
      "| _objective_69dd6_00011 | PENDING    |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | PENDING    |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 96 more trials not shown (96 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=14843)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=14843)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:15:32 (running for 00:02:38.05)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 116/infinite (105 PENDING, 4 RUNNING, 7 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00007 | RUNNING    | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |             |\n",
      "| _objective_69dd6_00008 | RUNNING    | 155.246.89.124:14759 |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00009 | RUNNING    | 155.246.89.124:14807 |     7.96157e-06 |                  2 |                            32 | 38.0065  |             |\n",
      "| _objective_69dd6_00010 | RUNNING    | 155.246.89.124:14843 |     1.33837e-05 |                  2 |                            64 | 12.8799  |             |\n",
      "| _objective_69dd6_00011 | PENDING    |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | PENDING    |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 96 more trials not shown (96 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:15:37 (running for 00:02:43.06)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 116/infinite (105 PENDING, 4 RUNNING, 7 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00007 | RUNNING    | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |             |\n",
      "| _objective_69dd6_00008 | RUNNING    | 155.246.89.124:14759 |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00009 | RUNNING    | 155.246.89.124:14807 |     7.96157e-06 |                  2 |                            32 | 38.0065  |             |\n",
      "| _objective_69dd6_00010 | RUNNING    | 155.246.89.124:14843 |     1.33837e-05 |                  2 |                            64 | 12.8799  |             |\n",
      "| _objective_69dd6_00011 | PENDING    |                      |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | PENDING    |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 96 more trials not shown (96 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=14706)\u001b[0m {'train_runtime': 52.4613, 'train_samples_per_second': 209.754, 'train_steps_per_second': 6.576, 'train_loss': 0.5804045746291893, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=14706)\u001b[0m {'eval_loss': 0.5164138078689575, 'eval_accuracy': 0.7426470588235294, 'eval_f1': 0.8314606741573034, 'eval_runtime': 0.7032, 'eval_samples_per_second': 580.207, 'eval_steps_per_second': 72.526, 'epoch': 3.0}\n",
      "Result for _objective_69dd6_00007:\n",
      "  date: 2022-07-21_18-15-40\n",
      "  done: true\n",
      "  epoch: 3.0\n",
      "  eval_accuracy: 0.7426470588235294\n",
      "  eval_f1: 0.8314606741573034\n",
      "  eval_loss: 0.5164138078689575\n",
      "  eval_runtime: 0.7032\n",
      "  eval_samples_per_second: 580.207\n",
      "  eval_steps_per_second: 72.526\n",
      "  experiment_id: fb00756b2f6f45b4927760f7e64e2ace\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.5741077329808328\n",
      "  pid: 14706\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 60.308714151382446\n",
      "  time_this_iter_s: 60.308714151382446\n",
      "  time_total_s: 60.308714151382446\n",
      "  timestamp: 1658452540\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00007\n",
      "  warmup_time: 0.005053043365478516\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:15:46 (running for 00:02:52.04)\n",
      "Memory usage on this node: 23.1/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 117/infinite (105 PENDING, 4 RUNNING, 8 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00008 | RUNNING    | 155.246.89.124:14759 |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00009 | RUNNING    | 155.246.89.124:14807 |     7.96157e-06 |                  2 |                            32 | 38.0065  |             |\n",
      "| _objective_69dd6_00010 | RUNNING    | 155.246.89.124:14843 |     1.33837e-05 |                  2 |                            64 | 12.8799  |             |\n",
      "| _objective_69dd6_00011 | RUNNING    | 155.246.89.124:14985 |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | PENDING    |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 97 more trials not shown (97 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=14985)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=14985)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=14985)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=14985)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=14985)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=14985)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=14985)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:15:51 (running for 00:02:57.05)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 117/infinite (105 PENDING, 4 RUNNING, 8 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00008 | RUNNING    | 155.246.89.124:14759 |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00009 | RUNNING    | 155.246.89.124:14807 |     7.96157e-06 |                  2 |                            32 | 38.0065  |             |\n",
      "| _objective_69dd6_00010 | RUNNING    | 155.246.89.124:14843 |     1.33837e-05 |                  2 |                            64 | 12.8799  |             |\n",
      "| _objective_69dd6_00011 | RUNNING    | 155.246.89.124:14985 |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | PENDING    |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 97 more trials not shown (97 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:15:56 (running for 00:03:02.07)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 117/infinite (105 PENDING, 4 RUNNING, 8 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00008 | RUNNING    | 155.246.89.124:14759 |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00009 | RUNNING    | 155.246.89.124:14807 |     7.96157e-06 |                  2 |                            32 | 38.0065  |             |\n",
      "| _objective_69dd6_00010 | RUNNING    | 155.246.89.124:14843 |     1.33837e-05 |                  2 |                            64 | 12.8799  |             |\n",
      "| _objective_69dd6_00011 | RUNNING    | 155.246.89.124:14985 |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | PENDING    |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 97 more trials not shown (97 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:16:01 (running for 00:03:07.08)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 117/infinite (105 PENDING, 4 RUNNING, 8 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00008 | RUNNING    | 155.246.89.124:14759 |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00009 | RUNNING    | 155.246.89.124:14807 |     7.96157e-06 |                  2 |                            32 | 38.0065  |             |\n",
      "| _objective_69dd6_00010 | RUNNING    | 155.246.89.124:14843 |     1.33837e-05 |                  2 |                            64 | 12.8799  |             |\n",
      "| _objective_69dd6_00011 | RUNNING    | 155.246.89.124:14985 |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | PENDING    |                      |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 97 more trials not shown (97 PENDING)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=14807)\u001b[0m {'train_runtime': 35.6806, 'train_samples_per_second': 205.602, 'train_steps_per_second': 6.446, 'train_loss': 0.5744724439538044, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=14807)\u001b[0m {'eval_loss': 0.5138959884643555, 'eval_accuracy': 0.7426470588235294, 'eval_f1': 0.8356807511737089, 'eval_runtime': 0.7006, 'eval_samples_per_second': 582.352, 'eval_steps_per_second': 72.794, 'epoch': 2.0}\n",
      "Result for _objective_69dd6_00009:\n",
      "  date: 2022-07-21_18-16-04\n",
      "  done: true\n",
      "  epoch: 2.0\n",
      "  eval_accuracy: 0.7426470588235294\n",
      "  eval_f1: 0.8356807511737089\n",
      "  eval_loss: 0.5138959884643555\n",
      "  eval_runtime: 0.7006\n",
      "  eval_samples_per_second: 582.352\n",
      "  eval_steps_per_second: 72.794\n",
      "  experiment_id: 809384a7b53e450186f8ede12af3fb89\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.5783278099972384\n",
      "  pid: 14807\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 43.276580572128296\n",
      "  time_this_iter_s: 43.276580572128296\n",
      "  time_total_s: 43.276580572128296\n",
      "  timestamp: 1658452564\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00009\n",
      "  warmup_time: 0.004802227020263672\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=14843)\u001b[0m {'train_runtime': 35.5341, 'train_samples_per_second': 206.45, 'train_steps_per_second': 6.473, 'train_loss': 0.5203576129415761, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=14843)\u001b[0m {'eval_loss': 0.48809701204299927, 'eval_accuracy': 0.7818627450980392, 'eval_f1': 0.8548123980424144, 'eval_runtime': 0.7082, 'eval_samples_per_second': 576.107, 'eval_steps_per_second': 72.013, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=14759)\u001b[0m {'train_runtime': 53.9122, 'train_samples_per_second': 204.11, 'train_steps_per_second': 6.399, 'train_loss': 0.47978108723958335, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=14759)\u001b[0m {'eval_loss': 0.5124346017837524, 'eval_accuracy': 0.8088235294117647, 'eval_f1': 0.8725490196078431, 'eval_runtime': 0.7162, 'eval_samples_per_second': 569.645, 'eval_steps_per_second': 71.206, 'epoch': 3.0}\n",
      "Result for _objective_69dd6_00010:\n",
      "  date: 2022-07-21_18-16-07\n",
      "  done: true\n",
      "  epoch: 2.0\n",
      "  eval_accuracy: 0.7818627450980392\n",
      "  eval_f1: 0.8548123980424144\n",
      "  eval_loss: 0.48809701204299927\n",
      "  eval_runtime: 0.7082\n",
      "  eval_samples_per_second: 576.107\n",
      "  eval_steps_per_second: 72.013\n",
      "  experiment_id: f9164fff15e142bb97f5b7521c719d98\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.6366751431404536\n",
      "  pid: 14843\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 43.227099657058716\n",
      "  time_this_iter_s: 43.227099657058716\n",
      "  time_total_s: 43.227099657058716\n",
      "  timestamp: 1658452567\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00010\n",
      "  warmup_time: 0.0038368701934814453\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:16:07 (running for 00:03:13.28)\n",
      "Memory usage on this node: 22.1/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 118/infinite (105 PENDING, 4 RUNNING, 9 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00008 | RUNNING    | 155.246.89.124:14759 |     1.53049e-05 |                  3 |                            64 | 34.5377  |             |\n",
      "| _objective_69dd6_00010 | RUNNING    | 155.246.89.124:14843 |     1.33837e-05 |                  2 |                            64 | 12.8799  |     1.63668 |\n",
      "| _objective_69dd6_00011 | RUNNING    | 155.246.89.124:14985 |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | RUNNING    | 155.246.89.124:15035 |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | PENDING    |                      |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | PENDING    |                      |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00020 | PENDING    |                      |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 98 more trials not shown (97 PENDING, 1 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00008:\n",
      "  date: 2022-07-21_18-16-08\n",
      "  done: true\n",
      "  epoch: 3.0\n",
      "  eval_accuracy: 0.8088235294117647\n",
      "  eval_f1: 0.8725490196078431\n",
      "  eval_loss: 0.5124346017837524\n",
      "  eval_runtime: 0.7162\n",
      "  eval_samples_per_second: 569.645\n",
      "  eval_steps_per_second: 71.206\n",
      "  experiment_id: 707cc9706374434bbdd820ce07e91a2a\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.6813725490196079\n",
      "  pid: 14759\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 61.669899463653564\n",
      "  time_this_iter_s: 61.669899463653564\n",
      "  time_total_s: 61.669899463653564\n",
      "  timestamp: 1658452568\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00008\n",
      "  warmup_time: 0.0043506622314453125\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15035)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=15035)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15035)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15035)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15035)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=15035)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=15035)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_objective pid=15074)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15074)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15074)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15074)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=15074)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=15080)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15080)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15080)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15080)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15080)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:16:14 (running for 00:03:20.07)\n",
      "Memory usage on this node: 22.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 120/infinite (105 PENDING, 4 RUNNING, 11 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00011 | RUNNING    | 155.246.89.124:14985 |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | RUNNING    | 155.246.89.124:15035 |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | RUNNING    | 155.246.89.124:15074 |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | RUNNING    | 155.246.89.124:15080 |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00020 | PENDING    |                      |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | PENDING    |                      |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | PENDING    |                      |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 100 more trials not shown (97 PENDING, 3 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15074)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=15074)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_objective pid=15080)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=15080)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:16:19 (running for 00:03:25.10)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 120/infinite (105 PENDING, 4 RUNNING, 11 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00011 | RUNNING    | 155.246.89.124:14985 |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | RUNNING    | 155.246.89.124:15035 |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | RUNNING    | 155.246.89.124:15074 |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | RUNNING    | 155.246.89.124:15080 |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00020 | PENDING    |                      |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | PENDING    |                      |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | PENDING    |                      |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 100 more trials not shown (97 PENDING, 3 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:16:24 (running for 00:03:30.11)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 120/infinite (105 PENDING, 4 RUNNING, 11 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00011 | RUNNING    | 155.246.89.124:14985 |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | RUNNING    | 155.246.89.124:15035 |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | RUNNING    | 155.246.89.124:15074 |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | RUNNING    | 155.246.89.124:15080 |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00020 | PENDING    |                      |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | PENDING    |                      |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | PENDING    |                      |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 100 more trials not shown (97 PENDING, 3 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:16:29 (running for 00:03:35.14)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 120/infinite (105 PENDING, 4 RUNNING, 11 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00011 | RUNNING    | 155.246.89.124:14985 |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | RUNNING    | 155.246.89.124:15035 |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | RUNNING    | 155.246.89.124:15074 |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | RUNNING    | 155.246.89.124:15080 |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00020 | PENDING    |                      |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | PENDING    |                      |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | PENDING    |                      |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 100 more trials not shown (97 PENDING, 3 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:16:34 (running for 00:03:40.15)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 120/infinite (105 PENDING, 4 RUNNING, 11 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00011 | RUNNING    | 155.246.89.124:14985 |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | RUNNING    | 155.246.89.124:15035 |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | RUNNING    | 155.246.89.124:15074 |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | RUNNING    | 155.246.89.124:15080 |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00020 | PENDING    |                      |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | PENDING    |                      |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | PENDING    |                      |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 100 more trials not shown (97 PENDING, 3 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:16:39 (running for 00:03:45.17)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 120/infinite (105 PENDING, 4 RUNNING, 11 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00011 | RUNNING    | 155.246.89.124:14985 |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | RUNNING    | 155.246.89.124:15035 |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | RUNNING    | 155.246.89.124:15074 |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | RUNNING    | 155.246.89.124:15080 |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00020 | PENDING    |                      |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | PENDING    |                      |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | PENDING    |                      |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 100 more trials not shown (97 PENDING, 3 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:16:44 (running for 00:03:50.18)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 120/infinite (105 PENDING, 4 RUNNING, 11 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00011 | RUNNING    | 155.246.89.124:14985 |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | RUNNING    | 155.246.89.124:15035 |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | RUNNING    | 155.246.89.124:15074 |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | RUNNING    | 155.246.89.124:15080 |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00020 | PENDING    |                      |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | PENDING    |                      |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | PENDING    |                      |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 100 more trials not shown (97 PENDING, 3 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:16:49 (running for 00:03:55.20)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 120/infinite (105 PENDING, 4 RUNNING, 11 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00011 | RUNNING    | 155.246.89.124:14985 |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | RUNNING    | 155.246.89.124:15035 |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | RUNNING    | 155.246.89.124:15074 |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | RUNNING    | 155.246.89.124:15080 |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00020 | PENDING    |                      |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | PENDING    |                      |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | PENDING    |                      |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 100 more trials not shown (97 PENDING, 3 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:16:54 (running for 00:04:00.22)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 120/infinite (105 PENDING, 4 RUNNING, 11 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00011 | RUNNING    | 155.246.89.124:14985 |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | RUNNING    | 155.246.89.124:15035 |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | RUNNING    | 155.246.89.124:15074 |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | RUNNING    | 155.246.89.124:15080 |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00020 | PENDING    |                      |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | PENDING    |                      |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | PENDING    |                      |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 100 more trials not shown (97 PENDING, 3 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=14985)\u001b[0m {'train_runtime': 69.3328, 'train_samples_per_second': 211.617, 'train_steps_per_second': 6.635, 'train_loss': 0.5860705831776495, 'epoch': 4.0}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:16:59 (running for 00:04:05.24)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 120/infinite (105 PENDING, 4 RUNNING, 11 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00011 | RUNNING    | 155.246.89.124:14985 |     2.89593e-06 |                  4 |                            32 | 18.1659  |             |\n",
      "| _objective_69dd6_00012 | RUNNING    | 155.246.89.124:15035 |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | RUNNING    | 155.246.89.124:15074 |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | RUNNING    | 155.246.89.124:15080 |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | PENDING    |                      |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00020 | PENDING    |                      |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | PENDING    |                      |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | PENDING    |                      |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 100 more trials not shown (97 PENDING, 3 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=14985)\u001b[0m {'eval_loss': 0.5343301892280579, 'eval_accuracy': 0.7279411764705882, 'eval_f1': 0.82574568288854, 'eval_runtime': 0.7011, 'eval_samples_per_second': 581.92, 'eval_steps_per_second': 72.74, 'epoch': 4.0}\n",
      "Result for _objective_69dd6_00011:\n",
      "  date: 2022-07-21_18-17-00\n",
      "  done: true\n",
      "  epoch: 4.0\n",
      "  eval_accuracy: 0.7279411764705882\n",
      "  eval_f1: 0.82574568288854\n",
      "  eval_loss: 0.5343301892280579\n",
      "  eval_runtime: 0.7011\n",
      "  eval_samples_per_second: 581.92\n",
      "  eval_steps_per_second: 72.74\n",
      "  experiment_id: 11bffde537e247059ace014c931916cd\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.5536868593591282\n",
      "  pid: 14985\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 77.6539957523346\n",
      "  time_this_iter_s: 77.6539957523346\n",
      "  time_total_s: 77.6539957523346\n",
      "  timestamp: 1658452620\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00011\n",
      "  warmup_time: 0.004194021224975586\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=15035)\u001b[0m {'train_runtime': 52.073, 'train_samples_per_second': 211.319, 'train_steps_per_second': 6.625, 'train_loss': 0.500417825450068, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=15035)\u001b[0m {'eval_loss': 0.4926145076751709, 'eval_accuracy': 0.7990196078431373, 'eval_f1': 0.8637873754152825, 'eval_runtime': 0.6973, 'eval_samples_per_second': 585.094, 'eval_steps_per_second': 73.137, 'epoch': 3.0}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:17:06 (running for 00:04:12.11)\n",
      "Memory usage on this node: 23.4/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 121/infinite (105 PENDING, 4 RUNNING, 12 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00012 | RUNNING    | 155.246.89.124:15035 |     9.78034e-06 |                  3 |                            32 | 36.4635  |             |\n",
      "| _objective_69dd6_00013 | RUNNING    | 155.246.89.124:15074 |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | RUNNING    | 155.246.89.124:15080 |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | RUNNING    | 155.246.89.124:15176 |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | PENDING    |                      |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00020 | PENDING    |                      |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | PENDING    |                      |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | PENDING    |                      |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00023 | PENDING    |                      |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 101 more trials not shown (97 PENDING, 4 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15176)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15176)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15176)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15176)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=15176)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00012:\n",
      "  date: 2022-07-21_18-17-07\n",
      "  done: true\n",
      "  epoch: 3.0\n",
      "  eval_accuracy: 0.7990196078431373\n",
      "  eval_f1: 0.8637873754152825\n",
      "  eval_loss: 0.4926145076751709\n",
      "  eval_runtime: 0.6973\n",
      "  eval_samples_per_second: 585.094\n",
      "  eval_steps_per_second: 73.137\n",
      "  experiment_id: 28e79585a83345298e413c5eb31cecb2\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.6628069832584198\n",
      "  pid: 15035\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 59.550392389297485\n",
      "  time_this_iter_s: 59.550392389297485\n",
      "  time_total_s: 59.550392389297485\n",
      "  timestamp: 1658452627\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00012\n",
      "  warmup_time: 0.004527091979980469\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15176)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=15176)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:17:12 (running for 00:04:18.13)\n",
      "Memory usage on this node: 23.0/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 122/infinite (105 PENDING, 4 RUNNING, 13 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00013 | RUNNING    | 155.246.89.124:15074 |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | RUNNING    | 155.246.89.124:15080 |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | RUNNING    | 155.246.89.124:15176 |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | RUNNING    | 155.246.89.124:15216 |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00020 | PENDING    |                      |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | PENDING    |                      |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | PENDING    |                      |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00023 | PENDING    |                      |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | PENDING    |                      |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 102 more trials not shown (97 PENDING, 5 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15216)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15216)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15216)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15216)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15216)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=15216)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=15216)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:17:17 (running for 00:04:23.14)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 122/infinite (105 PENDING, 4 RUNNING, 13 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00013 | RUNNING    | 155.246.89.124:15074 |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | RUNNING    | 155.246.89.124:15080 |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | RUNNING    | 155.246.89.124:15176 |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | RUNNING    | 155.246.89.124:15216 |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00020 | PENDING    |                      |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | PENDING    |                      |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | PENDING    |                      |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00023 | PENDING    |                      |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | PENDING    |                      |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 102 more trials not shown (97 PENDING, 5 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:17:22 (running for 00:04:28.16)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 122/infinite (105 PENDING, 4 RUNNING, 13 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00013 | RUNNING    | 155.246.89.124:15074 |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | RUNNING    | 155.246.89.124:15080 |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | RUNNING    | 155.246.89.124:15176 |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | RUNNING    | 155.246.89.124:15216 |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00020 | PENDING    |                      |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | PENDING    |                      |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | PENDING    |                      |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00023 | PENDING    |                      |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | PENDING    |                      |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 102 more trials not shown (97 PENDING, 5 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15074)\u001b[0m {'train_runtime': 70.2571, 'train_samples_per_second': 208.833, 'train_steps_per_second': 6.547, 'train_loss': 0.5810901144276495, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=15074)\u001b[0m {'eval_loss': 0.5369256138801575, 'eval_accuracy': 0.7058823529411765, 'eval_f1': 0.8192771084337349, 'eval_runtime': 0.727, 'eval_samples_per_second': 561.234, 'eval_steps_per_second': 70.154, 'epoch': 4.0}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:17:27 (running for 00:04:33.18)\n",
      "Memory usage on this node: 25.0/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 122/infinite (105 PENDING, 4 RUNNING, 13 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00013 | RUNNING    | 155.246.89.124:15074 |     2.31458e-06 |                  4 |                             8 | 13.1567  |             |\n",
      "| _objective_69dd6_00014 | RUNNING    | 155.246.89.124:15080 |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | RUNNING    | 155.246.89.124:15176 |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | RUNNING    | 155.246.89.124:15216 |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | PENDING    |                      |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00020 | PENDING    |                      |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | PENDING    |                      |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | PENDING    |                      |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00023 | PENDING    |                      |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | PENDING    |                      |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 102 more trials not shown (97 PENDING, 5 TERMINATED)\n",
      "\n",
      "\n",
      "Result for _objective_69dd6_00013:\n",
      "  date: 2022-07-21_18-17-28\n",
      "  done: true\n",
      "  epoch: 4.0\n",
      "  eval_accuracy: 0.7058823529411765\n",
      "  eval_f1: 0.8192771084337349\n",
      "  eval_loss: 0.5369256138801575\n",
      "  eval_runtime: 0.727\n",
      "  eval_samples_per_second: 561.234\n",
      "  eval_steps_per_second: 70.154\n",
      "  experiment_id: 1c38c87ce3e746e5b9209073c8685faf\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.5251594613749115\n",
      "  pid: 15074\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 77.61692667007446\n",
      "  time_this_iter_s: 77.61692667007446\n",
      "  time_total_s: 77.61692667007446\n",
      "  timestamp: 1658452648\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00013\n",
      "  warmup_time: 0.004492521286010742\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:17:33 (running for 00:04:39.14)\n",
      "Memory usage on this node: 23.1/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 123/infinite (105 PENDING, 4 RUNNING, 14 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00014 | RUNNING    | 155.246.89.124:15080 |     1.36584e-05 |                  5 |                             8 | 38.8138  |             |\n",
      "| _objective_69dd6_00015 | RUNNING    | 155.246.89.124:15176 |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | RUNNING    | 155.246.89.124:15216 |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | RUNNING    | 155.246.89.124:15266 |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00020 | PENDING    |                      |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | PENDING    |                      |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | PENDING    |                      |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00023 | PENDING    |                      |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | PENDING    |                      |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00025 | PENDING    |                      |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 103 more trials not shown (97 PENDING, 6 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15266)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15266)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15266)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15266)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15266)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15080)\u001b[0m {'loss': 0.3657, 'learning_rate': 1.781533832658595e-06, 'epoch': 4.35}\n",
      "\u001b[2m\u001b[36m(_objective pid=15080)\u001b[0m {'eval_loss': 0.43705764412879944, 'eval_accuracy': 0.8455882352941176, 'eval_f1': 0.8919382504288165, 'eval_runtime': 0.7191, 'eval_samples_per_second': 567.395, 'eval_steps_per_second': 70.924, 'epoch': 4.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15266)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=15266)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00014:\n",
      "  date: 2022-07-21_18-17-37\n",
      "  done: false\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.8455882352941176\n",
      "  eval_f1: 0.8919382504288165\n",
      "  eval_loss: 0.43705764412879944\n",
      "  eval_runtime: 0.7191\n",
      "  eval_samples_per_second: 567.395\n",
      "  eval_steps_per_second: 70.924\n",
      "  experiment_id: 326f459d8f1c4c28af3263a1d97cf6d1\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.7375264857229342\n",
      "  pid: 15080\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 85.86882424354553\n",
      "  time_this_iter_s: 85.86882424354553\n",
      "  time_total_s: 85.86882424354553\n",
      "  timestamp: 1658452657\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00014\n",
      "  warmup_time: 0.004141330718994141\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:17:42 (running for 00:04:47.93)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 123/infinite (105 PENDING, 4 RUNNING, 14 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00014 | RUNNING    | 155.246.89.124:15080 |     1.36584e-05 |                  5 |                             8 | 38.8138  |     1.73753 |\n",
      "| _objective_69dd6_00015 | RUNNING    | 155.246.89.124:15176 |     7.93429e-06 |                  2 |                            32 | 35.8983  |             |\n",
      "| _objective_69dd6_00016 | RUNNING    | 155.246.89.124:15216 |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | RUNNING    | 155.246.89.124:15266 |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | PENDING    |                      |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00020 | PENDING    |                      |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | PENDING    |                      |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | PENDING    |                      |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00023 | PENDING    |                      |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | PENDING    |                      |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00025 | PENDING    |                      |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 103 more trials not shown (97 PENDING, 6 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=15176)\u001b[0m {'train_runtime': 35.038, 'train_samples_per_second': 209.373, 'train_steps_per_second': 6.564, 'train_loss': 0.557811106806216, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=15176)\u001b[0m {'eval_loss': 0.5090649127960205, 'eval_accuracy': 0.7622549019607843, 'eval_f1': 0.8422764227642278, 'eval_runtime': 0.7021, 'eval_samples_per_second': 581.094, 'eval_steps_per_second': 72.637, 'epoch': 2.0}\n",
      "Result for _objective_69dd6_00015:\n",
      "  date: 2022-07-21_18-17-46\n",
      "  done: true\n",
      "  epoch: 2.0\n",
      "  eval_accuracy: 0.7622549019607843\n",
      "  eval_f1: 0.8422764227642278\n",
      "  eval_loss: 0.5090649127960205\n",
      "  eval_runtime: 0.7021\n",
      "  eval_samples_per_second: 581.094\n",
      "  eval_steps_per_second: 72.637\n",
      "  experiment_id: 9046ec7a6eaf4a1d8f3cd9023cb6ec79\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.604531324725012\n",
      "  pid: 15176\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 43.546980142593384\n",
      "  time_this_iter_s: 43.546980142593384\n",
      "  time_total_s: 43.546980142593384\n",
      "  timestamp: 1658452666\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00015\n",
      "  warmup_time: 0.0046994686126708984\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:17:47 (running for 00:04:53.14)\n",
      "Memory usage on this node: 22.1/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 123/infinite (104 PENDING, 4 RUNNING, 15 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00014 | RUNNING    | 155.246.89.124:15080 |     1.36584e-05 |                  5 |                             8 | 38.8138  |     1.73753 |\n",
      "| _objective_69dd6_00016 | RUNNING    | 155.246.89.124:15216 |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | RUNNING    | 155.246.89.124:15266 |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | RUNNING    | 155.246.89.124:15316 |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | PENDING    |                      |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00020 | PENDING    |                      |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | PENDING    |                      |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | PENDING    |                      |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00023 | PENDING    |                      |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | PENDING    |                      |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00025 | PENDING    |                      |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00026 | PENDING    |                      |     1.11036e-05 |                  2 |                            64 |  1.99135 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 103 more trials not shown (96 PENDING, 7 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15080)\u001b[0m {'train_runtime': 94.7001, 'train_samples_per_second': 193.664, 'train_steps_per_second': 6.072, 'train_loss': 0.33733815732209577, 'epoch': 5.0}\n",
      "Result for _objective_69dd6_00014:\n",
      "  date: 2022-07-21_18-17-37\n",
      "  done: true\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.8455882352941176\n",
      "  eval_f1: 0.8919382504288165\n",
      "  eval_loss: 0.43705764412879944\n",
      "  eval_runtime: 0.7191\n",
      "  eval_samples_per_second: 567.395\n",
      "  eval_steps_per_second: 70.924\n",
      "  experiment_id: 326f459d8f1c4c28af3263a1d97cf6d1\n",
      "  experiment_tag: 14_learning_rate=0.0000,num_train_epochs=5,per_device_train_batch_size=8,seed=38.8138\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.7375264857229342\n",
      "  pid: 15080\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 85.86882424354553\n",
      "  time_this_iter_s: 85.86882424354553\n",
      "  time_total_s: 85.86882424354553\n",
      "  timestamp: 1658452657\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00014\n",
      "  warmup_time: 0.004141330718994141\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15316)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15316)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15316)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15316)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15316)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=15316)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=15316)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:17:56 (running for 00:05:02.15)\n",
      "Memory usage on this node: 23.2/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 125/infinite (105 PENDING, 4 RUNNING, 16 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00016 | RUNNING    | 155.246.89.124:15216 |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | RUNNING    | 155.246.89.124:15266 |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | RUNNING    | 155.246.89.124:15316 |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | RUNNING    | 155.246.89.124:15351 |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00020 | PENDING    |                      |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | PENDING    |                      |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | PENDING    |                      |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00023 | PENDING    |                      |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | PENDING    |                      |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00025 | PENDING    |                      |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00026 | PENDING    |                      |     1.11036e-05 |                  2 |                            64 |  1.99135 |             |\n",
      "| _objective_69dd6_00027 | PENDING    |                      |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 105 more trials not shown (97 PENDING, 8 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15351)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=15351)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15351)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15351)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=15351)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=15351)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=15351)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:18:01 (running for 00:05:07.31)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 125/infinite (105 PENDING, 4 RUNNING, 16 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00016 | RUNNING    | 155.246.89.124:15216 |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | RUNNING    | 155.246.89.124:15266 |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | RUNNING    | 155.246.89.124:15316 |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | RUNNING    | 155.246.89.124:15351 |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00020 | PENDING    |                      |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | PENDING    |                      |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | PENDING    |                      |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00023 | PENDING    |                      |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | PENDING    |                      |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00025 | PENDING    |                      |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00026 | PENDING    |                      |     1.11036e-05 |                  2 |                            64 |  1.99135 |             |\n",
      "| _objective_69dd6_00027 | PENDING    |                      |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 105 more trials not shown (97 PENDING, 8 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:18:06 (running for 00:05:12.33)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 125/infinite (105 PENDING, 4 RUNNING, 16 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00016 | RUNNING    | 155.246.89.124:15216 |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | RUNNING    | 155.246.89.124:15266 |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | RUNNING    | 155.246.89.124:15316 |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | RUNNING    | 155.246.89.124:15351 |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00020 | PENDING    |                      |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | PENDING    |                      |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | PENDING    |                      |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00023 | PENDING    |                      |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | PENDING    |                      |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00025 | PENDING    |                      |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00026 | PENDING    |                      |     1.11036e-05 |                  2 |                            64 |  1.99135 |             |\n",
      "| _objective_69dd6_00027 | PENDING    |                      |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 105 more trials not shown (97 PENDING, 8 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15266)\u001b[0m {'train_runtime': 35.4891, 'train_samples_per_second': 206.712, 'train_steps_per_second': 6.481, 'train_loss': 0.5437726228133491, 'epoch': 2.0}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:18:11 (running for 00:05:17.35)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 125/infinite (105 PENDING, 4 RUNNING, 16 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00016 | RUNNING    | 155.246.89.124:15216 |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00017 | RUNNING    | 155.246.89.124:15266 |     1.20056e-05 |                  2 |                            32 | 38.645   |             |\n",
      "| _objective_69dd6_00018 | RUNNING    | 155.246.89.124:15316 |     1.21728e-05 |                  1 |                            64 | 12.5547  |             |\n",
      "| _objective_69dd6_00019 | RUNNING    | 155.246.89.124:15351 |     1.40962e-06 |                  1 |                            32 | 31.1175  |             |\n",
      "| _objective_69dd6_00020 | PENDING    |                      |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | PENDING    |                      |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | PENDING    |                      |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00023 | PENDING    |                      |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | PENDING    |                      |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00025 | PENDING    |                      |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00026 | PENDING    |                      |     1.11036e-05 |                  2 |                            64 |  1.99135 |             |\n",
      "| _objective_69dd6_00027 | PENDING    |                      |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 105 more trials not shown (97 PENDING, 8 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=15266)\u001b[0m {'eval_loss': 0.49004852771759033, 'eval_accuracy': 0.7916666666666666, 'eval_f1': 0.8631239935587761, 'eval_runtime': 0.709, 'eval_samples_per_second': 575.454, 'eval_steps_per_second': 71.932, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=15316)\u001b[0m {'train_runtime': 17.8211, 'train_samples_per_second': 205.824, 'train_steps_per_second': 6.453, 'train_loss': 0.5841136103091032, 'epoch': 1.0}\n",
      "Result for _objective_69dd6_00017:\n",
      "  date: 2022-07-21_18-18-13\n",
      "  done: true\n",
      "  epoch: 2.0\n",
      "  eval_accuracy: 0.7916666666666666\n",
      "  eval_f1: 0.8631239935587761\n",
      "  eval_loss: 0.49004852771759033\n",
      "  eval_runtime: 0.709\n",
      "  eval_samples_per_second: 575.454\n",
      "  eval_steps_per_second: 71.932\n",
      "  experiment_id: d61cf08e8ef340949eff693caecf4824\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.6547906602254427\n",
      "  pid: 15266\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 42.83633279800415\n",
      "  time_this_iter_s: 42.83633279800415\n",
      "  time_total_s: 42.83633279800415\n",
      "  timestamp: 1658452693\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00017\n",
      "  warmup_time: 0.0038738250732421875\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=15316)\u001b[0m {'eval_loss': 0.5453287363052368, 'eval_accuracy': 0.7279411764705882, 'eval_f1': 0.8251968503937007, 'eval_runtime': 0.7044, 'eval_samples_per_second': 579.179, 'eval_steps_per_second': 72.397, 'epoch': 1.0}\n",
      "Result for _objective_69dd6_00018:\n",
      "  date: 2022-07-21_18-18-15\n",
      "  done: true\n",
      "  epoch: 1.0\n",
      "  eval_accuracy: 0.7279411764705882\n",
      "  eval_f1: 0.8251968503937007\n",
      "  eval_loss: 0.5453287363052368\n",
      "  eval_runtime: 0.7044\n",
      "  eval_samples_per_second: 579.179\n",
      "  eval_steps_per_second: 72.397\n",
      "  experiment_id: 399311a4f574420bb3d82a28edc1a183\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.553138026864289\n",
      "  pid: 15316\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 25.33306384086609\n",
      "  time_this_iter_s: 25.33306384086609\n",
      "  time_total_s: 25.33306384086609\n",
      "  timestamp: 1658452695\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00018\n",
      "  warmup_time: 0.003960847854614258\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=15351)\u001b[0m {'train_runtime': 18.459, 'train_samples_per_second': 198.711, 'train_steps_per_second': 6.23, 'train_loss': 0.6880448714546535, 'epoch': 1.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=15351)\u001b[0m {'eval_loss': 0.6544497013092041, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.7152, 'eval_samples_per_second': 570.444, 'eval_steps_per_second': 71.306, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15404)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=15404)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15404)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15404)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15404)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00019:\n",
      "  date: 2022-07-21_18-18-19\n",
      "  done: true\n",
      "  epoch: 1.0\n",
      "  eval_accuracy: 0.6838235294117647\n",
      "  eval_f1: 0.8122270742358079\n",
      "  eval_loss: 0.6544497013092041\n",
      "  eval_runtime: 0.7152\n",
      "  eval_samples_per_second: 570.444\n",
      "  eval_steps_per_second: 71.306\n",
      "  experiment_id: 2304a1e18f0444249440eb583d294ccc\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.4960506036475727\n",
      "  pid: 15351\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 26.04690718650818\n",
      "  time_this_iter_s: 26.04690718650818\n",
      "  time_total_s: 26.04690718650818\n",
      "  timestamp: 1658452699\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00019\n",
      "  warmup_time: 0.004496097564697266\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:18:19 (running for 00:05:25.51)\n",
      "Memory usage on this node: 21.6/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 127/infinite (105 PENDING, 4 RUNNING, 18 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00016 | RUNNING    | 155.246.89.124:15216 |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00019 | RUNNING    | 155.246.89.124:15351 |     1.40962e-06 |                  1 |                            32 | 31.1175  |     1.49605 |\n",
      "| _objective_69dd6_00020 | RUNNING    | 155.246.89.124:15404 |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | RUNNING    | 155.246.89.124:15438 |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | PENDING    |                      |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00023 | PENDING    |                      |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | PENDING    |                      |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00025 | PENDING    |                      |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00026 | PENDING    |                      |     1.11036e-05 |                  2 |                            64 |  1.99135 |             |\n",
      "| _objective_69dd6_00027 | PENDING    |                      |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00028 | PENDING    |                      |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | PENDING    |                      |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 107 more trials not shown (97 PENDING, 10 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15438)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15438)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15438)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15438)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15438)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=15404)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=15404)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_objective pid=15438)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=15438)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_objective pid=15479)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15479)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15479)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15479)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=15479)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:18:25 (running for 00:05:31.20)\n",
      "Memory usage on this node: 23.3/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 128/infinite (105 PENDING, 4 RUNNING, 19 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00016 | RUNNING    | 155.246.89.124:15216 |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00020 | RUNNING    | 155.246.89.124:15404 |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | RUNNING    | 155.246.89.124:15438 |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | RUNNING    | 155.246.89.124:15479 |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00023 | PENDING    |                      |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | PENDING    |                      |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00025 | PENDING    |                      |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00026 | PENDING    |                      |     1.11036e-05 |                  2 |                            64 |  1.99135 |             |\n",
      "| _objective_69dd6_00027 | PENDING    |                      |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00028 | PENDING    |                      |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | PENDING    |                      |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | PENDING    |                      |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 108 more trials not shown (97 PENDING, 11 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15479)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=15479)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:18:30 (running for 00:05:36.21)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 128/infinite (105 PENDING, 4 RUNNING, 19 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00016 | RUNNING    | 155.246.89.124:15216 |     1.23156e-06 |                  5 |                             8 | 16.1584  |             |\n",
      "| _objective_69dd6_00020 | RUNNING    | 155.246.89.124:15404 |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | RUNNING    | 155.246.89.124:15438 |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | RUNNING    | 155.246.89.124:15479 |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00023 | PENDING    |                      |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | PENDING    |                      |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00025 | PENDING    |                      |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00026 | PENDING    |                      |     1.11036e-05 |                  2 |                            64 |  1.99135 |             |\n",
      "| _objective_69dd6_00027 | PENDING    |                      |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00028 | PENDING    |                      |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | PENDING    |                      |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | PENDING    |                      |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 108 more trials not shown (97 PENDING, 11 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=15216)\u001b[0m {'loss': 0.6075, 'learning_rate': 1.606378920478178e-07, 'epoch': 4.35}\n",
      "\u001b[2m\u001b[36m(_objective pid=15216)\u001b[0m {'eval_loss': 0.5619900226593018, 'eval_accuracy': 0.6985294117647058, 'eval_f1': 0.8193832599118943, 'eval_runtime': 0.7031, 'eval_samples_per_second': 580.271, 'eval_steps_per_second': 72.534, 'epoch': 4.35}\n",
      "Result for _objective_69dd6_00016:\n",
      "  date: 2022-07-21_18-18-33\n",
      "  done: false\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.6985294117647058\n",
      "  eval_f1: 0.8193832599118943\n",
      "  eval_loss: 0.5619900226593018\n",
      "  eval_runtime: 0.7031\n",
      "  eval_samples_per_second: 580.271\n",
      "  eval_steps_per_second: 72.534\n",
      "  experiment_id: de3df701fa644467bcc04061993ccab5\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.5179126716766\n",
      "  pid: 15216\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 83.70066928863525\n",
      "  time_this_iter_s: 83.70066928863525\n",
      "  time_total_s: 83.70066928863525\n",
      "  timestamp: 1658452713\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00016\n",
      "  warmup_time: 0.005797386169433594\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:18:39 (running for 00:05:44.88)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 128/infinite (105 PENDING, 4 RUNNING, 19 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00016 | RUNNING    | 155.246.89.124:15216 |     1.23156e-06 |                  5 |                             8 | 16.1584  |     1.51791 |\n",
      "| _objective_69dd6_00020 | RUNNING    | 155.246.89.124:15404 |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | RUNNING    | 155.246.89.124:15438 |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | RUNNING    | 155.246.89.124:15479 |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00023 | PENDING    |                      |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | PENDING    |                      |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00025 | PENDING    |                      |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00026 | PENDING    |                      |     1.11036e-05 |                  2 |                            64 |  1.99135 |             |\n",
      "| _objective_69dd6_00027 | PENDING    |                      |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00028 | PENDING    |                      |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | PENDING    |                      |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | PENDING    |                      |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 108 more trials not shown (97 PENDING, 11 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:18:44 (running for 00:05:49.90)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 128/infinite (105 PENDING, 4 RUNNING, 19 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00016 | RUNNING    | 155.246.89.124:15216 |     1.23156e-06 |                  5 |                             8 | 16.1584  |     1.51791 |\n",
      "| _objective_69dd6_00020 | RUNNING    | 155.246.89.124:15404 |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | RUNNING    | 155.246.89.124:15438 |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00022 | RUNNING    | 155.246.89.124:15479 |     1.70505e-06 |                  1 |                             8 | 25.3086  |             |\n",
      "| _objective_69dd6_00023 | PENDING    |                      |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | PENDING    |                      |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00025 | PENDING    |                      |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00026 | PENDING    |                      |     1.11036e-05 |                  2 |                            64 |  1.99135 |             |\n",
      "| _objective_69dd6_00027 | PENDING    |                      |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00028 | PENDING    |                      |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | PENDING    |                      |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | PENDING    |                      |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 108 more trials not shown (97 PENDING, 11 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=15479)\u001b[0m {'train_runtime': 18.3398, 'train_samples_per_second': 200.002, 'train_steps_per_second': 6.271, 'train_loss': 0.7025488148564878, 'epoch': 1.0}\n",
      "Result for _objective_69dd6_00016:\n",
      "  date: 2022-07-21_18-18-33\n",
      "  done: true\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.6985294117647058\n",
      "  eval_f1: 0.8193832599118943\n",
      "  eval_loss: 0.5619900226593018\n",
      "  eval_runtime: 0.7031\n",
      "  eval_samples_per_second: 580.271\n",
      "  eval_steps_per_second: 72.534\n",
      "  experiment_id: de3df701fa644467bcc04061993ccab5\n",
      "  experiment_tag: 16_learning_rate=0.0000,num_train_epochs=5,per_device_train_batch_size=8,seed=16.1584\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.5179126716766\n",
      "  pid: 15216\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 83.70066928863525\n",
      "  time_this_iter_s: 83.70066928863525\n",
      "  time_total_s: 83.70066928863525\n",
      "  timestamp: 1658452713\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00016\n",
      "  warmup_time: 0.005797386169433594\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=15216)\u001b[0m {'train_runtime': 91.0741, 'train_samples_per_second': 201.375, 'train_steps_per_second': 6.314, 'train_loss': 0.6015414893108866, 'epoch': 5.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=15479)\u001b[0m {'eval_loss': 0.6690647006034851, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.7229, 'eval_samples_per_second': 564.356, 'eval_steps_per_second': 70.544, 'epoch': 1.0}\n",
      "Result for _objective_69dd6_00022:\n",
      "  date: 2022-07-21_18-18-48\n",
      "  done: true\n",
      "  epoch: 1.0\n",
      "  eval_accuracy: 0.6838235294117647\n",
      "  eval_f1: 0.8122270742358079\n",
      "  eval_loss: 0.6690647006034851\n",
      "  eval_runtime: 0.7229\n",
      "  eval_samples_per_second: 564.356\n",
      "  eval_steps_per_second: 70.544\n",
      "  experiment_id: d27880bc938c432aa9fb47a0e1b817fc\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.4960506036475727\n",
      "  pid: 15479\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 26.039103984832764\n",
      "  time_this_iter_s: 26.039103984832764\n",
      "  time_total_s: 26.039103984832764\n",
      "  timestamp: 1658452728\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00022\n",
      "  warmup_time: 0.004112958908081055\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:18:49 (running for 00:05:55.21)\n",
      "Memory usage on this node: 19.3/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 129/infinite (104 PENDING, 4 RUNNING, 21 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00020 | RUNNING    | 155.246.89.124:15404 |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | RUNNING    | 155.246.89.124:15438 |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00023 | RUNNING    | 155.246.89.124:15537 |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | RUNNING    | 155.246.89.124:15569 |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00025 | PENDING    |                      |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00026 | PENDING    |                      |     1.11036e-05 |                  2 |                            64 |  1.99135 |             |\n",
      "| _objective_69dd6_00027 | PENDING    |                      |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00028 | PENDING    |                      |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | PENDING    |                      |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | PENDING    |                      |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | PENDING    |                      |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | PENDING    |                      |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 109 more trials not shown (96 PENDING, 13 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15537)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15537)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15537)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15537)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15537)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=15569)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15569)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15569)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15569)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=15569)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=15537)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=15537)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:18:56 (running for 00:06:02.27)\n",
      "Memory usage on this node: 24.9/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 130/infinite (105 PENDING, 4 RUNNING, 21 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00020 | RUNNING    | 155.246.89.124:15404 |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | RUNNING    | 155.246.89.124:15438 |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00023 | RUNNING    | 155.246.89.124:15537 |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | RUNNING    | 155.246.89.124:15569 |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00025 | PENDING    |                      |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00026 | PENDING    |                      |     1.11036e-05 |                  2 |                            64 |  1.99135 |             |\n",
      "| _objective_69dd6_00027 | PENDING    |                      |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00028 | PENDING    |                      |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | PENDING    |                      |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | PENDING    |                      |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | PENDING    |                      |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | PENDING    |                      |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 110 more trials not shown (97 PENDING, 13 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15569)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=15569)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:19:01 (running for 00:06:07.29)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 130/infinite (105 PENDING, 4 RUNNING, 21 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00020 | RUNNING    | 155.246.89.124:15404 |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | RUNNING    | 155.246.89.124:15438 |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00023 | RUNNING    | 155.246.89.124:15537 |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | RUNNING    | 155.246.89.124:15569 |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00025 | PENDING    |                      |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00026 | PENDING    |                      |     1.11036e-05 |                  2 |                            64 |  1.99135 |             |\n",
      "| _objective_69dd6_00027 | PENDING    |                      |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00028 | PENDING    |                      |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | PENDING    |                      |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | PENDING    |                      |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | PENDING    |                      |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | PENDING    |                      |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 110 more trials not shown (97 PENDING, 13 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:19:06 (running for 00:06:12.30)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 130/infinite (105 PENDING, 4 RUNNING, 21 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00020 | RUNNING    | 155.246.89.124:15404 |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | RUNNING    | 155.246.89.124:15438 |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00023 | RUNNING    | 155.246.89.124:15537 |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | RUNNING    | 155.246.89.124:15569 |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00025 | PENDING    |                      |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00026 | PENDING    |                      |     1.11036e-05 |                  2 |                            64 |  1.99135 |             |\n",
      "| _objective_69dd6_00027 | PENDING    |                      |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00028 | PENDING    |                      |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | PENDING    |                      |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | PENDING    |                      |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | PENDING    |                      |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | PENDING    |                      |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 110 more trials not shown (97 PENDING, 13 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:19:11 (running for 00:06:17.33)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 130/infinite (105 PENDING, 4 RUNNING, 21 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00020 | RUNNING    | 155.246.89.124:15404 |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | RUNNING    | 155.246.89.124:15438 |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00023 | RUNNING    | 155.246.89.124:15537 |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | RUNNING    | 155.246.89.124:15569 |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00025 | PENDING    |                      |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00026 | PENDING    |                      |     1.11036e-05 |                  2 |                            64 |  1.99135 |             |\n",
      "| _objective_69dd6_00027 | PENDING    |                      |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00028 | PENDING    |                      |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | PENDING    |                      |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | PENDING    |                      |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | PENDING    |                      |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | PENDING    |                      |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 110 more trials not shown (97 PENDING, 13 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=15404)\u001b[0m {'train_runtime': 52.7642, 'train_samples_per_second': 208.55, 'train_steps_per_second': 6.539, 'train_loss': 0.5822116575379302, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=15404)\u001b[0m {'eval_loss': 0.5297566056251526, 'eval_accuracy': 0.7205882352941176, 'eval_f1': 0.8267477203647416, 'eval_runtime': 0.7061, 'eval_samples_per_second': 577.796, 'eval_steps_per_second': 72.224, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=15438)\u001b[0m {'train_runtime': 52.2718, 'train_samples_per_second': 210.515, 'train_steps_per_second': 6.6, 'train_loss': 0.3314882361370584, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=15438)\u001b[0m {'eval_loss': 0.46171578764915466, 'eval_accuracy': 0.8357843137254902, 'eval_f1': 0.8870151770657673, 'eval_runtime': 0.7047, 'eval_samples_per_second': 579.009, 'eval_steps_per_second': 72.376, 'epoch': 3.0}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:19:16 (running for 00:06:22.35)\n",
      "Memory usage on this node: 24.9/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 130/infinite (105 PENDING, 4 RUNNING, 21 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00020 | RUNNING    | 155.246.89.124:15404 |     3.86346e-06 |                  3 |                            16 |  8.75485 |             |\n",
      "| _objective_69dd6_00021 | RUNNING    | 155.246.89.124:15438 |     3.80497e-05 |                  3 |                             8 |  3.88774 |             |\n",
      "| _objective_69dd6_00023 | RUNNING    | 155.246.89.124:15537 |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | RUNNING    | 155.246.89.124:15569 |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00025 | PENDING    |                      |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00026 | PENDING    |                      |     1.11036e-05 |                  2 |                            64 |  1.99135 |             |\n",
      "| _objective_69dd6_00027 | PENDING    |                      |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00028 | PENDING    |                      |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | PENDING    |                      |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | PENDING    |                      |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | PENDING    |                      |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | PENDING    |                      |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 110 more trials not shown (97 PENDING, 13 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00020:\n",
      "  date: 2022-07-21_18-19-16\n",
      "  done: true\n",
      "  epoch: 3.0\n",
      "  eval_accuracy: 0.7205882352941176\n",
      "  eval_f1: 0.8267477203647416\n",
      "  eval_loss: 0.5297566056251526\n",
      "  eval_runtime: 0.7061\n",
      "  eval_samples_per_second: 577.796\n",
      "  eval_steps_per_second: 72.224\n",
      "  experiment_id: 5abfc5d75b3e40639052df03da5b6177\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.5473359556588593\n",
      "  pid: 15404\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 60.4823842048645\n",
      "  time_this_iter_s: 60.4823842048645\n",
      "  time_total_s: 60.4823842048645\n",
      "  timestamp: 1658452756\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00020\n",
      "  warmup_time: 0.004002571105957031\n",
      "  \n",
      "Result for _objective_69dd6_00021:\n",
      "  date: 2022-07-21_18-19-18\n",
      "  done: true\n",
      "  epoch: 3.0\n",
      "  eval_accuracy: 0.8357843137254902\n",
      "  eval_f1: 0.8870151770657673\n",
      "  eval_loss: 0.46171578764915466\n",
      "  eval_runtime: 0.7047\n",
      "  eval_samples_per_second: 579.009\n",
      "  eval_steps_per_second: 72.376\n",
      "  experiment_id: 71827a3231ab492da5378a507a719ecc\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.7227994907912576\n",
      "  pid: 15438\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 59.871376037597656\n",
      "  time_this_iter_s: 59.871376037597656\n",
      "  time_total_s: 59.871376037597656\n",
      "  timestamp: 1658452758\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00021\n",
      "  warmup_time: 0.003961801528930664\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15637)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=15637)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15637)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15637)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=15637)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:19:23 (running for 00:06:29.25)\n",
      "Memory usage on this node: 22.1/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 132/infinite (105 PENDING, 4 RUNNING, 23 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00023 | RUNNING    | 155.246.89.124:15537 |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | RUNNING    | 155.246.89.124:15569 |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00025 | RUNNING    | 155.246.89.124:15637 |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00026 | RUNNING    | 155.246.89.124:15669 |     1.11036e-05 |                  2 |                            64 |  1.99135 |             |\n",
      "| _objective_69dd6_00027 | PENDING    |                      |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00028 | PENDING    |                      |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | PENDING    |                      |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | PENDING    |                      |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | PENDING    |                      |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | PENDING    |                      |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 112 more trials not shown (97 PENDING, 15 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15669)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15669)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15669)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15669)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15669)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=15637)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=15637)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_objective pid=15669)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=15669)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:19:28 (running for 00:06:34.27)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 132/infinite (105 PENDING, 4 RUNNING, 23 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00023 | RUNNING    | 155.246.89.124:15537 |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | RUNNING    | 155.246.89.124:15569 |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00025 | RUNNING    | 155.246.89.124:15637 |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00026 | RUNNING    | 155.246.89.124:15669 |     1.11036e-05 |                  2 |                            64 |  1.99135 |             |\n",
      "| _objective_69dd6_00027 | PENDING    |                      |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00028 | PENDING    |                      |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | PENDING    |                      |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | PENDING    |                      |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | PENDING    |                      |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | PENDING    |                      |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 112 more trials not shown (97 PENDING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:19:33 (running for 00:06:39.30)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 132/infinite (105 PENDING, 4 RUNNING, 23 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00023 | RUNNING    | 155.246.89.124:15537 |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | RUNNING    | 155.246.89.124:15569 |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00025 | RUNNING    | 155.246.89.124:15637 |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00026 | RUNNING    | 155.246.89.124:15669 |     1.11036e-05 |                  2 |                            64 |  1.99135 |             |\n",
      "| _objective_69dd6_00027 | PENDING    |                      |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00028 | PENDING    |                      |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | PENDING    |                      |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | PENDING    |                      |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | PENDING    |                      |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | PENDING    |                      |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 112 more trials not shown (97 PENDING, 15 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:19:38 (running for 00:06:44.31)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 132/infinite (105 PENDING, 4 RUNNING, 23 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00023 | RUNNING    | 155.246.89.124:15537 |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | RUNNING    | 155.246.89.124:15569 |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00025 | RUNNING    | 155.246.89.124:15637 |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00026 | RUNNING    | 155.246.89.124:15669 |     1.11036e-05 |                  2 |                            64 |  1.99135 |             |\n",
      "| _objective_69dd6_00027 | PENDING    |                      |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00028 | PENDING    |                      |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | PENDING    |                      |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | PENDING    |                      |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | PENDING    |                      |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | PENDING    |                      |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 112 more trials not shown (97 PENDING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:19:43 (running for 00:06:49.34)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 132/infinite (105 PENDING, 4 RUNNING, 23 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00023 | RUNNING    | 155.246.89.124:15537 |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | RUNNING    | 155.246.89.124:15569 |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00025 | RUNNING    | 155.246.89.124:15637 |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00026 | RUNNING    | 155.246.89.124:15669 |     1.11036e-05 |                  2 |                            64 |  1.99135 |             |\n",
      "| _objective_69dd6_00027 | PENDING    |                      |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00028 | PENDING    |                      |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | PENDING    |                      |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | PENDING    |                      |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | PENDING    |                      |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | PENDING    |                      |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 112 more trials not shown (97 PENDING, 15 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:19:48 (running for 00:06:54.35)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 132/infinite (105 PENDING, 4 RUNNING, 23 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00023 | RUNNING    | 155.246.89.124:15537 |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00024 | RUNNING    | 155.246.89.124:15569 |     1.32583e-05 |                  3 |                            16 |  5.66418 |             |\n",
      "| _objective_69dd6_00025 | RUNNING    | 155.246.89.124:15637 |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00026 | RUNNING    | 155.246.89.124:15669 |     1.11036e-05 |                  2 |                            64 |  1.99135 |             |\n",
      "| _objective_69dd6_00027 | PENDING    |                      |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00028 | PENDING    |                      |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | PENDING    |                      |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | PENDING    |                      |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | PENDING    |                      |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | PENDING    |                      |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 112 more trials not shown (97 PENDING, 15 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=15569)\u001b[0m {'train_runtime': 53.8318, 'train_samples_per_second': 204.414, 'train_steps_per_second': 6.409, 'train_loss': 0.47227221502774, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=15569)\u001b[0m {'eval_loss': 0.44820377230644226, 'eval_accuracy': 0.8112745098039216, 'eval_f1': 0.8714524207011687, 'eval_runtime': 0.7113, 'eval_samples_per_second': 573.579, 'eval_steps_per_second': 71.697, 'epoch': 3.0}\n",
      "Result for _objective_69dd6_00024:\n",
      "  date: 2022-07-21_18-19-52\n",
      "  done: true\n",
      "  epoch: 3.0\n",
      "  eval_accuracy: 0.8112745098039216\n",
      "  eval_f1: 0.8714524207011687\n",
      "  eval_loss: 0.44820377230644226\n",
      "  eval_runtime: 0.7113\n",
      "  eval_samples_per_second: 573.579\n",
      "  eval_steps_per_second: 71.697\n",
      "  experiment_id: 29d2c54e40a344458dedc5abe22c2a49\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.6827269305050903\n",
      "  pid: 15569\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 61.438082695007324\n",
      "  time_this_iter_s: 61.438082695007324\n",
      "  time_total_s: 61.438082695007324\n",
      "  timestamp: 1658452792\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00024\n",
      "  warmup_time: 0.004236459732055664\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:19:58 (running for 00:07:04.27)\n",
      "Memory usage on this node: 23.2/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 133/infinite (105 PENDING, 4 RUNNING, 24 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00023 | RUNNING    | 155.246.89.124:15537 |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00025 | RUNNING    | 155.246.89.124:15637 |     3.3233e-05  |                  2 |                            16 | 10.2034  |             |\n",
      "| _objective_69dd6_00026 | RUNNING    | 155.246.89.124:15669 |     1.11036e-05 |                  2 |                            64 |  1.99135 |             |\n",
      "| _objective_69dd6_00027 | RUNNING    | 155.246.89.124:15727 |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00028 | PENDING    |                      |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | PENDING    |                      |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | PENDING    |                      |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | PENDING    |                      |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | PENDING    |                      |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | PENDING    |                      |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 113 more trials not shown (97 PENDING, 16 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15727)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15727)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15727)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15727)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15727)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15637)\u001b[0m {'train_runtime': 35.4157, 'train_samples_per_second': 207.14, 'train_steps_per_second': 6.494, 'train_loss': 0.418805163839589, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15727)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=15727)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15669)\u001b[0m {'train_runtime': 34.8831, 'train_samples_per_second': 210.302, 'train_steps_per_second': 6.593, 'train_loss': 0.5509584509808084, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=15637)\u001b[0m {'eval_loss': 0.345292329788208, 'eval_accuracy': 0.8529411764705882, 'eval_f1': 0.8961937716262977, 'eval_runtime': 0.707, 'eval_samples_per_second': 577.067, 'eval_steps_per_second': 72.133, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=15669)\u001b[0m {'eval_loss': 0.5177404880523682, 'eval_accuracy': 0.7598039215686274, 'eval_f1': 0.8382838283828382, 'eval_runtime': 0.6999, 'eval_samples_per_second': 582.979, 'eval_steps_per_second': 72.872, 'epoch': 2.0}\n",
      "Result for _objective_69dd6_00025:\n",
      "  date: 2022-07-21_18-20-03\n",
      "  done: true\n",
      "  epoch: 2.0\n",
      "  eval_accuracy: 0.8529411764705882\n",
      "  eval_f1: 0.8961937716262977\n",
      "  eval_loss: 0.345292329788208\n",
      "  eval_runtime: 0.707\n",
      "  eval_samples_per_second: 577.067\n",
      "  eval_steps_per_second: 72.133\n",
      "  experiment_id: de74edc5df17434da7417cf9ac1a9e88\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.7491349480968859\n",
      "  pid: 15637\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 43.36165714263916\n",
      "  time_this_iter_s: 43.36165714263916\n",
      "  time_total_s: 43.36165714263916\n",
      "  timestamp: 1658452803\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00025\n",
      "  warmup_time: 0.004387855529785156\n",
      "  \n",
      "Result for _objective_69dd6_00026:\n",
      "  date: 2022-07-21_18-20-03\n",
      "  done: true\n",
      "  epoch: 2.0\n",
      "  eval_accuracy: 0.7598039215686274\n",
      "  eval_f1: 0.8382838283828382\n",
      "  eval_loss: 0.5177404880523682\n",
      "  eval_runtime: 0.6999\n",
      "  eval_samples_per_second: 582.979\n",
      "  eval_steps_per_second: 72.872\n",
      "  experiment_id: d02ffa9a84d641a4bfdc2ca7e7e262b4\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.5980877499514656\n",
      "  pid: 15669\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 42.877867460250854\n",
      "  time_this_iter_s: 42.877867460250854\n",
      "  time_total_s: 42.877867460250854\n",
      "  timestamp: 1658452803\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00026\n",
      "  warmup_time: 0.004647731781005859\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:20:03 (running for 00:07:09.77)\n",
      "Memory usage on this node: 22.0/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3.0/96 CPUs, 3.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 133/infinite (105 PENDING, 3 RUNNING, 25 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00023 | RUNNING    | 155.246.89.124:15537 |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00026 | RUNNING    | 155.246.89.124:15669 |     1.11036e-05 |                  2 |                            64 |  1.99135 |     1.59809 |\n",
      "| _objective_69dd6_00027 | RUNNING    | 155.246.89.124:15727 |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00028 | PENDING    |                      |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | PENDING    |                      |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | PENDING    |                      |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | PENDING    |                      |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | PENDING    |                      |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | PENDING    |                      |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | PENDING    |                      |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "| _objective_69dd6_00008 | TERMINATED | 155.246.89.124:14759 |     1.53049e-05 |                  3 |                            64 | 34.5377  |     1.68137 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 113 more trials not shown (96 PENDING, 16 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15776)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15776)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15776)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15776)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=15776)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=15774)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=15774)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15774)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15774)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=15774)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:20:09 (running for 00:07:15.30)\n",
      "Memory usage on this node: 22.1/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 135/infinite (105 PENDING, 4 RUNNING, 26 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00023 | RUNNING    | 155.246.89.124:15537 |     1.55174e-06 |                  5 |                            16 | 29.4546  |             |\n",
      "| _objective_69dd6_00027 | RUNNING    | 155.246.89.124:15727 |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00028 | RUNNING    | 155.246.89.124:15774 |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | RUNNING    | 155.246.89.124:15776 |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | PENDING    |                      |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | PENDING    |                      |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | PENDING    |                      |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | PENDING    |                      |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | PENDING    |                      |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | PENDING    |                      |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 115 more trials not shown (97 PENDING, 18 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=15537)\u001b[0m {'loss': 0.6225, 'learning_rate': 2.0240146501922493e-07, 'epoch': 4.35}\n",
      "\u001b[2m\u001b[36m(_objective pid=15537)\u001b[0m {'eval_loss': 0.5603407621383667, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8207407407407408, 'eval_runtime': 0.7009, 'eval_samples_per_second': 582.125, 'eval_steps_per_second': 72.766, 'epoch': 4.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15776)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=15776)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_objective pid=15774)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=15774)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00023:\n",
      "  date: 2022-07-21_18-20-12\n",
      "  done: false\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.7034313725490197\n",
      "  eval_f1: 0.8207407407407408\n",
      "  eval_loss: 0.5603407621383667\n",
      "  eval_runtime: 0.7009\n",
      "  eval_samples_per_second: 582.125\n",
      "  eval_steps_per_second: 72.766\n",
      "  experiment_id: dadacf57db2f4372b5645c5ccbc18123\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.5241721132897603\n",
      "  pid: 15537\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 82.8525927066803\n",
      "  time_this_iter_s: 82.8525927066803\n",
      "  time_total_s: 82.8525927066803\n",
      "  timestamp: 1658452812\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00023\n",
      "  warmup_time: 0.005011558532714844\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:20:17 (running for 00:07:23.77)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 135/infinite (105 PENDING, 4 RUNNING, 26 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00023 | RUNNING    | 155.246.89.124:15537 |     1.55174e-06 |                  5 |                            16 | 29.4546  |     1.52417 |\n",
      "| _objective_69dd6_00027 | RUNNING    | 155.246.89.124:15727 |     2.53185e-06 |                  1 |                            32 | 13.2599  |             |\n",
      "| _objective_69dd6_00028 | RUNNING    | 155.246.89.124:15774 |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | RUNNING    | 155.246.89.124:15776 |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | PENDING    |                      |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | PENDING    |                      |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | PENDING    |                      |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | PENDING    |                      |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | PENDING    |                      |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | PENDING    |                      |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 115 more trials not shown (97 PENDING, 18 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=15727)\u001b[0m {'train_runtime': 18.3872, 'train_samples_per_second': 199.487, 'train_steps_per_second': 6.254, 'train_loss': 0.6464202217433763, 'epoch': 1.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=15727)\u001b[0m {'eval_loss': 0.6184678077697754, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.7096, 'eval_samples_per_second': 574.949, 'eval_steps_per_second': 71.869, 'epoch': 1.0}\n",
      "Result for _objective_69dd6_00027:\n",
      "  date: 2022-07-21_18-20-21\n",
      "  done: true\n",
      "  epoch: 1.0\n",
      "  eval_accuracy: 0.6838235294117647\n",
      "  eval_f1: 0.8122270742358079\n",
      "  eval_loss: 0.6184678077697754\n",
      "  eval_runtime: 0.7096\n",
      "  eval_samples_per_second: 574.949\n",
      "  eval_steps_per_second: 71.869\n",
      "  experiment_id: 1b5fd2bae14e453cb510dc8fe6edbe04\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.4960506036475727\n",
      "  pid: 15727\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 26.150123834609985\n",
      "  time_this_iter_s: 26.150123834609985\n",
      "  time_total_s: 26.150123834609985\n",
      "  timestamp: 1658452821\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00027\n",
      "  warmup_time: 0.0037832260131835938\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:20:25 (running for 00:07:31.61)\n",
      "Memory usage on this node: 22.6/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 136/infinite (105 PENDING, 4 RUNNING, 27 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00023 | RUNNING    | 155.246.89.124:15537 |     1.55174e-06 |                  5 |                            16 | 29.4546  |     1.52417 |\n",
      "| _objective_69dd6_00028 | RUNNING    | 155.246.89.124:15774 |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | RUNNING    | 155.246.89.124:15776 |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | RUNNING    | 155.246.89.124:15860 |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | PENDING    |                      |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | PENDING    |                      |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | PENDING    |                      |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | PENDING    |                      |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | PENDING    |                      |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00038 | PENDING    |                      |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 116 more trials not shown (97 PENDING, 19 TERMINATED)\n",
      "\n",
      "\n",
      "Result for _objective_69dd6_00023:\n",
      "  date: 2022-07-21_18-20-12\n",
      "  done: true\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.7034313725490197\n",
      "  eval_f1: 0.8207407407407408\n",
      "  eval_loss: 0.5603407621383667\n",
      "  eval_runtime: 0.7009\n",
      "  eval_samples_per_second: 582.125\n",
      "  eval_steps_per_second: 72.766\n",
      "  experiment_id: dadacf57db2f4372b5645c5ccbc18123\n",
      "  experiment_tag: 23_learning_rate=0.0000,num_train_epochs=5,per_device_train_batch_size=16,seed=29.4546\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.5241721132897603\n",
      "  pid: 15537\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 82.8525927066803\n",
      "  time_this_iter_s: 82.8525927066803\n",
      "  time_total_s: 82.8525927066803\n",
      "  timestamp: 1658452812\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00023\n",
      "  warmup_time: 0.005011558532714844\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=15537)\u001b[0m {'train_runtime': 90.6485, 'train_samples_per_second': 202.32, 'train_steps_per_second': 6.343, 'train_loss': 0.6151333817191746, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15860)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=15860)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15860)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15860)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=15860)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=15860)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=15860)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:20:31 (running for 00:07:37.29)\n",
      "Memory usage on this node: 23.1/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 137/infinite (105 PENDING, 4 RUNNING, 28 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00028 | RUNNING    | 155.246.89.124:15774 |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | RUNNING    | 155.246.89.124:15776 |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | RUNNING    | 155.246.89.124:15860 |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | RUNNING    | 155.246.89.124:15896 |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | PENDING    |                      |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | PENDING    |                      |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | PENDING    |                      |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | PENDING    |                      |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00038 | PENDING    |                      |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 117 more trials not shown (97 PENDING, 20 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15896)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15896)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15896)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=15896)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=15896)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=15896)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=15896)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:20:36 (running for 00:07:42.32)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 137/infinite (105 PENDING, 4 RUNNING, 28 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00028 | RUNNING    | 155.246.89.124:15774 |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | RUNNING    | 155.246.89.124:15776 |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | RUNNING    | 155.246.89.124:15860 |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | RUNNING    | 155.246.89.124:15896 |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | PENDING    |                      |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | PENDING    |                      |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | PENDING    |                      |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | PENDING    |                      |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00038 | PENDING    |                      |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 117 more trials not shown (97 PENDING, 20 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:20:41 (running for 00:07:47.34)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 137/infinite (105 PENDING, 4 RUNNING, 28 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00028 | RUNNING    | 155.246.89.124:15774 |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | RUNNING    | 155.246.89.124:15776 |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | RUNNING    | 155.246.89.124:15860 |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | RUNNING    | 155.246.89.124:15896 |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | PENDING    |                      |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | PENDING    |                      |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | PENDING    |                      |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | PENDING    |                      |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00038 | PENDING    |                      |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 117 more trials not shown (97 PENDING, 20 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:20:46 (running for 00:07:52.36)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 137/infinite (105 PENDING, 4 RUNNING, 28 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00028 | RUNNING    | 155.246.89.124:15774 |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | RUNNING    | 155.246.89.124:15776 |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | RUNNING    | 155.246.89.124:15860 |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | RUNNING    | 155.246.89.124:15896 |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | PENDING    |                      |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | PENDING    |                      |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | PENDING    |                      |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | PENDING    |                      |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00038 | PENDING    |                      |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 117 more trials not shown (97 PENDING, 20 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:20:51 (running for 00:07:57.38)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 137/infinite (105 PENDING, 4 RUNNING, 28 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00028 | RUNNING    | 155.246.89.124:15774 |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | RUNNING    | 155.246.89.124:15776 |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | RUNNING    | 155.246.89.124:15860 |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | RUNNING    | 155.246.89.124:15896 |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | PENDING    |                      |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | PENDING    |                      |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | PENDING    |                      |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | PENDING    |                      |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00038 | PENDING    |                      |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 117 more trials not shown (97 PENDING, 20 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:20:56 (running for 00:08:02.41)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 137/infinite (105 PENDING, 4 RUNNING, 28 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00028 | RUNNING    | 155.246.89.124:15774 |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | RUNNING    | 155.246.89.124:15776 |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | RUNNING    | 155.246.89.124:15860 |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | RUNNING    | 155.246.89.124:15896 |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | PENDING    |                      |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | PENDING    |                      |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | PENDING    |                      |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | PENDING    |                      |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00038 | PENDING    |                      |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 117 more trials not shown (97 PENDING, 20 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:21:01 (running for 00:08:07.42)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 137/infinite (105 PENDING, 4 RUNNING, 28 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00028 | RUNNING    | 155.246.89.124:15774 |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00029 | RUNNING    | 155.246.89.124:15776 |     2.86811e-06 |                  3 |                            32 | 28.0966  |             |\n",
      "| _objective_69dd6_00030 | RUNNING    | 155.246.89.124:15860 |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | RUNNING    | 155.246.89.124:15896 |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | PENDING    |                      |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | PENDING    |                      |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | PENDING    |                      |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | PENDING    |                      |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00038 | PENDING    |                      |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 117 more trials not shown (97 PENDING, 20 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15776)\u001b[0m {'train_runtime': 52.2356, 'train_samples_per_second': 210.661, 'train_steps_per_second': 6.605, 'train_loss': 0.5844035715296648, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=15776)\u001b[0m {'eval_loss': 0.5386871099472046, 'eval_accuracy': 0.7083333333333334, 'eval_f1': 0.8188736681887367, 'eval_runtime': 0.6972, 'eval_samples_per_second': 585.195, 'eval_steps_per_second': 73.149, 'epoch': 3.0}\n",
      "Result for _objective_69dd6_00029:\n",
      "  date: 2022-07-21_18-21-06\n",
      "  done: true\n",
      "  epoch: 3.0\n",
      "  eval_accuracy: 0.7083333333333334\n",
      "  eval_f1: 0.8188736681887367\n",
      "  eval_loss: 0.5386871099472046\n",
      "  eval_runtime: 0.6972\n",
      "  eval_samples_per_second: 585.195\n",
      "  eval_steps_per_second: 73.149\n",
      "  experiment_id: df07c0ed860a4905b64a436acdbc2366\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.5272070015220702\n",
      "  pid: 15776\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 60.1130690574646\n",
      "  time_this_iter_s: 60.1130690574646\n",
      "  time_total_s: 60.1130690574646\n",
      "  timestamp: 1658452866\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00029\n",
      "  warmup_time: 0.00418400764465332\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:21:07 (running for 00:08:13.32)\n",
      "Memory usage on this node: 21.9/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 137/infinite (104 PENDING, 4 RUNNING, 29 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00028 | RUNNING    | 155.246.89.124:15774 |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00030 | RUNNING    | 155.246.89.124:15860 |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | RUNNING    | 155.246.89.124:15896 |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | RUNNING    | 155.246.89.124:16047 |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | PENDING    |                      |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | PENDING    |                      |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | PENDING    |                      |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00038 | PENDING    |                      |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | PENDING    |                      |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 117 more trials not shown (96 PENDING, 21 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16047)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=16047)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16047)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16047)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=16047)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:21:14 (running for 00:08:20.67)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 138/infinite (105 PENDING, 4 RUNNING, 29 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00028 | RUNNING    | 155.246.89.124:15774 |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00030 | RUNNING    | 155.246.89.124:15860 |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | RUNNING    | 155.246.89.124:15896 |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | RUNNING    | 155.246.89.124:16047 |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | PENDING    |                      |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | PENDING    |                      |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | PENDING    |                      |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00038 | PENDING    |                      |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | PENDING    |                      |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 118 more trials not shown (97 PENDING, 21 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16047)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=16047)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:21:19 (running for 00:08:25.70)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 138/infinite (105 PENDING, 4 RUNNING, 29 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00028 | RUNNING    | 155.246.89.124:15774 |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00030 | RUNNING    | 155.246.89.124:15860 |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | RUNNING    | 155.246.89.124:15896 |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | RUNNING    | 155.246.89.124:16047 |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | PENDING    |                      |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | PENDING    |                      |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | PENDING    |                      |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00038 | PENDING    |                      |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | PENDING    |                      |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 118 more trials not shown (97 PENDING, 21 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:21:24 (running for 00:08:30.72)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 138/infinite (105 PENDING, 4 RUNNING, 29 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00028 | RUNNING    | 155.246.89.124:15774 |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00030 | RUNNING    | 155.246.89.124:15860 |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | RUNNING    | 155.246.89.124:15896 |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | RUNNING    | 155.246.89.124:16047 |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | PENDING    |                      |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | PENDING    |                      |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | PENDING    |                      |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00038 | PENDING    |                      |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | PENDING    |                      |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 118 more trials not shown (97 PENDING, 21 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15774)\u001b[0m {'loss': 0.2566, 'learning_rate': 8.521702461166613e-06, 'epoch': 4.35}\n",
      "\u001b[2m\u001b[36m(_objective pid=15774)\u001b[0m {'eval_loss': 0.6253156661987305, 'eval_accuracy': 0.8602941176470589, 'eval_f1': 0.9028960817717206, 'eval_runtime': 0.7097, 'eval_samples_per_second': 574.868, 'eval_steps_per_second': 71.858, 'epoch': 4.35}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:21:29 (running for 00:08:35.74)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 138/infinite (105 PENDING, 4 RUNNING, 29 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00028 | RUNNING    | 155.246.89.124:15774 |     6.53331e-05 |                  5 |                            64 | 22.0538  |             |\n",
      "| _objective_69dd6_00030 | RUNNING    | 155.246.89.124:15860 |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | RUNNING    | 155.246.89.124:15896 |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | RUNNING    | 155.246.89.124:16047 |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | PENDING    |                      |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | PENDING    |                      |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | PENDING    |                      |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00038 | PENDING    |                      |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | PENDING    |                      |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 118 more trials not shown (97 PENDING, 21 TERMINATED)\n",
      "\n",
      "\n",
      "Result for _objective_69dd6_00028:\n",
      "  date: 2022-07-21_18-21-30\n",
      "  done: false\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.8602941176470589\n",
      "  eval_f1: 0.9028960817717206\n",
      "  eval_loss: 0.6253156661987305\n",
      "  eval_runtime: 0.7097\n",
      "  eval_samples_per_second: 574.868\n",
      "  eval_steps_per_second: 71.858\n",
      "  experiment_id: ee83fe0164674c1a99581fcc1d471cfe\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.7631901994187795\n",
      "  pid: 15774\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 84.14270210266113\n",
      "  time_this_iter_s: 84.14270210266113\n",
      "  time_total_s: 84.14270210266113\n",
      "  timestamp: 1658452890\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00028\n",
      "  warmup_time: 0.0036325454711914062\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:21:35 (running for 00:08:41.46)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 138/infinite (105 PENDING, 4 RUNNING, 29 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00028 | RUNNING    | 155.246.89.124:15774 |     6.53331e-05 |                  5 |                            64 | 22.0538  |     1.76319 |\n",
      "| _objective_69dd6_00030 | RUNNING    | 155.246.89.124:15860 |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | RUNNING    | 155.246.89.124:15896 |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | RUNNING    | 155.246.89.124:16047 |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | PENDING    |                      |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | PENDING    |                      |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | PENDING    |                      |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00038 | PENDING    |                      |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | PENDING    |                      |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 118 more trials not shown (97 PENDING, 21 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:21:40 (running for 00:08:46.49)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 138/infinite (105 PENDING, 4 RUNNING, 29 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00028 | RUNNING    | 155.246.89.124:15774 |     6.53331e-05 |                  5 |                            64 | 22.0538  |     1.76319 |\n",
      "| _objective_69dd6_00030 | RUNNING    | 155.246.89.124:15860 |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | RUNNING    | 155.246.89.124:15896 |     5.5325e-05  |                  4 |                            32 |  9.51918 |             |\n",
      "| _objective_69dd6_00032 | RUNNING    | 155.246.89.124:16047 |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | PENDING    |                      |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | PENDING    |                      |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | PENDING    |                      |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | PENDING    |                      |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00038 | PENDING    |                      |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | PENDING    |                      |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 118 more trials not shown (97 PENDING, 21 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=15896)\u001b[0m {'train_runtime': 69.4899, 'train_samples_per_second': 211.138, 'train_steps_per_second': 6.62, 'train_loss': 0.2692562103271484, 'epoch': 4.0}\n",
      "Result for _objective_69dd6_00028:\n",
      "  date: 2022-07-21_18-21-30\n",
      "  done: true\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.8602941176470589\n",
      "  eval_f1: 0.9028960817717206\n",
      "  eval_loss: 0.6253156661987305\n",
      "  eval_runtime: 0.7097\n",
      "  eval_samples_per_second: 574.868\n",
      "  eval_steps_per_second: 71.858\n",
      "  experiment_id: ee83fe0164674c1a99581fcc1d471cfe\n",
      "  experiment_tag: 28_learning_rate=0.0001,num_train_epochs=5,per_device_train_batch_size=64,seed=22.0538\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.7631901994187795\n",
      "  pid: 15774\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 84.14270210266113\n",
      "  time_this_iter_s: 84.14270210266113\n",
      "  time_total_s: 84.14270210266113\n",
      "  timestamp: 1658452890\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00028\n",
      "  warmup_time: 0.0036325454711914062\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=15774)\u001b[0m {'train_runtime': 92.2197, 'train_samples_per_second': 198.873, 'train_steps_per_second': 6.235, 'train_loss': 0.22829508781433105, 'epoch': 5.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=15896)\u001b[0m {'eval_loss': 0.6795796155929565, 'eval_accuracy': 0.8308823529411765, 'eval_f1': 0.8844221105527639, 'eval_runtime': 0.6981, 'eval_samples_per_second': 584.456, 'eval_steps_per_second': 73.057, 'epoch': 4.0}\n",
      "Result for _objective_69dd6_00031:\n",
      "  date: 2022-07-21_18-21-45\n",
      "  done: true\n",
      "  epoch: 4.0\n",
      "  eval_accuracy: 0.8308823529411765\n",
      "  eval_f1: 0.8844221105527639\n",
      "  eval_loss: 0.6795796155929565\n",
      "  eval_runtime: 0.6981\n",
      "  eval_samples_per_second: 584.456\n",
      "  eval_steps_per_second: 73.057\n",
      "  experiment_id: 1b96d8aff21e407faef9f547bbceffd9\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.7153044634939403\n",
      "  pid: 15896\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 76.9795229434967\n",
      "  time_this_iter_s: 76.9795229434967\n",
      "  time_total_s: 76.9795229434967\n",
      "  timestamp: 1658452905\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00031\n",
      "  warmup_time: 0.005257129669189453\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:21:45 (running for 00:08:51.53)\n",
      "Memory usage on this node: 22.0/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 139/infinite (105 PENDING, 4 RUNNING, 30 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00030 | RUNNING    | 155.246.89.124:15860 |     7.23428e-05 |                  5 |                            64 | 12.5297  |             |\n",
      "| _objective_69dd6_00031 | RUNNING    | 155.246.89.124:15896 |     5.5325e-05  |                  4 |                            32 |  9.51918 |     1.7153  |\n",
      "| _objective_69dd6_00032 | RUNNING    | 155.246.89.124:16047 |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | RUNNING    | 155.246.89.124:16103 |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | PENDING    |                      |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | PENDING    |                      |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | PENDING    |                      |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | PENDING    |                      |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00038 | PENDING    |                      |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | PENDING    |                      |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00041 | PENDING    |                      |     4.8994e-06  |                  1 |                             8 | 10.3429  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 119 more trials not shown (97 PENDING, 22 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=15860)\u001b[0m {'loss': 0.2182, 'learning_rate': 9.436017189998359e-06, 'epoch': 4.35}\n",
      "\u001b[2m\u001b[36m(_objective pid=15860)\u001b[0m {'eval_loss': 0.7862746119499207, 'eval_accuracy': 0.8480392156862745, 'eval_f1': 0.8912280701754387, 'eval_runtime': 0.7171, 'eval_samples_per_second': 568.933, 'eval_steps_per_second': 71.117, 'epoch': 4.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16103)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=16103)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16103)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16103)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=16103)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00030:\n",
      "  date: 2022-07-21_18-21-49\n",
      "  done: false\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.8480392156862745\n",
      "  eval_f1: 0.8912280701754387\n",
      "  eval_loss: 0.7862746119499207\n",
      "  eval_runtime: 0.7171\n",
      "  eval_samples_per_second: 568.933\n",
      "  eval_steps_per_second: 71.117\n",
      "  experiment_id: 9eec325dcf854b3499381366f4d96ef0\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.7392672858617133\n",
      "  pid: 15860\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 85.02760720252991\n",
      "  time_this_iter_s: 85.02760720252991\n",
      "  time_total_s: 85.02760720252991\n",
      "  timestamp: 1658452909\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00030\n",
      "  warmup_time: 0.004164457321166992\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16103)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=16103)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_objective pid=16140)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=16140)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16140)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16140)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=16140)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:21:54 (running for 00:09:00.67)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 140/infinite (105 PENDING, 4 RUNNING, 31 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00030 | RUNNING    | 155.246.89.124:15860 |     7.23428e-05 |                  5 |                            64 | 12.5297  |     1.73927 |\n",
      "| _objective_69dd6_00032 | RUNNING    | 155.246.89.124:16047 |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | RUNNING    | 155.246.89.124:16103 |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | RUNNING    | 155.246.89.124:16140 |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | PENDING    |                      |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | PENDING    |                      |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | PENDING    |                      |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00038 | PENDING    |                      |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | PENDING    |                      |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00041 | PENDING    |                      |     4.8994e-06  |                  1 |                             8 | 10.3429  |             |\n",
      "| _objective_69dd6_00042 | PENDING    |                      |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 120 more trials not shown (97 PENDING, 23 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16140)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=16140)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:21:59 (running for 00:09:05.69)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 140/infinite (105 PENDING, 4 RUNNING, 31 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00030 | RUNNING    | 155.246.89.124:15860 |     7.23428e-05 |                  5 |                            64 | 12.5297  |     1.73927 |\n",
      "| _objective_69dd6_00032 | RUNNING    | 155.246.89.124:16047 |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | RUNNING    | 155.246.89.124:16103 |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | RUNNING    | 155.246.89.124:16140 |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | PENDING    |                      |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | PENDING    |                      |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | PENDING    |                      |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00038 | PENDING    |                      |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | PENDING    |                      |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00041 | PENDING    |                      |     4.8994e-06  |                  1 |                             8 | 10.3429  |             |\n",
      "| _objective_69dd6_00042 | PENDING    |                      |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 120 more trials not shown (97 PENDING, 23 TERMINATED)\n",
      "\n",
      "\n",
      "Result for _objective_69dd6_00030:\n",
      "  date: 2022-07-21_18-21-49\n",
      "  done: true\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.8480392156862745\n",
      "  eval_f1: 0.8912280701754387\n",
      "  eval_loss: 0.7862746119499207\n",
      "  eval_runtime: 0.7171\n",
      "  eval_samples_per_second: 568.933\n",
      "  eval_steps_per_second: 71.117\n",
      "  experiment_id: 9eec325dcf854b3499381366f4d96ef0\n",
      "  experiment_tag: 30_learning_rate=0.0001,num_train_epochs=5,per_device_train_batch_size=64,seed=12.5297\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.7392672858617133\n",
      "  pid: 15860\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 85.02760720252991\n",
      "  time_this_iter_s: 85.02760720252991\n",
      "  time_total_s: 85.02760720252991\n",
      "  timestamp: 1658452909\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00030\n",
      "  warmup_time: 0.004164457321166992\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=15860)\u001b[0m {'train_runtime': 93.1537, 'train_samples_per_second': 196.879, 'train_steps_per_second': 6.173, 'train_loss': 0.19166852329088294, 'epoch': 5.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=16047)\u001b[0m {'train_runtime': 52.4628, 'train_samples_per_second': 209.748, 'train_steps_per_second': 6.576, 'train_loss': 0.33052788333616395, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=16047)\u001b[0m {'eval_loss': 0.474042147397995, 'eval_accuracy': 0.8602941176470589, 'eval_f1': 0.9025641025641027, 'eval_runtime': 0.6991, 'eval_samples_per_second': 583.608, 'eval_steps_per_second': 72.951, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16188)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=16188)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16188)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16188)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=16188)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:22:08 (running for 00:09:14.45)\n",
      "Memory usage on this node: 23.3/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 141/infinite (105 PENDING, 4 RUNNING, 32 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00032 | RUNNING    | 155.246.89.124:16047 |     6.09703e-05 |                  3 |                            32 | 13.6495  |             |\n",
      "| _objective_69dd6_00033 | RUNNING    | 155.246.89.124:16103 |     5.15936e-06 |                  1 |                            16 | 11.6132  |             |\n",
      "| _objective_69dd6_00034 | RUNNING    | 155.246.89.124:16140 |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | RUNNING    | 155.246.89.124:16188 |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | PENDING    |                      |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | PENDING    |                      |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00038 | PENDING    |                      |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | PENDING    |                      |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00041 | PENDING    |                      |     4.8994e-06  |                  1 |                             8 | 10.3429  |             |\n",
      "| _objective_69dd6_00042 | PENDING    |                      |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00043 | PENDING    |                      |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 121 more trials not shown (97 PENDING, 24 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=16103)\u001b[0m {'train_runtime': 18.0247, 'train_samples_per_second': 203.499, 'train_steps_per_second': 6.38, 'train_loss': 0.6352380503778873, 'epoch': 1.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=16103)\u001b[0m {'eval_loss': 0.5931549668312073, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.7227, 'eval_samples_per_second': 564.542, 'eval_steps_per_second': 70.568, 'epoch': 1.0}\n",
      "Result for _objective_69dd6_00032:\n",
      "  date: 2022-07-21_18-22-10\n",
      "  done: true\n",
      "  epoch: 3.0\n",
      "  eval_accuracy: 0.8602941176470589\n",
      "  eval_f1: 0.9025641025641027\n",
      "  eval_loss: 0.474042147397995\n",
      "  eval_runtime: 0.6991\n",
      "  eval_samples_per_second: 583.608\n",
      "  eval_steps_per_second: 72.951\n",
      "  experiment_id: cd39694fdfef466ea29c65708b7a8357\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.7628582202111616\n",
      "  pid: 16047\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 60.973103523254395\n",
      "  time_this_iter_s: 60.973103523254395\n",
      "  time_total_s: 60.973103523254395\n",
      "  timestamp: 1658452930\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00032\n",
      "  warmup_time: 0.004177093505859375\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16188)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=16188)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00033:\n",
      "  date: 2022-07-21_18-22-12\n",
      "  done: true\n",
      "  epoch: 1.0\n",
      "  eval_accuracy: 0.6838235294117647\n",
      "  eval_f1: 0.8122270742358079\n",
      "  eval_loss: 0.5931549668312073\n",
      "  eval_runtime: 0.7227\n",
      "  eval_samples_per_second: 564.542\n",
      "  eval_steps_per_second: 70.568\n",
      "  experiment_id: ce44801a522d4832a83df7a75a527951\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.4960506036475727\n",
      "  pid: 16103\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 25.56890869140625\n",
      "  time_this_iter_s: 25.56890869140625\n",
      "  time_total_s: 25.56890869140625\n",
      "  timestamp: 1658452932\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00033\n",
      "  warmup_time: 0.005347251892089844\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16231)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=16231)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16231)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16231)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=16231)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=16264)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=16264)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16264)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16264)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=16264)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:22:17 (running for 00:09:23.38)\n",
      "Memory usage on this node: 22.6/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 143/infinite (105 PENDING, 4 RUNNING, 34 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00034 | RUNNING    | 155.246.89.124:16140 |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | RUNNING    | 155.246.89.124:16188 |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | RUNNING    | 155.246.89.124:16231 |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | RUNNING    | 155.246.89.124:16264 |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00038 | PENDING    |                      |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | PENDING    |                      |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00041 | PENDING    |                      |     4.8994e-06  |                  1 |                             8 | 10.3429  |             |\n",
      "| _objective_69dd6_00042 | PENDING    |                      |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00043 | PENDING    |                      |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | PENDING    |                      |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | PENDING    |                      |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 123 more trials not shown (97 PENDING, 26 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16231)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=16231)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_objective pid=16264)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=16264)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:22:22 (running for 00:09:28.41)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 143/infinite (105 PENDING, 4 RUNNING, 34 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00034 | RUNNING    | 155.246.89.124:16140 |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | RUNNING    | 155.246.89.124:16188 |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | RUNNING    | 155.246.89.124:16231 |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | RUNNING    | 155.246.89.124:16264 |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00038 | PENDING    |                      |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | PENDING    |                      |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00041 | PENDING    |                      |     4.8994e-06  |                  1 |                             8 | 10.3429  |             |\n",
      "| _objective_69dd6_00042 | PENDING    |                      |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00043 | PENDING    |                      |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | PENDING    |                      |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | PENDING    |                      |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 123 more trials not shown (97 PENDING, 26 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:22:27 (running for 00:09:33.42)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 143/infinite (105 PENDING, 4 RUNNING, 34 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00034 | RUNNING    | 155.246.89.124:16140 |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | RUNNING    | 155.246.89.124:16188 |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | RUNNING    | 155.246.89.124:16231 |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | RUNNING    | 155.246.89.124:16264 |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00038 | PENDING    |                      |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | PENDING    |                      |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00041 | PENDING    |                      |     4.8994e-06  |                  1 |                             8 | 10.3429  |             |\n",
      "| _objective_69dd6_00042 | PENDING    |                      |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00043 | PENDING    |                      |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | PENDING    |                      |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | PENDING    |                      |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 123 more trials not shown (97 PENDING, 26 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:22:32 (running for 00:09:38.44)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 143/infinite (105 PENDING, 4 RUNNING, 34 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00034 | RUNNING    | 155.246.89.124:16140 |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | RUNNING    | 155.246.89.124:16188 |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | RUNNING    | 155.246.89.124:16231 |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | RUNNING    | 155.246.89.124:16264 |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00038 | PENDING    |                      |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | PENDING    |                      |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00041 | PENDING    |                      |     4.8994e-06  |                  1 |                             8 | 10.3429  |             |\n",
      "| _objective_69dd6_00042 | PENDING    |                      |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00043 | PENDING    |                      |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | PENDING    |                      |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | PENDING    |                      |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 123 more trials not shown (97 PENDING, 26 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:22:37 (running for 00:09:43.46)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 143/infinite (105 PENDING, 4 RUNNING, 34 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00034 | RUNNING    | 155.246.89.124:16140 |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | RUNNING    | 155.246.89.124:16188 |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | RUNNING    | 155.246.89.124:16231 |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00037 | RUNNING    | 155.246.89.124:16264 |     4.43002e-06 |                  1 |                             4 | 16.7496  |             |\n",
      "| _objective_69dd6_00038 | PENDING    |                      |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | PENDING    |                      |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00041 | PENDING    |                      |     4.8994e-06  |                  1 |                             8 | 10.3429  |             |\n",
      "| _objective_69dd6_00042 | PENDING    |                      |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00043 | PENDING    |                      |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | PENDING    |                      |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | PENDING    |                      |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 123 more trials not shown (97 PENDING, 26 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16264)\u001b[0m {'train_runtime': 18.2392, 'train_samples_per_second': 201.105, 'train_steps_per_second': 6.305, 'train_loss': 0.6323141346807065, 'epoch': 1.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=16264)\u001b[0m {'eval_loss': 0.5927693247795105, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.7077, 'eval_samples_per_second': 576.489, 'eval_steps_per_second': 72.061, 'epoch': 1.0}\n",
      "Result for _objective_69dd6_00037:\n",
      "  date: 2022-07-21_18-22-40\n",
      "  done: true\n",
      "  epoch: 1.0\n",
      "  eval_accuracy: 0.6838235294117647\n",
      "  eval_f1: 0.8122270742358079\n",
      "  eval_loss: 0.5927693247795105\n",
      "  eval_runtime: 0.7077\n",
      "  eval_samples_per_second: 576.489\n",
      "  eval_steps_per_second: 72.061\n",
      "  experiment_id: 81f054bb57d04b88be21bcf88d9cea5b\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.4960506036475727\n",
      "  pid: 16264\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 26.40869164466858\n",
      "  time_this_iter_s: 26.40869164466858\n",
      "  time_total_s: 26.40869164466858\n",
      "  timestamp: 1658452960\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00037\n",
      "  warmup_time: 0.003957271575927734\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16320)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=16320)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16320)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16320)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=16320)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:22:46 (running for 00:09:52.42)\n",
      "Memory usage on this node: 23.3/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 144/infinite (105 PENDING, 4 RUNNING, 35 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00034 | RUNNING    | 155.246.89.124:16140 |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | RUNNING    | 155.246.89.124:16188 |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | RUNNING    | 155.246.89.124:16231 |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00038 | RUNNING    | 155.246.89.124:16320 |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | PENDING    |                      |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00041 | PENDING    |                      |     4.8994e-06  |                  1 |                             8 | 10.3429  |             |\n",
      "| _objective_69dd6_00042 | PENDING    |                      |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00043 | PENDING    |                      |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | PENDING    |                      |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | PENDING    |                      |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | PENDING    |                      |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 124 more trials not shown (97 PENDING, 27 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16320)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=16320)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:22:51 (running for 00:09:57.44)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 144/infinite (105 PENDING, 4 RUNNING, 35 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00034 | RUNNING    | 155.246.89.124:16140 |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | RUNNING    | 155.246.89.124:16188 |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | RUNNING    | 155.246.89.124:16231 |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00038 | RUNNING    | 155.246.89.124:16320 |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | PENDING    |                      |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00041 | PENDING    |                      |     4.8994e-06  |                  1 |                             8 | 10.3429  |             |\n",
      "| _objective_69dd6_00042 | PENDING    |                      |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00043 | PENDING    |                      |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | PENDING    |                      |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | PENDING    |                      |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | PENDING    |                      |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 124 more trials not shown (97 PENDING, 27 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=16231)\u001b[0m {'train_runtime': 35.2673, 'train_samples_per_second': 208.011, 'train_steps_per_second': 6.522, 'train_loss': 0.452470762833305, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=16231)\u001b[0m {'eval_loss': 0.37553152441978455, 'eval_accuracy': 0.8333333333333334, 'eval_f1': 0.8847457627118644, 'eval_runtime': 0.698, 'eval_samples_per_second': 584.497, 'eval_steps_per_second': 73.062, 'epoch': 2.0}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:22:56 (running for 00:10:02.47)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 144/infinite (105 PENDING, 4 RUNNING, 35 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00034 | RUNNING    | 155.246.89.124:16140 |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | RUNNING    | 155.246.89.124:16188 |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00036 | RUNNING    | 155.246.89.124:16231 |     2.4259e-05  |                  2 |                            16 | 14.167   |             |\n",
      "| _objective_69dd6_00038 | RUNNING    | 155.246.89.124:16320 |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | PENDING    |                      |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | PENDING    |                      |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00041 | PENDING    |                      |     4.8994e-06  |                  1 |                             8 | 10.3429  |             |\n",
      "| _objective_69dd6_00042 | PENDING    |                      |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00043 | PENDING    |                      |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | PENDING    |                      |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | PENDING    |                      |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | PENDING    |                      |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 124 more trials not shown (97 PENDING, 27 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00036:\n",
      "  date: 2022-07-21_18-22-57\n",
      "  done: true\n",
      "  epoch: 2.0\n",
      "  eval_accuracy: 0.8333333333333334\n",
      "  eval_f1: 0.8847457627118644\n",
      "  eval_loss: 0.37553152441978455\n",
      "  eval_runtime: 0.698\n",
      "  eval_samples_per_second: 584.497\n",
      "  eval_steps_per_second: 73.062\n",
      "  experiment_id: 30701e6be95a4cfd9e40ad6971c33f8d\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.718079096045198\n",
      "  pid: 16231\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 43.42806363105774\n",
      "  time_this_iter_s: 43.42806363105774\n",
      "  time_total_s: 43.42806363105774\n",
      "  timestamp: 1658452977\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00036\n",
      "  warmup_time: 0.0038361549377441406\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:23:02 (running for 00:10:08.42)\n",
      "Memory usage on this node: 23.2/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 145/infinite (105 PENDING, 4 RUNNING, 36 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00034 | RUNNING    | 155.246.89.124:16140 |     7.14851e-06 |                  4 |                            16 | 14.7502  |             |\n",
      "| _objective_69dd6_00035 | RUNNING    | 155.246.89.124:16188 |     1.03253e-06 |                  3 |                            64 | 17.279   |             |\n",
      "| _objective_69dd6_00038 | RUNNING    | 155.246.89.124:16320 |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | RUNNING    | 155.246.89.124:16365 |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | PENDING    |                      |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00041 | PENDING    |                      |     4.8994e-06  |                  1 |                             8 | 10.3429  |             |\n",
      "| _objective_69dd6_00042 | PENDING    |                      |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00043 | PENDING    |                      |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | PENDING    |                      |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | PENDING    |                      |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | PENDING    |                      |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | PENDING    |                      |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 125 more trials not shown (97 PENDING, 28 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16365)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=16365)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16365)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16365)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=16365)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16140)\u001b[0m {'train_runtime': 69.3953, 'train_samples_per_second': 211.426, 'train_steps_per_second': 6.629, 'train_loss': 0.47288556306258495, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=16188)\u001b[0m {'train_runtime': 53.6975, 'train_samples_per_second': 204.926, 'train_steps_per_second': 6.425, 'train_loss': 0.6183022761690444, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=16140)\u001b[0m {'eval_loss': 0.4496769607067108, 'eval_accuracy': 0.8112745098039216, 'eval_f1': 0.8739770867430443, 'eval_runtime': 0.6961, 'eval_samples_per_second': 586.115, 'eval_steps_per_second': 73.264, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=16188)\u001b[0m {'eval_loss': 0.6032273769378662, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.7162, 'eval_samples_per_second': 569.656, 'eval_steps_per_second': 71.207, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16365)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=16365)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00034:\n",
      "  date: 2022-07-21_18-23-06\n",
      "  done: true\n",
      "  epoch: 4.0\n",
      "  eval_accuracy: 0.8112745098039216\n",
      "  eval_f1: 0.8739770867430443\n",
      "  eval_loss: 0.4496769607067108\n",
      "  eval_runtime: 0.6961\n",
      "  eval_samples_per_second: 586.115\n",
      "  eval_steps_per_second: 73.264\n",
      "  experiment_id: 0b10f3246b5f4e99addd37fcbfc596d6\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.6852515965469659\n",
      "  pid: 16140\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 77.09054899215698\n",
      "  time_this_iter_s: 77.09054899215698\n",
      "  time_total_s: 77.09054899215698\n",
      "  timestamp: 1658452986\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00034\n",
      "  warmup_time: 0.004339933395385742\n",
      "  \n",
      "Result for _objective_69dd6_00035:\n",
      "  date: 2022-07-21_18-23-07\n",
      "  done: true\n",
      "  epoch: 3.0\n",
      "  eval_accuracy: 0.6838235294117647\n",
      "  eval_f1: 0.8122270742358079\n",
      "  eval_loss: 0.6032273769378662\n",
      "  eval_runtime: 0.7162\n",
      "  eval_samples_per_second: 569.656\n",
      "  eval_steps_per_second: 71.207\n",
      "  experiment_id: f5146ca83e0d4ce8a875ac6d11d22901\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.4960506036475727\n",
      "  pid: 16188\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 62.09124541282654\n",
      "  time_this_iter_s: 62.09124541282654\n",
      "  time_total_s: 62.09124541282654\n",
      "  timestamp: 1658452987\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00035\n",
      "  warmup_time: 0.004224300384521484\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:23:07 (running for 00:10:13.61)\n",
      "Memory usage on this node: 22.0/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 146/infinite (105 PENDING, 4 RUNNING, 37 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00035 | RUNNING    | 155.246.89.124:16188 |     1.03253e-06 |                  3 |                            64 | 17.279   |     1.49605 |\n",
      "| _objective_69dd6_00038 | RUNNING    | 155.246.89.124:16320 |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | RUNNING    | 155.246.89.124:16365 |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | RUNNING    | 155.246.89.124:16411 |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00041 | PENDING    |                      |     4.8994e-06  |                  1 |                             8 | 10.3429  |             |\n",
      "| _objective_69dd6_00042 | PENDING    |                      |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00043 | PENDING    |                      |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | PENDING    |                      |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | PENDING    |                      |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | PENDING    |                      |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | PENDING    |                      |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | PENDING    |                      |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 126 more trials not shown (97 PENDING, 29 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16411)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=16411)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16411)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16411)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=16411)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=16411)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=16411)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:23:15 (running for 00:10:21.44)\n",
      "Memory usage on this node: 23.2/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 147/infinite (105 PENDING, 4 RUNNING, 38 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00038 | RUNNING    | 155.246.89.124:16320 |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | RUNNING    | 155.246.89.124:16365 |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | RUNNING    | 155.246.89.124:16411 |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00041 | RUNNING    | 155.246.89.124:16446 |     4.8994e-06  |                  1 |                             8 | 10.3429  |             |\n",
      "| _objective_69dd6_00042 | PENDING    |                      |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00043 | PENDING    |                      |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | PENDING    |                      |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | PENDING    |                      |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | PENDING    |                      |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | PENDING    |                      |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | PENDING    |                      |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | PENDING    |                      |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 127 more trials not shown (97 PENDING, 30 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16446)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=16446)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16446)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16446)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=16446)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=16446)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=16446)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:23:20 (running for 00:10:26.47)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 147/infinite (105 PENDING, 4 RUNNING, 38 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00038 | RUNNING    | 155.246.89.124:16320 |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | RUNNING    | 155.246.89.124:16365 |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | RUNNING    | 155.246.89.124:16411 |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00041 | RUNNING    | 155.246.89.124:16446 |     4.8994e-06  |                  1 |                             8 | 10.3429  |             |\n",
      "| _objective_69dd6_00042 | PENDING    |                      |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00043 | PENDING    |                      |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | PENDING    |                      |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | PENDING    |                      |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | PENDING    |                      |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | PENDING    |                      |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | PENDING    |                      |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | PENDING    |                      |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 127 more trials not shown (97 PENDING, 30 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:23:25 (running for 00:10:31.49)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 147/infinite (105 PENDING, 4 RUNNING, 38 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00038 | RUNNING    | 155.246.89.124:16320 |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | RUNNING    | 155.246.89.124:16365 |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | RUNNING    | 155.246.89.124:16411 |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00041 | RUNNING    | 155.246.89.124:16446 |     4.8994e-06  |                  1 |                             8 | 10.3429  |             |\n",
      "| _objective_69dd6_00042 | PENDING    |                      |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00043 | PENDING    |                      |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | PENDING    |                      |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | PENDING    |                      |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | PENDING    |                      |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | PENDING    |                      |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | PENDING    |                      |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | PENDING    |                      |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 127 more trials not shown (97 PENDING, 30 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:23:30 (running for 00:10:36.51)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 147/infinite (105 PENDING, 4 RUNNING, 38 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00038 | RUNNING    | 155.246.89.124:16320 |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | RUNNING    | 155.246.89.124:16365 |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | RUNNING    | 155.246.89.124:16411 |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00041 | RUNNING    | 155.246.89.124:16446 |     4.8994e-06  |                  1 |                             8 | 10.3429  |             |\n",
      "| _objective_69dd6_00042 | PENDING    |                      |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00043 | PENDING    |                      |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | PENDING    |                      |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | PENDING    |                      |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | PENDING    |                      |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | PENDING    |                      |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | PENDING    |                      |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | PENDING    |                      |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 127 more trials not shown (97 PENDING, 30 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:23:35 (running for 00:10:41.53)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 147/infinite (105 PENDING, 4 RUNNING, 38 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00038 | RUNNING    | 155.246.89.124:16320 |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | RUNNING    | 155.246.89.124:16365 |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | RUNNING    | 155.246.89.124:16411 |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00041 | RUNNING    | 155.246.89.124:16446 |     4.8994e-06  |                  1 |                             8 | 10.3429  |             |\n",
      "| _objective_69dd6_00042 | PENDING    |                      |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00043 | PENDING    |                      |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | PENDING    |                      |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | PENDING    |                      |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | PENDING    |                      |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | PENDING    |                      |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | PENDING    |                      |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | PENDING    |                      |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 127 more trials not shown (97 PENDING, 30 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16446)\u001b[0m {'train_runtime': 18.3273, 'train_samples_per_second': 200.138, 'train_steps_per_second': 6.275, 'train_loss': 0.6269056237262228, 'epoch': 1.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=16446)\u001b[0m {'eval_loss': 0.5999632477760315, 'eval_accuracy': 0.6985294117647058, 'eval_f1': 0.8188512518409425, 'eval_runtime': 0.7113, 'eval_samples_per_second': 573.573, 'eval_steps_per_second': 71.697, 'epoch': 1.0}\n",
      "Result for _objective_69dd6_00041:\n",
      "  date: 2022-07-21_18-23-39\n",
      "  done: true\n",
      "  epoch: 1.0\n",
      "  eval_accuracy: 0.6985294117647058\n",
      "  eval_f1: 0.8188512518409425\n",
      "  eval_loss: 0.5999632477760315\n",
      "  eval_runtime: 0.7113\n",
      "  eval_samples_per_second: 573.573\n",
      "  eval_steps_per_second: 71.697\n",
      "  experiment_id: 95372082a40c4e05979dfd13d0a4a0f9\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.5173806636056484\n",
      "  pid: 16446\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 26.5853214263916\n",
      "  time_this_iter_s: 26.5853214263916\n",
      "  time_total_s: 26.5853214263916\n",
      "  timestamp: 1658453019\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00041\n",
      "  warmup_time: 0.0038309097290039062\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:23:44 (running for 00:10:50.48)\n",
      "Memory usage on this node: 23.2/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 148/infinite (105 PENDING, 4 RUNNING, 39 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00038 | RUNNING    | 155.246.89.124:16320 |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | RUNNING    | 155.246.89.124:16365 |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | RUNNING    | 155.246.89.124:16411 |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00042 | RUNNING    | 155.246.89.124:16501 |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00043 | PENDING    |                      |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | PENDING    |                      |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | PENDING    |                      |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | PENDING    |                      |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | PENDING    |                      |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | PENDING    |                      |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | PENDING    |                      |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00050 | PENDING    |                      |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 128 more trials not shown (97 PENDING, 31 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16501)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=16501)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16501)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16501)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=16501)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=16501)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=16501)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:23:49 (running for 00:10:55.49)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 148/infinite (105 PENDING, 4 RUNNING, 39 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00038 | RUNNING    | 155.246.89.124:16320 |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | RUNNING    | 155.246.89.124:16365 |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00040 | RUNNING    | 155.246.89.124:16411 |     3.41635e-06 |                  2 |                            64 | 20.6045  |             |\n",
      "| _objective_69dd6_00042 | RUNNING    | 155.246.89.124:16501 |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00043 | PENDING    |                      |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | PENDING    |                      |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | PENDING    |                      |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | PENDING    |                      |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | PENDING    |                      |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | PENDING    |                      |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | PENDING    |                      |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00050 | PENDING    |                      |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 128 more trials not shown (97 PENDING, 31 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=16411)\u001b[0m {'train_runtime': 35.4602, 'train_samples_per_second': 206.88, 'train_steps_per_second': 6.486, 'train_loss': 0.6327998285708221, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=16411)\u001b[0m {'eval_loss': 0.5529996156692505, 'eval_accuracy': 0.7205882352941176, 'eval_f1': 0.8277945619335348, 'eval_runtime': 0.7042, 'eval_samples_per_second': 579.395, 'eval_steps_per_second': 72.424, 'epoch': 2.0}\n",
      "Result for _objective_69dd6_00040:\n",
      "  date: 2022-07-21_18-23-53\n",
      "  done: true\n",
      "  epoch: 2.0\n",
      "  eval_accuracy: 0.7205882352941176\n",
      "  eval_f1: 0.8277945619335348\n",
      "  eval_loss: 0.5529996156692505\n",
      "  eval_runtime: 0.7042\n",
      "  eval_samples_per_second: 579.395\n",
      "  eval_steps_per_second: 72.424\n",
      "  experiment_id: 8b0e9eacf3d84a70b65753e1433b010e\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.5483827972276525\n",
      "  pid: 16411\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 42.98010444641113\n",
      "  time_this_iter_s: 42.98010444641113\n",
      "  time_total_s: 42.98010444641113\n",
      "  timestamp: 1658453033\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00040\n",
      "  warmup_time: 0.004413604736328125\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16546)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=16546)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16546)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16546)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=16546)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:23:58 (running for 00:11:04.50)\n",
      "Memory usage on this node: 23.2/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 149/infinite (105 PENDING, 4 RUNNING, 40 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00038 | RUNNING    | 155.246.89.124:16320 |     3.21981e-06 |                  4 |                             8 | 10.8195  |             |\n",
      "| _objective_69dd6_00039 | RUNNING    | 155.246.89.124:16365 |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00042 | RUNNING    | 155.246.89.124:16501 |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00043 | RUNNING    | 155.246.89.124:16546 |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | PENDING    |                      |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | PENDING    |                      |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | PENDING    |                      |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | PENDING    |                      |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | PENDING    |                      |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | PENDING    |                      |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00050 | PENDING    |                      |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | PENDING    |                      |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 129 more trials not shown (97 PENDING, 32 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=16320)\u001b[0m {'train_runtime': 70.7386, 'train_samples_per_second': 207.411, 'train_steps_per_second': 6.503, 'train_loss': 0.5474149621051291, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=16320)\u001b[0m {'eval_loss': 0.5107375383377075, 'eval_accuracy': 0.7622549019607843, 'eval_f1': 0.8443017656500802, 'eval_runtime': 0.7102, 'eval_samples_per_second': 574.461, 'eval_steps_per_second': 71.808, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16546)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=16546)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00038:\n",
      "  date: 2022-07-21_18-24-02\n",
      "  done: true\n",
      "  epoch: 4.0\n",
      "  eval_accuracy: 0.7622549019607843\n",
      "  eval_f1: 0.8443017656500802\n",
      "  eval_loss: 0.5107375383377075\n",
      "  eval_runtime: 0.7102\n",
      "  eval_samples_per_second: 574.461\n",
      "  eval_steps_per_second: 71.808\n",
      "  experiment_id: 2c5ce6bbc05f461bb12580e723bf6054\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.6065566676108645\n",
      "  pid: 16320\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 78.99758458137512\n",
      "  time_this_iter_s: 78.99758458137512\n",
      "  time_total_s: 78.99758458137512\n",
      "  timestamp: 1658453042\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00038\n",
      "  warmup_time: 0.004060506820678711\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:24:08 (running for 00:11:14.49)\n",
      "Memory usage on this node: 23.2/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 150/infinite (105 PENDING, 4 RUNNING, 41 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00039 | RUNNING    | 155.246.89.124:16365 |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00042 | RUNNING    | 155.246.89.124:16501 |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00043 | RUNNING    | 155.246.89.124:16546 |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | RUNNING    | 155.246.89.124:16590 |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | PENDING    |                      |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | PENDING    |                      |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | PENDING    |                      |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | PENDING    |                      |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | PENDING    |                      |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00050 | PENDING    |                      |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | PENDING    |                      |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00052 | PENDING    |                      |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 130 more trials not shown (97 PENDING, 33 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16590)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=16590)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16590)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16590)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=16590)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=16590)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=16590)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:24:13 (running for 00:11:19.52)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 150/infinite (105 PENDING, 4 RUNNING, 41 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00039 | RUNNING    | 155.246.89.124:16365 |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00042 | RUNNING    | 155.246.89.124:16501 |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00043 | RUNNING    | 155.246.89.124:16546 |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | RUNNING    | 155.246.89.124:16590 |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | PENDING    |                      |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | PENDING    |                      |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | PENDING    |                      |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | PENDING    |                      |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | PENDING    |                      |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00050 | PENDING    |                      |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | PENDING    |                      |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00052 | PENDING    |                      |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 130 more trials not shown (97 PENDING, 33 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:24:18 (running for 00:11:24.53)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 150/infinite (105 PENDING, 4 RUNNING, 41 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00039 | RUNNING    | 155.246.89.124:16365 |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00042 | RUNNING    | 155.246.89.124:16501 |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00043 | RUNNING    | 155.246.89.124:16546 |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | RUNNING    | 155.246.89.124:16590 |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | PENDING    |                      |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | PENDING    |                      |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | PENDING    |                      |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | PENDING    |                      |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | PENDING    |                      |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00050 | PENDING    |                      |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | PENDING    |                      |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00052 | PENDING    |                      |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 130 more trials not shown (97 PENDING, 33 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16365)\u001b[0m {'loss': 0.2627, 'learning_rate': 3.4668463844895085e-06, 'epoch': 4.35}\n",
      "\u001b[2m\u001b[36m(_objective pid=16365)\u001b[0m {'eval_loss': 0.5161808133125305, 'eval_accuracy': 0.8529411764705882, 'eval_f1': 0.894736842105263, 'eval_runtime': 0.7001, 'eval_samples_per_second': 582.738, 'eval_steps_per_second': 72.842, 'epoch': 4.35}\n",
      "\u001b[2m\u001b[36m(_objective pid=16501)\u001b[0m {'train_runtime': 35.9635, 'train_samples_per_second': 203.985, 'train_steps_per_second': 6.395, 'train_loss': 0.5277658545452616, 'epoch': 2.0}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:24:23 (running for 00:11:29.56)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 150/infinite (105 PENDING, 4 RUNNING, 41 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00039 | RUNNING    | 155.246.89.124:16365 |     2.65792e-05 |                  5 |                             4 | 12.1088  |             |\n",
      "| _objective_69dd6_00042 | RUNNING    | 155.246.89.124:16501 |     1.15311e-05 |                  2 |                            32 | 39.4404  |             |\n",
      "| _objective_69dd6_00043 | RUNNING    | 155.246.89.124:16546 |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | RUNNING    | 155.246.89.124:16590 |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | PENDING    |                      |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | PENDING    |                      |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | PENDING    |                      |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | PENDING    |                      |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | PENDING    |                      |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00050 | PENDING    |                      |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | PENDING    |                      |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00052 | PENDING    |                      |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 130 more trials not shown (97 PENDING, 33 TERMINATED)\n",
      "\n",
      "\n",
      "Result for _objective_69dd6_00039:\n",
      "  date: 2022-07-21_18-24-23\n",
      "  done: false\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.8529411764705882\n",
      "  eval_f1: 0.894736842105263\n",
      "  eval_loss: 0.5161808133125305\n",
      "  eval_runtime: 0.7001\n",
      "  eval_samples_per_second: 582.738\n",
      "  eval_steps_per_second: 72.842\n",
      "  experiment_id: 67f1237821cd43fdaad6eb55c17b9e97\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.7476780185758511\n",
      "  pid: 16365\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 83.9464807510376\n",
      "  time_this_iter_s: 83.9464807510376\n",
      "  time_total_s: 83.9464807510376\n",
      "  timestamp: 1658453063\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00039\n",
      "  warmup_time: 0.0037915706634521484\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=16501)\u001b[0m {'eval_loss': 0.4785659611225128, 'eval_accuracy': 0.7916666666666666, 'eval_f1': 0.8599670510708401, 'eval_runtime': 0.7128, 'eval_samples_per_second': 572.417, 'eval_steps_per_second': 71.552, 'epoch': 2.0}\n",
      "Result for _objective_69dd6_00042:\n",
      "  date: 2022-07-21_18-24-25\n",
      "  done: true\n",
      "  epoch: 2.0\n",
      "  eval_accuracy: 0.7916666666666666\n",
      "  eval_f1: 0.8599670510708401\n",
      "  eval_loss: 0.4785659611225128\n",
      "  eval_runtime: 0.7128\n",
      "  eval_samples_per_second: 572.417\n",
      "  eval_steps_per_second: 71.552\n",
      "  experiment_id: 026d14816e524d719136fdb65fd5ac33\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.6516337177375067\n",
      "  pid: 16501\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 44.030537128448486\n",
      "  time_this_iter_s: 44.030537128448486\n",
      "  time_total_s: 44.030537128448486\n",
      "  timestamp: 1658453065\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00042\n",
      "  warmup_time: 0.004641056060791016\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:24:31 (running for 00:11:37.51)\n",
      "Memory usage on this node: 23.2/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 151/infinite (105 PENDING, 4 RUNNING, 42 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00039 | RUNNING    | 155.246.89.124:16365 |     2.65792e-05 |                  5 |                             4 | 12.1088  |     1.74768 |\n",
      "| _objective_69dd6_00043 | RUNNING    | 155.246.89.124:16546 |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | RUNNING    | 155.246.89.124:16590 |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | RUNNING    | 155.246.89.124:16640 |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | PENDING    |                      |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | PENDING    |                      |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | PENDING    |                      |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | PENDING    |                      |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00050 | PENDING    |                      |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | PENDING    |                      |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00052 | PENDING    |                      |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | PENDING    |                      |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 131 more trials not shown (97 PENDING, 34 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16640)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=16640)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16640)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16640)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=16640)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=16640)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=16640)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:24:36 (running for 00:11:42.54)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 151/infinite (105 PENDING, 4 RUNNING, 42 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00039 | RUNNING    | 155.246.89.124:16365 |     2.65792e-05 |                  5 |                             4 | 12.1088  |     1.74768 |\n",
      "| _objective_69dd6_00043 | RUNNING    | 155.246.89.124:16546 |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | RUNNING    | 155.246.89.124:16590 |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | RUNNING    | 155.246.89.124:16640 |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | PENDING    |                      |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | PENDING    |                      |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | PENDING    |                      |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | PENDING    |                      |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00050 | PENDING    |                      |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | PENDING    |                      |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00052 | PENDING    |                      |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | PENDING    |                      |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 131 more trials not shown (97 PENDING, 34 TERMINATED)\n",
      "\n",
      "\n",
      "Result for _objective_69dd6_00039:\n",
      "  date: 2022-07-21_18-24-23\n",
      "  done: true\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.8529411764705882\n",
      "  eval_f1: 0.894736842105263\n",
      "  eval_loss: 0.5161808133125305\n",
      "  eval_runtime: 0.7001\n",
      "  eval_samples_per_second: 582.738\n",
      "  eval_steps_per_second: 72.842\n",
      "  experiment_id: 67f1237821cd43fdaad6eb55c17b9e97\n",
      "  experiment_tag: 39_learning_rate=0.0000,num_train_epochs=5,per_device_train_batch_size=4,seed=12.1088\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.7476780185758511\n",
      "  pid: 16365\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 83.9464807510376\n",
      "  time_this_iter_s: 83.9464807510376\n",
      "  time_total_s: 83.9464807510376\n",
      "  timestamp: 1658453063\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00039\n",
      "  warmup_time: 0.0037915706634521484\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=16365)\u001b[0m {'train_runtime': 91.599, 'train_samples_per_second': 200.221, 'train_steps_per_second': 6.277, 'train_loss': 0.2330240473539933, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16682)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=16682)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16682)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16682)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=16682)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:24:42 (running for 00:11:48.52)\n",
      "Memory usage on this node: 23.3/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 152/infinite (105 PENDING, 4 RUNNING, 43 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00043 | RUNNING    | 155.246.89.124:16546 |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | RUNNING    | 155.246.89.124:16590 |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | RUNNING    | 155.246.89.124:16640 |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | RUNNING    | 155.246.89.124:16682 |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | PENDING    |                      |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | PENDING    |                      |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | PENDING    |                      |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00050 | PENDING    |                      |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | PENDING    |                      |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00052 | PENDING    |                      |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | PENDING    |                      |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | PENDING    |                      |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 132 more trials not shown (97 PENDING, 35 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16682)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=16682)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:24:47 (running for 00:11:53.55)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 152/infinite (105 PENDING, 4 RUNNING, 43 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00043 | RUNNING    | 155.246.89.124:16546 |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | RUNNING    | 155.246.89.124:16590 |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | RUNNING    | 155.246.89.124:16640 |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | RUNNING    | 155.246.89.124:16682 |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | PENDING    |                      |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | PENDING    |                      |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | PENDING    |                      |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00050 | PENDING    |                      |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | PENDING    |                      |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00052 | PENDING    |                      |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | PENDING    |                      |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | PENDING    |                      |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 132 more trials not shown (97 PENDING, 35 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:24:52 (running for 00:11:58.57)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 152/infinite (105 PENDING, 4 RUNNING, 43 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00043 | RUNNING    | 155.246.89.124:16546 |     1.45113e-06 |                  3 |                            64 | 10.4442  |             |\n",
      "| _objective_69dd6_00044 | RUNNING    | 155.246.89.124:16590 |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | RUNNING    | 155.246.89.124:16640 |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | RUNNING    | 155.246.89.124:16682 |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | PENDING    |                      |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | PENDING    |                      |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | PENDING    |                      |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00050 | PENDING    |                      |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | PENDING    |                      |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00052 | PENDING    |                      |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | PENDING    |                      |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | PENDING    |                      |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 132 more trials not shown (97 PENDING, 35 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16546)\u001b[0m {'train_runtime': 52.661, 'train_samples_per_second': 208.959, 'train_steps_per_second': 6.551, 'train_loss': 0.6271459164826766, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=16546)\u001b[0m {'eval_loss': 0.6045545935630798, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8145985401459854, 'eval_runtime': 0.6974, 'eval_samples_per_second': 585.018, 'eval_steps_per_second': 73.127, 'epoch': 3.0}\n",
      "Result for _objective_69dd6_00043:\n",
      "  date: 2022-07-21_18-24-56\n",
      "  done: true\n",
      "  epoch: 3.0\n",
      "  eval_accuracy: 0.6887254901960784\n",
      "  eval_f1: 0.8145985401459854\n",
      "  eval_loss: 0.6045545935630798\n",
      "  eval_runtime: 0.6974\n",
      "  eval_samples_per_second: 585.018\n",
      "  eval_steps_per_second: 73.127\n",
      "  experiment_id: 8a4108f8b32a4802b240841df633fbdf\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.5033240303420639\n",
      "  pid: 16546\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 60.329814195632935\n",
      "  time_this_iter_s: 60.329814195632935\n",
      "  time_total_s: 60.329814195632935\n",
      "  timestamp: 1658453096\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00043\n",
      "  warmup_time: 0.004744052886962891\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:25:01 (running for 00:12:07.55)\n",
      "Memory usage on this node: 23.1/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 153/infinite (105 PENDING, 4 RUNNING, 44 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00044 | RUNNING    | 155.246.89.124:16590 |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | RUNNING    | 155.246.89.124:16640 |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | RUNNING    | 155.246.89.124:16682 |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | RUNNING    | 155.246.89.124:16728 |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | PENDING    |                      |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | PENDING    |                      |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00050 | PENDING    |                      |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | PENDING    |                      |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00052 | PENDING    |                      |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | PENDING    |                      |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | PENDING    |                      |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | PENDING    |                      |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 133 more trials not shown (97 PENDING, 36 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16728)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=16728)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16728)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16728)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=16728)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16590)\u001b[0m {'train_runtime': 53.0796, 'train_samples_per_second': 207.311, 'train_steps_per_second': 6.5, 'train_loss': 0.4330056453096694, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16728)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=16728)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16590)\u001b[0m {'eval_loss': 0.43088459968566895, 'eval_accuracy': 0.8235294117647058, 'eval_f1': 0.8779661016949152, 'eval_runtime': 0.7107, 'eval_samples_per_second': 574.07, 'eval_steps_per_second': 71.759, 'epoch': 3.0}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:25:06 (running for 00:12:12.57)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 153/infinite (105 PENDING, 4 RUNNING, 44 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00044 | RUNNING    | 155.246.89.124:16590 |     1.83913e-05 |                  3 |                             4 | 32.8408  |             |\n",
      "| _objective_69dd6_00045 | RUNNING    | 155.246.89.124:16640 |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | RUNNING    | 155.246.89.124:16682 |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | RUNNING    | 155.246.89.124:16728 |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | PENDING    |                      |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | PENDING    |                      |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00050 | PENDING    |                      |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | PENDING    |                      |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00052 | PENDING    |                      |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | PENDING    |                      |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | PENDING    |                      |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | PENDING    |                      |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 133 more trials not shown (97 PENDING, 36 TERMINATED)\n",
      "\n",
      "\n",
      "Result for _objective_69dd6_00044:\n",
      "  date: 2022-07-21_18-25-07\n",
      "  done: true\n",
      "  epoch: 3.0\n",
      "  eval_accuracy: 0.8235294117647058\n",
      "  eval_f1: 0.8779661016949152\n",
      "  eval_loss: 0.43088459968566895\n",
      "  eval_runtime: 0.7107\n",
      "  eval_samples_per_second: 574.07\n",
      "  eval_steps_per_second: 71.759\n",
      "  experiment_id: b8b88cd6e10741efbdd365021c4ce033\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.701495513459621\n",
      "  pid: 16590\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 61.542484283447266\n",
      "  time_this_iter_s: 61.542484283447266\n",
      "  time_total_s: 61.542484283447266\n",
      "  timestamp: 1658453107\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00044\n",
      "  warmup_time: 0.004185676574707031\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:25:12 (running for 00:12:18.56)\n",
      "Memory usage on this node: 23.2/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 154/infinite (105 PENDING, 4 RUNNING, 45 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00045 | RUNNING    | 155.246.89.124:16640 |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | RUNNING    | 155.246.89.124:16682 |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | RUNNING    | 155.246.89.124:16728 |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | RUNNING    | 155.246.89.124:16781 |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | PENDING    |                      |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00050 | PENDING    |                      |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | PENDING    |                      |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00052 | PENDING    |                      |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | PENDING    |                      |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | PENDING    |                      |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | PENDING    |                      |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | PENDING    |                      |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 134 more trials not shown (97 PENDING, 37 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16781)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=16781)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16781)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16781)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=16781)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=16781)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=16781)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:25:17 (running for 00:12:23.58)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 154/infinite (105 PENDING, 4 RUNNING, 45 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00045 | RUNNING    | 155.246.89.124:16640 |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | RUNNING    | 155.246.89.124:16682 |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | RUNNING    | 155.246.89.124:16728 |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | RUNNING    | 155.246.89.124:16781 |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | PENDING    |                      |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00050 | PENDING    |                      |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | PENDING    |                      |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00052 | PENDING    |                      |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | PENDING    |                      |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | PENDING    |                      |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | PENDING    |                      |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | PENDING    |                      |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 134 more trials not shown (97 PENDING, 37 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:25:22 (running for 00:12:28.61)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 154/infinite (105 PENDING, 4 RUNNING, 45 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00045 | RUNNING    | 155.246.89.124:16640 |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | RUNNING    | 155.246.89.124:16682 |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | RUNNING    | 155.246.89.124:16728 |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | RUNNING    | 155.246.89.124:16781 |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | PENDING    |                      |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00050 | PENDING    |                      |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | PENDING    |                      |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00052 | PENDING    |                      |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | PENDING    |                      |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | PENDING    |                      |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | PENDING    |                      |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | PENDING    |                      |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 134 more trials not shown (97 PENDING, 37 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16640)\u001b[0m {'train_runtime': 53.281, 'train_samples_per_second': 206.528, 'train_steps_per_second': 6.475, 'train_loss': 0.6307004182235054, 'epoch': 3.0}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:25:27 (running for 00:12:33.62)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 154/infinite (105 PENDING, 4 RUNNING, 45 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00045 | RUNNING    | 155.246.89.124:16640 |     2.00187e-06 |                  3 |                            64 |  8.27422 |             |\n",
      "| _objective_69dd6_00046 | RUNNING    | 155.246.89.124:16682 |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | RUNNING    | 155.246.89.124:16728 |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | RUNNING    | 155.246.89.124:16781 |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | PENDING    |                      |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00050 | PENDING    |                      |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | PENDING    |                      |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00052 | PENDING    |                      |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | PENDING    |                      |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | PENDING    |                      |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | PENDING    |                      |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | PENDING    |                      |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 134 more trials not shown (97 PENDING, 37 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=16640)\u001b[0m {'eval_loss': 0.5590981841087341, 'eval_accuracy': 0.7009803921568627, 'eval_f1': 0.8200589970501474, 'eval_runtime': 0.7092, 'eval_samples_per_second': 575.324, 'eval_steps_per_second': 71.916, 'epoch': 3.0}\n",
      "Result for _objective_69dd6_00045:\n",
      "  date: 2022-07-21_18-25-29\n",
      "  done: true\n",
      "  epoch: 3.0\n",
      "  eval_accuracy: 0.7009803921568627\n",
      "  eval_f1: 0.8200589970501474\n",
      "  eval_loss: 0.5590981841087341\n",
      "  eval_runtime: 0.7092\n",
      "  eval_samples_per_second: 575.324\n",
      "  eval_steps_per_second: 71.916\n",
      "  experiment_id: c6338e5bcf3747c1b08e38b8b081c31c\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.5210393892070102\n",
      "  pid: 16640\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 61.213786363601685\n",
      "  time_this_iter_s: 61.213786363601685\n",
      "  time_total_s: 61.213786363601685\n",
      "  timestamp: 1658453129\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00045\n",
      "  warmup_time: 0.003745555877685547\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:25:35 (running for 00:12:41.58)\n",
      "Memory usage on this node: 23.2/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 155/infinite (105 PENDING, 4 RUNNING, 46 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00046 | RUNNING    | 155.246.89.124:16682 |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | RUNNING    | 155.246.89.124:16728 |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | RUNNING    | 155.246.89.124:16781 |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | RUNNING    | 155.246.89.124:16829 |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00050 | PENDING    |                      |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | PENDING    |                      |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00052 | PENDING    |                      |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | PENDING    |                      |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | PENDING    |                      |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | PENDING    |                      |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | PENDING    |                      |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | PENDING    |                      |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 135 more trials not shown (97 PENDING, 38 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16829)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=16829)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16829)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16829)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=16829)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=16829)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=16829)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:25:40 (running for 00:12:46.60)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 155/infinite (105 PENDING, 4 RUNNING, 46 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00046 | RUNNING    | 155.246.89.124:16682 |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | RUNNING    | 155.246.89.124:16728 |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | RUNNING    | 155.246.89.124:16781 |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | RUNNING    | 155.246.89.124:16829 |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00050 | PENDING    |                      |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | PENDING    |                      |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00052 | PENDING    |                      |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | PENDING    |                      |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | PENDING    |                      |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | PENDING    |                      |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | PENDING    |                      |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | PENDING    |                      |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 135 more trials not shown (97 PENDING, 38 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:25:45 (running for 00:12:51.76)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 155/infinite (105 PENDING, 4 RUNNING, 46 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00046 | RUNNING    | 155.246.89.124:16682 |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | RUNNING    | 155.246.89.124:16728 |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | RUNNING    | 155.246.89.124:16781 |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | RUNNING    | 155.246.89.124:16829 |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00050 | PENDING    |                      |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | PENDING    |                      |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00052 | PENDING    |                      |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | PENDING    |                      |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | PENDING    |                      |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | PENDING    |                      |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | PENDING    |                      |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | PENDING    |                      |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 135 more trials not shown (97 PENDING, 38 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:25:50 (running for 00:12:56.77)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 155/infinite (105 PENDING, 4 RUNNING, 46 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00046 | RUNNING    | 155.246.89.124:16682 |     5.20856e-05 |                  4 |                            16 | 27.425   |             |\n",
      "| _objective_69dd6_00047 | RUNNING    | 155.246.89.124:16728 |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00048 | RUNNING    | 155.246.89.124:16781 |     7.60408e-05 |                  2 |                            16 | 33.6707  |             |\n",
      "| _objective_69dd6_00049 | RUNNING    | 155.246.89.124:16829 |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00050 | PENDING    |                      |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | PENDING    |                      |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00052 | PENDING    |                      |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | PENDING    |                      |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | PENDING    |                      |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | PENDING    |                      |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | PENDING    |                      |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | PENDING    |                      |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 135 more trials not shown (97 PENDING, 38 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=16781)\u001b[0m {'train_runtime': 35.5941, 'train_samples_per_second': 206.102, 'train_steps_per_second': 6.462, 'train_loss': 0.36380336595618207, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=16781)\u001b[0m {'eval_loss': 0.32599422335624695, 'eval_accuracy': 0.875, 'eval_f1': 0.9116117850953207, 'eval_runtime': 0.7071, 'eval_samples_per_second': 576.987, 'eval_steps_per_second': 72.123, 'epoch': 2.0}\n",
      "Result for _objective_69dd6_00048:\n",
      "  date: 2022-07-21_18-25-53\n",
      "  done: true\n",
      "  epoch: 2.0\n",
      "  eval_accuracy: 0.875\n",
      "  eval_f1: 0.9116117850953207\n",
      "  eval_loss: 0.32599422335624695\n",
      "  eval_runtime: 0.7071\n",
      "  eval_samples_per_second: 576.987\n",
      "  eval_steps_per_second: 72.123\n",
      "  experiment_id: 373db3a64266463a8e3051e601345222\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.7866117850953207\n",
      "  pid: 16781\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 43.977459192276\n",
      "  time_this_iter_s: 43.977459192276\n",
      "  time_total_s: 43.977459192276\n",
      "  timestamp: 1658453153\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00048\n",
      "  warmup_time: 0.004152774810791016\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=16682)\u001b[0m {'train_runtime': 69.57, 'train_samples_per_second': 210.896, 'train_steps_per_second': 6.612, 'train_loss': 0.255156193608823, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=16682)\u001b[0m {'eval_loss': 0.5710057020187378, 'eval_accuracy': 0.8504901960784313, 'eval_f1': 0.8946459412780656, 'eval_runtime': 0.6972, 'eval_samples_per_second': 585.18, 'eval_steps_per_second': 73.148, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=16829)\u001b[0m {'train_runtime': 18.3781, 'train_samples_per_second': 199.586, 'train_steps_per_second': 6.257, 'train_loss': 0.6696663234544837, 'epoch': 1.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=16728)\u001b[0m {'train_runtime': 52.6002, 'train_samples_per_second': 209.201, 'train_steps_per_second': 6.559, 'train_loss': 0.34888586514237996, 'epoch': 3.0}\n",
      "Result for _objective_69dd6_00046:\n",
      "  date: 2022-07-21_18-25-57\n",
      "  done: true\n",
      "  epoch: 4.0\n",
      "  eval_accuracy: 0.8504901960784313\n",
      "  eval_f1: 0.8946459412780656\n",
      "  eval_loss: 0.5710057020187378\n",
      "  eval_runtime: 0.6972\n",
      "  eval_samples_per_second: 585.18\n",
      "  eval_steps_per_second: 73.148\n",
      "  experiment_id: dacce805f36d42f1b97436bed7b8b707\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.7451361373564969\n",
      "  pid: 16682\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 77.46924877166748\n",
      "  time_this_iter_s: 77.46924877166748\n",
      "  time_total_s: 77.46924877166748\n",
      "  timestamp: 1658453157\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00046\n",
      "  warmup_time: 0.0041658878326416016\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:25:57 (running for 00:13:03.32)\n",
      "Memory usage on this node: 22.3/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 156/infinite (105 PENDING, 4 RUNNING, 47 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00046 | RUNNING    | 155.246.89.124:16682 |     5.20856e-05 |                  4 |                            16 | 27.425   |     1.74514 |\n",
      "| _objective_69dd6_00047 | RUNNING    | 155.246.89.124:16728 |     2.64423e-05 |                  3 |                            32 | 14.598   |             |\n",
      "| _objective_69dd6_00049 | RUNNING    | 155.246.89.124:16829 |     4.80986e-06 |                  1 |                             8 |  9.15379 |             |\n",
      "| _objective_69dd6_00050 | RUNNING    | 155.246.89.124:16969 |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | PENDING    |                      |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00052 | PENDING    |                      |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | PENDING    |                      |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | PENDING    |                      |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | PENDING    |                      |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | PENDING    |                      |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | PENDING    |                      |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | PENDING    |                      |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 136 more trials not shown (97 PENDING, 39 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=16829)\u001b[0m {'eval_loss': 0.6018750667572021, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.7137, 'eval_samples_per_second': 571.657, 'eval_steps_per_second': 71.457, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16728)\u001b[0m {'eval_loss': 0.34871906042099, 'eval_accuracy': 0.8774509803921569, 'eval_f1': 0.9131944444444444, 'eval_runtime': 0.7147, 'eval_samples_per_second': 570.872, 'eval_steps_per_second': 71.359, 'epoch': 3.0}\n",
      "Result for _objective_69dd6_00049:\n",
      "  date: 2022-07-21_18-25-59\n",
      "  done: true\n",
      "  epoch: 1.0\n",
      "  eval_accuracy: 0.6838235294117647\n",
      "  eval_f1: 0.8122270742358079\n",
      "  eval_loss: 0.6018750667572021\n",
      "  eval_runtime: 0.7137\n",
      "  eval_samples_per_second: 571.657\n",
      "  eval_steps_per_second: 71.457\n",
      "  experiment_id: c1ce178ab3eb417c8b92bb528176a5f4\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.4960506036475727\n",
      "  pid: 16829\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 26.407043933868408\n",
      "  time_this_iter_s: 26.407043933868408\n",
      "  time_total_s: 26.407043933868408\n",
      "  timestamp: 1658453159\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00049\n",
      "  warmup_time: 0.003947734832763672\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16969)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=16969)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16969)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=16969)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=16969)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00047:\n",
      "  date: 2022-07-21_18-25-59\n",
      "  done: true\n",
      "  epoch: 3.0\n",
      "  eval_accuracy: 0.8774509803921569\n",
      "  eval_f1: 0.9131944444444444\n",
      "  eval_loss: 0.34871906042099\n",
      "  eval_runtime: 0.7147\n",
      "  eval_samples_per_second: 570.872\n",
      "  eval_steps_per_second: 71.359\n",
      "  experiment_id: 5167b0fe61f740ef9aba5862588cd463\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.7906454248366013\n",
      "  pid: 16728\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 61.0132839679718\n",
      "  time_this_iter_s: 61.0132839679718\n",
      "  time_total_s: 61.0132839679718\n",
      "  timestamp: 1658453159\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00047\n",
      "  warmup_time: 0.0050182342529296875\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=16969)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=16969)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_objective pid=17010)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=17010)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17010)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17010)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=17010)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=17045)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=17045)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17045)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17045)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=17045)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=17010)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=17010)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_objective pid=17081)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=17081)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17081)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17081)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=17081)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:26:05 (running for 00:13:11.59)\n",
      "Memory usage on this node: 22.6/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 159/infinite (105 PENDING, 4 RUNNING, 50 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00050 | RUNNING    | 155.246.89.124:16969 |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | RUNNING    | 155.246.89.124:17010 |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00052 | RUNNING    | 155.246.89.124:17045 |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | RUNNING    | 155.246.89.124:17081 |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | PENDING    |                      |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | PENDING    |                      |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | PENDING    |                      |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | PENDING    |                      |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | PENDING    |                      |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 139 more trials not shown (97 PENDING, 42 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17045)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=17045)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_objective pid=17081)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=17081)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:26:10 (running for 00:13:16.63)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 159/infinite (105 PENDING, 4 RUNNING, 50 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00050 | RUNNING    | 155.246.89.124:16969 |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | RUNNING    | 155.246.89.124:17010 |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00052 | RUNNING    | 155.246.89.124:17045 |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | RUNNING    | 155.246.89.124:17081 |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | PENDING    |                      |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | PENDING    |                      |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | PENDING    |                      |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | PENDING    |                      |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | PENDING    |                      |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 139 more trials not shown (97 PENDING, 42 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:26:15 (running for 00:13:21.65)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 159/infinite (105 PENDING, 4 RUNNING, 50 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00050 | RUNNING    | 155.246.89.124:16969 |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | RUNNING    | 155.246.89.124:17010 |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00052 | RUNNING    | 155.246.89.124:17045 |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | RUNNING    | 155.246.89.124:17081 |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | PENDING    |                      |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | PENDING    |                      |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | PENDING    |                      |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | PENDING    |                      |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | PENDING    |                      |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 139 more trials not shown (97 PENDING, 42 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:26:20 (running for 00:13:26.68)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 159/infinite (105 PENDING, 4 RUNNING, 50 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00050 | RUNNING    | 155.246.89.124:16969 |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00051 | RUNNING    | 155.246.89.124:17010 |     1.07962e-05 |                  1 |                            32 | 10.4322  |             |\n",
      "| _objective_69dd6_00052 | RUNNING    | 155.246.89.124:17045 |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | RUNNING    | 155.246.89.124:17081 |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | PENDING    |                      |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | PENDING    |                      |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | PENDING    |                      |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | PENDING    |                      |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | PENDING    |                      |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 139 more trials not shown (97 PENDING, 42 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=17010)\u001b[0m {'train_runtime': 17.9834, 'train_samples_per_second': 203.966, 'train_steps_per_second': 6.395, 'train_loss': 0.5939695938773777, 'epoch': 1.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=17010)\u001b[0m {'eval_loss': 0.5452465415000916, 'eval_accuracy': 0.7352941176470589, 'eval_f1': 0.8322981366459627, 'eval_runtime': 0.7018, 'eval_samples_per_second': 581.354, 'eval_steps_per_second': 72.669, 'epoch': 1.0}\n",
      "Result for _objective_69dd6_00051:\n",
      "  date: 2022-07-21_18-26-25\n",
      "  done: true\n",
      "  epoch: 1.0\n",
      "  eval_accuracy: 0.7352941176470589\n",
      "  eval_f1: 0.8322981366459627\n",
      "  eval_loss: 0.5452465415000916\n",
      "  eval_runtime: 0.7018\n",
      "  eval_samples_per_second: 581.354\n",
      "  eval_steps_per_second: 72.669\n",
      "  experiment_id: bcb6133d80f841c8a0ce11ca5ee36a14\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.5675922542930216\n",
      "  pid: 17010\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 25.723238468170166\n",
      "  time_this_iter_s: 25.723238468170166\n",
      "  time_total_s: 25.723238468170166\n",
      "  timestamp: 1658453185\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00051\n",
      "  warmup_time: 0.004443645477294922\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:26:30 (running for 00:13:36.62)\n",
      "Memory usage on this node: 23.2/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 160/infinite (105 PENDING, 4 RUNNING, 51 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00050 | RUNNING    | 155.246.89.124:16969 |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00052 | RUNNING    | 155.246.89.124:17045 |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | RUNNING    | 155.246.89.124:17081 |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | RUNNING    | 155.246.89.124:17140 |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | PENDING    |                      |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | PENDING    |                      |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | PENDING    |                      |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | PENDING    |                      |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 140 more trials not shown (97 PENDING, 43 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17140)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=17140)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17140)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17140)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=17140)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=17140)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=17140)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:26:35 (running for 00:13:41.65)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 160/infinite (105 PENDING, 4 RUNNING, 51 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00050 | RUNNING    | 155.246.89.124:16969 |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00052 | RUNNING    | 155.246.89.124:17045 |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | RUNNING    | 155.246.89.124:17081 |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | RUNNING    | 155.246.89.124:17140 |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | PENDING    |                      |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | PENDING    |                      |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | PENDING    |                      |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | PENDING    |                      |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 140 more trials not shown (97 PENDING, 43 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:26:40 (running for 00:13:46.66)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 160/infinite (105 PENDING, 4 RUNNING, 51 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00050 | RUNNING    | 155.246.89.124:16969 |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00052 | RUNNING    | 155.246.89.124:17045 |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | RUNNING    | 155.246.89.124:17081 |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | RUNNING    | 155.246.89.124:17140 |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | PENDING    |                      |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | PENDING    |                      |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | PENDING    |                      |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | PENDING    |                      |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 140 more trials not shown (97 PENDING, 43 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:26:45 (running for 00:13:51.69)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 160/infinite (105 PENDING, 4 RUNNING, 51 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00050 | RUNNING    | 155.246.89.124:16969 |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00052 | RUNNING    | 155.246.89.124:17045 |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | RUNNING    | 155.246.89.124:17081 |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | RUNNING    | 155.246.89.124:17140 |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | PENDING    |                      |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | PENDING    |                      |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | PENDING    |                      |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | PENDING    |                      |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 140 more trials not shown (97 PENDING, 43 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:26:50 (running for 00:13:56.71)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 160/infinite (105 PENDING, 4 RUNNING, 51 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00050 | RUNNING    | 155.246.89.124:16969 |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00052 | RUNNING    | 155.246.89.124:17045 |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | RUNNING    | 155.246.89.124:17081 |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | RUNNING    | 155.246.89.124:17140 |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | PENDING    |                      |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | PENDING    |                      |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | PENDING    |                      |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | PENDING    |                      |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 140 more trials not shown (97 PENDING, 43 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:26:55 (running for 00:14:01.74)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 160/infinite (105 PENDING, 4 RUNNING, 51 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00050 | RUNNING    | 155.246.89.124:16969 |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00052 | RUNNING    | 155.246.89.124:17045 |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | RUNNING    | 155.246.89.124:17081 |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | RUNNING    | 155.246.89.124:17140 |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | PENDING    |                      |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | PENDING    |                      |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | PENDING    |                      |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | PENDING    |                      |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 140 more trials not shown (97 PENDING, 43 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=17045)\u001b[0m {'train_runtime': 53.0375, 'train_samples_per_second': 207.476, 'train_steps_per_second': 6.505, 'train_loss': 0.4764518848363904, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=17081)\u001b[0m {'train_runtime': 52.2943, 'train_samples_per_second': 210.425, 'train_steps_per_second': 6.597, 'train_loss': 0.5729502802309783, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=17045)\u001b[0m {'eval_loss': 0.496328741312027, 'eval_accuracy': 0.8088235294117647, 'eval_f1': 0.8695652173913043, 'eval_runtime': 0.7087, 'eval_samples_per_second': 575.732, 'eval_steps_per_second': 71.967, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=17081)\u001b[0m {'eval_loss': 0.5272387862205505, 'eval_accuracy': 0.7352941176470589, 'eval_f1': 0.8307210031347961, 'eval_runtime': 0.6971, 'eval_samples_per_second': 585.321, 'eval_steps_per_second': 73.165, 'epoch': 3.0}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:27:00 (running for 00:14:06.76)\n",
      "Memory usage on this node: 25.0/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 160/infinite (105 PENDING, 4 RUNNING, 51 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00050 | RUNNING    | 155.246.89.124:16969 |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00052 | RUNNING    | 155.246.89.124:17045 |     1.30794e-05 |                  3 |                             4 |  8.35958 |             |\n",
      "| _objective_69dd6_00053 | RUNNING    | 155.246.89.124:17081 |     4.99366e-06 |                  3 |                             4 | 34.3966  |             |\n",
      "| _objective_69dd6_00054 | RUNNING    | 155.246.89.124:17140 |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | PENDING    |                      |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | PENDING    |                      |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | PENDING    |                      |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | PENDING    |                      |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 140 more trials not shown (97 PENDING, 43 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00053:\n",
      "  date: 2022-07-21_18-27-02\n",
      "  done: true\n",
      "  epoch: 3.0\n",
      "  eval_accuracy: 0.7352941176470589\n",
      "  eval_f1: 0.8307210031347961\n",
      "  eval_loss: 0.5272387862205505\n",
      "  eval_runtime: 0.6971\n",
      "  eval_samples_per_second: 585.321\n",
      "  eval_steps_per_second: 73.165\n",
      "  experiment_id: 972be55aff6d4a6991ff7c7327bdc17e\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.566015120781855\n",
      "  pid: 17081\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 59.74909210205078\n",
      "  time_this_iter_s: 59.74909210205078\n",
      "  time_total_s: 59.74909210205078\n",
      "  timestamp: 1658453222\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00053\n",
      "  warmup_time: 0.004727840423583984\n",
      "  \n",
      "Result for _objective_69dd6_00052:\n",
      "  date: 2022-07-21_18-27-02\n",
      "  done: true\n",
      "  epoch: 3.0\n",
      "  eval_accuracy: 0.8088235294117647\n",
      "  eval_f1: 0.8695652173913043\n",
      "  eval_loss: 0.496328741312027\n",
      "  eval_runtime: 0.7087\n",
      "  eval_samples_per_second: 575.732\n",
      "  eval_steps_per_second: 71.967\n",
      "  experiment_id: 8e1ddeb0c71b42d9a9b94cea02980ad0\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.6783887468030692\n",
      "  pid: 17045\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 60.57197570800781\n",
      "  time_this_iter_s: 60.57197570800781\n",
      "  time_total_s: 60.57197570800781\n",
      "  timestamp: 1658453222\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00052\n",
      "  warmup_time: 0.004229307174682617\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:27:07 (running for 00:14:13.67)\n",
      "Memory usage on this node: 21.5/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 162/infinite (105 PENDING, 4 RUNNING, 53 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00050 | RUNNING    | 155.246.89.124:16969 |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00054 | RUNNING    | 155.246.89.124:17140 |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | RUNNING    | 155.246.89.124:17198 |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | RUNNING    | 155.246.89.124:17200 |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | PENDING    |                      |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | PENDING    |                      |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 142 more trials not shown (97 PENDING, 45 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17198)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=17198)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17198)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17198)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=17198)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=17200)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=17200)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17200)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17200)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=17200)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=17198)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=17198)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_objective pid=17200)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=17200)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:27:12 (running for 00:14:18.69)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 162/infinite (105 PENDING, 4 RUNNING, 53 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00050 | RUNNING    | 155.246.89.124:16969 |     3.28007e-06 |                  4 |                             4 |  7.82324 |             |\n",
      "| _objective_69dd6_00054 | RUNNING    | 155.246.89.124:17140 |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | RUNNING    | 155.246.89.124:17198 |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | RUNNING    | 155.246.89.124:17200 |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | PENDING    |                      |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | PENDING    |                      |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 142 more trials not shown (97 PENDING, 45 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=16969)\u001b[0m {'train_runtime': 72.7029, 'train_samples_per_second': 201.808, 'train_steps_per_second': 6.327, 'train_loss': 0.5643414704695991, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=16969)\u001b[0m {'eval_loss': 0.5209173560142517, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8330733229329172, 'eval_runtime': 0.7265, 'eval_samples_per_second': 561.591, 'eval_steps_per_second': 70.199, 'epoch': 4.0}\n",
      "Result for _objective_69dd6_00050:\n",
      "  date: 2022-07-21_18-27-17\n",
      "  done: true\n",
      "  epoch: 4.0\n",
      "  eval_accuracy: 0.7377450980392157\n",
      "  eval_f1: 0.8330733229329172\n",
      "  eval_loss: 0.5209173560142517\n",
      "  eval_runtime: 0.7265\n",
      "  eval_samples_per_second: 561.591\n",
      "  eval_steps_per_second: 70.199\n",
      "  experiment_id: 1a1a2051687a4f42b43783cadde7a7a8\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.570818420972133\n",
      "  pid: 16969\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 80.8859269618988\n",
      "  time_this_iter_s: 80.8859269618988\n",
      "  time_total_s: 80.8859269618988\n",
      "  timestamp: 1658453237\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00050\n",
      "  warmup_time: 0.00484013557434082\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:27:18 (running for 00:14:24.66)\n",
      "Memory usage on this node: 22.0/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 162/infinite (104 PENDING, 4 RUNNING, 54 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00054 | RUNNING    | 155.246.89.124:17140 |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | RUNNING    | 155.246.89.124:17198 |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | RUNNING    | 155.246.89.124:17200 |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | RUNNING    | 155.246.89.124:17280 |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | PENDING    |                      |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 142 more trials not shown (96 PENDING, 46 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17280)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=17280)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17280)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17280)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=17280)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17140)\u001b[0m {'train_runtime': 52.3349, 'train_samples_per_second': 210.261, 'train_steps_per_second': 6.592, 'train_loss': 0.4318983437358469, 'epoch': 3.0}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:27:26 (running for 00:14:32.73)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 163/infinite (105 PENDING, 4 RUNNING, 54 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00054 | RUNNING    | 155.246.89.124:17140 |     1.92337e-05 |                  3 |                            32 | 37.4898  |             |\n",
      "| _objective_69dd6_00055 | RUNNING    | 155.246.89.124:17198 |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | RUNNING    | 155.246.89.124:17200 |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | RUNNING    | 155.246.89.124:17280 |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | PENDING    |                      |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 143 more trials not shown (97 PENDING, 46 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=17140)\u001b[0m {'eval_loss': 0.3891903758049011, 'eval_accuracy': 0.8431372549019608, 'eval_f1': 0.8907849829351535, 'eval_runtime': 0.7002, 'eval_samples_per_second': 582.72, 'eval_steps_per_second': 72.84, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17280)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=17280)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00054:\n",
      "  date: 2022-07-21_18-27-28\n",
      "  done: true\n",
      "  epoch: 3.0\n",
      "  eval_accuracy: 0.8431372549019608\n",
      "  eval_f1: 0.8907849829351535\n",
      "  eval_loss: 0.3891903758049011\n",
      "  eval_runtime: 0.7002\n",
      "  eval_samples_per_second: 582.72\n",
      "  eval_steps_per_second: 72.84\n",
      "  experiment_id: 159f8a7eeed54498913073891ba59b69\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.7339222378371142\n",
      "  pid: 17140\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 60.44512629508972\n",
      "  time_this_iter_s: 60.44512629508972\n",
      "  time_total_s: 60.44512629508972\n",
      "  timestamp: 1658453248\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00054\n",
      "  warmup_time: 0.00439143180847168\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:27:33 (running for 00:14:39.69)\n",
      "Memory usage on this node: 23.1/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 164/infinite (105 PENDING, 4 RUNNING, 55 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00055 | RUNNING    | 155.246.89.124:17198 |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | RUNNING    | 155.246.89.124:17200 |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | RUNNING    | 155.246.89.124:17280 |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | RUNNING    | 155.246.89.124:17323 |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 144 more trials not shown (97 PENDING, 47 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17323)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=17323)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17323)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17323)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=17323)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=17323)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=17323)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:27:38 (running for 00:14:44.71)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 164/infinite (105 PENDING, 4 RUNNING, 55 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00055 | RUNNING    | 155.246.89.124:17198 |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | RUNNING    | 155.246.89.124:17200 |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | RUNNING    | 155.246.89.124:17280 |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | RUNNING    | 155.246.89.124:17323 |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 144 more trials not shown (97 PENDING, 47 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:27:43 (running for 00:14:49.73)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 164/infinite (105 PENDING, 4 RUNNING, 55 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00055 | RUNNING    | 155.246.89.124:17198 |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | RUNNING    | 155.246.89.124:17200 |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | RUNNING    | 155.246.89.124:17280 |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | RUNNING    | 155.246.89.124:17323 |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 144 more trials not shown (97 PENDING, 47 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:27:48 (running for 00:14:54.75)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 164/infinite (105 PENDING, 4 RUNNING, 55 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00055 | RUNNING    | 155.246.89.124:17198 |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | RUNNING    | 155.246.89.124:17200 |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | RUNNING    | 155.246.89.124:17280 |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | RUNNING    | 155.246.89.124:17323 |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 144 more trials not shown (97 PENDING, 47 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:27:53 (running for 00:14:59.78)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 164/infinite (105 PENDING, 4 RUNNING, 55 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00055 | RUNNING    | 155.246.89.124:17198 |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | RUNNING    | 155.246.89.124:17200 |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | RUNNING    | 155.246.89.124:17280 |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | RUNNING    | 155.246.89.124:17323 |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 144 more trials not shown (97 PENDING, 47 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:27:58 (running for 00:15:04.79)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 164/infinite (105 PENDING, 4 RUNNING, 55 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00055 | RUNNING    | 155.246.89.124:17198 |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | RUNNING    | 155.246.89.124:17200 |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | RUNNING    | 155.246.89.124:17280 |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | RUNNING    | 155.246.89.124:17323 |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 144 more trials not shown (97 PENDING, 47 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:28:03 (running for 00:15:09.86)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 164/infinite (105 PENDING, 4 RUNNING, 55 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00055 | RUNNING    | 155.246.89.124:17198 |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | RUNNING    | 155.246.89.124:17200 |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | RUNNING    | 155.246.89.124:17280 |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | RUNNING    | 155.246.89.124:17323 |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 144 more trials not shown (97 PENDING, 47 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:28:08 (running for 00:15:14.87)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 164/infinite (105 PENDING, 4 RUNNING, 55 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00055 | RUNNING    | 155.246.89.124:17198 |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | RUNNING    | 155.246.89.124:17200 |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | RUNNING    | 155.246.89.124:17280 |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | RUNNING    | 155.246.89.124:17323 |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 144 more trials not shown (97 PENDING, 47 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:28:14 (running for 00:15:19.90)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 164/infinite (105 PENDING, 4 RUNNING, 55 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00055 | RUNNING    | 155.246.89.124:17198 |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | RUNNING    | 155.246.89.124:17200 |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | RUNNING    | 155.246.89.124:17280 |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | RUNNING    | 155.246.89.124:17323 |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 144 more trials not shown (97 PENDING, 47 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:28:19 (running for 00:15:24.92)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 164/infinite (105 PENDING, 4 RUNNING, 55 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00055 | RUNNING    | 155.246.89.124:17198 |     6.2677e-05  |                  4 |                             4 | 23.6468  |             |\n",
      "| _objective_69dd6_00056 | RUNNING    | 155.246.89.124:17200 |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00057 | RUNNING    | 155.246.89.124:17280 |     9.35896e-06 |                  3 |                             4 | 26.4265  |             |\n",
      "| _objective_69dd6_00058 | RUNNING    | 155.246.89.124:17323 |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | PENDING    |                      |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | PENDING    |                      |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 144 more trials not shown (97 PENDING, 47 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=17198)\u001b[0m {'train_runtime': 69.6831, 'train_samples_per_second': 210.553, 'train_steps_per_second': 6.601, 'train_loss': 0.2656600122866423, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=17280)\u001b[0m {'train_runtime': 52.9941, 'train_samples_per_second': 207.646, 'train_steps_per_second': 6.51, 'train_loss': 0.4844509843466938, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=17198)\u001b[0m {'eval_loss': 0.5218693017959595, 'eval_accuracy': 0.8676470588235294, 'eval_f1': 0.9084745762711864, 'eval_runtime': 0.6973, 'eval_samples_per_second': 585.111, 'eval_steps_per_second': 73.139, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=17280)\u001b[0m {'eval_loss': 0.45135819911956787, 'eval_accuracy': 0.8063725490196079, 'eval_f1': 0.869851729818781, 'eval_runtime': 0.7102, 'eval_samples_per_second': 574.447, 'eval_steps_per_second': 71.806, 'epoch': 3.0}\n",
      "Result for _objective_69dd6_00055:\n",
      "  date: 2022-07-21_18-28-22\n",
      "  done: true\n",
      "  epoch: 4.0\n",
      "  eval_accuracy: 0.8676470588235294\n",
      "  eval_f1: 0.9084745762711864\n",
      "  eval_loss: 0.5218693017959595\n",
      "  eval_runtime: 0.6973\n",
      "  eval_samples_per_second: 585.111\n",
      "  eval_steps_per_second: 73.139\n",
      "  experiment_id: f1012effe5c64ac280c08fdf07f3f0b4\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.7761216350947158\n",
      "  pid: 17198\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 77.29342293739319\n",
      "  time_this_iter_s: 77.29342293739319\n",
      "  time_total_s: 77.29342293739319\n",
      "  timestamp: 1658453302\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00055\n",
      "  warmup_time: 0.004853248596191406\n",
      "  \n",
      "Result for _objective_69dd6_00057:\n",
      "  date: 2022-07-21_18-28-23\n",
      "  done: true\n",
      "  epoch: 3.0\n",
      "  eval_accuracy: 0.8063725490196079\n",
      "  eval_f1: 0.869851729818781\n",
      "  eval_loss: 0.45135819911956787\n",
      "  eval_runtime: 0.7102\n",
      "  eval_samples_per_second: 574.447\n",
      "  eval_steps_per_second: 71.806\n",
      "  experiment_id: 5a94049ee2bc4586a6a0d8f7aecb64b4\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.6762242788383888\n",
      "  pid: 17280\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 61.30399537086487\n",
      "  time_this_iter_s: 61.30399537086487\n",
      "  time_total_s: 61.30399537086487\n",
      "  timestamp: 1658453303\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00057\n",
      "  warmup_time: 0.005054950714111328\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=17200)\u001b[0m {'loss': 0.2825, 'learning_rate': 2.7694718611774557e-06, 'epoch': 4.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17383)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=17383)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17383)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17383)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=17383)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17200)\u001b[0m {'eval_loss': 0.5123111605644226, 'eval_accuracy': 0.8455882352941176, 'eval_f1': 0.8904347826086957, 'eval_runtime': 0.7094, 'eval_samples_per_second': 575.125, 'eval_steps_per_second': 71.891, 'epoch': 4.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17415)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=17415)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17415)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17415)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=17415)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:28:28 (running for 00:15:34.74)\n",
      "Memory usage on this node: 22.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 166/infinite (105 PENDING, 4 RUNNING, 57 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00056 | RUNNING    | 155.246.89.124:17200 |     2.12326e-05 |                  5 |                             8 | 12.0729  |             |\n",
      "| _objective_69dd6_00058 | RUNNING    | 155.246.89.124:17323 |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | RUNNING    | 155.246.89.124:17383 |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | RUNNING    | 155.246.89.124:17415 |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | PENDING    |                      |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 146 more trials not shown (97 PENDING, 49 TERMINATED)\n",
      "\n",
      "\n",
      "Result for _objective_69dd6_00056:\n",
      "  date: 2022-07-21_18-28-29\n",
      "  done: false\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.8455882352941176\n",
      "  eval_f1: 0.8904347826086957\n",
      "  eval_loss: 0.5123111605644226\n",
      "  eval_runtime: 0.7094\n",
      "  eval_samples_per_second: 575.125\n",
      "  eval_steps_per_second: 71.891\n",
      "  experiment_id: 39badd4a16d4435b9fab4d77f89f91c4\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.7360230179028133\n",
      "  pid: 17200\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 84.56960248947144\n",
      "  time_this_iter_s: 84.56960248947144\n",
      "  time_total_s: 84.56960248947144\n",
      "  timestamp: 1658453309\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00056\n",
      "  warmup_time: 0.004675626754760742\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17383)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=17383)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_objective pid=17415)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=17415)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:28:34 (running for 00:15:40.52)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 166/infinite (105 PENDING, 4 RUNNING, 57 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00056 | RUNNING    | 155.246.89.124:17200 |     2.12326e-05 |                  5 |                             8 | 12.0729  |     1.73602 |\n",
      "| _objective_69dd6_00058 | RUNNING    | 155.246.89.124:17323 |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | RUNNING    | 155.246.89.124:17383 |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | RUNNING    | 155.246.89.124:17415 |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | PENDING    |                      |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 146 more trials not shown (97 PENDING, 49 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:28:39 (running for 00:15:45.55)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 166/infinite (105 PENDING, 4 RUNNING, 57 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00056 | RUNNING    | 155.246.89.124:17200 |     2.12326e-05 |                  5 |                             8 | 12.0729  |     1.73602 |\n",
      "| _objective_69dd6_00058 | RUNNING    | 155.246.89.124:17323 |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | RUNNING    | 155.246.89.124:17383 |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | RUNNING    | 155.246.89.124:17415 |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | PENDING    |                      |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | PENDING    |                      |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 146 more trials not shown (97 PENDING, 49 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00056:\n",
      "  date: 2022-07-21_18-28-29\n",
      "  done: true\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.8455882352941176\n",
      "  eval_f1: 0.8904347826086957\n",
      "  eval_loss: 0.5123111605644226\n",
      "  eval_runtime: 0.7094\n",
      "  eval_samples_per_second: 575.125\n",
      "  eval_steps_per_second: 71.891\n",
      "  experiment_id: 39badd4a16d4435b9fab4d77f89f91c4\n",
      "  experiment_tag: 56_learning_rate=0.0000,num_train_epochs=5,per_device_train_batch_size=8,seed=12.0729\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.7360230179028133\n",
      "  pid: 17200\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 84.56960248947144\n",
      "  time_this_iter_s: 84.56960248947144\n",
      "  time_total_s: 84.56960248947144\n",
      "  timestamp: 1658453309\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00056\n",
      "  warmup_time: 0.004675626754760742\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=17200)\u001b[0m {'train_runtime': 92.4419, 'train_samples_per_second': 198.395, 'train_steps_per_second': 6.22, 'train_loss': 0.25232481002807616, 'epoch': 5.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=17323)\u001b[0m {'train_runtime': 69.949, 'train_samples_per_second': 209.753, 'train_steps_per_second': 6.576, 'train_loss': 0.5744997107464335, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=17323)\u001b[0m {'eval_loss': 0.5272525548934937, 'eval_accuracy': 0.7426470588235294, 'eval_f1': 0.8341232227488151, 'eval_runtime': 0.7329, 'eval_samples_per_second': 556.672, 'eval_steps_per_second': 69.584, 'epoch': 4.0}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:28:48 (running for 00:15:54.74)\n",
      "Memory usage on this node: 23.3/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 167/infinite (105 PENDING, 4 RUNNING, 58 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00058 | RUNNING    | 155.246.89.124:17323 |     2.24828e-06 |                  4 |                            64 | 10.2527  |             |\n",
      "| _objective_69dd6_00059 | RUNNING    | 155.246.89.124:17383 |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | RUNNING    | 155.246.89.124:17415 |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | RUNNING    | 155.246.89.124:17470 |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | PENDING    |                      |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | PENDING    |                      |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 147 more trials not shown (97 PENDING, 50 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17470)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=17470)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17470)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17470)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=17470)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00058:\n",
      "  date: 2022-07-21_18-28-49\n",
      "  done: true\n",
      "  epoch: 4.0\n",
      "  eval_accuracy: 0.7426470588235294\n",
      "  eval_f1: 0.8341232227488151\n",
      "  eval_loss: 0.5272525548934937\n",
      "  eval_runtime: 0.7329\n",
      "  eval_samples_per_second: 556.672\n",
      "  eval_steps_per_second: 69.584\n",
      "  experiment_id: 3dba443704ee42d3a4979c373188717f\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.5767702815723446\n",
      "  pid: 17323\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 78.02809524536133\n",
      "  time_this_iter_s: 78.02809524536133\n",
      "  time_total_s: 78.02809524536133\n",
      "  timestamp: 1658453329\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00058\n",
      "  warmup_time: 0.004340648651123047\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17470)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=17470)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_objective pid=17510)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=17510)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17510)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17510)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=17510)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:28:54 (running for 00:16:00.74)\n",
      "Memory usage on this node: 23.2/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 168/infinite (105 PENDING, 4 RUNNING, 59 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00059 | RUNNING    | 155.246.89.124:17383 |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | RUNNING    | 155.246.89.124:17415 |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | RUNNING    | 155.246.89.124:17470 |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | RUNNING    | 155.246.89.124:17510 |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | PENDING    |                      |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 148 more trials not shown (97 PENDING, 51 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17510)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=17510)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:28:59 (running for 00:16:05.77)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 168/infinite (105 PENDING, 4 RUNNING, 59 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00059 | RUNNING    | 155.246.89.124:17383 |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | RUNNING    | 155.246.89.124:17415 |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | RUNNING    | 155.246.89.124:17470 |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | RUNNING    | 155.246.89.124:17510 |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | PENDING    |                      |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 148 more trials not shown (97 PENDING, 51 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:29:04 (running for 00:16:10.79)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 168/infinite (105 PENDING, 4 RUNNING, 59 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00059 | RUNNING    | 155.246.89.124:17383 |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | RUNNING    | 155.246.89.124:17415 |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | RUNNING    | 155.246.89.124:17470 |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | RUNNING    | 155.246.89.124:17510 |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | PENDING    |                      |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 148 more trials not shown (97 PENDING, 51 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:29:09 (running for 00:16:15.82)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 168/infinite (105 PENDING, 4 RUNNING, 59 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00059 | RUNNING    | 155.246.89.124:17383 |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | RUNNING    | 155.246.89.124:17415 |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | RUNNING    | 155.246.89.124:17470 |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | RUNNING    | 155.246.89.124:17510 |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | PENDING    |                      |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 148 more trials not shown (97 PENDING, 51 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:29:14 (running for 00:16:20.84)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 168/infinite (105 PENDING, 4 RUNNING, 59 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00059 | RUNNING    | 155.246.89.124:17383 |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | RUNNING    | 155.246.89.124:17415 |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | RUNNING    | 155.246.89.124:17470 |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | RUNNING    | 155.246.89.124:17510 |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | PENDING    |                      |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 148 more trials not shown (97 PENDING, 51 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:29:19 (running for 00:16:25.87)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 168/infinite (105 PENDING, 4 RUNNING, 59 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00059 | RUNNING    | 155.246.89.124:17383 |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | RUNNING    | 155.246.89.124:17415 |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | RUNNING    | 155.246.89.124:17470 |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | RUNNING    | 155.246.89.124:17510 |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | PENDING    |                      |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 148 more trials not shown (97 PENDING, 51 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=17383)\u001b[0m {'train_runtime': 52.5722, 'train_samples_per_second': 209.312, 'train_steps_per_second': 6.562, 'train_loss': 0.5895312765370244, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=17383)\u001b[0m {'eval_loss': 0.5589921474456787, 'eval_accuracy': 0.7132352941176471, 'eval_f1': 0.821917808219178, 'eval_runtime': 0.708, 'eval_samples_per_second': 576.249, 'eval_steps_per_second': 72.031, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=17415)\u001b[0m {'train_runtime': 53.1261, 'train_samples_per_second': 207.13, 'train_steps_per_second': 6.494, 'train_loss': 0.5025847946388134, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=17415)\u001b[0m {'eval_loss': 0.48340773582458496, 'eval_accuracy': 0.821078431372549, 'eval_f1': 0.8781302170283807, 'eval_runtime': 0.7081, 'eval_samples_per_second': 576.183, 'eval_steps_per_second': 72.023, 'epoch': 3.0}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:29:25 (running for 00:16:30.89)\n",
      "Memory usage on this node: 24.9/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 168/infinite (105 PENDING, 4 RUNNING, 59 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00059 | RUNNING    | 155.246.89.124:17383 |     2.27848e-06 |                  3 |                             4 | 26.6469  |             |\n",
      "| _objective_69dd6_00060 | RUNNING    | 155.246.89.124:17415 |     1.21641e-05 |                  3 |                            64 | 15.3409  |             |\n",
      "| _objective_69dd6_00061 | RUNNING    | 155.246.89.124:17470 |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | RUNNING    | 155.246.89.124:17510 |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | PENDING    |                      |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | PENDING    |                      |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | PENDING    |                      |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 148 more trials not shown (97 PENDING, 51 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00059:\n",
      "  date: 2022-07-21_18-29-26\n",
      "  done: true\n",
      "  epoch: 3.0\n",
      "  eval_accuracy: 0.7132352941176471\n",
      "  eval_f1: 0.821917808219178\n",
      "  eval_loss: 0.5589921474456787\n",
      "  eval_runtime: 0.708\n",
      "  eval_samples_per_second: 576.249\n",
      "  eval_steps_per_second: 72.031\n",
      "  experiment_id: 3c07ab5d74c545af85234e15646f74e3\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.535153102336825\n",
      "  pid: 17383\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 61.170451402664185\n",
      "  time_this_iter_s: 61.170451402664185\n",
      "  time_total_s: 61.170451402664185\n",
      "  timestamp: 1658453366\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00059\n",
      "  warmup_time: 0.004281282424926758\n",
      "  \n",
      "Result for _objective_69dd6_00060:\n",
      "  date: 2022-07-21_18-29-26\n",
      "  done: true\n",
      "  epoch: 3.0\n",
      "  eval_accuracy: 0.821078431372549\n",
      "  eval_f1: 0.8781302170283807\n",
      "  eval_loss: 0.48340773582458496\n",
      "  eval_runtime: 0.7081\n",
      "  eval_samples_per_second: 576.183\n",
      "  eval_steps_per_second: 72.023\n",
      "  experiment_id: 4f84cb5ddb694cf0b7399cba0ec9debd\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.6992086484009297\n",
      "  pid: 17415\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 60.67166304588318\n",
      "  time_this_iter_s: 60.67166304588318\n",
      "  time_total_s: 60.67166304588318\n",
      "  timestamp: 1658453366\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00060\n",
      "  warmup_time: 0.004026651382446289\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:29:31 (running for 00:16:37.81)\n",
      "Memory usage on this node: 21.6/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 170/infinite (105 PENDING, 4 RUNNING, 61 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00061 | RUNNING    | 155.246.89.124:17470 |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | RUNNING    | 155.246.89.124:17510 |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | RUNNING    | 155.246.89.124:17567 |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | RUNNING    | 155.246.89.124:17569 |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | PENDING    |                      |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | PENDING    |                      |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 150 more trials not shown (97 PENDING, 53 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17569)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=17569)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17569)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17569)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=17569)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=17567)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=17567)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17567)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17567)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=17567)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=17569)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=17569)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_objective pid=17567)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=17567)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:29:36 (running for 00:16:42.83)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 170/infinite (105 PENDING, 4 RUNNING, 61 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00061 | RUNNING    | 155.246.89.124:17470 |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | RUNNING    | 155.246.89.124:17510 |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | RUNNING    | 155.246.89.124:17567 |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | RUNNING    | 155.246.89.124:17569 |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | PENDING    |                      |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | PENDING    |                      |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 150 more trials not shown (97 PENDING, 53 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:29:41 (running for 00:16:47.86)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 170/infinite (105 PENDING, 4 RUNNING, 61 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00061 | RUNNING    | 155.246.89.124:17470 |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | RUNNING    | 155.246.89.124:17510 |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | RUNNING    | 155.246.89.124:17567 |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | RUNNING    | 155.246.89.124:17569 |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | PENDING    |                      |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | PENDING    |                      |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 150 more trials not shown (97 PENDING, 53 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17470)\u001b[0m {'train_runtime': 53.8374, 'train_samples_per_second': 204.393, 'train_steps_per_second': 6.408, 'train_loss': 0.4972229888473732, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=17470)\u001b[0m {'eval_loss': 0.46878859400749207, 'eval_accuracy': 0.7941176470588235, 'eval_f1': 0.8618421052631581, 'eval_runtime': 0.7186, 'eval_samples_per_second': 567.748, 'eval_steps_per_second': 70.969, 'epoch': 3.0}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:29:46 (running for 00:16:52.88)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 170/infinite (105 PENDING, 4 RUNNING, 61 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00061 | RUNNING    | 155.246.89.124:17470 |     9.40772e-06 |                  3 |                            64 | 17.9414  |             |\n",
      "| _objective_69dd6_00062 | RUNNING    | 155.246.89.124:17510 |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | RUNNING    | 155.246.89.124:17567 |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | RUNNING    | 155.246.89.124:17569 |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | PENDING    |                      |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | PENDING    |                      |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | PENDING    |                      |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 150 more trials not shown (97 PENDING, 53 TERMINATED)\n",
      "\n",
      "\n",
      "Result for _objective_69dd6_00061:\n",
      "  date: 2022-07-21_18-29-48\n",
      "  done: true\n",
      "  epoch: 3.0\n",
      "  eval_accuracy: 0.7941176470588235\n",
      "  eval_f1: 0.8618421052631581\n",
      "  eval_loss: 0.46878859400749207\n",
      "  eval_runtime: 0.7186\n",
      "  eval_samples_per_second: 567.748\n",
      "  eval_steps_per_second: 70.969\n",
      "  experiment_id: 4fdc410c4fd14f1db4c35621da268565\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.6559597523219816\n",
      "  pid: 17470\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 61.97088861465454\n",
      "  time_this_iter_s: 61.97088861465454\n",
      "  time_total_s: 61.97088861465454\n",
      "  timestamp: 1658453388\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00061\n",
      "  warmup_time: 0.004340410232543945\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=17569)\u001b[0m {'train_runtime': 18.2184, 'train_samples_per_second': 201.335, 'train_steps_per_second': 6.312, 'train_loss': 0.6488585762355639, 'epoch': 1.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=17569)\u001b[0m {'eval_loss': 0.6333580613136292, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.7355, 'eval_samples_per_second': 554.731, 'eval_steps_per_second': 69.341, 'epoch': 1.0}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:29:53 (running for 00:16:59.81)\n",
      "Memory usage on this node: 23.2/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 171/infinite (105 PENDING, 4 RUNNING, 62 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00062 | RUNNING    | 155.246.89.124:17510 |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | RUNNING    | 155.246.89.124:17567 |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00064 | RUNNING    | 155.246.89.124:17569 |     1.11849e-06 |                  1 |                            32 |  2.70055 |             |\n",
      "| _objective_69dd6_00065 | RUNNING    | 155.246.89.124:17652 |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | PENDING    |                      |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | PENDING    |                      |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | PENDING    |                      |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | PENDING    |                      |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 151 more trials not shown (97 PENDING, 54 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17652)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=17652)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17652)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17652)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=17652)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00064:\n",
      "  date: 2022-07-21_18-29-54\n",
      "  done: true\n",
      "  epoch: 1.0\n",
      "  eval_accuracy: 0.6838235294117647\n",
      "  eval_f1: 0.8122270742358079\n",
      "  eval_loss: 0.6333580613136292\n",
      "  eval_runtime: 0.7355\n",
      "  eval_samples_per_second: 554.731\n",
      "  eval_steps_per_second: 69.341\n",
      "  experiment_id: 58a83e4876c245eb8f2e19fd6fb40c86\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.4960506036475727\n",
      "  pid: 17569\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 26.00676465034485\n",
      "  time_this_iter_s: 26.00676465034485\n",
      "  time_total_s: 26.00676465034485\n",
      "  timestamp: 1658453394\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00064\n",
      "  warmup_time: 0.004320859909057617\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17652)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=17652)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:30:00 (running for 00:17:06.80)\n",
      "Memory usage on this node: 23.2/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 172/infinite (105 PENDING, 4 RUNNING, 63 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00062 | RUNNING    | 155.246.89.124:17510 |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | RUNNING    | 155.246.89.124:17567 |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00065 | RUNNING    | 155.246.89.124:17652 |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | RUNNING    | 155.246.89.124:17691 |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | PENDING    |                      |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | PENDING    |                      |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | PENDING    |                      |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | PENDING    |                      |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 152 more trials not shown (97 PENDING, 55 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17691)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=17691)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17691)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17691)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=17691)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=17691)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=17691)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:30:05 (running for 00:17:11.83)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 172/infinite (105 PENDING, 4 RUNNING, 63 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00062 | RUNNING    | 155.246.89.124:17510 |     1.01222e-05 |                  4 |                             4 | 27.088   |             |\n",
      "| _objective_69dd6_00063 | RUNNING    | 155.246.89.124:17567 |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00065 | RUNNING    | 155.246.89.124:17652 |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | RUNNING    | 155.246.89.124:17691 |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | PENDING    |                      |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | PENDING    |                      |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | PENDING    |                      |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | PENDING    |                      |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 152 more trials not shown (97 PENDING, 55 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=17510)\u001b[0m {'train_runtime': 69.1662, 'train_samples_per_second': 212.127, 'train_steps_per_second': 6.651, 'train_loss': 0.4343888655952785, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=17510)\u001b[0m {'eval_loss': 0.45951634645462036, 'eval_accuracy': 0.8063725490196079, 'eval_f1': 0.8676716917922948, 'eval_runtime': 0.7002, 'eval_samples_per_second': 582.724, 'eval_steps_per_second': 72.84, 'epoch': 4.0}\n",
      "Result for _objective_69dd6_00062:\n",
      "  date: 2022-07-21_18-30-08\n",
      "  done: true\n",
      "  epoch: 4.0\n",
      "  eval_accuracy: 0.8063725490196079\n",
      "  eval_f1: 0.8676716917922948\n",
      "  eval_loss: 0.45951634645462036\n",
      "  eval_runtime: 0.7002\n",
      "  eval_samples_per_second: 582.724\n",
      "  eval_steps_per_second: 72.84\n",
      "  experiment_id: 6ea164a7eb0948dab5916b8c963ebf5b\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.6740442408119027\n",
      "  pid: 17510\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 77.02550506591797\n",
      "  time_this_iter_s: 77.02550506591797\n",
      "  time_total_s: 77.02550506591797\n",
      "  timestamp: 1658453408\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00062\n",
      "  warmup_time: 0.00423121452331543\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:30:14 (running for 00:17:20.81)\n",
      "Memory usage on this node: 23.1/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 173/infinite (105 PENDING, 4 RUNNING, 64 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00063 | RUNNING    | 155.246.89.124:17567 |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00065 | RUNNING    | 155.246.89.124:17652 |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | RUNNING    | 155.246.89.124:17691 |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | RUNNING    | 155.246.89.124:17739 |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | PENDING    |                      |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | PENDING    |                      |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | PENDING    |                      |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | PENDING    |                      |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 153 more trials not shown (97 PENDING, 56 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17739)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=17739)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17739)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17739)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=17739)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=17739)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=17739)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:30:19 (running for 00:17:25.84)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 173/infinite (105 PENDING, 4 RUNNING, 64 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00063 | RUNNING    | 155.246.89.124:17567 |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00065 | RUNNING    | 155.246.89.124:17652 |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | RUNNING    | 155.246.89.124:17691 |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | RUNNING    | 155.246.89.124:17739 |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | PENDING    |                      |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | PENDING    |                      |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | PENDING    |                      |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | PENDING    |                      |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 153 more trials not shown (97 PENDING, 56 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:30:24 (running for 00:17:30.86)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 173/infinite (105 PENDING, 4 RUNNING, 64 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00063 | RUNNING    | 155.246.89.124:17567 |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00065 | RUNNING    | 155.246.89.124:17652 |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | RUNNING    | 155.246.89.124:17691 |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | RUNNING    | 155.246.89.124:17739 |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | PENDING    |                      |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | PENDING    |                      |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | PENDING    |                      |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | PENDING    |                      |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 153 more trials not shown (97 PENDING, 56 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:30:30 (running for 00:17:35.89)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 173/infinite (105 PENDING, 4 RUNNING, 64 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00063 | RUNNING    | 155.246.89.124:17567 |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00065 | RUNNING    | 155.246.89.124:17652 |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | RUNNING    | 155.246.89.124:17691 |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | RUNNING    | 155.246.89.124:17739 |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | PENDING    |                      |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | PENDING    |                      |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | PENDING    |                      |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | PENDING    |                      |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 153 more trials not shown (97 PENDING, 56 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:30:35 (running for 00:17:40.90)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 173/infinite (105 PENDING, 4 RUNNING, 64 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00063 | RUNNING    | 155.246.89.124:17567 |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00065 | RUNNING    | 155.246.89.124:17652 |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | RUNNING    | 155.246.89.124:17691 |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | RUNNING    | 155.246.89.124:17739 |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | PENDING    |                      |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | PENDING    |                      |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | PENDING    |                      |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | PENDING    |                      |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 153 more trials not shown (97 PENDING, 56 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:30:40 (running for 00:17:45.94)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 173/infinite (105 PENDING, 4 RUNNING, 64 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00063 | RUNNING    | 155.246.89.124:17567 |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00065 | RUNNING    | 155.246.89.124:17652 |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | RUNNING    | 155.246.89.124:17691 |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | RUNNING    | 155.246.89.124:17739 |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | PENDING    |                      |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | PENDING    |                      |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | PENDING    |                      |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | PENDING    |                      |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 153 more trials not shown (97 PENDING, 56 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:30:45 (running for 00:17:50.95)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 173/infinite (105 PENDING, 4 RUNNING, 64 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00063 | RUNNING    | 155.246.89.124:17567 |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00065 | RUNNING    | 155.246.89.124:17652 |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | RUNNING    | 155.246.89.124:17691 |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | RUNNING    | 155.246.89.124:17739 |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | PENDING    |                      |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | PENDING    |                      |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | PENDING    |                      |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | PENDING    |                      |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 153 more trials not shown (97 PENDING, 56 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17567)\u001b[0m {'loss': 0.579, 'learning_rate': 3.2053790514538977e-07, 'epoch': 4.35}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:30:50 (running for 00:17:55.98)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 173/infinite (105 PENDING, 4 RUNNING, 64 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00063 | RUNNING    | 155.246.89.124:17567 |     2.45746e-06 |                  5 |                            32 | 20.4685  |             |\n",
      "| _objective_69dd6_00065 | RUNNING    | 155.246.89.124:17652 |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | RUNNING    | 155.246.89.124:17691 |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | RUNNING    | 155.246.89.124:17739 |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | PENDING    |                      |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | PENDING    |                      |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | PENDING    |                      |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | PENDING    |                      |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 153 more trials not shown (97 PENDING, 56 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=17567)\u001b[0m {'eval_loss': 0.5274462103843689, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8304278922345483, 'eval_runtime': 0.7047, 'eval_samples_per_second': 579.003, 'eval_steps_per_second': 72.375, 'epoch': 4.35}\n",
      "Result for _objective_69dd6_00063:\n",
      "  date: 2022-07-21_18-30-52\n",
      "  done: false\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.7377450980392157\n",
      "  eval_f1: 0.8304278922345483\n",
      "  eval_loss: 0.5274462103843689\n",
      "  eval_runtime: 0.7047\n",
      "  eval_samples_per_second: 579.003\n",
      "  eval_steps_per_second: 72.375\n",
      "  experiment_id: 831e627e481e46c39e91e63c0b7b5691\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.568172990273764\n",
      "  pid: 17567\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 83.36274766921997\n",
      "  time_this_iter_s: 83.36274766921997\n",
      "  time_total_s: 83.36274766921997\n",
      "  timestamp: 1658453452\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00063\n",
      "  warmup_time: 0.00409698486328125\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:30:57 (running for 00:18:03.23)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 173/infinite (105 PENDING, 4 RUNNING, 64 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00063 | RUNNING    | 155.246.89.124:17567 |     2.45746e-06 |                  5 |                            32 | 20.4685  |     1.56817 |\n",
      "| _objective_69dd6_00065 | RUNNING    | 155.246.89.124:17652 |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | RUNNING    | 155.246.89.124:17691 |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | RUNNING    | 155.246.89.124:17739 |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | PENDING    |                      |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | PENDING    |                      |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | PENDING    |                      |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | PENDING    |                      |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 153 more trials not shown (97 PENDING, 56 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:31:02 (running for 00:18:08.27)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 173/infinite (105 PENDING, 4 RUNNING, 64 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00063 | RUNNING    | 155.246.89.124:17567 |     2.45746e-06 |                  5 |                            32 | 20.4685  |     1.56817 |\n",
      "| _objective_69dd6_00065 | RUNNING    | 155.246.89.124:17652 |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | RUNNING    | 155.246.89.124:17691 |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | RUNNING    | 155.246.89.124:17739 |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | PENDING    |                      |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | PENDING    |                      |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | PENDING    |                      |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | PENDING    |                      |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | PENDING    |                      |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 153 more trials not shown (97 PENDING, 56 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(_objective pid=17567)\u001b[0m {'train_runtime': 91.296, 'train_samples_per_second': 200.885, 'train_steps_per_second': 6.298, 'train_loss': 0.5692047583538553, 'epoch': 5.0}\n",
      "Result for _objective_69dd6_00063:\n",
      "  date: 2022-07-21_18-30-52\n",
      "  done: true\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.7377450980392157\n",
      "  eval_f1: 0.8304278922345483\n",
      "  eval_loss: 0.5274462103843689\n",
      "  eval_runtime: 0.7047\n",
      "  eval_samples_per_second: 579.003\n",
      "  eval_steps_per_second: 72.375\n",
      "  experiment_id: 831e627e481e46c39e91e63c0b7b5691\n",
      "  experiment_tag: 63_learning_rate=0.0000,num_train_epochs=5,per_device_train_batch_size=32,seed=20.4685\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.568172990273764\n",
      "  pid: 17567\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 83.36274766921997\n",
      "  time_this_iter_s: 83.36274766921997\n",
      "  time_total_s: 83.36274766921997\n",
      "  timestamp: 1658453452\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00063\n",
      "  warmup_time: 0.00409698486328125\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=17739)\u001b[0m {'train_runtime': 51.6944, 'train_samples_per_second': 212.866, 'train_steps_per_second': 6.674, 'train_loss': 0.451590673474298, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=17739)\u001b[0m {'eval_loss': 0.40495121479034424, 'eval_accuracy': 0.8235294117647058, 'eval_f1': 0.8758620689655173, 'eval_runtime': 0.696, 'eval_samples_per_second': 586.236, 'eval_steps_per_second': 73.279, 'epoch': 3.0}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:31:10 (running for 00:18:16.86)\n",
      "Memory usage on this node: 23.4/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 174/infinite (105 PENDING, 4 RUNNING, 65 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00065 | RUNNING    | 155.246.89.124:17652 |     7.60181e-05 |                  5 |                            16 | 11.9029  |             |\n",
      "| _objective_69dd6_00066 | RUNNING    | 155.246.89.124:17691 |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00067 | RUNNING    | 155.246.89.124:17739 |     1.27506e-05 |                  3 |                            32 | 39.2329  |             |\n",
      "| _objective_69dd6_00068 | RUNNING    | 155.246.89.124:17903 |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | PENDING    |                      |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | PENDING    |                      |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | PENDING    |                      |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | PENDING    |                      |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | PENDING    |                      |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00076 | PENDING    |                      |     5.93245e-05 |                  4 |                            16 | 23.5757  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 154 more trials not shown (97 PENDING, 57 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17903)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=17903)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17903)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17903)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=17903)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00067:\n",
      "  date: 2022-07-21_18-31-11\n",
      "  done: true\n",
      "  epoch: 3.0\n",
      "  eval_accuracy: 0.8235294117647058\n",
      "  eval_f1: 0.8758620689655173\n",
      "  eval_loss: 0.40495121479034424\n",
      "  eval_runtime: 0.696\n",
      "  eval_samples_per_second: 586.236\n",
      "  eval_steps_per_second: 73.279\n",
      "  experiment_id: 722bd3104ab24f2e91a9105af8c2ad54\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.699391480730223\n",
      "  pid: 17739\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 59.62249517440796\n",
      "  time_this_iter_s: 59.62249517440796\n",
      "  time_total_s: 59.62249517440796\n",
      "  timestamp: 1658453471\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00067\n",
      "  warmup_time: 0.004449129104614258\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17903)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=17903)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17652)\u001b[0m {'loss': 0.2682, 'learning_rate': 9.91540795696083e-06, 'epoch': 4.35}\n",
      "\u001b[2m\u001b[36m(_objective pid=17652)\u001b[0m {'eval_loss': 0.6045624017715454, 'eval_accuracy': 0.875, 'eval_f1': 0.9125214408233276, 'eval_runtime': 0.7163, 'eval_samples_per_second': 569.594, 'eval_steps_per_second': 71.199, 'epoch': 4.35}\n",
      "Result for _objective_69dd6_00065:\n",
      "  date: 2022-07-21_18-31-16\n",
      "  done: false\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.875\n",
      "  eval_f1: 0.9125214408233276\n",
      "  eval_loss: 0.6045624017715454\n",
      "  eval_runtime: 0.7163\n",
      "  eval_samples_per_second: 569.594\n",
      "  eval_steps_per_second: 71.199\n",
      "  experiment_id: befb6afde34c42328972a00d5172d7ba\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.7875214408233275\n",
      "  pid: 17652\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 85.03163027763367\n",
      "  time_this_iter_s: 85.03163027763367\n",
      "  time_total_s: 85.03163027763367\n",
      "  timestamp: 1658453476\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00065\n",
      "  warmup_time: 0.00374603271484375\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:31:16 (running for 00:18:22.50)\n",
      "Memory usage on this node: 23.2/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 175/infinite (105 PENDING, 4 RUNNING, 66 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00065 | RUNNING    | 155.246.89.124:17652 |     7.60181e-05 |                  5 |                            16 | 11.9029  |     1.78752 |\n",
      "| _objective_69dd6_00066 | RUNNING    | 155.246.89.124:17691 |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00068 | RUNNING    | 155.246.89.124:17903 |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | RUNNING    | 155.246.89.124:17943 |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | PENDING    |                      |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | PENDING    |                      |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | PENDING    |                      |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | PENDING    |                      |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00076 | PENDING    |                      |     5.93245e-05 |                  4 |                            16 | 23.5757  |             |\n",
      "| _objective_69dd6_00077 | PENDING    |                      |     8.53485e-06 |                  5 |                             8 | 33.7184  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 155 more trials not shown (97 PENDING, 58 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17943)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=17943)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17943)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17943)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=17943)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=17943)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=17943)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17691)\u001b[0m {'loss': 0.3, 'learning_rate': 4.0816049362471356e-06, 'epoch': 4.35}\n",
      "\u001b[2m\u001b[36m(_objective pid=17691)\u001b[0m {'eval_loss': 0.5637134909629822, 'eval_accuracy': 0.8578431372549019, 'eval_f1': 0.8993055555555555, 'eval_runtime': 0.7099, 'eval_samples_per_second': 574.725, 'eval_steps_per_second': 71.841, 'epoch': 4.35}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:31:21 (running for 00:18:27.52)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 175/infinite (105 PENDING, 4 RUNNING, 66 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00065 | RUNNING    | 155.246.89.124:17652 |     7.60181e-05 |                  5 |                            16 | 11.9029  |     1.78752 |\n",
      "| _objective_69dd6_00066 | RUNNING    | 155.246.89.124:17691 |     3.12923e-05 |                  5 |                             4 | 37.2044  |             |\n",
      "| _objective_69dd6_00068 | RUNNING    | 155.246.89.124:17903 |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | RUNNING    | 155.246.89.124:17943 |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | PENDING    |                      |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | PENDING    |                      |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | PENDING    |                      |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | PENDING    |                      |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00076 | PENDING    |                      |     5.93245e-05 |                  4 |                            16 | 23.5757  |             |\n",
      "| _objective_69dd6_00077 | PENDING    |                      |     8.53485e-06 |                  5 |                             8 | 33.7184  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 155 more trials not shown (97 PENDING, 58 TERMINATED)\n",
      "\n",
      "\n",
      "Result for _objective_69dd6_00066:\n",
      "  date: 2022-07-21_18-31-22\n",
      "  done: false\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.8578431372549019\n",
      "  eval_f1: 0.8993055555555555\n",
      "  eval_loss: 0.5637134909629822\n",
      "  eval_runtime: 0.7099\n",
      "  eval_samples_per_second: 574.725\n",
      "  eval_steps_per_second: 71.841\n",
      "  experiment_id: 59706dc711de4786a70339600b1b2614\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.7571486928104574\n",
      "  pid: 17691\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 84.81545829772949\n",
      "  time_this_iter_s: 84.81545829772949\n",
      "  time_total_s: 84.81545829772949\n",
      "  timestamp: 1658453482\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00066\n",
      "  warmup_time: 0.004529237747192383\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:31:27 (running for 00:18:33.85)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 175/infinite (105 PENDING, 4 RUNNING, 66 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00065 | RUNNING    | 155.246.89.124:17652 |     7.60181e-05 |                  5 |                            16 | 11.9029  |     1.78752 |\n",
      "| _objective_69dd6_00066 | RUNNING    | 155.246.89.124:17691 |     3.12923e-05 |                  5 |                             4 | 37.2044  |     1.75715 |\n",
      "| _objective_69dd6_00068 | RUNNING    | 155.246.89.124:17903 |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | RUNNING    | 155.246.89.124:17943 |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | PENDING    |                      |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | PENDING    |                      |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | PENDING    |                      |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | PENDING    |                      |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | PENDING    |                      |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00076 | PENDING    |                      |     5.93245e-05 |                  4 |                            16 | 23.5757  |             |\n",
      "| _objective_69dd6_00077 | PENDING    |                      |     8.53485e-06 |                  5 |                             8 | 33.7184  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 155 more trials not shown (97 PENDING, 58 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00065:\n",
      "  date: 2022-07-21_18-31-16\n",
      "  done: true\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.875\n",
      "  eval_f1: 0.9125214408233276\n",
      "  eval_loss: 0.6045624017715454\n",
      "  eval_runtime: 0.7163\n",
      "  eval_samples_per_second: 569.594\n",
      "  eval_steps_per_second: 71.199\n",
      "  experiment_id: befb6afde34c42328972a00d5172d7ba\n",
      "  experiment_tag: 65_learning_rate=0.0001,num_train_epochs=5,per_device_train_batch_size=16,seed=11.9029\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.7875214408233275\n",
      "  pid: 17652\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 85.03163027763367\n",
      "  time_this_iter_s: 85.03163027763367\n",
      "  time_total_s: 85.03163027763367\n",
      "  timestamp: 1658453476\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00065\n",
      "  warmup_time: 0.00374603271484375\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=17652)\u001b[0m {'train_runtime': 92.9745, 'train_samples_per_second': 197.258, 'train_steps_per_second': 6.184, 'train_loss': 0.23954330734584642, 'epoch': 5.0}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:31:34 (running for 00:18:40.88)\n",
      "Memory usage on this node: 23.2/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 176/infinite (105 PENDING, 4 RUNNING, 67 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00066 | RUNNING    | 155.246.89.124:17691 |     3.12923e-05 |                  5 |                             4 | 37.2044  |     1.75715 |\n",
      "| _objective_69dd6_00068 | RUNNING    | 155.246.89.124:17903 |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | RUNNING    | 155.246.89.124:17943 |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | RUNNING    | 155.246.89.124:17995 |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | PENDING    |                      |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | PENDING    |                      |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | PENDING    |                      |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | PENDING    |                      |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00076 | PENDING    |                      |     5.93245e-05 |                  4 |                            16 | 23.5757  |             |\n",
      "| _objective_69dd6_00077 | PENDING    |                      |     8.53485e-06 |                  5 |                             8 | 33.7184  |             |\n",
      "| _objective_69dd6_00078 | PENDING    |                      |     1.1508e-06  |                  4 |                            16 |  2.51455 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 156 more trials not shown (97 PENDING, 59 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17995)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=17995)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17995)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=17995)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=17995)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00066:\n",
      "  date: 2022-07-21_18-31-22\n",
      "  done: true\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.8578431372549019\n",
      "  eval_f1: 0.8993055555555555\n",
      "  eval_loss: 0.5637134909629822\n",
      "  eval_runtime: 0.7099\n",
      "  eval_samples_per_second: 574.725\n",
      "  eval_steps_per_second: 71.841\n",
      "  experiment_id: 59706dc711de4786a70339600b1b2614\n",
      "  experiment_tag: 66_learning_rate=0.0000,num_train_epochs=5,per_device_train_batch_size=4,seed=37.2044\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.7571486928104574\n",
      "  pid: 17691\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 84.81545829772949\n",
      "  time_this_iter_s: 84.81545829772949\n",
      "  time_total_s: 84.81545829772949\n",
      "  timestamp: 1658453482\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00066\n",
      "  warmup_time: 0.004529237747192383\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=17691)\u001b[0m {'train_runtime': 92.4165, 'train_samples_per_second': 198.449, 'train_steps_per_second': 6.222, 'train_loss': 0.2706667485444442, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17995)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=17995)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:31:42 (running for 00:18:47.91)\n",
      "Memory usage on this node: 23.2/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 177/infinite (105 PENDING, 4 RUNNING, 68 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00068 | RUNNING    | 155.246.89.124:17903 |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | RUNNING    | 155.246.89.124:17943 |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | RUNNING    | 155.246.89.124:17995 |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | RUNNING    | 155.246.89.124:18034 |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | PENDING    |                      |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | PENDING    |                      |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | PENDING    |                      |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00076 | PENDING    |                      |     5.93245e-05 |                  4 |                            16 | 23.5757  |             |\n",
      "| _objective_69dd6_00077 | PENDING    |                      |     8.53485e-06 |                  5 |                             8 | 33.7184  |             |\n",
      "| _objective_69dd6_00078 | PENDING    |                      |     1.1508e-06  |                  4 |                            16 |  2.51455 |             |\n",
      "| _objective_69dd6_00079 | PENDING    |                      |     1.79523e-06 |                  1 |                            32 | 33.2869  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 157 more trials not shown (97 PENDING, 60 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=18034)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=18034)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=18034)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=18034)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=18034)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[2m\u001b[36m(_objective pid=18034)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=18034)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:31:47 (running for 00:18:52.92)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 177/infinite (105 PENDING, 4 RUNNING, 68 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00068 | RUNNING    | 155.246.89.124:17903 |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | RUNNING    | 155.246.89.124:17943 |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | RUNNING    | 155.246.89.124:17995 |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | RUNNING    | 155.246.89.124:18034 |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | PENDING    |                      |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | PENDING    |                      |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | PENDING    |                      |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00076 | PENDING    |                      |     5.93245e-05 |                  4 |                            16 | 23.5757  |             |\n",
      "| _objective_69dd6_00077 | PENDING    |                      |     8.53485e-06 |                  5 |                             8 | 33.7184  |             |\n",
      "| _objective_69dd6_00078 | PENDING    |                      |     1.1508e-06  |                  4 |                            16 |  2.51455 |             |\n",
      "| _objective_69dd6_00079 | PENDING    |                      |     1.79523e-06 |                  1 |                            32 | 33.2869  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 157 more trials not shown (97 PENDING, 60 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:31:52 (running for 00:18:57.96)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 177/infinite (105 PENDING, 4 RUNNING, 68 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00068 | RUNNING    | 155.246.89.124:17903 |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00069 | RUNNING    | 155.246.89.124:17943 |     4.30372e-06 |                  2 |                             8 | 22.7152  |             |\n",
      "| _objective_69dd6_00070 | RUNNING    | 155.246.89.124:17995 |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | RUNNING    | 155.246.89.124:18034 |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | PENDING    |                      |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | PENDING    |                      |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | PENDING    |                      |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | PENDING    |                      |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00076 | PENDING    |                      |     5.93245e-05 |                  4 |                            16 | 23.5757  |             |\n",
      "| _objective_69dd6_00077 | PENDING    |                      |     8.53485e-06 |                  5 |                             8 | 33.7184  |             |\n",
      "| _objective_69dd6_00078 | PENDING    |                      |     1.1508e-06  |                  4 |                            16 |  2.51455 |             |\n",
      "| _objective_69dd6_00079 | PENDING    |                      |     1.79523e-06 |                  1 |                            32 | 33.2869  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 157 more trials not shown (97 PENDING, 60 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17943)\u001b[0m {'train_runtime': 34.8522, 'train_samples_per_second': 210.489, 'train_steps_per_second': 6.599, 'train_loss': 0.6032722141431726, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=17943)\u001b[0m {'eval_loss': 0.5540974736213684, 'eval_accuracy': 0.7156862745098039, 'eval_f1': 0.8268656716417911, 'eval_runtime': 0.6976, 'eval_samples_per_second': 584.86, 'eval_steps_per_second': 73.107, 'epoch': 2.0}\n",
      "Result for _objective_69dd6_00069:\n",
      "  date: 2022-07-21_18-31-56\n",
      "  done: true\n",
      "  epoch: 2.0\n",
      "  eval_accuracy: 0.7156862745098039\n",
      "  eval_f1: 0.8268656716417911\n",
      "  eval_loss: 0.5540974736213684\n",
      "  eval_runtime: 0.6976\n",
      "  eval_samples_per_second: 584.86\n",
      "  eval_steps_per_second: 73.107\n",
      "  experiment_id: 841380a03b4b4ec6974a499ea2712140\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.542551946151595\n",
      "  pid: 17943\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 42.42157959938049\n",
      "  time_this_iter_s: 42.42157959938049\n",
      "  time_total_s: 42.42157959938049\n",
      "  timestamp: 1658453516\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00069\n",
      "  warmup_time: 0.004594564437866211\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=18082)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=18082)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=18082)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=18082)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=18082)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:32:02 (running for 00:19:07.90)\n",
      "Memory usage on this node: 23.2/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 178/infinite (105 PENDING, 4 RUNNING, 69 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00068 | RUNNING    | 155.246.89.124:17903 |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00070 | RUNNING    | 155.246.89.124:17995 |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | RUNNING    | 155.246.89.124:18034 |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | RUNNING    | 155.246.89.124:18082 |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | PENDING    |                      |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | PENDING    |                      |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | PENDING    |                      |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00076 | PENDING    |                      |     5.93245e-05 |                  4 |                            16 | 23.5757  |             |\n",
      "| _objective_69dd6_00077 | PENDING    |                      |     8.53485e-06 |                  5 |                             8 | 33.7184  |             |\n",
      "| _objective_69dd6_00078 | PENDING    |                      |     1.1508e-06  |                  4 |                            16 |  2.51455 |             |\n",
      "| _objective_69dd6_00079 | PENDING    |                      |     1.79523e-06 |                  1 |                            32 | 33.2869  |             |\n",
      "| _objective_69dd6_00080 | PENDING    |                      |     2.70173e-06 |                  5 |                            64 | 18.8333  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 158 more trials not shown (97 PENDING, 61 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=18082)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=18082)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:32:07 (running for 00:19:12.95)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 178/infinite (105 PENDING, 4 RUNNING, 69 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00068 | RUNNING    | 155.246.89.124:17903 |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00070 | RUNNING    | 155.246.89.124:17995 |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | RUNNING    | 155.246.89.124:18034 |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | RUNNING    | 155.246.89.124:18082 |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | PENDING    |                      |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | PENDING    |                      |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | PENDING    |                      |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00076 | PENDING    |                      |     5.93245e-05 |                  4 |                            16 | 23.5757  |             |\n",
      "| _objective_69dd6_00077 | PENDING    |                      |     8.53485e-06 |                  5 |                             8 | 33.7184  |             |\n",
      "| _objective_69dd6_00078 | PENDING    |                      |     1.1508e-06  |                  4 |                            16 |  2.51455 |             |\n",
      "| _objective_69dd6_00079 | PENDING    |                      |     1.79523e-06 |                  1 |                            32 | 33.2869  |             |\n",
      "| _objective_69dd6_00080 | PENDING    |                      |     2.70173e-06 |                  5 |                            64 | 18.8333  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 158 more trials not shown (97 PENDING, 61 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:32:12 (running for 00:19:17.96)\n",
      "Memory usage on this node: 24.7/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 178/infinite (105 PENDING, 4 RUNNING, 69 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00068 | RUNNING    | 155.246.89.124:17903 |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00070 | RUNNING    | 155.246.89.124:17995 |     7.24492e-05 |                  2 |                             8 | 24.9853  |             |\n",
      "| _objective_69dd6_00071 | RUNNING    | 155.246.89.124:18034 |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | RUNNING    | 155.246.89.124:18082 |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | PENDING    |                      |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | PENDING    |                      |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | PENDING    |                      |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00076 | PENDING    |                      |     5.93245e-05 |                  4 |                            16 | 23.5757  |             |\n",
      "| _objective_69dd6_00077 | PENDING    |                      |     8.53485e-06 |                  5 |                             8 | 33.7184  |             |\n",
      "| _objective_69dd6_00078 | PENDING    |                      |     1.1508e-06  |                  4 |                            16 |  2.51455 |             |\n",
      "| _objective_69dd6_00079 | PENDING    |                      |     1.79523e-06 |                  1 |                            32 | 33.2869  |             |\n",
      "| _objective_69dd6_00080 | PENDING    |                      |     2.70173e-06 |                  5 |                            64 | 18.8333  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 158 more trials not shown (97 PENDING, 61 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17995)\u001b[0m {'train_runtime': 35.9762, 'train_samples_per_second': 203.912, 'train_steps_per_second': 6.393, 'train_loss': 0.3865083113960598, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=17995)\u001b[0m {'eval_loss': 0.32902276515960693, 'eval_accuracy': 0.8700980392156863, 'eval_f1': 0.9081455805892548, 'eval_runtime': 0.7132, 'eval_samples_per_second': 572.088, 'eval_steps_per_second': 71.511, 'epoch': 2.0}\n",
      "Result for _objective_69dd6_00070:\n",
      "  date: 2022-07-21_18-32-16\n",
      "  done: true\n",
      "  epoch: 2.0\n",
      "  eval_accuracy: 0.8700980392156863\n",
      "  eval_f1: 0.9081455805892548\n",
      "  eval_loss: 0.32902276515960693\n",
      "  eval_runtime: 0.7132\n",
      "  eval_samples_per_second: 572.088\n",
      "  eval_steps_per_second: 71.511\n",
      "  experiment_id: 0daf7358936d4ea99b072e6b22992753\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.778243619804941\n",
      "  pid: 17995\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 44.45774245262146\n",
      "  time_this_iter_s: 44.45774245262146\n",
      "  time_total_s: 44.45774245262146\n",
      "  timestamp: 1658453536\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00070\n",
      "  warmup_time: 0.0048198699951171875\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=18034)\u001b[0m {'train_runtime': 35.4899, 'train_samples_per_second': 206.707, 'train_steps_per_second': 6.481, 'train_loss': 0.6111123126486073, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=18034)\u001b[0m {'eval_loss': 0.5671584010124207, 'eval_accuracy': 0.7083333333333334, 'eval_f1': 0.8221225710014948, 'eval_runtime': 0.7108, 'eval_samples_per_second': 574.017, 'eval_steps_per_second': 71.752, 'epoch': 2.0}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:32:22 (running for 00:19:27.94)\n",
      "Memory usage on this node: 23.3/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 179/infinite (105 PENDING, 4 RUNNING, 70 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00068 | RUNNING    | 155.246.89.124:17903 |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00071 | RUNNING    | 155.246.89.124:18034 |     3.2235e-06  |                  2 |                             4 | 35.2175  |             |\n",
      "| _objective_69dd6_00072 | RUNNING    | 155.246.89.124:18082 |     4.98126e-05 |                  1 |                            64 | 28.3969  |             |\n",
      "| _objective_69dd6_00073 | RUNNING    | 155.246.89.124:18130 |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | PENDING    |                      |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | PENDING    |                      |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00076 | PENDING    |                      |     5.93245e-05 |                  4 |                            16 | 23.5757  |             |\n",
      "| _objective_69dd6_00077 | PENDING    |                      |     8.53485e-06 |                  5 |                             8 | 33.7184  |             |\n",
      "| _objective_69dd6_00078 | PENDING    |                      |     1.1508e-06  |                  4 |                            16 |  2.51455 |             |\n",
      "| _objective_69dd6_00079 | PENDING    |                      |     1.79523e-06 |                  1 |                            32 | 33.2869  |             |\n",
      "| _objective_69dd6_00080 | PENDING    |                      |     2.70173e-06 |                  5 |                            64 | 18.8333  |             |\n",
      "| _objective_69dd6_00081 | PENDING    |                      |     2.44771e-06 |                  3 |                            32 | 25.8598  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 159 more trials not shown (97 PENDING, 62 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=18130)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=18130)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=18130)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=18130)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=18130)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=18082)\u001b[0m {'train_runtime': 17.962, 'train_samples_per_second': 204.209, 'train_steps_per_second': 6.402, 'train_loss': 0.52468493917714, 'epoch': 1.0}\n",
      "Result for _objective_69dd6_00071:\n",
      "  date: 2022-07-21_18-32-22\n",
      "  done: true\n",
      "  epoch: 2.0\n",
      "  eval_accuracy: 0.7083333333333334\n",
      "  eval_f1: 0.8221225710014948\n",
      "  eval_loss: 0.5671584010124207\n",
      "  eval_runtime: 0.7108\n",
      "  eval_samples_per_second: 574.017\n",
      "  eval_steps_per_second: 71.752\n",
      "  experiment_id: a6dd3336b9c145bcb16aaa40294afae5\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.5304559043348283\n",
      "  pid: 18034\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 43.59377884864807\n",
      "  time_this_iter_s: 43.59377884864807\n",
      "  time_total_s: 43.59377884864807\n",
      "  timestamp: 1658453542\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00071\n",
      "  warmup_time: 0.004415035247802734\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=18082)\u001b[0m {'eval_loss': 0.4221910834312439, 'eval_accuracy': 0.8284313725490197, 'eval_f1': 0.8758865248226951, 'eval_runtime': 0.7073, 'eval_samples_per_second': 576.85, 'eval_steps_per_second': 72.106, 'epoch': 1.0}\n",
      "Result for _objective_69dd6_00072:\n",
      "  date: 2022-07-21_18-32-24\n",
      "  done: true\n",
      "  epoch: 1.0\n",
      "  eval_accuracy: 0.8284313725490197\n",
      "  eval_f1: 0.8758865248226951\n",
      "  eval_loss: 0.4221910834312439\n",
      "  eval_runtime: 0.7073\n",
      "  eval_samples_per_second: 576.85\n",
      "  eval_steps_per_second: 72.106\n",
      "  experiment_id: 034f3f0f8bd14fc0b6b053fb5d78cb06\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.7043178973717148\n",
      "  pid: 18082\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 25.632285356521606\n",
      "  time_this_iter_s: 25.632285356521606\n",
      "  time_total_s: 25.632285356521606\n",
      "  timestamp: 1658453544\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00072\n",
      "  warmup_time: 0.004385948181152344\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=18130)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=18130)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_objective pid=18170)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=18170)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=18170)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=18170)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=18170)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17903)\u001b[0m {'loss': 0.5404, 'learning_rate': 5.061639409459995e-07, 'epoch': 4.35}\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:32:30 (running for 00:19:35.92)\n",
      "Memory usage on this node: 23.0/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 181/infinite (105 PENDING, 4 RUNNING, 72 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00068 | RUNNING    | 155.246.89.124:17903 |     3.88059e-06 |                  5 |                             4 |  8.44553 |             |\n",
      "| _objective_69dd6_00073 | RUNNING    | 155.246.89.124:18130 |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | RUNNING    | 155.246.89.124:18170 |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | RUNNING    | 155.246.89.124:18204 |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00076 | PENDING    |                      |     5.93245e-05 |                  4 |                            16 | 23.5757  |             |\n",
      "| _objective_69dd6_00077 | PENDING    |                      |     8.53485e-06 |                  5 |                             8 | 33.7184  |             |\n",
      "| _objective_69dd6_00078 | PENDING    |                      |     1.1508e-06  |                  4 |                            16 |  2.51455 |             |\n",
      "| _objective_69dd6_00079 | PENDING    |                      |     1.79523e-06 |                  1 |                            32 | 33.2869  |             |\n",
      "| _objective_69dd6_00080 | PENDING    |                      |     2.70173e-06 |                  5 |                            64 | 18.8333  |             |\n",
      "| _objective_69dd6_00081 | PENDING    |                      |     2.44771e-06 |                  3 |                            32 | 25.8598  |             |\n",
      "| _objective_69dd6_00082 | PENDING    |                      |     1.84285e-06 |                  2 |                            16 | 21.1357  |             |\n",
      "| _objective_69dd6_00083 | PENDING    |                      |     3.89379e-05 |                  3 |                             8 | 18.1199  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 161 more trials not shown (97 PENDING, 64 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=18204)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=18204)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=18204)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=18204)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "\u001b[2m\u001b[36m(_objective pid=18204)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=17903)\u001b[0m {'eval_loss': 0.5103585124015808, 'eval_accuracy': 0.7720588235294118, 'eval_f1': 0.8482871125611746, 'eval_runtime': 0.7118, 'eval_samples_per_second': 573.216, 'eval_steps_per_second': 71.652, 'epoch': 4.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=18170)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=18170)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00068:\n",
      "  date: 2022-07-21_18-32-32\n",
      "  done: false\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.7720588235294118\n",
      "  eval_f1: 0.8482871125611746\n",
      "  eval_loss: 0.5103585124015808\n",
      "  eval_runtime: 0.7118\n",
      "  eval_samples_per_second: 573.216\n",
      "  eval_steps_per_second: 71.652\n",
      "  experiment_id: dd3b43c10e81457cbcbc61fb9b4b7b10\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.6203459360905863\n",
      "  pid: 17903\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 84.21447491645813\n",
      "  time_this_iter_s: 84.21447491645813\n",
      "  time_total_s: 84.21447491645813\n",
      "  timestamp: 1658453552\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00068\n",
      "  warmup_time: 0.003912210464477539\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=18204)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=18204)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:32:37 (running for 00:19:43.25)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 181/infinite (105 PENDING, 4 RUNNING, 72 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00068 | RUNNING    | 155.246.89.124:17903 |     3.88059e-06 |                  5 |                             4 |  8.44553 |     1.62035 |\n",
      "| _objective_69dd6_00073 | RUNNING    | 155.246.89.124:18130 |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | RUNNING    | 155.246.89.124:18170 |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | RUNNING    | 155.246.89.124:18204 |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00076 | PENDING    |                      |     5.93245e-05 |                  4 |                            16 | 23.5757  |             |\n",
      "| _objective_69dd6_00077 | PENDING    |                      |     8.53485e-06 |                  5 |                             8 | 33.7184  |             |\n",
      "| _objective_69dd6_00078 | PENDING    |                      |     1.1508e-06  |                  4 |                            16 |  2.51455 |             |\n",
      "| _objective_69dd6_00079 | PENDING    |                      |     1.79523e-06 |                  1 |                            32 | 33.2869  |             |\n",
      "| _objective_69dd6_00080 | PENDING    |                      |     2.70173e-06 |                  5 |                            64 | 18.8333  |             |\n",
      "| _objective_69dd6_00081 | PENDING    |                      |     2.44771e-06 |                  3 |                            32 | 25.8598  |             |\n",
      "| _objective_69dd6_00082 | PENDING    |                      |     1.84285e-06 |                  2 |                            16 | 21.1357  |             |\n",
      "| _objective_69dd6_00083 | PENDING    |                      |     3.89379e-05 |                  3 |                             8 | 18.1199  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 161 more trials not shown (97 PENDING, 64 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:32:42 (running for 00:19:48.28)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 181/infinite (105 PENDING, 4 RUNNING, 72 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00068 | RUNNING    | 155.246.89.124:17903 |     3.88059e-06 |                  5 |                             4 |  8.44553 |     1.62035 |\n",
      "| _objective_69dd6_00073 | RUNNING    | 155.246.89.124:18130 |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | RUNNING    | 155.246.89.124:18170 |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | RUNNING    | 155.246.89.124:18204 |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00076 | PENDING    |                      |     5.93245e-05 |                  4 |                            16 | 23.5757  |             |\n",
      "| _objective_69dd6_00077 | PENDING    |                      |     8.53485e-06 |                  5 |                             8 | 33.7184  |             |\n",
      "| _objective_69dd6_00078 | PENDING    |                      |     1.1508e-06  |                  4 |                            16 |  2.51455 |             |\n",
      "| _objective_69dd6_00079 | PENDING    |                      |     1.79523e-06 |                  1 |                            32 | 33.2869  |             |\n",
      "| _objective_69dd6_00080 | PENDING    |                      |     2.70173e-06 |                  5 |                            64 | 18.8333  |             |\n",
      "| _objective_69dd6_00081 | PENDING    |                      |     2.44771e-06 |                  3 |                            32 | 25.8598  |             |\n",
      "| _objective_69dd6_00082 | PENDING    |                      |     1.84285e-06 |                  2 |                            16 | 21.1357  |             |\n",
      "| _objective_69dd6_00083 | PENDING    |                      |     3.89379e-05 |                  3 |                             8 | 18.1199  |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 161 more trials not shown (97 PENDING, 64 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _objective_69dd6_00068:\n",
      "  date: 2022-07-21_18-32-32\n",
      "  done: true\n",
      "  epoch: 4.35\n",
      "  eval_accuracy: 0.7720588235294118\n",
      "  eval_f1: 0.8482871125611746\n",
      "  eval_loss: 0.5103585124015808\n",
      "  eval_runtime: 0.7118\n",
      "  eval_samples_per_second: 573.216\n",
      "  eval_steps_per_second: 71.652\n",
      "  experiment_id: dd3b43c10e81457cbcbc61fb9b4b7b10\n",
      "  experiment_tag: 68_learning_rate=0.0000,num_train_epochs=5,per_device_train_batch_size=4,seed=8.4455\n",
      "  hostname: tmdev\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 155.246.89.124\n",
      "  objective: 1.6203459360905863\n",
      "  pid: 17903\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 84.21447491645813\n",
      "  time_this_iter_s: 84.21447491645813\n",
      "  time_total_s: 84.21447491645813\n",
      "  timestamp: 1658453552\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 69dd6_00068\n",
      "  warmup_time: 0.003912210464477539\n",
      "  \n",
      "\u001b[2m\u001b[36m(_objective pid=17903)\u001b[0m {'train_runtime': 91.3858, 'train_samples_per_second': 200.688, 'train_steps_per_second': 6.292, 'train_loss': 0.5280312247898268, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=18259)\u001b[0m Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=18259)\u001b[0m - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "\u001b[2m\u001b[36m(_objective pid=18259)\u001b[0m - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[2m\u001b[36m(_objective pid=18259)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[2m\u001b[36m(_objective pid=18259)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:32:51 (running for 00:19:56.95)\n",
      "Memory usage on this node: 23.3/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4.0/96 CPUs, 4.0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 182/infinite (105 PENDING, 4 RUNNING, 73 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00073 | RUNNING    | 155.246.89.124:18130 |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | RUNNING    | 155.246.89.124:18170 |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | RUNNING    | 155.246.89.124:18204 |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00076 | RUNNING    | 155.246.89.124:18259 |     5.93245e-05 |                  4 |                            16 | 23.5757  |             |\n",
      "| _objective_69dd6_00077 | PENDING    |                      |     8.53485e-06 |                  5 |                             8 | 33.7184  |             |\n",
      "| _objective_69dd6_00078 | PENDING    |                      |     1.1508e-06  |                  4 |                            16 |  2.51455 |             |\n",
      "| _objective_69dd6_00079 | PENDING    |                      |     1.79523e-06 |                  1 |                            32 | 33.2869  |             |\n",
      "| _objective_69dd6_00080 | PENDING    |                      |     2.70173e-06 |                  5 |                            64 | 18.8333  |             |\n",
      "| _objective_69dd6_00081 | PENDING    |                      |     2.44771e-06 |                  3 |                            32 | 25.8598  |             |\n",
      "| _objective_69dd6_00082 | PENDING    |                      |     1.84285e-06 |                  2 |                            16 | 21.1357  |             |\n",
      "| _objective_69dd6_00083 | PENDING    |                      |     3.89379e-05 |                  3 |                             8 | 18.1199  |             |\n",
      "| _objective_69dd6_00084 | PENDING    |                      |     1.12383e-06 |                  5 |                             4 |  4.15405 |             |\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 162 more trials not shown (97 PENDING, 65 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=18259)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(_objective pid=18259)\u001b[0m   warnings.warn(\n",
      "2022-07-21 18:32:56,075\tINFO stopper.py:363 -- Reached timeout of 1200 seconds. Stopping all trials.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-07-21 18:32:56 (running for 00:20:02.21)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/96 CPUs, 0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 182/infinite (182 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "| _objective_69dd6_00008 | TERMINATED | 155.246.89.124:14759 |     1.53049e-05 |                  3 |                            64 | 34.5377  |     1.68137 |\n",
      "| _objective_69dd6_00009 | TERMINATED | 155.246.89.124:14807 |     7.96157e-06 |                  2 |                            32 | 38.0065  |     1.57833 |\n",
      "| _objective_69dd6_00010 | TERMINATED | 155.246.89.124:14843 |     1.33837e-05 |                  2 |                            64 | 12.8799  |     1.63668 |\n",
      "| _objective_69dd6_00011 | TERMINATED | 155.246.89.124:14985 |     2.89593e-06 |                  4 |                            32 | 18.1659  |     1.55369 |\n",
      "| _objective_69dd6_00012 | TERMINATED | 155.246.89.124:15035 |     9.78034e-06 |                  3 |                            32 | 36.4635  |     1.66281 |\n",
      "| _objective_69dd6_00013 | TERMINATED | 155.246.89.124:15074 |     2.31458e-06 |                  4 |                             8 | 13.1567  |     1.52516 |\n",
      "| _objective_69dd6_00014 | TERMINATED | 155.246.89.124:15080 |     1.36584e-05 |                  5 |                             8 | 38.8138  |     1.73753 |\n",
      "| _objective_69dd6_00015 | TERMINATED | 155.246.89.124:15176 |     7.93429e-06 |                  2 |                            32 | 35.8983  |     1.60453 |\n",
      "| _objective_69dd6_00016 | TERMINATED | 155.246.89.124:15216 |     1.23156e-06 |                  5 |                             8 | 16.1584  |     1.51791 |\n",
      "| _objective_69dd6_00017 | TERMINATED | 155.246.89.124:15266 |     1.20056e-05 |                  2 |                            32 | 38.645   |     1.65479 |\n",
      "| _objective_69dd6_00018 | TERMINATED | 155.246.89.124:15316 |     1.21728e-05 |                  1 |                            64 | 12.5547  |     1.55314 |\n",
      "| _objective_69dd6_00019 | TERMINATED | 155.246.89.124:15351 |     1.40962e-06 |                  1 |                            32 | 31.1175  |     1.49605 |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "... 162 more trials not shown (162 TERMINATED)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-07-21 18:32:56 (running for 00:20:02.42)\n",
      "Memory usage on this node: 24.8/376.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/96 CPUs, 0/4 GPUs, 0.0/250.63 GiB heap, 0.0/111.41 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/_objective_2022-07-21_18-12-54\n",
      "Number of trials: 182/infinite (182 TERMINATED)\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "| Trial name             | status     | loc                  |   learning_rate |   num_train_epochs |   per_device_train_batch_size |     seed |   objective |\n",
      "|------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------|\n",
      "| _objective_69dd6_00000 | TERMINATED | 155.246.89.124:14389 |     5.61152e-06 |                  5 |                            64 |  8.15396 |     1.64976 |\n",
      "| _objective_69dd6_00001 | TERMINATED | 155.246.89.124:14428 |     1.56207e-05 |                  2 |                            16 |  7.08379 |     1.67665 |\n",
      "| _objective_69dd6_00002 | TERMINATED | 155.246.89.124:14429 |     8.28892e-06 |                  5 |                            16 | 24.4435  |     1.69756 |\n",
      "| _objective_69dd6_00003 | TERMINATED | 155.246.89.124:14430 |     1.09943e-06 |                  2 |                             8 | 29.158   |     1.49187 |\n",
      "| _objective_69dd6_00004 | TERMINATED | 155.246.89.124:14570 |     2.3102e-06  |                  5 |                             8 | 25.0818  |     1.51997 |\n",
      "| _objective_69dd6_00005 | TERMINATED | 155.246.89.124:14603 |     1.12076e-05 |                  4 |                            16 |  1.89943 |     1.66879 |\n",
      "| _objective_69dd6_00006 | TERMINATED | 155.246.89.124:14670 |     1.67381e-05 |                  2 |                            32 |  2.81996 |     1.68706 |\n",
      "| _objective_69dd6_00007 | TERMINATED | 155.246.89.124:14706 |     5.4041e-06  |                  3 |                            32 | 15.916   |     1.57411 |\n",
      "| _objective_69dd6_00008 | TERMINATED | 155.246.89.124:14759 |     1.53049e-05 |                  3 |                            64 | 34.5377  |     1.68137 |\n",
      "| _objective_69dd6_00009 | TERMINATED | 155.246.89.124:14807 |     7.96157e-06 |                  2 |                            32 | 38.0065  |     1.57833 |\n",
      "| _objective_69dd6_00010 | TERMINATED | 155.246.89.124:14843 |     1.33837e-05 |                  2 |                            64 | 12.8799  |     1.63668 |\n",
      "| _objective_69dd6_00011 | TERMINATED | 155.246.89.124:14985 |     2.89593e-06 |                  4 |                            32 | 18.1659  |     1.55369 |\n",
      "| _objective_69dd6_00012 | TERMINATED | 155.246.89.124:15035 |     9.78034e-06 |                  3 |                            32 | 36.4635  |     1.66281 |\n",
      "| _objective_69dd6_00013 | TERMINATED | 155.246.89.124:15074 |     2.31458e-06 |                  4 |                             8 | 13.1567  |     1.52516 |\n",
      "| _objective_69dd6_00014 | TERMINATED | 155.246.89.124:15080 |     1.36584e-05 |                  5 |                             8 | 38.8138  |     1.73753 |\n",
      "| _objective_69dd6_00015 | TERMINATED | 155.246.89.124:15176 |     7.93429e-06 |                  2 |                            32 | 35.8983  |     1.60453 |\n",
      "| _objective_69dd6_00016 | TERMINATED | 155.246.89.124:15216 |     1.23156e-06 |                  5 |                             8 | 16.1584  |     1.51791 |\n",
      "| _objective_69dd6_00017 | TERMINATED | 155.246.89.124:15266 |     1.20056e-05 |                  2 |                            32 | 38.645   |     1.65479 |\n",
      "| _objective_69dd6_00018 | TERMINATED | 155.246.89.124:15316 |     1.21728e-05 |                  1 |                            64 | 12.5547  |     1.55314 |\n",
      "| _objective_69dd6_00019 | TERMINATED | 155.246.89.124:15351 |     1.40962e-06 |                  1 |                            32 | 31.1175  |     1.49605 |\n",
      "| _objective_69dd6_00020 | TERMINATED | 155.246.89.124:15404 |     3.86346e-06 |                  3 |                            16 |  8.75485 |     1.54734 |\n",
      "| _objective_69dd6_00021 | TERMINATED | 155.246.89.124:15438 |     3.80497e-05 |                  3 |                             8 |  3.88774 |     1.7228  |\n",
      "| _objective_69dd6_00022 | TERMINATED | 155.246.89.124:15479 |     1.70505e-06 |                  1 |                             8 | 25.3086  |     1.49605 |\n",
      "| _objective_69dd6_00023 | TERMINATED | 155.246.89.124:15537 |     1.55174e-06 |                  5 |                            16 | 29.4546  |     1.52417 |\n",
      "| _objective_69dd6_00024 | TERMINATED | 155.246.89.124:15569 |     1.32583e-05 |                  3 |                            16 |  5.66418 |     1.68273 |\n",
      "| _objective_69dd6_00025 | TERMINATED | 155.246.89.124:15637 |     3.3233e-05  |                  2 |                            16 | 10.2034  |     1.74913 |\n",
      "| _objective_69dd6_00026 | TERMINATED | 155.246.89.124:15669 |     1.11036e-05 |                  2 |                            64 |  1.99135 |     1.59809 |\n",
      "| _objective_69dd6_00027 | TERMINATED | 155.246.89.124:15727 |     2.53185e-06 |                  1 |                            32 | 13.2599  |     1.49605 |\n",
      "| _objective_69dd6_00028 | TERMINATED | 155.246.89.124:15774 |     6.53331e-05 |                  5 |                            64 | 22.0538  |     1.76319 |\n",
      "| _objective_69dd6_00029 | TERMINATED | 155.246.89.124:15776 |     2.86811e-06 |                  3 |                            32 | 28.0966  |     1.52721 |\n",
      "| _objective_69dd6_00030 | TERMINATED | 155.246.89.124:15860 |     7.23428e-05 |                  5 |                            64 | 12.5297  |     1.73927 |\n",
      "| _objective_69dd6_00031 | TERMINATED | 155.246.89.124:15896 |     5.5325e-05  |                  4 |                            32 |  9.51918 |     1.7153  |\n",
      "| _objective_69dd6_00032 | TERMINATED | 155.246.89.124:16047 |     6.09703e-05 |                  3 |                            32 | 13.6495  |     1.76286 |\n",
      "| _objective_69dd6_00033 | TERMINATED | 155.246.89.124:16103 |     5.15936e-06 |                  1 |                            16 | 11.6132  |     1.49605 |\n",
      "| _objective_69dd6_00034 | TERMINATED | 155.246.89.124:16140 |     7.14851e-06 |                  4 |                            16 | 14.7502  |     1.68525 |\n",
      "| _objective_69dd6_00035 | TERMINATED | 155.246.89.124:16188 |     1.03253e-06 |                  3 |                            64 | 17.279   |     1.49605 |\n",
      "| _objective_69dd6_00036 | TERMINATED | 155.246.89.124:16231 |     2.4259e-05  |                  2 |                            16 | 14.167   |     1.71808 |\n",
      "| _objective_69dd6_00037 | TERMINATED | 155.246.89.124:16264 |     4.43002e-06 |                  1 |                             4 | 16.7496  |     1.49605 |\n",
      "| _objective_69dd6_00038 | TERMINATED | 155.246.89.124:16320 |     3.21981e-06 |                  4 |                             8 | 10.8195  |     1.60656 |\n",
      "| _objective_69dd6_00039 | TERMINATED | 155.246.89.124:16365 |     2.65792e-05 |                  5 |                             4 | 12.1088  |     1.74768 |\n",
      "| _objective_69dd6_00040 | TERMINATED | 155.246.89.124:16411 |     3.41635e-06 |                  2 |                            64 | 20.6045  |     1.54838 |\n",
      "| _objective_69dd6_00041 | TERMINATED | 155.246.89.124:16446 |     4.8994e-06  |                  1 |                             8 | 10.3429  |     1.51738 |\n",
      "| _objective_69dd6_00042 | TERMINATED | 155.246.89.124:16501 |     1.15311e-05 |                  2 |                            32 | 39.4404  |     1.65163 |\n",
      "| _objective_69dd6_00043 | TERMINATED | 155.246.89.124:16546 |     1.45113e-06 |                  3 |                            64 | 10.4442  |     1.50332 |\n",
      "| _objective_69dd6_00044 | TERMINATED | 155.246.89.124:16590 |     1.83913e-05 |                  3 |                             4 | 32.8408  |     1.7015  |\n",
      "| _objective_69dd6_00045 | TERMINATED | 155.246.89.124:16640 |     2.00187e-06 |                  3 |                            64 |  8.27422 |     1.52104 |\n",
      "| _objective_69dd6_00046 | TERMINATED | 155.246.89.124:16682 |     5.20856e-05 |                  4 |                            16 | 27.425   |     1.74514 |\n",
      "| _objective_69dd6_00047 | TERMINATED | 155.246.89.124:16728 |     2.64423e-05 |                  3 |                            32 | 14.598   |     1.79065 |\n",
      "| _objective_69dd6_00048 | TERMINATED | 155.246.89.124:16781 |     7.60408e-05 |                  2 |                            16 | 33.6707  |     1.78661 |\n",
      "| _objective_69dd6_00049 | TERMINATED | 155.246.89.124:16829 |     4.80986e-06 |                  1 |                             8 |  9.15379 |     1.49605 |\n",
      "| _objective_69dd6_00050 | TERMINATED | 155.246.89.124:16969 |     3.28007e-06 |                  4 |                             4 |  7.82324 |     1.57082 |\n",
      "| _objective_69dd6_00051 | TERMINATED | 155.246.89.124:17010 |     1.07962e-05 |                  1 |                            32 | 10.4322  |     1.56759 |\n",
      "| _objective_69dd6_00052 | TERMINATED | 155.246.89.124:17045 |     1.30794e-05 |                  3 |                             4 |  8.35958 |     1.67839 |\n",
      "| _objective_69dd6_00053 | TERMINATED | 155.246.89.124:17081 |     4.99366e-06 |                  3 |                             4 | 34.3966  |     1.56602 |\n",
      "| _objective_69dd6_00054 | TERMINATED | 155.246.89.124:17140 |     1.92337e-05 |                  3 |                            32 | 37.4898  |     1.73392 |\n",
      "| _objective_69dd6_00055 | TERMINATED | 155.246.89.124:17198 |     6.2677e-05  |                  4 |                             4 | 23.6468  |     1.77612 |\n",
      "| _objective_69dd6_00056 | TERMINATED | 155.246.89.124:17200 |     2.12326e-05 |                  5 |                             8 | 12.0729  |     1.73602 |\n",
      "| _objective_69dd6_00057 | TERMINATED | 155.246.89.124:17280 |     9.35896e-06 |                  3 |                             4 | 26.4265  |     1.67622 |\n",
      "| _objective_69dd6_00058 | TERMINATED | 155.246.89.124:17323 |     2.24828e-06 |                  4 |                            64 | 10.2527  |     1.57677 |\n",
      "| _objective_69dd6_00059 | TERMINATED | 155.246.89.124:17383 |     2.27848e-06 |                  3 |                             4 | 26.6469  |     1.53515 |\n",
      "| _objective_69dd6_00060 | TERMINATED | 155.246.89.124:17415 |     1.21641e-05 |                  3 |                            64 | 15.3409  |     1.69921 |\n",
      "| _objective_69dd6_00061 | TERMINATED | 155.246.89.124:17470 |     9.40772e-06 |                  3 |                            64 | 17.9414  |     1.65596 |\n",
      "| _objective_69dd6_00062 | TERMINATED | 155.246.89.124:17510 |     1.01222e-05 |                  4 |                             4 | 27.088   |     1.67404 |\n",
      "| _objective_69dd6_00063 | TERMINATED | 155.246.89.124:17567 |     2.45746e-06 |                  5 |                            32 | 20.4685  |     1.56817 |\n",
      "| _objective_69dd6_00064 | TERMINATED | 155.246.89.124:17569 |     1.11849e-06 |                  1 |                            32 |  2.70055 |     1.49605 |\n",
      "| _objective_69dd6_00065 | TERMINATED | 155.246.89.124:17652 |     7.60181e-05 |                  5 |                            16 | 11.9029  |     1.78752 |\n",
      "| _objective_69dd6_00066 | TERMINATED | 155.246.89.124:17691 |     3.12923e-05 |                  5 |                             4 | 37.2044  |     1.75715 |\n",
      "| _objective_69dd6_00067 | TERMINATED | 155.246.89.124:17739 |     1.27506e-05 |                  3 |                            32 | 39.2329  |     1.69939 |\n",
      "| _objective_69dd6_00068 | TERMINATED | 155.246.89.124:17903 |     3.88059e-06 |                  5 |                             4 |  8.44553 |     1.62035 |\n",
      "| _objective_69dd6_00069 | TERMINATED | 155.246.89.124:17943 |     4.30372e-06 |                  2 |                             8 | 22.7152  |     1.54255 |\n",
      "| _objective_69dd6_00070 | TERMINATED | 155.246.89.124:17995 |     7.24492e-05 |                  2 |                             8 | 24.9853  |     1.77824 |\n",
      "| _objective_69dd6_00071 | TERMINATED | 155.246.89.124:18034 |     3.2235e-06  |                  2 |                             4 | 35.2175  |     1.53046 |\n",
      "| _objective_69dd6_00072 | TERMINATED | 155.246.89.124:18082 |     4.98126e-05 |                  1 |                            64 | 28.3969  |     1.70432 |\n",
      "| _objective_69dd6_00073 | TERMINATED | 155.246.89.124:18130 |     3.9176e-06  |                  2 |                             4 | 32.5944  |             |\n",
      "| _objective_69dd6_00074 | TERMINATED | 155.246.89.124:18170 |     1.6712e-05  |                  4 |                             4 | 20.9424  |             |\n",
      "| _objective_69dd6_00075 | TERMINATED | 155.246.89.124:18204 |     1.80214e-05 |                  4 |                            32 | 26.3486  |             |\n",
      "| _objective_69dd6_00076 | TERMINATED | 155.246.89.124:18259 |     5.93245e-05 |                  4 |                            16 | 23.5757  |             |\n",
      "| _objective_69dd6_00077 | TERMINATED |                      |     8.53485e-06 |                  5 |                             8 | 33.7184  |             |\n",
      "| _objective_69dd6_00078 | TERMINATED |                      |     1.1508e-06  |                  4 |                            16 |  2.51455 |             |\n",
      "| _objective_69dd6_00079 | TERMINATED |                      |     1.79523e-06 |                  1 |                            32 | 33.2869  |             |\n",
      "| _objective_69dd6_00080 | TERMINATED |                      |     2.70173e-06 |                  5 |                            64 | 18.8333  |             |\n",
      "| _objective_69dd6_00081 | TERMINATED |                      |     2.44771e-06 |                  3 |                            32 | 25.8598  |             |\n",
      "| _objective_69dd6_00082 | TERMINATED |                      |     1.84285e-06 |                  2 |                            16 | 21.1357  |             |\n",
      "| _objective_69dd6_00083 | TERMINATED |                      |     3.89379e-05 |                  3 |                             8 | 18.1199  |             |\n",
      "| _objective_69dd6_00084 | TERMINATED |                      |     1.12383e-06 |                  5 |                             4 |  4.15405 |             |\n",
      "| _objective_69dd6_00085 | TERMINATED |                      |     2.38232e-05 |                  1 |                             4 |  7.75848 |             |\n",
      "| _objective_69dd6_00086 | TERMINATED |                      |     7.66839e-06 |                  1 |                            64 | 26.7477  |             |\n",
      "| _objective_69dd6_00087 | TERMINATED |                      |     1.89035e-05 |                  5 |                            64 | 29.778   |             |\n",
      "| _objective_69dd6_00088 | TERMINATED |                      |     1.67279e-05 |                  3 |                            16 | 10.6615  |             |\n",
      "| _objective_69dd6_00089 | TERMINATED |                      |     3.27863e-05 |                  1 |                            32 | 14.3333  |             |\n",
      "| _objective_69dd6_00090 | TERMINATED |                      |     1.23596e-06 |                  1 |                            32 | 13.1451  |             |\n",
      "| _objective_69dd6_00091 | TERMINATED |                      |     2.24213e-06 |                  2 |                            64 | 30.7712  |             |\n",
      "| _objective_69dd6_00092 | TERMINATED |                      |     8.85001e-06 |                  1 |                            64 | 19.1223  |             |\n",
      "| _objective_69dd6_00093 | TERMINATED |                      |     6.26628e-06 |                  2 |                            32 | 38.0167  |             |\n",
      "| _objective_69dd6_00094 | TERMINATED |                      |     1.23199e-06 |                  2 |                             8 | 25.4085  |             |\n",
      "| _objective_69dd6_00095 | TERMINATED |                      |     1.0048e-05  |                  5 |                             8 | 27.6746  |             |\n",
      "| _objective_69dd6_00096 | TERMINATED |                      |     1.12985e-06 |                  3 |                            32 | 32.237   |             |\n",
      "| _objective_69dd6_00097 | TERMINATED |                      |     5.97503e-06 |                  4 |                            64 |  6.01151 |             |\n",
      "| _objective_69dd6_00098 | TERMINATED |                      |     1.23377e-05 |                  5 |                             4 | 25.4116  |             |\n",
      "| _objective_69dd6_00099 | TERMINATED |                      |     8.36337e-05 |                  2 |                            64 |  9.06069 |             |\n",
      "| _objective_69dd6_00100 | TERMINATED |                      |     1.37633e-06 |                  2 |                             8 |  2.51956 |             |\n",
      "| _objective_69dd6_00101 | TERMINATED |                      |     2.32281e-05 |                  1 |                            64 | 26.5732  |             |\n",
      "| _objective_69dd6_00102 | TERMINATED |                      |     4.89498e-05 |                  2 |                            16 | 14.2844  |             |\n",
      "| _objective_69dd6_00103 | TERMINATED |                      |     3.66193e-06 |                  4 |                             8 | 28.0227  |             |\n",
      "| _objective_69dd6_00104 | TERMINATED |                      |     1.81086e-05 |                  5 |                             4 |  2.52827 |             |\n",
      "| _objective_69dd6_00105 | TERMINATED |                      |     4.0454e-05  |                  1 |                            64 | 22.3709  |             |\n",
      "| _objective_69dd6_00106 | TERMINATED |                      |     3.17124e-05 |                  3 |                            32 | 39.6297  |             |\n",
      "| _objective_69dd6_00107 | TERMINATED |                      |     5.54672e-06 |                  5 |                            64 | 10.3053  |             |\n",
      "| _objective_69dd6_00108 | TERMINATED |                      |     3.01868e-05 |                  3 |                             4 |  5.02183 |             |\n",
      "| _objective_69dd6_00109 | TERMINATED |                      |     1.17126e-05 |                  4 |                            64 | 33.2318  |             |\n",
      "| _objective_69dd6_00110 | TERMINATED |                      |     6.18083e-05 |                  1 |                            64 |  3.08593 |             |\n",
      "| _objective_69dd6_00111 | TERMINATED |                      |     6.46791e-05 |                  4 |                            32 | 14.8413  |             |\n",
      "| _objective_69dd6_00112 | TERMINATED |                      |     7.94555e-05 |                  4 |                            64 | 23.3641  |             |\n",
      "| _objective_69dd6_00113 | TERMINATED |                      |     1.52549e-06 |                  4 |                            16 | 13.8179  |             |\n",
      "| _objective_69dd6_00114 | TERMINATED |                      |     2.66352e-06 |                  5 |                             4 | 31.8716  |             |\n",
      "| _objective_69dd6_00115 | TERMINATED |                      |     1.68628e-06 |                  5 |                             8 | 20.2824  |             |\n",
      "| _objective_69dd6_00116 | TERMINATED |                      |     7.63943e-06 |                  5 |                             8 | 14.6857  |             |\n",
      "| _objective_69dd6_00117 | TERMINATED |                      |     8.65573e-05 |                  1 |                            32 | 30.6989  |             |\n",
      "| _objective_69dd6_00118 | TERMINATED |                      |     5.41673e-05 |                  5 |                             4 |  9.68048 |             |\n",
      "| _objective_69dd6_00119 | TERMINATED |                      |     4.40271e-05 |                  2 |                            64 |  6.71759 |             |\n",
      "| _objective_69dd6_00120 | TERMINATED |                      |     1.478e-06   |                  3 |                            64 | 23.6709  |             |\n",
      "| _objective_69dd6_00121 | TERMINATED |                      |     5.51168e-06 |                  4 |                             4 | 10.2307  |             |\n",
      "| _objective_69dd6_00122 | TERMINATED |                      |     1.52678e-05 |                  4 |                            16 | 15.6741  |             |\n",
      "| _objective_69dd6_00123 | TERMINATED |                      |     3.58339e-05 |                  3 |                            16 | 10.7002  |             |\n",
      "| _objective_69dd6_00124 | TERMINATED |                      |     1.66876e-06 |                  3 |                             8 | 10.8936  |             |\n",
      "| _objective_69dd6_00125 | TERMINATED |                      |     8.65608e-06 |                  2 |                            64 | 29.898   |             |\n",
      "| _objective_69dd6_00126 | TERMINATED |                      |     4.42161e-05 |                  1 |                            32 | 27.5605  |             |\n",
      "| _objective_69dd6_00127 | TERMINATED |                      |     8.40127e-05 |                  4 |                             4 | 12.1428  |             |\n",
      "| _objective_69dd6_00128 | TERMINATED |                      |     2.80022e-06 |                  2 |                            64 |  1.47402 |             |\n",
      "| _objective_69dd6_00129 | TERMINATED |                      |     1.21989e-06 |                  5 |                            64 |  2.69263 |             |\n",
      "| _objective_69dd6_00130 | TERMINATED |                      |     9.68121e-05 |                  5 |                            16 | 10.8666  |             |\n",
      "| _objective_69dd6_00131 | TERMINATED |                      |     8.68171e-05 |                  2 |                             4 |  7.4824  |             |\n",
      "| _objective_69dd6_00132 | TERMINATED |                      |     2.46319e-05 |                  1 |                            16 | 25.4748  |             |\n",
      "| _objective_69dd6_00133 | TERMINATED |                      |     6.34331e-05 |                  1 |                             8 | 36.6949  |             |\n",
      "| _objective_69dd6_00134 | TERMINATED |                      |     7.95835e-05 |                  4 |                            64 |  5.16349 |             |\n",
      "| _objective_69dd6_00135 | TERMINATED |                      |     3.58726e-06 |                  4 |                             8 | 26.2271  |             |\n",
      "| _objective_69dd6_00136 | TERMINATED |                      |     2.876e-06   |                  4 |                             4 |  4.03165 |             |\n",
      "| _objective_69dd6_00137 | TERMINATED |                      |     3.31055e-06 |                  3 |                             4 | 28.2283  |             |\n",
      "| _objective_69dd6_00138 | TERMINATED |                      |     3.62683e-06 |                  5 |                            32 | 32.738   |             |\n",
      "| _objective_69dd6_00139 | TERMINATED |                      |     3.48269e-06 |                  5 |                            64 | 36.5262  |             |\n",
      "| _objective_69dd6_00140 | TERMINATED |                      |     7.60438e-05 |                  3 |                             4 | 29.3031  |             |\n",
      "| _objective_69dd6_00141 | TERMINATED |                      |     6.86256e-06 |                  2 |                            64 | 22.5119  |             |\n",
      "| _objective_69dd6_00142 | TERMINATED |                      |     1.1291e-06  |                  1 |                             8 | 31.3265  |             |\n",
      "| _objective_69dd6_00143 | TERMINATED |                      |     9.43088e-05 |                  1 |                             8 | 15.6928  |             |\n",
      "| _objective_69dd6_00144 | TERMINATED |                      |     5.77806e-06 |                  3 |                            64 | 33.8426  |             |\n",
      "| _objective_69dd6_00145 | TERMINATED |                      |     1.33975e-06 |                  1 |                             4 | 17.178   |             |\n",
      "| _objective_69dd6_00146 | TERMINATED |                      |     1.06499e-06 |                  4 |                            64 | 32.7031  |             |\n",
      "| _objective_69dd6_00147 | TERMINATED |                      |     9.84631e-05 |                  5 |                            64 | 23.8208  |             |\n",
      "| _objective_69dd6_00148 | TERMINATED |                      |     7.7541e-05  |                  2 |                            64 | 15.7362  |             |\n",
      "| _objective_69dd6_00149 | TERMINATED |                      |     7.96321e-06 |                  1 |                            64 | 38.208   |             |\n",
      "| _objective_69dd6_00150 | TERMINATED |                      |     2.5969e-06  |                  1 |                             8 | 27.1963  |             |\n",
      "| _objective_69dd6_00151 | TERMINATED |                      |     5.20386e-06 |                  2 |                            16 | 20.4284  |             |\n",
      "| _objective_69dd6_00152 | TERMINATED |                      |     1.0973e-05  |                  4 |                            32 | 32.839   |             |\n",
      "| _objective_69dd6_00153 | TERMINATED |                      |     1.32396e-05 |                  3 |                            64 | 16.7358  |             |\n",
      "| _objective_69dd6_00154 | TERMINATED |                      |     1.74028e-05 |                  2 |                            32 | 32.3967  |             |\n",
      "| _objective_69dd6_00155 | TERMINATED |                      |     9.13956e-05 |                  2 |                            16 | 24.0068  |             |\n",
      "| _objective_69dd6_00156 | TERMINATED |                      |     1.52056e-06 |                  2 |                             4 | 14.582   |             |\n",
      "| _objective_69dd6_00157 | TERMINATED |                      |     3.69238e-05 |                  4 |                             8 | 12.6204  |             |\n",
      "| _objective_69dd6_00158 | TERMINATED |                      |     5.30551e-05 |                  5 |                             8 | 32.0624  |             |\n",
      "| _objective_69dd6_00159 | TERMINATED |                      |     7.13141e-05 |                  2 |                            32 | 30.9878  |             |\n",
      "| _objective_69dd6_00160 | TERMINATED |                      |     8.2846e-06  |                  2 |                             8 | 25.2114  |             |\n",
      "| _objective_69dd6_00161 | TERMINATED |                      |     4.54468e-06 |                  3 |                            16 | 23.6063  |             |\n",
      "| _objective_69dd6_00162 | TERMINATED |                      |     1.41816e-06 |                  1 |                            16 | 18.9446  |             |\n",
      "| _objective_69dd6_00163 | TERMINATED |                      |     1.8952e-06  |                  4 |                             4 |  8.09332 |             |\n",
      "| _objective_69dd6_00164 | TERMINATED |                      |     6.21694e-05 |                  3 |                             8 | 21.0942  |             |\n",
      "| _objective_69dd6_00165 | TERMINATED |                      |     1.59908e-05 |                  3 |                            64 |  2.59388 |             |\n",
      "| _objective_69dd6_00166 | TERMINATED |                      |     4.89965e-06 |                  2 |                            64 |  7.90341 |             |\n",
      "| _objective_69dd6_00167 | TERMINATED |                      |     1.2515e-05  |                  5 |                             8 | 18.9704  |             |\n",
      "| _objective_69dd6_00168 | TERMINATED |                      |     6.14376e-05 |                  1 |                            64 | 20.6333  |             |\n",
      "| _objective_69dd6_00169 | TERMINATED |                      |     4.39709e-06 |                  2 |                             4 | 32.177   |             |\n",
      "| _objective_69dd6_00170 | TERMINATED |                      |     2.37449e-05 |                  3 |                            64 | 36.914   |             |\n",
      "| _objective_69dd6_00171 | TERMINATED |                      |     1.01202e-06 |                  4 |                             4 | 32.4418  |             |\n",
      "| _objective_69dd6_00172 | TERMINATED |                      |     1.56515e-05 |                  4 |                             8 |  9.16462 |             |\n",
      "| _objective_69dd6_00173 | TERMINATED |                      |     3.31063e-05 |                  2 |                            16 | 30.1514  |             |\n",
      "| _objective_69dd6_00174 | TERMINATED |                      |     3.19797e-06 |                  3 |                            16 | 35.9131  |             |\n",
      "| _objective_69dd6_00175 | TERMINATED |                      |     1.15938e-05 |                  5 |                            16 | 34.8214  |             |\n",
      "| _objective_69dd6_00176 | TERMINATED |                      |     6.2277e-06  |                  1 |                            32 | 29.7588  |             |\n",
      "| _objective_69dd6_00177 | TERMINATED |                      |     1.09684e-06 |                  1 |                             8 | 33.7877  |             |\n",
      "| _objective_69dd6_00178 | TERMINATED |                      |     1.17671e-05 |                  1 |                            32 | 35.7306  |             |\n",
      "| _objective_69dd6_00179 | TERMINATED |                      |     8.87033e-06 |                  2 |                            64 | 31.7777  |             |\n",
      "| _objective_69dd6_00180 | TERMINATED |                      |     9.10257e-06 |                  4 |                             8 | 21.9472  |             |\n",
      "| _objective_69dd6_00181 | TERMINATED |                      |     1.30462e-05 |                  1 |                             8 | 23.0139  |             |\n",
      "+------------------------+------------+----------------------+-----------------+--------------------+-------------------------------+----------+-------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_objective pid=18130)\u001b[0m {'train_runtime': 36.538, 'train_samples_per_second': 200.777, 'train_steps_per_second': 6.295, 'train_loss': 0.6007047570270041, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=18130)\u001b[0m {'eval_loss': 0.5508173704147339, 'eval_accuracy': 0.7279411764705882, 'eval_f1': 0.8315629742033385, 'eval_runtime': 0.7217, 'eval_samples_per_second': 565.358, 'eval_steps_per_second': 70.67, 'epoch': 2.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=18204)\u001b[0m {'train_runtime': 68.8183, 'train_samples_per_second': 213.199, 'train_steps_per_second': 6.684, 'train_loss': 0.3360565185546875, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=18170)\u001b[0m {'train_runtime': 70.7138, 'train_samples_per_second': 207.484, 'train_steps_per_second': 6.505, 'train_loss': 0.39700443433678667, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=18204)\u001b[0m {'eval_loss': 0.39877229928970337, 'eval_accuracy': 0.8406862745098039, 'eval_f1': 0.8877374784110534, 'eval_runtime': 0.6981, 'eval_samples_per_second': 584.482, 'eval_steps_per_second': 73.06, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=18170)\u001b[0m {'eval_loss': 0.4371611773967743, 'eval_accuracy': 0.8186274509803921, 'eval_f1': 0.8732876712328768, 'eval_runtime': 0.7117, 'eval_samples_per_second': 573.27, 'eval_steps_per_second': 71.659, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=18259)\u001b[0m {'train_runtime': 69.959, 'train_samples_per_second': 209.723, 'train_steps_per_second': 6.575, 'train_loss': 0.2631151945694633, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(_objective pid=18259)\u001b[0m {'eval_loss': 0.5329757928848267, 'eval_accuracy': 0.8578431372549019, 'eval_f1': 0.902027027027027, 'eval_runtime': 0.7312, 'eval_samples_per_second': 558.01, 'eval_steps_per_second': 69.751, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 18:34:05,908\tINFO tune.py:747 -- Total run time: 1271.80 seconds (1202.22 seconds for the tuning loop).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BestRun(run_id='69dd6_00047', objective=1.7906454248366013, hyperparameters={'learning_rate': 2.6442290056449527e-05, 'num_train_epochs': 3, 'seed': 14.597973504377446, 'per_device_train_batch_size': 32})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from transformers import (AutoModelForSequenceClassification, AutoTokenizer,\n",
    "                          Trainer, TrainingArguments)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "dataset = load_dataset('glue', 'mrpc')\n",
    "metric = load_metric('glue', 'mrpc')\n",
    "\n",
    "def encode(examples):\n",
    "    outputs = tokenizer(\n",
    "        examples['sentence1'], examples['sentence2'], truncation=True)\n",
    "    return outputs\n",
    "\n",
    "encoded_dataset = dataset.map(encode, batched=True)\n",
    "\n",
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\n",
    "        'bert-base-uncased', return_dict=True)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = predictions.argmax(axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Evaluate during training and a bit more often\n",
    "# than the default to be able to prune bad trials early.\n",
    "# Disabling tqdm is a matter of preference.\n",
    "training_args = TrainingArguments(\n",
    "    \"test\", evaluation_strategy=\"steps\", eval_steps=500, disable_tqdm=True)\n",
    "trainer = Trainer(\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    model_init=model_init,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "# Default objective is the sum of all metrics\n",
    "# when metrics are provided, so we have to maximize it.\n",
    "trainer.hyperparameter_search(\n",
    "    local_dir=\"data/output/\",\n",
    "    time_budget_s=TIME_BUDGET,\n",
    "    direction=\"maximize\", \n",
    "    backend=\"ray\", \n",
    "    n_trials=-1, # number of trials,\n",
    "    keep_checkpoints_num=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 1.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 1.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.4211966209891772e-05, 'num_train_epochs': 0.22667066737595704, 'per_device_train_batch_size': 4, 'warmup_ratio': 0.0638407085008166, 'weight_decay': 0.24365576482793252, 'adam_epsilon': 1.2017005181798623e-08, 'seed': 44, 'global_max_steps': 567, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 1.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 0.00010969207855501012, 'num_train_epochs': 0.5341197058945968, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.00727467370977386, 'weight_decay': 0.2998042286577564, 'adam_epsilon': 2.5359832189101376e-08, 'seed': 44, 'global_max_steps': 168, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 0.00010969207855501012, 'num_train_epochs': 0.5341197058945968, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.00727467370977386, 'weight_decay': 0.2998042286577564, 'adam_epsilon': 2.5359832189101376e-08, 'seed': 44, 'global_max_steps': 168, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 6.105850155006292e-06, 'num_train_epochs': 0.5203392488419986, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.02982185620209511, 'weight_decay': 0.06967105125024514, 'adam_epsilon': 2.8808753274240916e-07, 'seed': 42, 'global_max_steps': 163, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 0.00010969207855501012, 'num_train_epochs': 0.5341197058945968, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.00727467370977386, 'weight_decay': 0.2998042286577564, 'adam_epsilon': 2.5359832189101376e-08, 'seed': 44, 'global_max_steps': 168, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 9.029571768192494e-05, 'num_train_epochs': 0.23081935882872334, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.05927331754619176, 'weight_decay': 0.06990187648448716, 'adam_epsilon': 2.6275569358808137e-08, 'seed': 41, 'global_max_steps': 145, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 0.00010969207855501012, 'num_train_epochs': 0.5341197058945968, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.00727467370977386, 'weight_decay': 0.2998042286577564, 'adam_epsilon': 2.5359832189101376e-08, 'seed': 44, 'global_max_steps': 168, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 0.00010208514406839324, 'num_train_epochs': 0.24916036398153807, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.28313267937361647, 'adam_epsilon': 1.5042842082223077e-08, 'seed': 44, 'global_max_steps': 78, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 0.00010969207855501012, 'num_train_epochs': 0.5341197058945968, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.00727467370977386, 'weight_decay': 0.2998042286577564, 'adam_epsilon': 2.5359832189101376e-08, 'seed': 44, 'global_max_steps': 168, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 0.00011786584823407102, 'num_train_epochs': 1.1449809097488275, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.015398649752204965, 'weight_decay': 0.3, 'adam_epsilon': 4.275263179285732e-08, 'seed': 43, 'global_max_steps': 313, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 0.00011786584823407102, 'num_train_epochs': 1.1449809097488275, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.015398649752204965, 'weight_decay': 0.3, 'adam_epsilon': 4.275263179285732e-08, 'seed': 43, 'global_max_steps': 313, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 3.59933640287326e-05, 'num_train_epochs': 1.7937390219164033, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.016745580745240057, 'weight_decay': 0.2892279950527897, 'adam_epsilon': 6.514301011066509e-08, 'seed': 44, 'global_max_steps': 313, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 3.59933640287326e-05, 'num_train_epochs': 1.7937390219164033, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.016745580745240057, 'weight_decay': 0.2892279950527897, 'adam_epsilon': 6.514301011066509e-08, 'seed': 44, 'global_max_steps': 313, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.4736175808553141e-05, 'num_train_epochs': 7.623375372739029, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.21605876280261357, 'weight_decay': 0.11938244526496489, 'adam_epsilon': 7.353322403647365e-07, 'seed': 42, 'global_max_steps': 1878, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.4736175808553141e-05, 'num_train_epochs': 7.623375372739029, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.21605876280261357, 'weight_decay': 0.11938244526496489, 'adam_epsilon': 7.353322403647365e-07, 'seed': 42, 'global_max_steps': 1878, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 0.0001178658482340711, 'num_train_epochs': 1.1449809097488262, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.015398649752204969, 'weight_decay': 0.3, 'adam_epsilon': 4.275263179285729e-08, 'seed': 43, 'global_max_steps': 313, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.4736175808553141e-05, 'num_train_epochs': 7.623375372739029, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.21605876280261357, 'weight_decay': 0.11938244526496489, 'adam_epsilon': 7.353322403647365e-07, 'seed': 42, 'global_max_steps': 1878, 'learner': 'transformer'}}\n"
     ]
    }
   ],
   "source": [
    "from flaml.data import get_output_from_log\n",
    "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
    "    get_output_from_log(filename=automl_settings['log_file_name'], time_budget=3000)\n",
    "for config in config_history:\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Wall Clock Time (s)')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "print(len(valid_loss_history))\n",
    "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
    "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Spooky-author-identification example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-22 07:20:52 (running for 00:30:13.14)<br>Memory usage on this node: 19.0/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/4 CPUs, 0/4 GPUs, 0.0/252.65 GiB heap, 0.0/112.27 GiB objects (0.0/1.0 accelerator_type:V100)<br>Current best trial: 504afb96 with val_loss=0.11011235955056176 and parameters={'learning_rate': 4.567279255636039e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 32, 'seed': 37, 'global_max_steps': 9223372036854775807, 'learner': 'transformer'}<br>Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-22_06-50-38<br>Number of trials: 12/1000000 (12 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=78542)\u001b[0m {'train_runtime': 675.882, 'train_samples_per_second': 108.628, 'train_steps_per_second': 6.791, 'train_loss': 0.15587145374491324, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=78542)\u001b[0m The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\u001b[2m\u001b[36m(train pid=78542)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=78542)\u001b[0m   Num examples = 4895\n",
      "\u001b[2m\u001b[36m(train pid=78542)\u001b[0m   Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=78793)\u001b[0m {'eval_loss': 0.47973549365997314, 'eval_automl_metric': 0.12134831460674156, 'eval_runtime': 42.4421, 'eval_samples_per_second': 115.334, 'eval_steps_per_second': 115.334, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(train pid=78793)\u001b[0m {'train_runtime': 482.2078, 'train_samples_per_second': 121.806, 'train_steps_per_second': 1.908, 'train_loss': 0.23729169679724652, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=78793)\u001b[0m The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\u001b[2m\u001b[36m(train pid=78793)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=78793)\u001b[0m   Num examples = 4895\n",
      "\u001b[2m\u001b[36m(train pid=78793)\u001b[0m   Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=78225)\u001b[0m {'loss': 0.1844, 'learning_rate': 2.7020242630660653e-06, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=78542)\u001b[0m Didn't find file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-22_06-50-38/train_e041e7d6_10_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=5,per_device_trai_2022-07-22_07-09-19/checkpoint-4590/added_tokens.json. We won't load it.\n",
      "\u001b[2m\u001b[36m(train pid=78542)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-22_06-50-38/train_e041e7d6_10_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=5,per_device_trai_2022-07-22_07-09-19/checkpoint-4590/vocab.txt\n",
      "\u001b[2m\u001b[36m(train pid=78542)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-22_06-50-38/train_e041e7d6_10_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=5,per_device_trai_2022-07-22_07-09-19/checkpoint-4590/tokenizer.json\n",
      "\u001b[2m\u001b[36m(train pid=78542)\u001b[0m loading file None\n",
      "\u001b[2m\u001b[36m(train pid=78542)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-22_06-50-38/train_e041e7d6_10_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=5,per_device_trai_2022-07-22_07-09-19/checkpoint-4590/special_tokens_map.json\n",
      "\u001b[2m\u001b[36m(train pid=78542)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-22_06-50-38/train_e041e7d6_10_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=5,per_device_trai_2022-07-22_07-09-19/checkpoint-4590/tokenizer_config.json\n",
      "\u001b[2m\u001b[36m(train pid=78793)\u001b[0m Didn't find file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-22_06-50-38/train_567b6878_11_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-22_07-12-37/checkpoint-920/added_tokens.json. We won't load it.\n",
      "\u001b[2m\u001b[36m(train pid=78793)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-22_06-50-38/train_567b6878_11_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-22_07-12-37/checkpoint-920/vocab.txt\n",
      "\u001b[2m\u001b[36m(train pid=78793)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-22_06-50-38/train_567b6878_11_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-22_07-12-37/checkpoint-920/tokenizer.json\n",
      "\u001b[2m\u001b[36m(train pid=78793)\u001b[0m loading file None\n",
      "\u001b[2m\u001b[36m(train pid=78793)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-22_06-50-38/train_567b6878_11_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-22_07-12-37/checkpoint-920/special_tokens_map.json\n",
      "\u001b[2m\u001b[36m(train pid=78793)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-22_06-50-38/train_567b6878_11_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-22_07-12-37/checkpoint-920/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=78225)\u001b[0m {'eval_loss': 0.7813186049461365, 'eval_automl_metric': 0.13564862104187947, 'eval_runtime': 38.0461, 'eval_samples_per_second': 128.66, 'eval_steps_per_second': 128.66, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(train pid=78225)\u001b[0m {'loss': 0.0829, 'learning_rate': 2.3353000145500413e-06, 'epoch': 3.13}\n",
      "\u001b[2m\u001b[36m(train pid=79025)\u001b[0m {'eval_loss': 0.5877022743225098, 'eval_automl_metric': 0.11848825331971402, 'eval_runtime': 40.6459, 'eval_samples_per_second': 120.43, 'eval_steps_per_second': 120.43, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(train pid=78225)\u001b[0m {'loss': 0.0714, 'learning_rate': 1.9685757660340173e-06, 'epoch': 3.27}\n",
      "\u001b[2m\u001b[36m(train pid=79025)\u001b[0m {'loss': 0.0237, 'learning_rate': 3.91430499829805e-06, 'epoch': 4.36}\n",
      "\u001b[2m\u001b[36m(train pid=78225)\u001b[0m {'loss': 0.0584, 'learning_rate': 1.6018515175179931e-06, 'epoch': 3.41}\n",
      "\u001b[2m\u001b[36m(train pid=78225)\u001b[0m {'loss': 0.0836, 'learning_rate': 1.235127269001969e-06, 'epoch': 3.54}\n",
      "\u001b[2m\u001b[36m(train pid=78225)\u001b[0m {'loss': 0.0335, 'learning_rate': 8.684030204859451e-07, 'epoch': 3.68}\n",
      "\u001b[2m\u001b[36m(train pid=79025)\u001b[0m {'eval_loss': 0.6322397589683533, 'eval_automl_metric': 0.11664964249233911, 'eval_runtime': 39.775, 'eval_samples_per_second': 123.067, 'eval_steps_per_second': 123.067, 'epoch': 5.0}\n",
      "\u001b[2m\u001b[36m(train pid=79025)\u001b[0m {'train_runtime': 607.6324, 'train_samples_per_second': 120.83, 'train_steps_per_second': 3.777, 'train_loss': 0.17213530145699163, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=79025)\u001b[0m The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\u001b[2m\u001b[36m(train pid=79025)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=79025)\u001b[0m   Num examples = 4895\n",
      "\u001b[2m\u001b[36m(train pid=79025)\u001b[0m   Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=78225)\u001b[0m {'loss': 0.0562, 'learning_rate': 5.01678771969921e-07, 'epoch': 3.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=79025)\u001b[0m Didn't find file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-22_06-50-38/train_9a34cd4a_12_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=5,per_device_trai_2022-07-22_07-14-32/checkpoint-2295/added_tokens.json. We won't load it.\n",
      "\u001b[2m\u001b[36m(train pid=79025)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-22_06-50-38/train_9a34cd4a_12_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=5,per_device_trai_2022-07-22_07-14-32/checkpoint-2295/vocab.txt\n",
      "\u001b[2m\u001b[36m(train pid=79025)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-22_06-50-38/train_9a34cd4a_12_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=5,per_device_trai_2022-07-22_07-14-32/checkpoint-2295/tokenizer.json\n",
      "\u001b[2m\u001b[36m(train pid=79025)\u001b[0m loading file None\n",
      "\u001b[2m\u001b[36m(train pid=79025)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-22_06-50-38/train_9a34cd4a_12_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=5,per_device_trai_2022-07-22_07-14-32/checkpoint-2295/special_tokens_map.json\n",
      "\u001b[2m\u001b[36m(train pid=79025)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-22_06-50-38/train_9a34cd4a_12_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=5,per_device_trai_2022-07-22_07-14-32/checkpoint-2295/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=78225)\u001b[0m {'loss': 0.0527, 'learning_rate': 1.3495452345389687e-07, 'epoch': 3.95}\n",
      "\u001b[2m\u001b[36m(train pid=78225)\u001b[0m {'eval_loss': 0.8104404211044312, 'eval_automl_metric': 0.12625127681307458, 'eval_runtime': 37.4885, 'eval_samples_per_second': 130.573, 'eval_steps_per_second': 130.573, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(train pid=78225)\u001b[0m {'train_runtime': 1051.1951, 'train_samples_per_second': 55.875, 'train_steps_per_second': 13.969, 'train_loss': 0.2927411694969607, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=78225)\u001b[0m The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\u001b[2m\u001b[36m(train pid=78225)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=78225)\u001b[0m   Num examples = 4895\n",
      "\u001b[2m\u001b[36m(train pid=78225)\u001b[0m   Batch size = 1\n",
      "\u001b[2m\u001b[36m(train pid=78225)\u001b[0m Didn't find file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-22_06-50-38/train_d0e0b7d6_9_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_train_2022-07-22_07-08-52/checkpoint-14684/added_tokens.json. We won't load it.\n",
      "\u001b[2m\u001b[36m(train pid=78225)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-22_06-50-38/train_d0e0b7d6_9_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_train_2022-07-22_07-08-52/checkpoint-14684/vocab.txt\n",
      "\u001b[2m\u001b[36m(train pid=78225)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-22_06-50-38/train_d0e0b7d6_9_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_train_2022-07-22_07-08-52/checkpoint-14684/tokenizer.json\n",
      "\u001b[2m\u001b[36m(train pid=78225)\u001b[0m loading file None\n",
      "\u001b[2m\u001b[36m(train pid=78225)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-22_06-50-38/train_d0e0b7d6_9_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_train_2022-07-22_07-08-52/checkpoint-14684/special_tokens_map.json\n",
      "\u001b[2m\u001b[36m(train pid=78225)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-22_06-50-38/train_d0e0b7d6_9_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_train_2022-07-22_07-08-52/checkpoint-14684/tokenizer_config.json\n",
      "2022-07-22 07:27:20,126\tINFO tune.py:747 -- Total run time: 2201.85 seconds (1801.97 seconds for the tuning loop).\n",
      "[flaml.automl: 07-22 07:27:25] {3314} INFO - selected model: None\n",
      "/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2317, 'learning_rate': 5.95732076822092e-06, 'epoch': 4.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 07-22 07:35:19] {3457} INFO - retrain transformer for 474.4s\n",
      "[flaml.automl: 07-22 07:35:19] {3464} INFO - retrained model: None\n",
      "[flaml.automl: 07-22 07:35:19] {2742} INFO - fit succeeded\n",
      "[flaml.automl: 07-22 07:35:19] {2743} INFO - Time taken to find the best model: 1118.247492313385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 463.5873, 'train_samples_per_second': 158.374, 'train_steps_per_second': 1.24, 'train_loss': 0.20362980179164722, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "import ray\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "ray.init(num_cpus=4, num_gpus=4, ignore_reinit_error=True)\n",
    "\n",
    "df = pd.read_csv('/data/xliu127/projects/hyperopt/FLAML/data/spooky-author-identification.csv')\n",
    "X, y = df.drop('author', axis=1), df['author']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=123)\n",
    "\n",
    "\n",
    "print(len(X_train), len(X_val))\n",
    "automl_model = AutoML()\n",
    "\n",
    "automl_settings = {\n",
    "    \"time_budget\": 1800,                 \n",
    "    \"task\": \"seq-classification\",       \n",
    "    \"fit_kwargs_by_estimator\": {\n",
    "        \"transformer\": {\n",
    "            \"output_dir\": \"data/output/\",   \n",
    "            \"model_path\": \"bert-base-uncased\",  \n",
    "        }\n",
    "    },\n",
    "    \"metric\": \"accuracy\",\n",
    "    \"gpu_per_trial\": 1,  \n",
    "    \"log_file_name\": \"spooky_bert.log\", \n",
    "    \"log_type\": \"all\",                 \n",
    "    \"use_ray\": {\"local_dir\": \"data/output/\"},                    # set whether to use Ray\n",
    "    \"n_concurrent_trials\": 4,\n",
    "    \"keep_search_state\": True,          # keeping the search state\n",
    "}\n",
    "\n",
    "automl_model.fit(X_train=X_train, y_train=y_train,X_val=X_val, y_val=y_val, **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best loss for spooky author identification: 0.11133810010214507\n"
     ]
    }
   ],
   "source": [
    "print(\"the best loss for spooky author identification: {}\".format(automl_model.best_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-21 21:21:15 (running for 00:30:10.30)<br>Memory usage on this node: 20.5/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/4 CPUs, 0/4 GPUs, 0.0/252.62 GiB heap, 0.0/112.26 GiB objects (0.0/1.0 accelerator_type:V100)<br>Current best trial: 84d3be85 with val_loss=0.12951991828396325 and parameters={'learning_rate': 4.486769916716146e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 8, 'seed': 28, 'global_max_steps': 9223372036854775807, 'learner': 'transformer'}<br>Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05<br>Number of trials: 12/1000000 (12 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m {'eval_loss': 0.7418951392173767, 'eval_automl_metric': 0.1284984678243105, 'eval_runtime': 37.3935, 'eval_samples_per_second': 130.905, 'eval_steps_per_second': 130.905, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m {'train_runtime': 565.7729, 'train_samples_per_second': 103.816, 'train_steps_per_second': 6.49, 'train_loss': 0.2802804773409642, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m   Num examples = 4895\n",
      "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m   Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m {'eval_loss': 1.0893423557281494, 'eval_automl_metric': 0.6024514811031665, 'eval_runtime': 39.7178, 'eval_samples_per_second': 123.245, 'eval_steps_per_second': 123.245, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m {'loss': 0.2369, 'learning_rate': 1.4090340380281214e-05, 'epoch': 2.72}\n",
      "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m {'train_runtime': 566.9953, 'train_samples_per_second': 77.694, 'train_steps_per_second': 9.714, 'train_loss': 1.0928592581461545, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m {'eval_loss': 1.092341661453247, 'eval_automl_metric': 0.6024514811031665, 'eval_runtime': 38.0057, 'eval_samples_per_second': 128.797, 'eval_steps_per_second': 128.797, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m   Num examples = 4895\n",
      "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m   Batch size = 1\n",
      "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m Didn't find file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_60247332_10_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-21_21-11-36/checkpoint-3672/added_tokens.json. We won't load it.\n",
      "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_60247332_10_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-21_21-11-36/checkpoint-3672/vocab.json\n",
      "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_60247332_10_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-21_21-11-36/checkpoint-3672/merges.txt\n",
      "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_60247332_10_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-21_21-11-36/checkpoint-3672/tokenizer.json\n",
      "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m loading file None\n",
      "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_60247332_10_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-21_21-11-36/checkpoint-3672/special_tokens_map.json\n",
      "\u001b[2m\u001b[36m(train pid=50245)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_60247332_10_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=4,per_device_trai_2022-07-21_21-11-36/checkpoint-3672/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m {'loss': 1.0896, 'learning_rate': 1.5104688589428795e-05, 'epoch': 3.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m Didn't find file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_6861ba34_11_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=3,per_device_trai_2022-07-21_21-11-51/checkpoint-3672/added_tokens.json. We won't load it.\n",
      "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_6861ba34_11_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=3,per_device_trai_2022-07-21_21-11-51/checkpoint-3672/vocab.json\n",
      "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_6861ba34_11_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=3,per_device_trai_2022-07-21_21-11-51/checkpoint-3672/merges.txt\n",
      "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_6861ba34_11_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=3,per_device_trai_2022-07-21_21-11-51/checkpoint-3672/tokenizer.json\n",
      "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m loading file None\n",
      "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_6861ba34_11_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=3,per_device_trai_2022-07-21_21-11-51/checkpoint-3672/special_tokens_map.json\n",
      "\u001b[2m\u001b[36m(train pid=50412)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_6861ba34_11_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=3,per_device_trai_2022-07-21_21-11-51/checkpoint-3672/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m {'loss': 0.2195, 'learning_rate': 1.2404892966371977e-05, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m {'loss': 1.0907, 'learning_rate': 1.2732721160184323e-05, 'epoch': 3.27}\n",
      "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m {'loss': 0.1252, 'learning_rate': 1.0719445552462741e-05, 'epoch': 3.27}\n",
      "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m {'loss': 1.0926, 'learning_rate': 1.0360753730939852e-05, 'epoch': 3.41}\n",
      "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m {'loss': 0.1093, 'learning_rate': 9.033998138553504e-06, 'epoch': 3.54}\n",
      "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m {'loss': 1.0908, 'learning_rate': 7.988786301695379e-06, 'epoch': 3.54}\n",
      "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m {'loss': 0.1166, 'learning_rate': 7.348550724644269e-06, 'epoch': 3.81}\n",
      "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m {'loss': 1.0899, 'learning_rate': 5.616818872450909e-06, 'epoch': 3.68}\n",
      "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m {'loss': 1.0923, 'learning_rate': 3.244851443206437e-06, 'epoch': 3.81}\n",
      "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m {'eval_loss': 0.7831101417541504, 'eval_automl_metric': 0.13462717058222673, 'eval_runtime': 37.9679, 'eval_samples_per_second': 128.925, 'eval_steps_per_second': 128.925, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m {'loss': 1.0862, 'learning_rate': 8.728840139619655e-07, 'epoch': 3.95}\n",
      "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m {'loss': 0.1164, 'learning_rate': 5.663103310735033e-06, 'epoch': 4.08}\n",
      "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m {'eval_loss': 1.0893481969833374, 'eval_automl_metric': 0.6024514811031665, 'eval_runtime': 36.2865, 'eval_samples_per_second': 134.899, 'eval_steps_per_second': 134.899, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m {'train_runtime': 1069.9104, 'train_samples_per_second': 54.898, 'train_steps_per_second': 13.725, 'train_loss': 1.0960205283875493, 'epoch': 4.0}\n",
      "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m   Num examples = 4895\n",
      "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m   Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m {'loss': 0.0542, 'learning_rate': 3.977655896825797e-06, 'epoch': 4.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m Didn't find file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_ebe7d3ee_9_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=4,per_device_train_2022-07-21_21-08-22/checkpoint-11013/added_tokens.json. We won't load it.\n",
      "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_ebe7d3ee_9_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=4,per_device_train_2022-07-21_21-08-22/checkpoint-11013/vocab.json\n",
      "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_ebe7d3ee_9_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=4,per_device_train_2022-07-21_21-08-22/checkpoint-11013/merges.txt\n",
      "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_ebe7d3ee_9_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=4,per_device_train_2022-07-21_21-08-22/checkpoint-11013/tokenizer.json\n",
      "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m loading file None\n",
      "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_ebe7d3ee_9_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=4,per_device_train_2022-07-21_21-08-22/checkpoint-11013/special_tokens_map.json\n",
      "\u001b[2m\u001b[36m(train pid=49988)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_ebe7d3ee_9_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0001,num_train_epochs=4,per_device_train_2022-07-21_21-08-22/checkpoint-11013/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m {'loss': 0.0618, 'learning_rate': 2.2922084829165607e-06, 'epoch': 4.63}\n",
      "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m {'loss': 0.0494, 'learning_rate': 6.06761069007325e-07, 'epoch': 4.9}\n",
      "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m {'eval_loss': 0.88468998670578, 'eval_automl_metric': 0.12972420837589382, 'eval_runtime': 37.9519, 'eval_samples_per_second': 128.979, 'eval_steps_per_second': 128.979, 'epoch': 5.0}\n",
      "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m {'train_runtime': 873.0679, 'train_samples_per_second': 84.094, 'train_steps_per_second': 10.515, 'train_loss': 0.27977710040306475, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m   Num examples = 4895\n",
      "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m   Batch size = 1\n",
      "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m Didn't find file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_bd71ed64_12_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=5,per_device_trai_2022-07-21_21-14-13/checkpoint-9180/added_tokens.json. We won't load it.\n",
      "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_bd71ed64_12_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=5,per_device_trai_2022-07-21_21-14-13/checkpoint-9180/vocab.json\n",
      "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_bd71ed64_12_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=5,per_device_trai_2022-07-21_21-14-13/checkpoint-9180/merges.txt\n",
      "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_bd71ed64_12_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=5,per_device_trai_2022-07-21_21-14-13/checkpoint-9180/tokenizer.json\n",
      "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m loading file None\n",
      "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_bd71ed64_12_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=5,per_device_trai_2022-07-21_21-14-13/checkpoint-9180/special_tokens_map.json\n",
      "\u001b[2m\u001b[36m(train pid=50658)\u001b[0m loading file /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-07-21_20-51-05/train_bd71ed64_12_global_max_steps=9223372036854775807,learner=transformer,learning_rate=0.0000,num_train_epochs=5,per_device_trai_2022-07-21_21-14-13/checkpoint-9180/tokenizer_config.json\n",
      "2022-07-21 21:29:43,228\tINFO tune.py:747 -- Total run time: 2317.81 seconds (1801.93 seconds for the tuning loop).\n",
      "[flaml.automl: 07-21 21:29:46] {3314} INFO - selected model: None\n",
      "/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5742, 'learning_rate': 3.264882684494973e-05, 'epoch': 1.09}\n"
     ]
    }
   ],
   "source": [
    "automl_settings[\"fit_kwargs_by_estimator\"][\"transformer\"][\"model_path\"] = \"roberta-base\"\n",
    "automl_settings[\"log_file_name\"] = \"spooky_roberta.log\"\n",
    "automl_model.fit(X_train=X_train, y_train=y_train,X_val=X_val, y_val=y_val, **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from flaml.data import get_output_from_log\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "for each_file_name in ['bert', 'roberta']:\n",
    "    time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
    "        get_output_from_log(filename='spooky_' + each_file_name + '.log', time_budget=3000)\n",
    "    print(len(valid_loss_history))\n",
    "    plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
    "    plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
    "\n",
    "plt.legend(['bert', 'roberta'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Other Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides sequence classification, FLAML currently also supports four other tasks (more tasks are to be supported, which can be found on FLAML's documentation website https://microsoft.github.io/FLAML/docs/Examples/AutoML-NLP):\n",
    "\n",
    "- sequence regression: predicting a float number from the input sequence, e.g., predicting the rating of a hotel review based on the text content;\n",
    "- token classification: predicting the label of each token in a sequence, e.g., named entity recognition;\n",
    "- multiple choice: predicting the best second half of a sentence that comes next to the first part of a sentence based on common sensen reasoning. An example is seen below;\n",
    "- (abstractive) summarization: generating the textual summarization of an input paragraph;\n",
    "\n",
    "For each task, you only have to change the \"Load data and preprocess\" with the corresponding data loading process. For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Multiple Choice Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple choice is a task of predicting the best second half of a sentence that follows the first half based on common sense reasoning. An example of multiple-choice classification problem is:\n",
    "\n",
    "On stage, a woman takes a seat at the piano. She\n",
    "a) sits on a bench as her sister plays with the doll.\n",
    "b) smiles with someone as the music plays.\n",
    "c) is in the crowd, watching the dancers.\n",
    "d) *nervously sets her fingers on the keys*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: swag/regular\n",
      "Reusing dataset swag (/home/xliu127/.cache/huggingface/datasets/swag/regular/0.0.0/9640de08cdba6a1469ed3834fcab4b8ad8e38caf5d1ba5e7436d8b1fd067ad4c)\n",
      "No config specified, defaulting to: swag/regular\n",
      "Reusing dataset swag (/home/xliu127/.cache/huggingface/datasets/swag/regular/0.0.0/9640de08cdba6a1469ed3834fcab4b8ad8e38caf5d1ba5e7436d8b1fd067ad4c)\n",
      "No config specified, defaulting to: swag/regular\n",
      "Reusing dataset swag (/home/xliu127/.cache/huggingface/datasets/swag/regular/0.0.0/9640de08cdba6a1469ed3834fcab4b8ad8e38caf5d1ba5e7436d8b1fd067ad4c)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"swag\", split=\"train\").to_pandas().iloc[:10000]\n",
    "dev_dataset = load_dataset(\"swag\", split=\"validation\").to_pandas().iloc[:10000]\n",
    "test_dataset = load_dataset(\"swag\", split=\"test\").to_pandas()\n",
    "\n",
    "custom_sent_keys = [\n",
    "        \"sent1\",\n",
    "        \"sent2\",\n",
    "        \"ending0\",\n",
    "        \"ending1\",\n",
    "        \"ending2\",\n",
    "        \"ending3\",\n",
    "        \"gold-source\",\n",
    "        \"video-id\",\n",
    "        \"startphrase\",\n",
    "        \"fold-ind\",\n",
    "    ]                                                  # specify the column names of the input sentences\n",
    "label_key = \"label\"                                    # specify the column name of the label\n",
    "\n",
    "X_train, y_train = train_dataset[custom_sent_keys], train_dataset[label_key]\n",
    "X_val, y_val = dev_dataset[custom_sent_keys], dev_dataset[label_key]\n",
    "X_test = test_dataset[custom_sent_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Members of the procession walk down the street holding small horn brass instruments.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.iloc[0][\"sent1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-19 14:39:29 (running for 00:08:29.94)<br>Memory usage on this node: 33.0/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/96 CPUs, 0/4 GPUs, 0.0/250.17 GiB heap, 0.0/111.21 GiB objects (0.0/1.0 accelerator_type:V100)<br>Current best trial: de45e672 with val_loss=0.18300000000000005 and parameters={'learning_rate': 6.104513714676502e-06, 'num_train_epochs': 2.3743291981165893, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.23610846764298543, 'weight_decay': 0.20205904544254147, 'adam_epsilon': 5.752964074991208e-08, 'seed': 41, 'global_max_steps': 9223372036854775807, 'learner': 'transformer'}<br>Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-03-19_14-30-59<br>Number of trials: 10/1000000 (10 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=86157)\u001b[0m {'eval_loss': 0.6315866112709045, 'eval_automl_metric': 0.18779999999999997, 'eval_runtime': 15.4883, 'eval_samples_per_second': 645.648, 'eval_steps_per_second': 40.353, 'epoch': 1.66}\n",
      "\u001b[2m\u001b[36m(train pid=86157)\u001b[0m {'train_runtime': 190.7625, 'train_samples_per_second': 87.254, 'train_steps_per_second': 10.909, 'train_loss': 0.5091343906738046, 'epoch': 1.66}\n",
      "\u001b[2m\u001b[36m(train pid=86249)\u001b[0m {'eval_loss': 1.2118068933486938, 'eval_automl_metric': 0.2015, 'eval_runtime': 15.2585, 'eval_samples_per_second': 655.374, 'eval_steps_per_second': 40.961, 'epoch': 2.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=86157)\u001b[0m Using amp half precision backend\n",
      "\u001b[2m\u001b[36m(train pid=86157)\u001b[0m The following columns in the test set  don't have a corresponding argument in `RobertaForMultipleChoice.forward` and have been ignored: ending3, ending1, video-id, sent1, ending0, sent2, fold-ind, ending2, startphrase, gold-source. If ending3, ending1, video-id, sent1, ending0, sent2, fold-ind, ending2, startphrase, gold-source are not expected by `RobertaForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "\u001b[2m\u001b[36m(train pid=86157)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=86157)\u001b[0m   Num examples = 10000\n",
      "\u001b[2m\u001b[36m(train pid=86157)\u001b[0m   Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=86249)\u001b[0m {'eval_loss': 1.2118068933486938, 'eval_automl_metric': 0.2015, 'eval_runtime': 15.1369, 'eval_samples_per_second': 660.639, 'eval_steps_per_second': 41.29, 'epoch': 2.87}\n",
      "\u001b[2m\u001b[36m(train pid=86249)\u001b[0m {'train_runtime': 546.3809, 'train_samples_per_second': 156.658, 'train_steps_per_second': 39.165, 'train_loss': 0.5030154804349909, 'epoch': 2.87}\n",
      "\u001b[2m\u001b[36m(train pid=86195)\u001b[0m {'loss': 0.4854, 'learning_rate': 1.3592147782116173e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=86249)\u001b[0m Using amp half precision backend\n",
      "\u001b[2m\u001b[36m(train pid=86249)\u001b[0m The following columns in the test set  don't have a corresponding argument in `RobertaForMultipleChoice.forward` and have been ignored: fold-ind, sent2, gold-source, ending1, startphrase, sent1, ending0, video-id, ending2, ending3. If fold-ind, sent2, gold-source, ending1, startphrase, sent1, ending0, video-id, ending2, ending3 are not expected by `RobertaForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "\u001b[2m\u001b[36m(train pid=86249)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=86249)\u001b[0m   Num examples = 10000\n",
      "\u001b[2m\u001b[36m(train pid=86249)\u001b[0m   Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=86195)\u001b[0m {'eval_loss': 0.49709731340408325, 'eval_automl_metric': 0.17600000000000005, 'eval_runtime': 15.4983, 'eval_samples_per_second': 645.232, 'eval_steps_per_second': 40.327, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-19 14:41:56,719\tWARNING ray_trial_executor.py:146 -- Skipping cleanup - trainable.stop did not return in time. Consider making `stop` a faster operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=86195)\u001b[0m {'eval_loss': 0.5254333019256592, 'eval_automl_metric': 0.17800000000000005, 'eval_runtime': 15.45, 'eval_samples_per_second': 647.251, 'eval_steps_per_second': 40.453, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(train pid=86195)\u001b[0m {'loss': 0.3989, 'learning_rate': 3.8051750127352887e-07, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-19 14:42:56,729\tWARNING ray_trial_executor.py:146 -- Skipping cleanup - trainable.stop did not return in time. Consider making `stop` a faster operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=86195)\u001b[0m {'eval_loss': 0.5254867076873779, 'eval_automl_metric': 0.17789999999999995, 'eval_runtime': 15.424, 'eval_samples_per_second': 648.341, 'eval_steps_per_second': 40.521, 'epoch': 3.0}\n",
      "\u001b[2m\u001b[36m(train pid=86195)\u001b[0m {'eval_loss': 0.5332269072532654, 'eval_automl_metric': 0.17830000000000001, 'eval_runtime': 15.4452, 'eval_samples_per_second': 647.45, 'eval_steps_per_second': 40.466, 'epoch': 3.39}\n",
      "\u001b[2m\u001b[36m(train pid=86195)\u001b[0m {'train_runtime': 382.2827, 'train_samples_per_second': 88.597, 'train_steps_per_second': 11.076, 'train_loss': 0.5299136270370808, 'epoch': 3.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-19 14:43:56,739\tWARNING ray_trial_executor.py:146 -- Skipping cleanup - trainable.stop did not return in time. Consider making `stop` a faster operation.\n",
      "\u001b[2m\u001b[36m(train pid=86195)\u001b[0m Using amp half precision backend\n",
      "\u001b[2m\u001b[36m(train pid=86195)\u001b[0m The following columns in the test set  don't have a corresponding argument in `RobertaForMultipleChoice.forward` and have been ignored: ending2, sent1, ending0, sent2, ending3, video-id, gold-source, ending1, startphrase, fold-ind. If ending2, sent1, ending0, sent2, ending3, video-id, gold-source, ending1, startphrase, fold-ind are not expected by `RobertaForMultipleChoice.forward`,  you can safely ignore this message.\n",
      "\u001b[2m\u001b[36m(train pid=86195)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=86195)\u001b[0m   Num examples = 10000\n",
      "\u001b[2m\u001b[36m(train pid=86195)\u001b[0m   Batch size = 16\n",
      "2022-03-19 14:44:14,271\tINFO tune.py:639 -- Total run time: 795.18 seconds (504.18 seconds for the tuning loop).\n",
      "[flaml.automl: 03-19 14:44:19] {2837} INFO - selected model: None\n",
      "/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6603, 'learning_rate': 4.631567529441369e-06, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 03-19 14:46:08] {2947} INFO - retrain transformer for 109.2s\n",
      "[flaml.automl: 03-19 14:46:08] {2954} INFO - retrained model: None\n",
      "[flaml.automl: 03-19 14:46:08] {2283} INFO - fit succeeded\n",
      "[flaml.automl: 03-19 14:46:08] {2284} INFO - Time taken to find the best model: 319.927033662796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 96.899, 'train_samples_per_second': 245.031, 'train_steps_per_second': 30.63, 'train_loss': 0.6602518278346073, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "''' import AutoML class from flaml package '''\n",
    "from flaml import AutoML\n",
    "automl = AutoML()\n",
    "\n",
    "if not ray.is_initialized():\n",
    "    ray.init()\n",
    "\n",
    "automl_settings = {\n",
    "    \"time_budget\": 500,                 # setting the time budget\n",
    "    \"task\": \"multichoice-classification\",       # setting the task as multiplechoice-classification\n",
    "    \"fit_kwargs_by_estimator\": {          # if model_path is not set, the default model is facebook/muppet-roberta-base: https://huggingface.co/facebook/muppet-roberta-base\n",
    "        \"transformer\": {\n",
    "            \"output_dir\": \"data/output/\",  # setting the output directory\n",
    "            \"ckpt_per_epoch\": 1,           # setting the number of checkoints per epoch\n",
    "            \"per_device_eval_batch_size\": 16, # the batch size for validation (inference)\n",
    "        }\n",
    "    },\n",
    "    \"gpu_per_trial\": 1,                 # set to 0 if no GPU is available\n",
    "    \"log_file_name\": \"seqclass.log\",    # set the file to save the log for HPO\n",
    "    \"log_type\": \"all\",                  # the log type for trials: \"all\" if logging all the trials, \"better\" if only keeping the better trials\n",
    "    \"use_ray\": {\"local_dir\": \"data/output/\"},                    # set whether to use Ray\n",
    "    \"n_concurrent_trials\": 4\n",
    "}\n",
    "\n",
    "'''The main flaml automl API'''\n",
    "automl.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 0.00021956991427751982, 'num_train_epochs': 0.3549576494055084, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.07425273520338253, 'weight_decay': 0.03879221030529465, 'adam_epsilon': 3.7880482987985576e-08, 'seed': 43, 'global_max_steps': 444, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 0.00021956991427751982, 'num_train_epochs': 0.3549576494055084, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.07425273520338253, 'weight_decay': 0.03879221030529465, 'adam_epsilon': 3.7880482987985576e-08, 'seed': 43, 'global_max_steps': 444, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 1.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 1.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.3241899893349513e-06, 'num_train_epochs': 0.4379128434860086, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.257055208282222, 'weight_decay': 0.012652183020312091, 'adam_epsilon': 1.0189125195705357e-07, 'seed': 43, 'global_max_steps': 274, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 1.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 0.0002562922748967212, 'num_train_epochs': 0.1802995999606059, 'per_device_train_batch_size': 4, 'warmup_ratio': 0.1809477882684876, 'weight_decay': 0.10305626005953175, 'adam_epsilon': 5.536776887412208e-08, 'seed': 42, 'global_max_steps': 451, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 1.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 313, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 6.104513714676502e-06, 'num_train_epochs': 2.3743291981165893, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.23610846764298543, 'weight_decay': 0.20205904544254147, 'adam_epsilon': 5.752964074991208e-08, 'seed': 41, 'global_max_steps': 1251, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 6.104513714676502e-06, 'num_train_epochs': 2.3743291981165893, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.23610846764298543, 'weight_decay': 0.20205904544254147, 'adam_epsilon': 5.752964074991208e-08, 'seed': 41, 'global_max_steps': 1251, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 9.306519250357542e-06, 'num_train_epochs': 0.4664878701006166, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 5.931759315303309e-07, 'seed': 43, 'global_max_steps': 147, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 6.104513714676502e-06, 'num_train_epochs': 2.3743291981165893, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.23610846764298543, 'weight_decay': 0.20205904544254147, 'adam_epsilon': 5.752964074991208e-08, 'seed': 41, 'global_max_steps': 1251, 'learner': 'transformer'}}\n",
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from flaml.data import get_output_from_log\n",
    "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
    "    get_output_from_log(filename=automl_settings['log_file_name'], time_budget=3000)\n",
    "for config in config_history:\n",
    "    print(config)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Wall Clock Time (s)')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "print(len(valid_loss_history))\n",
    "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
    "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Text Summarization Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text summarization task summarizes a long text into a short sentence. For example:\n",
    "\n",
    "- Document: Army explosives experts were called out to deal with a suspect package at the offices on the Newtownards Road on Friday night. Roads were sealed off and traffic diverted as a controlled explosion was carried out. The premises, used by East Belfast MP Naomi Long, have been targeted a number of times. Most recently, petrol bomb attacks were carried out on the offices on consecutive nights in April and May. The attacks began following a Belfast City Council vote in December 2012 restricting the flying of the union flag at the City Hall. Condemning the latest hoax, Alliance MLA Chris Lyttle said: \"It is a serious incident for the local area, it causes serious disruption, it puts people's lives at risk, it can prevent emergency services reaching the area. \"Ultimately we need people with information to share that with the police in order for them to do their job and bring these people to justice.\n",
    "\n",
    "- Summary: A suspicious package left outside an Alliance Party office in east Belfast has been declared a hoax.\n",
    "\n",
    "In this example, we use FLAML to perform *abstractive summarization* using the t5-small language model, i.e., the summary is generated word-by-word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset xsum (/home/xliu127/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset xsum (/home/xliu127/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934)\n",
      "Using custom data configuration default\n",
      "Reusing dataset xsum (/home/xliu127/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"xsum\", split=\"train\").to_pandas()\n",
    "print(len(train_dataset))\n",
    "dev_dataset = load_dataset(\"xsum\", split=\"validation\").to_pandas()\n",
    "test_dataset = load_dataset(\"xsum\", split=\"test\").to_pandas()\n",
    "\n",
    "custom_sent_keys = [\"document\"]       # specify the column names of the input sentences\n",
    "label_key = \"summary\"                 # specify the column name of the label                              \n",
    "\n",
    "X_train, y_train = train_dataset[custom_sent_keys], train_dataset[label_key]\n",
    "X_val, y_val = dev_dataset[custom_sent_keys], dev_dataset[label_key]\n",
    "X_test = test_dataset[custom_sent_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-03-19 14:55:00 (running for 00:08:31.38)<br>Memory usage on this node: 23.1/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/96 CPUs, 0/4 GPUs, 0.0/250.17 GiB heap, 0.0/111.21 GiB objects (0.0/1.0 accelerator_type:V100)<br>Current best trial: 08b6571c with val_loss=0.8569452656271894 and parameters={'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 1.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 9223372036854775807, 'learner': 'transformer', 'FLAML_sample_size': 10000}<br>Result logdir: /data/xliu127/projects/hyperopt/FLAML/notebook/data/output/train_2022-03-19_14-46-29<br>Number of trials: 8/1000000 (8 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m {'loss': 8.7635, 'learning_rate': 1.2308416834153697e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m   warnings.warn(\n",
      "2022-03-19 14:56:00,679\tWARNING ray_trial_executor.py:146 -- Skipping cleanup - trainable.stop did not return in time. Consider making `stop` a faster operation.\n",
      "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m [nltk_data] Downloading package punkt to /home/xliu127/nltk_data...\n",
      "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m [nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m {'eval_loss': 6.893245697021484, 'eval_automl_metric': 0.8537338408275918, 'eval_runtime': 102.2734, 'eval_samples_per_second': 110.801, 'eval_steps_per_second': 6.932, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-19 14:57:00,687\tWARNING ray_trial_executor.py:146 -- Skipping cleanup - trainable.stop did not return in time. Consider making `stop` a faster operation.\n",
      "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m [nltk_data] Downloading package punkt to /home/xliu127/nltk_data...\n",
      "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m [nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m {'eval_loss': 7.381210803985596, 'eval_automl_metric': 0.8475751825208984, 'eval_runtime': 107.4032, 'eval_samples_per_second': 105.509, 'eval_steps_per_second': 6.601, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m [nltk_data] Downloading package punkt to /home/xliu127/nltk_data...\n",
      "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m [nltk_data]   Package punkt is already up-to-date!\n",
      "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m [nltk_data] Downloading package punkt to /home/xliu127/nltk_data...\n",
      "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m [nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m {'eval_loss': 10.150897979736328, 'eval_automl_metric': 0.8566791839938478, 'eval_runtime': 108.2143, 'eval_samples_per_second': 104.718, 'eval_steps_per_second': 6.552, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-19 14:58:00,697\tWARNING ray_trial_executor.py:146 -- Skipping cleanup - trainable.stop did not return in time. Consider making `stop` a faster operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m {'eval_loss': 11.665904998779297, 'eval_automl_metric': 0.858011676038827, 'eval_runtime': 109.4667, 'eval_samples_per_second': 103.52, 'eval_steps_per_second': 6.477, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m [nltk_data] Downloading package punkt to /home/xliu127/nltk_data...\n",
      "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m [nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m {'eval_loss': 6.893245697021484, 'eval_automl_metric': 0.8537338408275918, 'eval_runtime': 110.7246, 'eval_samples_per_second': 102.344, 'eval_steps_per_second': 6.403, 'epoch': 0.11}\n",
      "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m {'train_runtime': 220.8946, 'train_samples_per_second': 4.648, 'train_steps_per_second': 0.149, 'train_loss': 8.763471198804451, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-19 14:59:00,706\tWARNING ray_trial_executor.py:146 -- Skipping cleanup - trainable.stop did not return in time. Consider making `stop` a faster operation.\n",
      "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m Using amp half precision backend\n",
      "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m   Num examples = 11332\n",
      "\u001b[2m\u001b[36m(train pid=86232)\u001b[0m   Batch size = 16\n",
      "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m [nltk_data] Downloading package punkt to /home/xliu127/nltk_data...\n",
      "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m [nltk_data]   Package punkt is already up-to-date!\n",
      "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m [nltk_data] Downloading package punkt to /home/xliu127/nltk_data...\n",
      "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m [nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m {'eval_loss': 7.381210803985596, 'eval_automl_metric': 0.8475751825208984, 'eval_runtime': 109.1975, 'eval_samples_per_second': 103.775, 'eval_steps_per_second': 6.493, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m [nltk_data] Downloading package punkt to /home/xliu127/nltk_data...\n",
      "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m [nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m {'train_runtime': 232.9303, 'train_samples_per_second': 10.067, 'train_steps_per_second': 1.262, 'train_loss': 9.880440506280637, 'epoch': 0.16}\n",
      "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m {'eval_loss': 10.150897979736328, 'eval_automl_metric': 0.8566791839938478, 'eval_runtime': 108.3182, 'eval_samples_per_second': 104.618, 'eval_steps_per_second': 6.546, 'epoch': 0.36}\n",
      "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m {'train_runtime': 232.4568, 'train_samples_per_second': 92.218, 'train_steps_per_second': 2.887, 'train_loss': 11.215172903878349, 'epoch': 0.36}\n",
      "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m {'eval_loss': 11.665904998779297, 'eval_automl_metric': 0.858011676038827, 'eval_runtime': 110.526, 'eval_samples_per_second': 102.528, 'eval_steps_per_second': 6.415, 'epoch': 0.38}\n",
      "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m {'train_runtime': 236.6253, 'train_samples_per_second': 19.714, 'train_steps_per_second': 0.621, 'train_loss': 11.549961930614407, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-19 15:00:00,942\tWARNING ray_trial_executor.py:146 -- Skipping cleanup - trainable.stop did not return in time. Consider making `stop` a faster operation.\n",
      "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m Using amp half precision backend\n",
      "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m   Num examples = 11332\n",
      "\u001b[2m\u001b[36m(train pid=86184)\u001b[0m   Batch size = 16\n",
      "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m Using amp half precision backend\n",
      "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m   Num examples = 11332\n",
      "\u001b[2m\u001b[36m(train pid=86160)\u001b[0m   Batch size = 16\n",
      "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m Using amp half precision backend\n",
      "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m ***** Running Prediction *****\n",
      "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m   Num examples = 11332\n",
      "\u001b[2m\u001b[36m(train pid=86225)\u001b[0m   Batch size = 16\n",
      "2022-03-19 15:01:00,948\tWARNING ray_trial_executor.py:146 -- Skipping cleanup - trainable.stop did not return in time. Consider making `stop` a faster operation.\n",
      "2022-03-19 15:02:20,150\tINFO tune.py:639 -- Total run time: 950.87 seconds (500.36 seconds for the tuning loop).\n",
      "[flaml.automl: 03-19 15:02:25] {2837} INFO - selected model: None\n",
      "/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "[flaml.automl: 03-19 15:14:54] {2947} INFO - retrain transformer for 748.2s\n",
      "[flaml.automl: 03-19 15:14:54] {2954} INFO - retrained model: None\n",
      "[flaml.automl: 03-19 15:14:54] {2283} INFO - fit succeeded\n",
      "[flaml.automl: 03-19 15:14:54] {2284} INFO - Time taken to find the best model: 472.3055913448334\n",
      "[flaml.automl: 03-19 15:14:54] {2295} WARNING - Time taken to find the best model is 94% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 14.6848, 'train_samples_per_second': 13894.959, 'train_steps_per_second': 434.258, 'train_loss': 10.199760437011719, 'epoch': 0.02}\n"
     ]
    }
   ],
   "source": [
    "''' import AutoML class from flaml package '''\n",
    "from flaml import AutoML\n",
    "automl = AutoML()\n",
    "\n",
    "import ray\n",
    "if not ray.is_initialized():\n",
    "    ray.init()\n",
    "\n",
    "automl_settings = {\n",
    "    \"time_budget\": 500,         # setting the time budget\n",
    "    \"task\": \"summarization\",    # setting the task as summarization\n",
    "    \"fit_kwargs_by_estimator\": {  # if model_path is not set, the default model is t5-small: https://huggingface.co/t5-small\n",
    "        \"transformer\": {\n",
    "            \"output_dir\": \"data/output/\",  # setting the output directory\n",
    "            \"ckpt_per_epoch\": 1,    # setting the number of checkoints per epoch\n",
    "            \"model_path\": \"t5-small\",\n",
    "            \"per_device_eval_batch_size\": 16,  # the batch size for validation (inference)\n",
    "        }\n",
    "    },\n",
    "    \"gpu_per_trial\": 1,  # set to 0 if no GPU is available\n",
    "    \"log_file_name\": \"seqclass.log\",  # set the file to save the log for HPO\n",
    "    \"log_type\": \"all\",   # the log type for trials: \"all\" if logging all the trials, \"better\" if only keeping the better trials\n",
    "    \"use_ray\": {\"local_dir\": \"data/output/\"},  # set whether to use Ray\n",
    "    \"metric\": \"rouge1\",\n",
    "    \"n_concurrent_trials\": 4,  # sample: False # if the time is sufficient (e.g., longer than one trial's running time), you can set \n",
    "}\n",
    "\n",
    "'''The main flaml automl API'''\n",
    "automl.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 3.6439277745413994e-06, 'num_train_epochs': 0.454119690781029, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.04654549348562217, 'weight_decay': 0.06669806327326033, 'adam_epsilon': 2.5833461668835812e-08, 'seed': 42, 'global_max_steps': 125, 'learner': 'transformer', 'FLAML_sample_size': 10000}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 3.6439277745413994e-06, 'num_train_epochs': 0.454119690781029, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.04654549348562217, 'weight_decay': 0.06669806327326033, 'adam_epsilon': 2.5833461668835812e-08, 'seed': 42, 'global_max_steps': 125, 'learner': 'transformer', 'FLAML_sample_size': 10000}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 1.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 112, 'learner': 'transformer', 'FLAML_sample_size': 10000}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 1.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 112, 'learner': 'transformer', 'FLAML_sample_size': 10000}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 3.4236378229097798e-06, 'num_train_epochs': 8.919336644807531, 'per_device_train_batch_size': 4, 'warmup_ratio': 0.022492820063166875, 'weight_decay': 0.27013721375576616, 'adam_epsilon': 6.366959214432801e-08, 'seed': 43, 'global_max_steps': 180, 'learner': 'transformer', 'FLAML_sample_size': 10000}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 1.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 112, 'learner': 'transformer', 'FLAML_sample_size': 10000}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 2.83823390666728e-06, 'num_train_epochs': 1.6667827812145841, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.04013366246992448, 'weight_decay': 0.2945152447208819, 'adam_epsilon': 4.694476379503266e-08, 'seed': 43, 'global_max_steps': 163, 'learner': 'transformer', 'FLAML_sample_size': 10000}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 1.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 112, 'learner': 'transformer', 'FLAML_sample_size': 10000}}\n",
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from flaml.data import get_output_from_log\n",
    "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
    "    get_output_from_log(filename=automl_settings['log_file_name'], time_budget=3000)\n",
    "for config in config_history:\n",
    "    print(config)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Wall Clock Time (s)')\n",
    "plt.ylabel('Rouge 1')\n",
    "print(len(valid_loss_history))\n",
    "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
    "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels ['prison link Cymru said some ex-offenders were living rough for up to ']\n"
     ]
    }
   ],
   "source": [
    "'''compute predictions of testing dataset''' \n",
    "y_pred = automl.predict([\"Prison Link Cymru had 1,099 referrals in 2015-16 and said some ex-offenders were living rough for up to a year before finding suitable accommodation.\\nWorkers at the charity claim investment in housing would be cheaper than jailing homeless repeat offenders.\\nThe Welsh Government said more people than ever were getting help to address housing problems.\\nChanges to the Housing Act in Wales, introduced in 2015, removed the right for prison leavers to be given priority for accommodation.\\nPrison Link Cymru, which helps people find accommodation after their release, said things were generally good for women because issues such as children or domestic violence were now considered.\\nHowever, the same could not be said for men, the charity said, because issues which often affect them, such as post traumatic stress disorder or drug dependency, were often viewed as less of a priority.\\nAndrew Stevens, who works in Welsh prisons trying to secure housing for prison leavers, said the need for accommodation was 'chronic'.\\n'There\\'s a desperate need for it, finding suitable accommodation for those leaving prison there is just a lack of it everywhere,' he said.\\n'It could take six months to a year, without a lot of help they could be on the streets for six months.\\n'When you think of the consequences of either being on the street, especially with the cold weather at the moment or you may have a roof over your head, sometimes there is only one choice.'\\nMr Stevens believes building more one-bedroom flats could help ease the problem.\\n'The average price is a hundred pounds a week to keep someone in a rented flat, prison is a lot more than that so I would imagine it would save the public purse quite a few pounds,' he said.\\nOfficial figures show 830 one-bedroom properties were built in the year to March 2016, of an overall total of 6,900 new properties in Wales.\\nMarc, 50, who has been in and out of prison for the past 20 years for burglary offences, said he struggled to find accommodation each time he was released.\\nHe said he would ask himself: 'Where am I going to stay? Where am I going to live? Have I got somewhere where I can see my daughter.'\\n'You\\'re put out among the same sort of people doing the same sort of thing, and it\\'s difficult, it\\'s difficult to get away from it. It\\'s like every man for himself, there\\'s nothing.'\\nMarc has now found stable accommodation with homeless charity Emmaus and said it had been life changing.\\n'You feel safe, you got hot food, you\\'ve got company of people in similar situations to yourself but all dealing with different issues. It\\'s a constructive, helpful atmosphere,' he said.\\nTom Clarke, chief executive of Emmaus South Wales, agreed there was not enough support available.\\n'We do still see [people] homeless on the streets, so clearly they haven\\'t got accommodation and haven\\'t got provision,' he said.\\n'I think the key is connecting people with the services they need. I don\\'t delude myself that Emmaus can offer a one size fits all for everyone, we can\\'t.\\n'But there must be other opportunities and given suitable encouragement I believe that can and should happen.'\\nA Welsh Government spokesman said the national pathway for homeless services to children, young people and adults in the secure estate had prevented many people from losing their home whilst serving their prison sentence.\\nIt added there were already significant demands for one-bedroom flats across the public and private sector and it was providing 20,000 new affordable homes in the next five years.\"])\n",
    "print('Predicted labels', y_pred)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9d36fc5b7c3dd4177ff1b60184dd696c0acc18150a44682abca4d769811bd46"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
