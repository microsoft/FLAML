{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved. \n",
    "\n",
    "Licensed under the MIT License.\n",
    "\n",
    "# FineTuning NLP Models with FLAML Library\n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "FLAML is a Python library (https://github.com/microsoft/FLAML) designed to automatically produce accurate machine learning models \n",
    "with low computational cost. It is fast and economical. The simple and lightweight design makes it easy to use and extend, such as adding new learners. FLAML can \n",
    "- serve as an economical AutoML engine,\n",
    "- be used as a fast hyperparameter tuning tool, or \n",
    "- be embedded in self-tuning software that requires low latency & resource in repetitive\n",
    "   tuning tasks.\n",
    "\n",
    "In this notebook, we demonstrate how to use the FLAML library to fine tune an NLP language model with hyperparameter search. \n",
    "\n",
    "FLAML requires `Python>=3.6`. To run this notebook example, please install flaml with the `notebook` option:\n",
    "```bash\n",
    "pip install flaml[notebook,nlp]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flaml[nlp,notebook,optuna,ray] in /data/xliu127/projects/hyperopt/FLAML (0.9.7)\n",
      "\u001B[33mWARNING: flaml 0.9.7 does not provide the extra 'optuna'\u001B[0m\u001B[33m\n",
      "\u001B[0mRequirement already satisfied: NumPy>=1.16.2 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[nlp,notebook,optuna,ray]) (1.22.2)\n",
      "Requirement already satisfied: lightgbm>=2.3.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[nlp,notebook,optuna,ray]) (3.3.2)\n",
      "Requirement already satisfied: xgboost<=1.3.3,>=0.90 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[nlp,notebook,optuna,ray]) (1.3.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[nlp,notebook,optuna,ray]) (1.8.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[nlp,notebook,optuna,ray]) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[nlp,notebook,optuna,ray]) (1.0.2)\n",
      "Requirement already satisfied: ray[tune]~=1.10 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[nlp,notebook,optuna,ray]) (1.10.0)\n",
      "Requirement already satisfied: openml==0.10.2 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[nlp,notebook,optuna,ray]) (0.10.2)\n",
      "Requirement already satisfied: jupyter in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[nlp,notebook,optuna,ray]) (1.0.0)\n",
      "Requirement already satisfied: matplotlib in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[nlp,notebook,optuna,ray]) (3.5.1)\n",
      "Requirement already satisfied: rgf-python in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[nlp,notebook,optuna,ray]) (3.12.0)\n",
      "Requirement already satisfied: catboost>=0.26 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[nlp,notebook,optuna,ray]) (1.0.4)\n",
      "Requirement already satisfied: transformers>=4.14 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[nlp,notebook,optuna,ray]) (4.16.2)\n",
      "Requirement already satisfied: datasets in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[nlp,notebook,optuna,ray]) (1.18.3)\n",
      "Requirement already satisfied: torch in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[nlp,notebook,optuna,ray]) (1.10.2)\n",
      "Requirement already satisfied: seqeval in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[nlp,notebook,optuna,ray]) (1.2.2)\n",
      "Requirement already satisfied: nltk in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[nlp,notebook,optuna,ray]) (3.7)\n",
      "Requirement already satisfied: rouge_score in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from flaml[nlp,notebook,optuna,ray]) (0.0.4)\n",
      "Requirement already satisfied: python-dateutil in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from openml==0.10.2->flaml[nlp,notebook,optuna,ray]) (2.8.2)\n",
      "Requirement already satisfied: xmltodict in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from openml==0.10.2->flaml[nlp,notebook,optuna,ray]) (0.12.0)\n",
      "Requirement already satisfied: liac-arff>=2.4.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from openml==0.10.2->flaml[nlp,notebook,optuna,ray]) (2.5.0)\n",
      "Requirement already satisfied: requests in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from openml==0.10.2->flaml[nlp,notebook,optuna,ray]) (2.27.1)\n",
      "Requirement already satisfied: graphviz in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from catboost>=0.26->flaml[nlp,notebook,optuna,ray]) (0.19.1)\n",
      "Requirement already satisfied: six in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from catboost>=0.26->flaml[nlp,notebook,optuna,ray]) (1.16.0)\n",
      "Requirement already satisfied: plotly in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from catboost>=0.26->flaml[nlp,notebook,optuna,ray]) (5.6.0)\n",
      "Requirement already satisfied: wheel in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from lightgbm>=2.3.1->flaml[nlp,notebook,optuna,ray]) (0.37.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from pandas>=1.1.4->flaml[nlp,notebook,optuna,ray]) (2021.3)\n",
      "Requirement already satisfied: pyyaml in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[nlp,notebook,optuna,ray]) (6.0)\n",
      "Requirement already satisfied: protobuf>=3.15.3 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[nlp,notebook,optuna,ray]) (3.19.4)\n",
      "Requirement already satisfied: filelock in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[nlp,notebook,optuna,ray]) (3.6.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[nlp,notebook,optuna,ray]) (1.0.3)\n",
      "Requirement already satisfied: attrs in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[nlp,notebook,optuna,ray]) (21.4.0)\n",
      "Requirement already satisfied: redis>=3.5.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[nlp,notebook,optuna,ray]) (4.1.4)\n",
      "Requirement already satisfied: grpcio>=1.28.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[nlp,notebook,optuna,ray]) (1.44.0)\n",
      "Requirement already satisfied: click>=7.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[nlp,notebook,optuna,ray]) (8.0.3)\n",
      "Requirement already satisfied: jsonschema in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[nlp,notebook,optuna,ray]) (3.2.0)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[nlp,notebook,optuna,ray]) (2.5)\n",
      "Requirement already satisfied: tabulate in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ray[tune]~=1.10->flaml[nlp,notebook,optuna,ray]) (0.8.9)\n",
      "Requirement already satisfied: joblib>=0.11 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from scikit-learn>=0.24->flaml[nlp,notebook,optuna,ray]) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from scikit-learn>=0.24->flaml[nlp,notebook,optuna,ray]) (3.1.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from transformers>=4.14->flaml[nlp,notebook,optuna,ray]) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from transformers>=4.14->flaml[nlp,notebook,optuna,ray]) (21.3)\n",
      "Requirement already satisfied: sacremoses in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from transformers>=4.14->flaml[nlp,notebook,optuna,ray]) (0.0.47)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from transformers>=4.14->flaml[nlp,notebook,optuna,ray]) (0.11.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from transformers>=4.14->flaml[nlp,notebook,optuna,ray]) (0.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from transformers>=4.14->flaml[nlp,notebook,optuna,ray]) (2022.1.18)\n",
      "Requirement already satisfied: aiohttp in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from datasets->flaml[nlp,notebook,optuna,ray]) (3.8.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from datasets->flaml[nlp,notebook,optuna,ray]) (2022.2.0)\n",
      "Requirement already satisfied: multiprocess in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from datasets->flaml[nlp,notebook,optuna,ray]) (0.70.12.2)\n",
      "Requirement already satisfied: xxhash in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from datasets->flaml[nlp,notebook,optuna,ray]) (3.0.0)\n",
      "Requirement already satisfied: dill in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from datasets->flaml[nlp,notebook,optuna,ray]) (0.3.4)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from datasets->flaml[nlp,notebook,optuna,ray]) (7.0.0)\n",
      "Requirement already satisfied: qtconsole in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter->flaml[nlp,notebook,optuna,ray]) (5.2.2)\n",
      "Requirement already satisfied: notebook in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter->flaml[nlp,notebook,optuna,ray]) (6.4.8)\n",
      "Requirement already satisfied: ipywidgets in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter->flaml[nlp,notebook,optuna,ray]) (7.6.5)\n",
      "Requirement already satisfied: ipykernel in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter->flaml[nlp,notebook,optuna,ray]) (6.9.1)\n",
      "Requirement already satisfied: nbconvert in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter->flaml[nlp,notebook,optuna,ray]) (6.4.2)\n",
      "Requirement already satisfied: jupyter-console in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter->flaml[nlp,notebook,optuna,ray]) (6.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from matplotlib->flaml[nlp,notebook,optuna,ray]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from matplotlib->flaml[nlp,notebook,optuna,ray]) (4.29.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from matplotlib->flaml[nlp,notebook,optuna,ray]) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from matplotlib->flaml[nlp,notebook,optuna,ray]) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from matplotlib->flaml[nlp,notebook,optuna,ray]) (9.0.1)\n",
      "Requirement already satisfied: absl-py in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from rouge_score->flaml[nlp,notebook,optuna,ray]) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from torch->flaml[nlp,notebook,optuna,ray]) (4.1.1)\n",
      "Requirement already satisfied: deprecated>=1.2.3 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from redis>=3.5.0->ray[tune]~=1.10->flaml[nlp,notebook,optuna,ray]) (1.2.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from requests->openml==0.10.2->flaml[nlp,notebook,optuna,ray]) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from requests->openml==0.10.2->flaml[nlp,notebook,optuna,ray]) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from requests->openml==0.10.2->flaml[nlp,notebook,optuna,ray]) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from requests->openml==0.10.2->flaml[nlp,notebook,optuna,ray]) (1.26.8)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from aiohttp->datasets->flaml[nlp,notebook,optuna,ray]) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from aiohttp->datasets->flaml[nlp,notebook,optuna,ray]) (1.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from aiohttp->datasets->flaml[nlp,notebook,optuna,ray]) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from aiohttp->datasets->flaml[nlp,notebook,optuna,ray]) (1.3.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from aiohttp->datasets->flaml[nlp,notebook,optuna,ray]) (4.0.2)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[nlp,notebook,optuna,ray]) (1.5.1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[nlp,notebook,optuna,ray]) (8.0.1)\n",
      "Requirement already satisfied: traitlets<6.0,>=5.1.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[nlp,notebook,optuna,ray]) (5.1.1)\n",
      "Requirement already satisfied: nest-asyncio in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[nlp,notebook,optuna,ray]) (1.5.4)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[nlp,notebook,optuna,ray]) (7.1.2)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[nlp,notebook,optuna,ray]) (0.1.3)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipykernel->jupyter->flaml[nlp,notebook,optuna,ray]) (6.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipywidgets->jupyter->flaml[nlp,notebook,optuna,ray]) (3.5.2)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipywidgets->jupyter->flaml[nlp,notebook,optuna,ray]) (5.1.3)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipywidgets->jupyter->flaml[nlp,notebook,optuna,ray]) (0.2.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipywidgets->jupyter->flaml[nlp,notebook,optuna,ray]) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jsonschema->ray[tune]~=1.10->flaml[nlp,notebook,optuna,ray]) (60.9.3)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jsonschema->ray[tune]~=1.10->flaml[nlp,notebook,optuna,ray]) (0.18.0)\n",
      "Requirement already satisfied: pygments in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter-console->jupyter->flaml[nlp,notebook,optuna,ray]) (2.11.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jupyter-console->jupyter->flaml[nlp,notebook,optuna,ray]) (3.0.28)\n",
      "Requirement already satisfied: bleach in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[nlp,notebook,optuna,ray]) (4.1.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[nlp,notebook,optuna,ray]) (0.1.2)\n",
      "Requirement already satisfied: jinja2>=2.4 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[nlp,notebook,optuna,ray]) (3.0.3)\n",
      "Requirement already satisfied: jupyter-core in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[nlp,notebook,optuna,ray]) (4.9.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[nlp,notebook,optuna,ray]) (1.5.0)\n",
      "Requirement already satisfied: defusedxml in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[nlp,notebook,optuna,ray]) (0.7.1)\n",
      "Requirement already satisfied: testpath in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[nlp,notebook,optuna,ray]) (0.5.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[nlp,notebook,optuna,ray]) (0.4)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[nlp,notebook,optuna,ray]) (0.5.11)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from nbconvert->jupyter->flaml[nlp,notebook,optuna,ray]) (0.8.4)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from notebook->jupyter->flaml[nlp,notebook,optuna,ray]) (0.13.1)\n",
      "Requirement already satisfied: argon2-cffi in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from notebook->jupyter->flaml[nlp,notebook,optuna,ray]) (21.3.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from notebook->jupyter->flaml[nlp,notebook,optuna,ray]) (1.8.0)\n",
      "Requirement already satisfied: prometheus-client in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from notebook->jupyter->flaml[nlp,notebook,optuna,ray]) (0.13.1)\n",
      "Requirement already satisfied: pyzmq>=17 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from notebook->jupyter->flaml[nlp,notebook,optuna,ray]) (22.3.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from plotly->catboost>=0.26->flaml[nlp,notebook,optuna,ray]) (8.0.1)\n",
      "Requirement already satisfied: qtpy in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from qtconsole->jupyter->flaml[nlp,notebook,optuna,ray]) (2.0.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[tune]~=1.10->flaml[nlp,notebook,optuna,ray]) (1.13.3)\n",
      "Requirement already satisfied: stack-data in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[nlp,notebook,optuna,ray]) (0.2.0)\n",
      "Requirement already satisfied: decorator in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[nlp,notebook,optuna,ray]) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[nlp,notebook,optuna,ray]) (0.7.5)\n",
      "Requirement already satisfied: backcall in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[nlp,notebook,optuna,ray]) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[nlp,notebook,optuna,ray]) (0.18.1)\n",
      "Requirement already satisfied: black in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[nlp,notebook,optuna,ray]) (22.1.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->flaml[nlp,notebook,optuna,ray]) (4.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jinja2>=2.4->nbconvert->jupyter->flaml[nlp,notebook,optuna,ray]) (2.0.1)\n",
      "Requirement already satisfied: wcwidth in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter->flaml[nlp,notebook,optuna,ray]) (0.2.5)\n",
      "Requirement already satisfied: ptyprocess in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from terminado>=0.8.3->notebook->jupyter->flaml[nlp,notebook,optuna,ray]) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter->flaml[nlp,notebook,optuna,ray]) (21.2.0)\n",
      "Requirement already satisfied: webencodings in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from bleach->nbconvert->jupyter->flaml[nlp,notebook,optuna,ray]) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->flaml[nlp,notebook,optuna,ray]) (0.8.3)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->flaml[nlp,notebook,optuna,ray]) (1.15.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from black->ipython>=7.23.1->ipykernel->jupyter->flaml[nlp,notebook,optuna,ray]) (2.0.1)\n",
      "Requirement already satisfied: platformdirs>=2 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from black->ipython>=7.23.1->ipykernel->jupyter->flaml[nlp,notebook,optuna,ray]) (2.5.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from black->ipython>=7.23.1->ipykernel->jupyter->flaml[nlp,notebook,optuna,ray]) (0.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from black->ipython>=7.23.1->ipykernel->jupyter->flaml[nlp,notebook,optuna,ray]) (0.4.3)\n",
      "Requirement already satisfied: executing in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->flaml[nlp,notebook,optuna,ray]) (0.8.2)\n",
      "Requirement already satisfied: pure-eval in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->flaml[nlp,notebook,optuna,ray]) (0.2.2)\n",
      "Requirement already satisfied: asttokens in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->flaml[nlp,notebook,optuna,ray]) (2.0.5)\n",
      "Requirement already satisfied: pycparser in /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->flaml[nlp,notebook,optuna,ray]) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install flaml[nlp,ray,notebook,optuna];\n",
    "# from v0.6.6, catboost is made an optional dependency to build conda package.\n",
    "# to install catboost without installing the notebook option, you can run:\n",
    "# !pip install flaml[catboost]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sentiment Classification Example\n",
    "## Load data and preprocess\n",
    "\n",
    "The Stanford Sentiment treebank (SST-2) dataset is a dataset for sentiment classification. First, let's load this dataset into pandas dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/xliu127/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Reusing dataset glue (/home/xliu127/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Reusing dataset glue (/home/xliu127/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"glue\", \"sst2\", split=\"train\").to_pandas().iloc[0:10000]\n",
    "dev_dataset = load_dataset(\"glue\", \"sst2\", split=\"validation\").to_pandas().iloc[0:10000]\n",
    "test_dataset = load_dataset(\"glue\", \"sst2\", split=\"test\").to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the first 5 examples of this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hide new secretions from the parental units</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contains no wit , only labored gags</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that loves its characters and communicates som...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>remains utterly satisfied to remain the same t...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on the worst revenge-of-the-nerds clichés the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label  idx\n",
       "0       hide new secretions from the parental units       0    0\n",
       "1               contains no wit , only labored gags       0    1\n",
       "2  that loves its characters and communicates som...      1    2\n",
       "3  remains utterly satisfied to remain the same t...      0    3\n",
       "4  on the worst revenge-of-the-nerds clichés the ...      0    4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the data into X and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sent_keys = [\"sentence\"]          # specify the column names of the input sentences\n",
    "label_key = \"label\"                                    # specify the column name of the label\n",
    "\n",
    "X_train, y_train = train_dataset[custom_sent_keys], train_dataset[label_key]\n",
    "X_val, y_val = dev_dataset[custom_sent_keys], dev_dataset[label_key]\n",
    "X_test = test_dataset[custom_sent_keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run FLAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' import AutoML class from flaml package '''\n",
    "from flaml import AutoML\n",
    "automl = AutoML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    \"time_budget\": 500,                                 # setting the time budget\n",
    "    \"task\": \"seq-classification\",                       # specifying your task is seq-classification \n",
    "    \"custom_hpo_args\": {\"output_dir\": \"data/output/\", \"ckpt_per_epoch\": 1, \"model_path\": \"google/electra-base-discriminator\"},  # specifying your output directory\n",
    "    \"gpu_per_trial\": 1,                                 # set to 0 if no GPU is available\n",
    "    \"log_file_name\": \"seqclass.log\",\n",
    "    \"log_type\": \"all\",\n",
    "    \"n_concurrent_trials\": 4,\n",
    "    \"max_iter\": 8,\n",
    "    \"sample\": False,\n",
    "    \"hpo_method\": \"optuna\"                            \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-27 20:23:48 (running for 00:08:22.09)<br>Memory usage on this node: 23.6/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/96 CPUs, 0/4 GPUs, 0.0/250.42 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Current best trial: 3d9e1fd8 with val_loss=0.0745412844036697 and parameters={'learning_rate': 8.421292235057749e-05, 'num_train_epochs': 0.6593869048703147, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.19685216027373567, 'weight_decay': 0.16931560182347347, 'adam_epsilon': 9.840094059810994e-07, 'seed': 42, 'global_max_steps': 9223372036854775807, 'learner': 'transformer'}<br>Result logdir: /home/xliu127/ray_results/train_2022-02-27_20-15-26<br>Number of trials: 8/8 (8 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(train pid=27674)\u001B[0m {'eval_loss': 0.3430978059768677, 'eval_automl_metric': 0.0665137614678899, 'eval_runtime': 10.5616, 'eval_samples_per_second': 82.563, 'eval_steps_per_second': 82.563, 'epoch': 2.0}\n",
      "\u001B[2m\u001B[36m(train pid=27662)\u001B[0m {'eval_loss': 0.4666380286216736, 'eval_automl_metric': 0.0665137614678899, 'eval_runtime': 9.6845, 'eval_samples_per_second': 90.041, 'eval_steps_per_second': 90.041, 'epoch': 5.0}\n",
      "\u001B[2m\u001B[36m(train pid=27667)\u001B[0m {'eval_loss': 0.4148450493812561, 'eval_automl_metric': 0.06307339449541283, 'eval_runtime': 9.5869, 'eval_samples_per_second': 90.957, 'eval_steps_per_second': 90.957, 'epoch': 5.0}\n",
      "\u001B[2m\u001B[36m(train pid=27667)\u001B[0m {'eval_loss': 0.43206584453582764, 'eval_automl_metric': 0.06422018348623848, 'eval_runtime': 9.5331, 'eval_samples_per_second': 91.471, 'eval_steps_per_second': 91.471, 'epoch': 5.08}\n",
      "\u001B[2m\u001B[36m(train pid=27662)\u001B[0m {'eval_loss': 0.46918314695358276, 'eval_automl_metric': 0.06536697247706424, 'eval_runtime': 9.6084, 'eval_samples_per_second': 90.754, 'eval_steps_per_second': 90.754, 'epoch': 5.1}\n",
      "\u001B[2m\u001B[36m(train pid=27667)\u001B[0m {'eval_loss': 0.43206584453582764, 'eval_automl_metric': 0.06422018348623848, 'eval_runtime': 9.1155, 'eval_samples_per_second': 95.661, 'eval_steps_per_second': 95.661, 'epoch': 5.08}\n",
      "\u001B[2m\u001B[36m(train pid=27662)\u001B[0m {'eval_loss': 0.46918314695358276, 'eval_automl_metric': 0.06536697247706424, 'eval_runtime': 9.869, 'eval_samples_per_second': 88.358, 'eval_steps_per_second': 88.358, 'epoch': 5.1}\n",
      "\u001B[2m\u001B[36m(train pid=27667)\u001B[0m {'train_runtime': 526.3996, 'train_samples_per_second': 168.677, 'train_steps_per_second': 21.085, 'train_loss': 0.17942396026027224, 'epoch': 5.08}\n",
      "\u001B[2m\u001B[36m(train pid=27662)\u001B[0m {'train_runtime': 527.2879, 'train_samples_per_second': 119.61, 'train_steps_per_second': 14.952, 'train_loss': 0.16184668756917509, 'epoch': 5.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(train pid=27667)\u001B[0m ***** Running Prediction *****\n",
      "\u001B[2m\u001B[36m(train pid=27667)\u001B[0m   Num examples = 872\n",
      "\u001B[2m\u001B[36m(train pid=27667)\u001B[0m   Batch size = 32\n",
      "\u001B[2m\u001B[36m(train pid=27662)\u001B[0m ***** Running Prediction *****\n",
      "\u001B[2m\u001B[36m(train pid=27662)\u001B[0m   Num examples = 872\n",
      "\u001B[2m\u001B[36m(train pid=27662)\u001B[0m   Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(train pid=27674)\u001B[0m {'eval_loss': 0.37832382321357727, 'eval_automl_metric': 0.06766055045871555, 'eval_runtime': 11.0124, 'eval_samples_per_second': 79.184, 'eval_steps_per_second': 79.184, 'epoch': 2.31}\n",
      "\u001B[2m\u001B[36m(train pid=27674)\u001B[0m {'train_runtime': 498.5467, 'train_samples_per_second': 46.323, 'train_steps_per_second': 11.582, 'train_loss': 0.27595042092270783, 'epoch': 2.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(train pid=27674)\u001B[0m ***** Running Prediction *****\n",
      "\u001B[2m\u001B[36m(train pid=27674)\u001B[0m   Num examples = 872\n",
      "\u001B[2m\u001B[36m(train pid=27674)\u001B[0m   Batch size = 32\n",
      "2022-02-27 20:25:07,379\tINFO tune.py:636 -- Total run time: 580.93 seconds (500.46 seconds for the tuning loop).\n",
      "[flaml.automl: 02-27 20:25:09] {2763} INFO - selected model: None\n",
      "\u001B[32m[I 2022-02-27 20:25:09,404]\u001B[0m A new study created in memory with name: optuna\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-27 20:25:10 (running for 00:00:01.04)<br>Memory usage on this node: 13.2/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.42 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-02-27_20-25-09<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m E0227 20:25:10.462152096   31299 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-27 20:25:15 (running for 00:00:06.04)<br>Memory usage on this node: 13.3/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.42 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-02-27_20-25-09<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-27 20:25:20 (running for 00:00:11.06)<br>Memory usage on this node: 16.3/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.42 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-02-27_20-25-09<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m /data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m   warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-27 20:25:25 (running for 00:00:16.06)<br>Memory usage on this node: 16.6/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.42 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-02-27_20-25-09<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-27 20:25:30 (running for 00:00:21.08)<br>Memory usage on this node: 16.6/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.42 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-02-27_20-25-09<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-27 20:25:35 (running for 00:00:26.08)<br>Memory usage on this node: 16.6/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.42 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-02-27_20-25-09<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-27 20:25:40 (running for 00:00:31.10)<br>Memory usage on this node: 16.6/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.42 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-02-27_20-25-09<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-27 20:25:45 (running for 00:00:36.10)<br>Memory usage on this node: 16.6/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.42 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-02-27_20-25-09<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-27 20:25:50 (running for 00:00:41.11)<br>Memory usage on this node: 16.6/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.42 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-02-27_20-25-09<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m {'loss': 0.3877, 'learning_rate': 7.632591149599169e-07, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m 2022-02-27 20:25:55,167\tERROR function_runner.py:268 -- Runner Thread raised error.\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m Traceback (most recent call last):\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/torch/serialization.py\", line 379, in save\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m     _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/torch/serialization.py\", line 499, in _save\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m     zip_file.write_record(name, storage.data_ptr(), num_bytes)\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m OSError: [Errno 28] No space left on device\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m \n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m During handling of the above exception, another exception occurred:\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m \n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m Traceback (most recent call last):\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 262, in run\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m     self._entrypoint()\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 330, in entrypoint\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m     return self._trainable_func(self.config, self._status_reporter,\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m     return method(self, *_args, **_kwargs)\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m     output = fn()\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m   File \"/data/xliu127/projects/hyperopt/FLAML/flaml/automl.py\", line 344, in _trainable_function_wrapper\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m     return_estimator, train_time = train_estimator(\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m   File \"/data/xliu127/projects/hyperopt/FLAML/flaml/ml.py\", line 616, in train_estimator\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m     train_time = estimator.fit(X_train, y_train, budget, **fit_kwargs)\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m   File \"/data/xliu127/projects/hyperopt/FLAML/flaml/model.py\", line 594, in fit\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m     self._trainer.train()\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 1440, in train\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m     self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 1569, in _maybe_log_save_evaluate\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m     self._save_checkpoint(model, trial, metrics=metrics)\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/transformers/trainer.py\", line 1667, in _save_checkpoint\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m     torch.save(self.optimizer.state_dict(), os.path.join(output_dir, OPTIMIZER_NAME))\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/torch/serialization.py\", line 380, in save\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m     return\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/torch/serialization.py\", line 259, in __exit__\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m     self.file_like.write_end_of_file()\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m RuntimeError: [enforce fail at inline_container.cc:300] . unexpected pos 442378816 vs 442378704\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m Exception in thread Thread-2:\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m Traceback (most recent call last):\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/torch/serialization.py\", line 379, in save\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m     _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/torch/serialization.py\", line 499, in _save\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m     zip_file.write_record(name, storage.data_ptr(), num_bytes)\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m OSError: [Errno 28] No space left on device\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m \n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m During handling of the above exception, another exception occurred:\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m \n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m Traceback (most recent call last):\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m     self.run()\n",
      "\u001B[2m\u001B[36m(_trainable_function_wrapper pid=27621)\u001B[0m   File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/function_runner\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-27 20:25:55 (running for 00:00:46.12)<br>Memory usage on this node: 13.2/376.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/96 CPUs, 1.0/4 GPUs, 0.0/250.42 GiB heap, 0.0/111.32 GiB objects (0.0/1.0 accelerator_type:V100)<br>Result logdir: /home/xliu127/ray_results/_trainable_function_wrapper_2022-02-27_20-25-09<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-27 20:25:55,652\tERROR trial_runner.py:927 -- Trial _trainable_function_wrapper_69f64116: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 893, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 707, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/worker.py\", line 1735, in get\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
      "2022-02-27 20:25:55,664\tWARNING worker.py:1257 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff3aeb2745be60de2a7febe18d01000000 Worker ID: a76ec9bb9318e69fe23aaced8b4b8db1e92a8c10787d03d4385adc72 Node ID: 592bbe24171b85c5315c49e3b41aec9de5b5924cc560b192cb9ae3e2 Worker IP address: 155.246.89.124 Worker port: 43313 Worker PID: 27621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trial _trainable_function_wrapper_69f64116 errored with parameters={'learning_rate': 8.421292235057749e-05, 'num_train_epochs': 0.6593869048703147, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.19685216027373567, 'weight_decay': 0.16931560182347347, 'adam_epsilon': 9.840094059810994e-07, 'seed': 42, 'global_max_steps': 413, 'learner': 'transformer'}. Error file: /home/xliu127/ray_results/_trainable_function_wrapper_2022-02-27_20-25-09/_trainable_function_wrapper_69f64116_1_adam_epsilon=9.8401e-07,global_max_steps=413,learner=transformer,learning_rate=8.4213e-05,n_2022-02-27_20-25-09/error.txt\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRayActorError\u001B[0m                             Traceback (most recent call last)",
      "\u001B[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/trial_runner.py\u001B[0m in \u001B[0;36m_process_trial\u001B[0;34m(self, trial)\u001B[0m\n\u001B[1;32m    892\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 893\u001B[0;31m             \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrial_executor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfetch_result\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    894\u001B[0m             with warn_if_slow(\n",
      "\u001B[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\u001B[0m in \u001B[0;36mfetch_result\u001B[0;34m(self, trial)\u001B[0m\n\u001B[1;32m    706\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mwarn_if_slow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"fetch_result\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 707\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mray\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrial_future\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mDEFAULT_GET_TIMEOUT\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    708\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    104\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 105\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    106\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/worker.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(object_refs, timeout)\u001B[0m\n\u001B[1;32m   1734\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1735\u001B[0;31m                     \u001B[0;32mraise\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1736\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRayActorError\u001B[0m: The actor died unexpectedly before finishing this task.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_27244/1318418430.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;34m'''The main flaml automl API'''\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mautoml\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_val\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mX_val\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_val\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0my_val\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mautoml_settings\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/data/xliu127/projects/hyperopt/FLAML/flaml/automl.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X_train, y_train, dataframe, label, metric, task, n_jobs, log_file_name, estimator_list, time_budget, max_iter, sample, ensemble, eval_method, log_type, model_history, split_ratio, n_splits, log_training_metric, mem_thres, pred_time_limit, train_time_limit, X_val, y_val, sample_weight_val, groups_val, groups, verbose, retrain_full, split_type, learner_selector, hpo_method, starting_points, seed, n_concurrent_trials, keep_search_state, early_stop, append_log, auto_augment, min_sample_size, use_ray, **fit_kwargs)\u001B[0m\n\u001B[1;32m   2226\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mtraining_log_writer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlog_file_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mappend_log\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0msave_helper\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2227\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_training_log\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msave_helper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2228\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_search\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2229\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2230\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_training_log\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/xliu127/projects/hyperopt/FLAML/flaml/automl.py\u001B[0m in \u001B[0;36m_search\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   2866\u001B[0m                         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_trained_estimator\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2867\u001B[0m                         \u001B[0mretrain_time\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2868\u001B[0;31m                     \u001B[0;34m)\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_state\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_train_with_config\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2869\u001B[0m                         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_best_estimator\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2870\u001B[0m                         \u001B[0mstate\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbest_config\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/xliu127/projects/hyperopt/FLAML/flaml/automl.py\u001B[0m in \u001B[0;36m_train_with_config\u001B[0;34m(self, estimator, config_w_resource, sample_size)\u001B[0m\n\u001B[1;32m    360\u001B[0m                 )\n\u001B[1;32m    361\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 362\u001B[0;31m             analysis = tune.run(\n\u001B[0m\u001B[1;32m    363\u001B[0m                 \u001B[0m_trainable_function_wrapper\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    364\u001B[0m                 \u001B[0mconfig\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mconfig_w_resource\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/xliu127/projects/hyperopt/FLAML/flaml/tune/tune.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(evaluation_function, config, low_cost_partial_config, cat_hp_cost, metric, mode, time_budget_s, points_to_evaluate, evaluated_rewards, resource_attr, min_resource, max_resource, reduction_factor, scheduler, search_alg, verbose, local_dir, num_samples, resources_per_trial, config_constraints, metric_constraints, max_failure, use_ray, use_incumbent_result_in_evaluation)\u001B[0m\n\u001B[1;32m    408\u001B[0m             )\n\u001B[1;32m    409\u001B[0m         \u001B[0m_use_ray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 410\u001B[0;31m         return tune.run(\n\u001B[0m\u001B[1;32m    411\u001B[0m             \u001B[0mevaluation_function\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    412\u001B[0m             \u001B[0mmetric\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmetric\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/tune.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, queue_trials, loggers, _remote)\u001B[0m\n\u001B[1;32m    605\u001B[0m     \u001B[0mprogress_reporter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_start_time\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtune_start\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    606\u001B[0m     \u001B[0;32mwhile\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mrunner\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_finished\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mstate\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0msignal\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSIGINT\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 607\u001B[0;31m         \u001B[0mrunner\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    608\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mhas_verbosity\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mVerbosity\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mV1_EXPERIMENT\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    609\u001B[0m             \u001B[0m_report_progress\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrunner\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprogress_reporter\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/trial_runner.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    703\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrial_executor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0min_staging_grace_period\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    704\u001B[0m                     \u001B[0mtimeout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0.1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 705\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_process_events\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    706\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    707\u001B[0m                 self._insufficient_resources_manager.on_no_available_trials(\n",
      "\u001B[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/trial_runner.py\u001B[0m in \u001B[0;36m_process_events\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    864\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    865\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mwarn_if_slow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"process_trial\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 866\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_process_trial\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    867\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    868\u001B[0m             \u001B[0;31m# `self._queued_trial_decisions` now contains a final decision\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/trial_runner.py\u001B[0m in \u001B[0;36m_process_trial\u001B[0;34m(self, trial)\u001B[0m\n\u001B[1;32m    926\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    927\u001B[0m                 \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merror_msg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 928\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_process_trial_failure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraceback\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat_exc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    929\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    930\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_process_trial_result\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrial\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/trial_runner.py\u001B[0m in \u001B[0;36m_process_trial_failure\u001B[0;34m(self, trial, error_msg)\u001B[0m\n\u001B[1;32m   1147\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_scheduler_alg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_trial_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrial\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1148\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_search_alg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_trial_complete\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrial_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merror\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1149\u001B[0;31m                 self._callbacks.on_trial_error(\n\u001B[0m\u001B[1;32m   1150\u001B[0m                     \u001B[0miteration\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_iteration\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1151\u001B[0m                     \u001B[0mtrials\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_trials\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/callback.py\u001B[0m in \u001B[0;36mon_trial_error\u001B[0;34m(self, **info)\u001B[0m\n\u001B[1;32m    253\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mon_trial_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    254\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mcallback\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_callbacks\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 255\u001B[0;31m             \u001B[0mcallback\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_trial_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    256\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    257\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mon_checkpoint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/logger.py\u001B[0m in \u001B[0;36mon_trial_error\u001B[0;34m(self, iteration, trials, trial, **info)\u001B[0m\n\u001B[1;32m    421\u001B[0m     def on_trial_error(self, iteration: int, trials: List[\"Trial\"],\n\u001B[1;32m    422\u001B[0m                        trial: \"Trial\", **info):\n\u001B[0;32m--> 423\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlog_trial_end\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfailed\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    424\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    425\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/ray/tune/logger.py\u001B[0m in \u001B[0;36mlog_trial_end\u001B[0;34m(self, trial, failed)\u001B[0m\n\u001B[1;32m    677\u001B[0m                 }\n\u001B[1;32m    678\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_try_log_hparams\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscrubbed_result\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 679\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_trial_writer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtrial\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    680\u001B[0m             \u001B[0;32mdel\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_trial_writer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtrial\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    681\u001B[0m             \u001B[0;32mdel\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_trial_result\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtrial\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/tensorboardX/writer.py\u001B[0m in \u001B[0;36mclose\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1294\u001B[0m             \u001B[0;32mreturn\u001B[0m  \u001B[0;31m# ignore double close\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1295\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mwriter\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mall_writers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1296\u001B[0;31m             \u001B[0mwriter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflush\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1297\u001B[0m             \u001B[0mwriter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1298\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfile_writer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mall_writers\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/tensorboardX/writer.py\u001B[0m in \u001B[0;36mflush\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    191\u001B[0m         \u001B[0mdisk\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    192\u001B[0m         \"\"\"\n\u001B[0;32m--> 193\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevent_writer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflush\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    194\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    195\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/tensorboardX/event_file_writer.py\u001B[0m in \u001B[0;36mflush\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    146\u001B[0m         \"\"\"\n\u001B[1;32m    147\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_closed\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 148\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_ev_writer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflush\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    149\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    150\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/tensorboardX/event_file_writer.py\u001B[0m in \u001B[0;36mflush\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     67\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     68\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_outstanding_events\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 69\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_py_recordio_writer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflush\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     70\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/tensorboardX/record_writer.py\u001B[0m in \u001B[0;36mflush\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    188\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    189\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mflush\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 190\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_writer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflush\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    191\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    192\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mOSError\u001B[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "'''The main flaml automl API'''\n",
    "automl.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **automl_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ML leaner: transformer\n",
      "Best hyperparmeter config: {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 3.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 71, 'FLAML_sample_size': 10000}\n",
      "Best accuracy on validation data: 0.9541\n",
      "Training duration of best run: 75.44 s\n"
     ]
    }
   ],
   "source": [
    "'''retrieve best config and best learner'''\n",
    "print('Best hyperparmeter config:', automl.best_config)\n",
    "print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
    "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''pickle and save the automl object'''\n",
    "import pickle\n",
    "with open('automl.pkl', 'wb') as f:\n",
    "    pickle.dump(automl, f, pickle.HIGHEST_PROTOCOL)\n",
    "'''load pickled automl object'''\n",
    "with open('automl.pkl', 'rb') as f:\n",
    "    automl = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1821\n",
      "  Batch size = 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels [1 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "'''compute predictions of testing dataset''' \n",
    "y_pred = automl.predict(X_test)\n",
    "print('Predicted labels', y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 3.712265538348735e-06, 'num_train_epochs': 0.48393026940649086, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.16407075452197886, 'weight_decay': 0.23644850941274287, 'adam_epsilon': 4.4247296834481804e-07, 'seed': 44, 'global_max_steps': 152, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 3.712265538348735e-06, 'num_train_epochs': 0.48393026940649086, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.16407075452197886, 'weight_decay': 0.23644850941274287, 'adam_epsilon': 4.4247296834481804e-07, 'seed': 44, 'global_max_steps': 152, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 0.0005028960644627165, 'num_train_epochs': 0.39537091142700365, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.11233519789666767, 'weight_decay': 0.12350220333125939, 'adam_epsilon': 7.185362414507391e-07, 'seed': 43, 'global_max_steps': 495, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 3.712265538348735e-06, 'num_train_epochs': 0.48393026940649086, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.16407075452197886, 'weight_decay': 0.23644850941274287, 'adam_epsilon': 4.4247296834481804e-07, 'seed': 44, 'global_max_steps': 152, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 8.421292235057749e-05, 'num_train_epochs': 0.6593869048703147, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.19685216027373567, 'weight_decay': 0.16931560182347347, 'adam_epsilon': 9.840094059810994e-07, 'seed': 42, 'global_max_steps': 413, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 8.421292235057749e-05, 'num_train_epochs': 0.6593869048703147, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.19685216027373567, 'weight_decay': 0.16931560182347347, 'adam_epsilon': 9.840094059810994e-07, 'seed': 42, 'global_max_steps': 413, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 7.170358160153936e-06, 'num_train_epochs': 0.28998348420090736, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.20798724893902748, 'weight_decay': 0.05797307630916362, 'adam_epsilon': 5.6929420097316636e-08, 'seed': 41, 'global_max_steps': 363, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 8.421292235057749e-05, 'num_train_epochs': 0.6593869048703147, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.19685216027373567, 'weight_decay': 0.16931560182347347, 'adam_epsilon': 9.840094059810994e-07, 'seed': 42, 'global_max_steps': 413, 'learner': 'transformer'}}\n",
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 0.00014019132043158598, 'num_train_epochs': 1.590838074955561, 'per_device_train_batch_size': 8, 'warmup_ratio': 0.14927591511788035, 'weight_decay': 0.06870749086793847, 'adam_epsilon': 2.305765574688916e-08, 'seed': 41, 'global_max_steps': 1989, 'learner': 'transformer'}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 8.421292235057749e-05, 'num_train_epochs': 0.6593869048703147, 'per_device_train_batch_size': 16, 'warmup_ratio': 0.19685216027373567, 'weight_decay': 0.16931560182347347, 'adam_epsilon': 9.840094059810994e-07, 'seed': 42, 'global_max_steps': 413, 'learner': 'transformer'}}\n"
     ]
    }
   ],
   "source": [
    "from flaml.data import get_output_from_log\n",
    "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
    "    get_output_from_log(filename=automl_settings['log_file_name'], time_budget=3000)\n",
    "for config in config_history:\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Wall Clock Time (s)')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "print(len(valid_loss_history))\n",
    "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
    "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Paraphrase Detection Example\n",
    "### Load data and preprocess\n",
    "\n",
    "The Microsoft Research Parallel Corpus (MRPC) is a dataset for paraphrase detection. An example pair of sentences is:\n",
    "\n",
    "* sentence 1: Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .\n",
    "* sentence 2: Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .\n",
    "\n",
    "First, let's load this dataset in to pandas dataframes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/xliu127/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Reusing dataset glue (/home/xliu127/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Reusing dataset glue (/home/xliu127/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"glue\", \"mrpc\", split=\"train\").to_pandas()\n",
    "dev_dataset = load_dataset(\"glue\", \"mrpc\", split=\"validation\").to_pandas()\n",
    "test_dataset = load_dataset(\"glue\", \"mrpc\", split=\"test\").to_pandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 5 examples of this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amrozi accused his brother , whom he called \" ...</td>\n",
       "      <td>Referring to him as only \" the witness \" , Amr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yucaipa owned Dominick 's before selling the c...</td>\n",
       "      <td>Yucaipa bought Dominick 's in 1995 for $ 693 m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They had published an advertisement on the Int...</td>\n",
       "      <td>On June 10 , the ship 's owners had published ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Around 0335 GMT , Tab shares were up 19 cents ...</td>\n",
       "      <td>Tab shares jumped 20 cents , or 4.6 % , to set...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The stock rose $ 2.11 , or about 11 percent , ...</td>\n",
       "      <td>PG &amp; E Corp. shares jumped $ 1.63 or 8 percent...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  Amrozi accused his brother , whom he called \" ...   \n",
       "1  Yucaipa owned Dominick 's before selling the c...   \n",
       "2  They had published an advertisement on the Int...   \n",
       "3  Around 0335 GMT , Tab shares were up 19 cents ...   \n",
       "4  The stock rose $ 2.11 , or about 11 percent , ...   \n",
       "\n",
       "                                           sentence2  label  idx  \n",
       "0  Referring to him as only \" the witness \" , Amr...      1    0  \n",
       "1  Yucaipa bought Dominick 's in 1995 for $ 693 m...      0    1  \n",
       "2  On June 10 , the ship 's owners had published ...      1    2  \n",
       "3  Tab shares jumped 20 cents , or 4.6 % , to set...      0    3  \n",
       "4  PG & E Corp. shares jumped $ 1.63 or 8 percent...      1    4  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the data into X and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['sentence'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_33499/1434884187.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mlabel_key\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"label\"\u001B[0m                                    \u001B[0;31m# specify the column name of the label\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_dataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcustom_sent_keys\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_dataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mlabel_key\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0mX_val\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_val\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdev_dataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcustom_sent_keys\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdev_dataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mlabel_key\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0mX_test\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtest_dataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcustom_sent_keys\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3509\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mis_iterator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3510\u001B[0m                 \u001B[0mkey\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3511\u001B[0;31m             \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_indexer_strict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"columns\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3512\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3513\u001B[0m         \u001B[0;31m# take() does not accept boolean indexers\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36m_get_indexer_strict\u001B[0;34m(self, key, axis_name)\u001B[0m\n\u001B[1;32m   5780\u001B[0m             \u001B[0mkeyarr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindexer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnew_indexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reindex_non_unique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkeyarr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5781\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 5782\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_raise_if_missing\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkeyarr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindexer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   5783\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5784\u001B[0m         \u001B[0mkeyarr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtake\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/installation/anaconda3/envs/tmp/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36m_raise_if_missing\u001B[0;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[1;32m   5840\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0muse_interval_msg\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5841\u001B[0m                     \u001B[0mkey\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 5842\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   5843\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5844\u001B[0m             \u001B[0mnot_found\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mensure_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mmissing_mask\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnonzero\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: \"None of [Index(['sentence'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "custom_sent_keys = [\"sentence1\", \"sentence2\"]          # specify the column names of the input sentences\n",
    "label_key = \"label\"                                    # specify the column name of the label\n",
    "\n",
    "X_train, y_train = train_dataset[custom_sent_keys], train_dataset[label_key]\n",
    "X_val, y_val = dev_dataset[custom_sent_keys], dev_dataset[label_key]\n",
    "X_test = test_dataset[custom_sent_keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Run FLAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "''' import AutoML class from flaml package '''\n",
    "from flaml import AutoML\n",
    "automl = AutoML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    \"time_budget\": 300,                                 # setting the time budget\n",
    "    \"task\": \"seq-classification\",                       # specifying your task is seq-classification \n",
    "    \"custom_hpo_args\": {\"output_dir\": \"data/output/\", \"ckpt_per_epoch\": 1, \"model_path\": \"google/electra-base-discriminator\"},  # specifying your output directory\n",
    "    \"gpu_per_trial\": 1,                                 # set to 0 if no GPU is available\n",
    "    \"log_file_name\": \"seqclass.log\",                          \n",
    "    \"log_type\": \"all\",\n",
    "    \"n_concurrent_trials\": 4,\n",
    "    \"max_iter\": 8,\n",
    "    \"sample\": False\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_33499/1318418430.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;34m'''The main flaml automl API'''\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mautoml\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_val\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mX_val\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_val\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0my_val\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mautoml_settings\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "'''The main flaml automl API'''\n",
    "automl.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **automl_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ML leaner: transformer\n",
      "Best hyperparmeter config: {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 3.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 69, 'FLAML_sample_size': 10000}\n",
      "Best accuracy on validation data: 0.9553\n",
      "Training duration of best run: 65.26 s\n"
     ]
    }
   ],
   "source": [
    "'''retrieve best config and best learner'''\n",
    "print('Best hyperparmeter config:', automl.best_config)\n",
    "print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
    "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''pickle and save the automl object'''\n",
    "import pickle\n",
    "with open('automl.pkl', 'wb') as f:\n",
    "    pickle.dump(automl, f, pickle.HIGHEST_PROTOCOL)\n",
    "'''load pickled automl object'''\n",
    "with open('automl.pkl', 'rb') as f:\n",
    "    automl = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1821\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='456' max='456' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [456/456 00:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels [0 0 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "'''compute predictions of testing dataset''' \n",
    "y_pred = automl.predict(X_test)\n",
    "print('Predicted labels', y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "### Log history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Current Learner': 'transformer', 'Current Sample': 10000, 'Current Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 3.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 71, 'FLAML_sample_size': 10000}, 'Best Learner': 'transformer', 'Best Hyper-parameters': {'learning_rate': 1.0000000000000003e-05, 'num_train_epochs': 3.0, 'per_device_train_batch_size': 32, 'warmup_ratio': 0.0, 'weight_decay': 0.0, 'adam_epsilon': 1e-06, 'seed': 42, 'global_max_steps': 71, 'FLAML_sample_size': 10000}}\n"
     ]
    }
   ],
   "source": [
    "from flaml.data import get_output_from_log\n",
    "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
    "    get_output_from_log(filename=automl_settings['log_file_name'], time_budget=240)\n",
    "for config in config_history:\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Wall Clock Time (s)')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
    "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9d36fc5b7c3dd4177ff1b60184dd696c0acc18150a44682abca4d769811bd46"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}