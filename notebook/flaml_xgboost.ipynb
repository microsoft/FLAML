{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved. \n",
    "\n",
    "Licensed under the MIT License.\n",
    "\n",
    "# Tune XGBoost with FLAML Library\n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "FLAML is a Python library (https://github.com/microsoft/FLAML) designed to automatically produce accurate machine learning models \n",
    "with low computational cost. It is fast and cheap. The simple and lightweight design makes it easy \n",
    "to use and extend, such as adding new learners. FLAML can \n",
    "- serve as an economical AutoML engine,\n",
    "- be used as a fast hyperparameter tuning tool, or \n",
    "- be embedded in self-tuning software that requires low latency & resource in repetitive\n",
    "   tuning tasks.\n",
    "\n",
    "In this notebook, we demonstrate how to use FLAML library to tune hyperparameters of XGBoost with a regression example.\n",
    "\n",
    "FLAML requires `Python>=3.6`. To run this notebook example, please install flaml with the `notebook` option:\n",
    "```bash\n",
    "pip install flaml[notebook]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flaml[notebook];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Regression Example\n",
    "### Load data and preprocess\n",
    "\n",
    "Download [houses dataset](https://www.openml.org/d/537) from OpenML. The task is to predict median price of the house in the region based on demographic composition and a state of housing market in the region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load dataset from ./openml_ds537.pkl\n",
      "Dataset name: houses\n",
      "X_train.shape: (15480, 8), y_train.shape: (15480,);\n",
      "X_test.shape: (5160, 8), y_test.shape: (5160,)\n"
     ]
    }
   ],
   "source": [
    "from flaml.data import load_openml_dataset\n",
    "X_train, X_test, y_train, y_test = load_openml_dataset(dataset_id=537, data_dir='./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Run FLAML\n",
    "In the FLAML automl run configuration, users can specify the task type, time budget, error metric, learner list, whether to subsample, resampling strategy type, and so on. All these arguments have default values which will be used if users do not provide them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "''' import AutoML class from flaml package '''\n",
    "from flaml import AutoML\n",
    "automl = AutoML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"time_budget\": 120,  # total running time in seconds\n",
    "    \"metric\": 'r2',  # primary metrics for regression can be chosen from: ['mae','mse','r2']\n",
    "    \"estimator_list\": ['xgboost'],  # list of ML learners; we tune xgboost in this example\n",
    "    \"task\": 'regression',  # task type    \n",
    "    \"log_file_name\": 'houses_experiment.log',  # flaml log file\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 11-23 01:28:26] {1861} INFO - task = regression\n",
      "[flaml.automl: 11-23 01:28:26] {1863} INFO - Data split method: uniform\n",
      "[flaml.automl: 11-23 01:28:26] {1867} INFO - Evaluation method: cv\n",
      "[flaml.automl: 11-23 01:28:26] {1933} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl: 11-23 01:28:26] {1985} INFO - List of ML learners in AutoML Run: ['xgboost']\n",
      "[flaml.automl: 11-23 01:28:26] {2223} INFO - iteration 0, current learner xgboost\n",
      "[flaml.automl: 11-23 01:28:26] {2337} INFO - Estimated sufficient time budget=1362s. Estimated necessary time budget=1s.\n",
      "[flaml.automl: 11-23 01:28:26] {2417} INFO -  at 0.2s,\testimator xgboost's best error=2.1267,\tbest estimator xgboost's best error=2.1267\n",
      "[flaml.automl: 11-23 01:28:26] {2223} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl: 11-23 01:28:26] {2417} INFO -  at 0.3s,\testimator xgboost's best error=2.1267,\tbest estimator xgboost's best error=2.1267\n",
      "[flaml.automl: 11-23 01:28:26] {2223} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl: 11-23 01:28:26] {2417} INFO -  at 0.4s,\testimator xgboost's best error=0.8485,\tbest estimator xgboost's best error=0.8485\n",
      "[flaml.automl: 11-23 01:28:26] {2223} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl: 11-23 01:28:27] {2417} INFO -  at 0.5s,\testimator xgboost's best error=0.3799,\tbest estimator xgboost's best error=0.3799\n",
      "[flaml.automl: 11-23 01:28:27] {2223} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl: 11-23 01:28:27] {2417} INFO -  at 0.6s,\testimator xgboost's best error=0.3799,\tbest estimator xgboost's best error=0.3799\n",
      "[flaml.automl: 11-23 01:28:27] {2223} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl: 11-23 01:28:27] {2417} INFO -  at 0.8s,\testimator xgboost's best error=0.3799,\tbest estimator xgboost's best error=0.3799\n",
      "[flaml.automl: 11-23 01:28:27] {2223} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl: 11-23 01:28:27] {2417} INFO -  at 1.0s,\testimator xgboost's best error=0.2992,\tbest estimator xgboost's best error=0.2992\n",
      "[flaml.automl: 11-23 01:28:27] {2223} INFO - iteration 7, current learner xgboost\n",
      "[flaml.automl: 11-23 01:28:27] {2417} INFO -  at 1.2s,\testimator xgboost's best error=0.2992,\tbest estimator xgboost's best error=0.2992\n",
      "[flaml.automl: 11-23 01:28:27] {2223} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl: 11-23 01:28:27] {2417} INFO -  at 1.3s,\testimator xgboost's best error=0.2992,\tbest estimator xgboost's best error=0.2992\n",
      "[flaml.automl: 11-23 01:28:27] {2223} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl: 11-23 01:28:28] {2417} INFO -  at 1.5s,\testimator xgboost's best error=0.2513,\tbest estimator xgboost's best error=0.2513\n",
      "[flaml.automl: 11-23 01:28:28] {2223} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl: 11-23 01:28:28] {2417} INFO -  at 1.6s,\testimator xgboost's best error=0.2513,\tbest estimator xgboost's best error=0.2513\n",
      "[flaml.automl: 11-23 01:28:28] {2223} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl: 11-23 01:28:28] {2417} INFO -  at 1.8s,\testimator xgboost's best error=0.2513,\tbest estimator xgboost's best error=0.2513\n",
      "[flaml.automl: 11-23 01:28:28] {2223} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl: 11-23 01:28:28] {2417} INFO -  at 2.1s,\testimator xgboost's best error=0.2113,\tbest estimator xgboost's best error=0.2113\n",
      "[flaml.automl: 11-23 01:28:28] {2223} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl: 11-23 01:28:28] {2417} INFO -  at 2.3s,\testimator xgboost's best error=0.2113,\tbest estimator xgboost's best error=0.2113\n",
      "[flaml.automl: 11-23 01:28:28] {2223} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl: 11-23 01:28:29] {2417} INFO -  at 2.9s,\testimator xgboost's best error=0.2090,\tbest estimator xgboost's best error=0.2090\n",
      "[flaml.automl: 11-23 01:28:29] {2223} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl: 11-23 01:28:29] {2417} INFO -  at 3.4s,\testimator xgboost's best error=0.2090,\tbest estimator xgboost's best error=0.2090\n",
      "[flaml.automl: 11-23 01:28:29] {2223} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl: 11-23 01:28:31] {2417} INFO -  at 4.7s,\testimator xgboost's best error=0.1919,\tbest estimator xgboost's best error=0.1919\n",
      "[flaml.automl: 11-23 01:28:31] {2223} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl: 11-23 01:28:31] {2417} INFO -  at 5.1s,\testimator xgboost's best error=0.1919,\tbest estimator xgboost's best error=0.1919\n",
      "[flaml.automl: 11-23 01:28:31] {2223} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl: 11-23 01:28:34] {2417} INFO -  at 8.1s,\testimator xgboost's best error=0.1797,\tbest estimator xgboost's best error=0.1797\n",
      "[flaml.automl: 11-23 01:28:34] {2223} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl: 11-23 01:28:35] {2417} INFO -  at 8.8s,\testimator xgboost's best error=0.1797,\tbest estimator xgboost's best error=0.1797\n",
      "[flaml.automl: 11-23 01:28:35] {2223} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl: 11-23 01:29:03] {2417} INFO -  at 36.8s,\testimator xgboost's best error=0.1797,\tbest estimator xgboost's best error=0.1797\n",
      "[flaml.automl: 11-23 01:29:03] {2223} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl: 11-23 01:29:05] {2417} INFO -  at 38.9s,\testimator xgboost's best error=0.1797,\tbest estimator xgboost's best error=0.1797\n",
      "[flaml.automl: 11-23 01:29:05] {2223} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl: 11-23 01:29:11] {2417} INFO -  at 45.4s,\testimator xgboost's best error=0.1782,\tbest estimator xgboost's best error=0.1782\n",
      "[flaml.automl: 11-23 01:29:11] {2223} INFO - iteration 23, current learner xgboost\n",
      "[flaml.automl: 11-23 01:29:17] {2417} INFO -  at 51.2s,\testimator xgboost's best error=0.1782,\tbest estimator xgboost's best error=0.1782\n",
      "[flaml.automl: 11-23 01:29:17] {2223} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl: 11-23 01:29:25] {2417} INFO -  at 58.5s,\testimator xgboost's best error=0.1782,\tbest estimator xgboost's best error=0.1782\n",
      "[flaml.automl: 11-23 01:29:25] {2223} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl: 11-23 01:29:26] {2417} INFO -  at 59.8s,\testimator xgboost's best error=0.1782,\tbest estimator xgboost's best error=0.1782\n",
      "[flaml.automl: 11-23 01:29:26] {2223} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl: 11-23 01:30:13] {2417} INFO -  at 107.3s,\testimator xgboost's best error=0.1660,\tbest estimator xgboost's best error=0.1660\n",
      "[flaml.automl: 11-23 01:30:23] {2629} INFO - retrain xgboost for 9.5s\n",
      "[flaml.automl: 11-23 01:30:23] {2634} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree',\n",
      "             colsample_bylevel=0.5656764254642628, colsample_bynode=1,\n",
      "             colsample_bytree=0.7313266091895249, gamma=0, gpu_id=-1,\n",
      "             grow_policy='lossguide', importance_type='gain',\n",
      "             interaction_constraints='', learning_rate=0.034786853332414935,\n",
      "             max_delta_step=0, max_depth=0, max_leaves=160,\n",
      "             min_child_weight=32.57408640781376, missing=nan,\n",
      "             monotone_constraints='()', n_estimators=776, n_jobs=-1,\n",
      "             num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0.005771390107656191, reg_lambda=1.49126672786588,\n",
      "             scale_pos_weight=1, subsample=0.9152991332236934,\n",
      "             tree_method='hist', use_label_encoder=False, validate_parameters=1,\n",
      "             verbosity=0)\n",
      "[flaml.automl: 11-23 01:30:23] {2014} INFO - fit succeeded\n",
      "[flaml.automl: 11-23 01:30:23] {2016} INFO - Time taken to find the best model: 107.32724642753601\n",
      "[flaml.automl: 11-23 01:30:23] {2030} WARNING - Time taken to find the best model is 89% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
     ]
    }
   ],
   "source": [
    "'''The main flaml automl API'''\n",
    "automl.fit(X_train=X_train, y_train=y_train, **settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Best model and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparmeter config: {'n_estimators': 776, 'max_leaves': 160, 'min_child_weight': 32.57408640781376, 'learning_rate': 0.034786853332414935, 'subsample': 0.9152991332236934, 'colsample_bylevel': 0.5656764254642628, 'colsample_bytree': 0.7313266091895249, 'reg_alpha': 0.005771390107656191, 'reg_lambda': 1.49126672786588}\n",
      "Best r2 on validation data: 0.834\n",
      "Training duration of best run: 9.471 s\n"
     ]
    }
   ],
   "source": [
    "# retrieve best config\n",
    "print('Best hyperparmeter config:', automl.best_config)\n",
    "print('Best r2 on validation data: {0:.4g}'.format(1 - automl.best_loss))\n",
    "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "             colsample_bylevel=0.5656764254642628, colsample_bynode=1,\n",
       "             colsample_bytree=0.7313266091895249, gamma=0, gpu_id=-1,\n",
       "             grow_policy='lossguide', importance_type='gain',\n",
       "             interaction_constraints='', learning_rate=0.034786853332414935,\n",
       "             max_delta_step=0, max_depth=0, max_leaves=160,\n",
       "             min_child_weight=32.57408640781376, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=776, n_jobs=-1,\n",
       "             num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0.005771390107656191, reg_lambda=1.49126672786588,\n",
       "             scale_pos_weight=1, subsample=0.9152991332236934,\n",
       "             tree_method='hist', use_label_encoder=False, validate_parameters=1,\n",
       "             verbosity=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.model.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 8 artists>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot feature importance\n",
    "import matplotlib.pyplot as plt\n",
    "plt.barh(X_train.columns, automl.model.estimator.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# pickle and save the automl object\n",
    "import pickle\n",
    "with open('automl.pkl', 'wb') as f:\n",
    "    pickle.dump(automl, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels [137582.95 255519.23 139866.06 ... 185638.95 202493.78 269308.22]\n",
      "True labels 14740    136900.0\n",
      "10101    241300.0\n",
      "20566    200700.0\n",
      "2670      72500.0\n",
      "15709    460000.0\n",
      "           ...   \n",
      "13132    121200.0\n",
      "8228     137500.0\n",
      "3948     160900.0\n",
      "8522     227300.0\n",
      "16798    265600.0\n",
      "Name: median_house_value, Length: 5160, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# compute predictions of testing dataset\n",
    "y_pred = automl.predict(X_test)\n",
    "print('Predicted labels', y_pred)\n",
    "print('True labels', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 = 0.8439648010782455\n",
      "mse = 2062552297.637671\n",
      "mae = 30303.196010098716\n"
     ]
    }
   ],
   "source": [
    "# compute different metric values on testing dataset\n",
    "from flaml.ml import sklearn_metric_loss_score\n",
    "print('r2', '=', 1 - sklearn_metric_loss_score('r2', y_pred, y_test))\n",
    "print('mse', '=', sklearn_metric_loss_score('mse', y_pred, y_test))\n",
    "print('mae', '=', sklearn_metric_loss_score('mae', y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Current Learner': 'xgboost', 'Current Sample': 15480, 'Current Hyper-parameters': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.09999999999999995, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.09999999999999995, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}}\n",
      "{'Current Learner': 'xgboost', 'Current Sample': 15480, 'Current Hyper-parameters': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25912534572860485, 'subsample': 0.9266743941610592, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292954}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25912534572860485, 'subsample': 0.9266743941610592, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292954}}\n",
      "{'Current Learner': 'xgboost', 'Current Sample': 15480, 'Current Hyper-parameters': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 1.8630223791106992, 'learning_rate': 1.0, 'subsample': 0.8513627344387318, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217073, 'reg_lambda': 0.27901659190538414}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 1.8630223791106992, 'learning_rate': 1.0, 'subsample': 0.8513627344387318, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217073, 'reg_lambda': 0.27901659190538414}}\n",
      "{'Current Learner': 'xgboost', 'Current Sample': 15480, 'Current Hyper-parameters': {'n_estimators': 11, 'max_leaves': 4, 'min_child_weight': 5.909231502320296, 'learning_rate': 1.0, 'subsample': 0.8894434216129232, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013605736901132325, 'reg_lambda': 0.1222158118565165}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 11, 'max_leaves': 4, 'min_child_weight': 5.909231502320296, 'learning_rate': 1.0, 'subsample': 0.8894434216129232, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013605736901132325, 'reg_lambda': 0.1222158118565165}}\n",
      "{'Current Learner': 'xgboost', 'Current Sample': 15480, 'Current Hyper-parameters': {'n_estimators': 11, 'max_leaves': 11, 'min_child_weight': 8.517629386811171, 'learning_rate': 1.0, 'subsample': 0.9233328006239466, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9468117873770695, 'reg_alpha': 0.034996420228767956, 'reg_lambda': 0.6169079461473824}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 11, 'max_leaves': 11, 'min_child_weight': 8.517629386811171, 'learning_rate': 1.0, 'subsample': 0.9233328006239466, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.9468117873770695, 'reg_alpha': 0.034996420228767956, 'reg_lambda': 0.6169079461473824}}\n",
      "{'Current Learner': 'xgboost', 'Current Sample': 15480, 'Current Hyper-parameters': {'n_estimators': 20, 'max_leaves': 15, 'min_child_weight': 43.62419686983011, 'learning_rate': 0.6413547778096401, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8481188761562112, 'reg_alpha': 0.01241885232679939, 'reg_lambda': 0.21352682817916668}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 20, 'max_leaves': 15, 'min_child_weight': 43.62419686983011, 'learning_rate': 0.6413547778096401, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8481188761562112, 'reg_alpha': 0.01241885232679939, 'reg_lambda': 0.21352682817916668}}\n",
      "{'Current Learner': 'xgboost', 'Current Sample': 15480, 'Current Hyper-parameters': {'n_estimators': 58, 'max_leaves': 8, 'min_child_weight': 51.84874392377357, 'learning_rate': 0.23511987355535005, 'subsample': 1.0, 'colsample_bylevel': 0.8182737361783602, 'colsample_bytree': 0.8031986460435498, 'reg_alpha': 0.00400039941928546, 'reg_lambda': 0.38702529681004805}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 58, 'max_leaves': 8, 'min_child_weight': 51.84874392377357, 'learning_rate': 0.23511987355535005, 'subsample': 1.0, 'colsample_bylevel': 0.8182737361783602, 'colsample_bytree': 0.8031986460435498, 'reg_alpha': 0.00400039941928546, 'reg_lambda': 0.38702529681004805}}\n",
      "{'Current Learner': 'xgboost', 'Current Sample': 15480, 'Current Hyper-parameters': {'n_estimators': 101, 'max_leaves': 14, 'min_child_weight': 7.444058088783035, 'learning_rate': 0.39220715578198356, 'subsample': 1.0, 'colsample_bylevel': 0.6274332478496758, 'colsample_bytree': 0.7190251742957809, 'reg_alpha': 0.007212902167942765, 'reg_lambda': 0.20172056689658188}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 101, 'max_leaves': 14, 'min_child_weight': 7.444058088783035, 'learning_rate': 0.39220715578198356, 'subsample': 1.0, 'colsample_bylevel': 0.6274332478496758, 'colsample_bytree': 0.7190251742957809, 'reg_alpha': 0.007212902167942765, 'reg_lambda': 0.20172056689658188}}\n",
      "{'Current Learner': 'xgboost', 'Current Sample': 15480, 'Current Hyper-parameters': {'n_estimators': 205, 'max_leaves': 30, 'min_child_weight': 5.450621032615097, 'learning_rate': 0.12229148765139466, 'subsample': 0.8895588746662894, 'colsample_bylevel': 0.47518959001130784, 'colsample_bytree': 0.6845612830806885, 'reg_alpha': 0.01126059820390593, 'reg_lambda': 0.08170816686602457}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 205, 'max_leaves': 30, 'min_child_weight': 5.450621032615097, 'learning_rate': 0.12229148765139466, 'subsample': 0.8895588746662894, 'colsample_bylevel': 0.47518959001130784, 'colsample_bytree': 0.6845612830806885, 'reg_alpha': 0.01126059820390593, 'reg_lambda': 0.08170816686602457}}\n",
      "{'Current Learner': 'xgboost', 'Current Sample': 15480, 'Current Hyper-parameters': {'n_estimators': 222, 'max_leaves': 62, 'min_child_weight': 7.5054716192185795, 'learning_rate': 0.04623175582706435, 'subsample': 0.8756054034199897, 'colsample_bylevel': 0.44768367042684304, 'colsample_bytree': 0.7352307811741962, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.6207832675443773}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 222, 'max_leaves': 62, 'min_child_weight': 7.5054716192185795, 'learning_rate': 0.04623175582706435, 'subsample': 0.8756054034199897, 'colsample_bylevel': 0.44768367042684304, 'colsample_bytree': 0.7352307811741962, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.6207832675443773}}\n"
     ]
    }
   ],
   "source": [
    "from flaml.data import get_output_from_log\n",
    "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
    "    get_output_from_log(filename=settings['log_file_name'], time_budget=60)\n",
    "\n",
    "for config in config_history:\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Wall Clock Time (s)')\n",
    "plt.ylabel('Validation r2')\n",
    "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
    "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparison with untuned XGBoost\n",
    "\n",
    "### FLAML's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flaml (120s) r2 = 0.8439648010782455\n"
     ]
    }
   ],
   "source": [
    "print('flaml (120s) r2', '=', 1 - sklearn_metric_loss_score('r2', y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=32, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default xgboost r2 = 0.8265451174596482\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb.predict(X_test)\n",
    "from flaml.ml import sklearn_metric_loss_score\n",
    "print('default xgboost r2', '=', 1 - sklearn_metric_loss_score('r2', y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Add customized XGBoost learners in FLAML\n",
    "You can easily enable a custom objective function by adding a customized XGBoost learner (inherit XGBoostEstimator or XGBoostSklearnEstimator) in FLAML. In the following example, we show how to add such a customized XGBoost learner with a custom objective function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 11-23 01:30:27] {1861} INFO - task = regression\n",
      "[flaml.automl: 11-23 01:30:27] {1863} INFO - Data split method: uniform\n",
      "[flaml.automl: 11-23 01:30:27] {1867} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 11-23 01:30:27] {1933} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl: 11-23 01:30:27] {1985} INFO - List of ML learners in AutoML Run: ['my_xgb1', 'my_xgb2']\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 0, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:27] {2337} INFO - Estimated sufficient time budget=341s. Estimated necessary time budget=0s.\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.1s,\testimator my_xgb1's best error=1.7590,\tbest estimator my_xgb1's best error=1.7590\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 1, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.1s,\testimator my_xgb1's best error=0.7534,\tbest estimator my_xgb1's best error=0.7534\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 2, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.1s,\testimator my_xgb1's best error=0.7534,\tbest estimator my_xgb1's best error=0.7534\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 3, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.1s,\testimator my_xgb1's best error=0.7534,\tbest estimator my_xgb1's best error=0.7534\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 4, current learner my_xgb2\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.2s,\testimator my_xgb2's best error=4.1611,\tbest estimator my_xgb1's best error=0.7534\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 5, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.2s,\testimator my_xgb1's best error=0.7534,\tbest estimator my_xgb1's best error=0.7534\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 6, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.2s,\testimator my_xgb1's best error=0.7534,\tbest estimator my_xgb1's best error=0.7534\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 7, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.2s,\testimator my_xgb1's best error=0.7534,\tbest estimator my_xgb1's best error=0.7534\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 8, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.3s,\testimator my_xgb1's best error=0.4908,\tbest estimator my_xgb1's best error=0.4908\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 9, current learner my_xgb2\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.3s,\testimator my_xgb2's best error=4.1611,\tbest estimator my_xgb1's best error=0.4908\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 10, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.3s,\testimator my_xgb1's best error=0.4908,\tbest estimator my_xgb1's best error=0.4908\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 11, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.4s,\testimator my_xgb1's best error=0.4908,\tbest estimator my_xgb1's best error=0.4908\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 12, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.4s,\testimator my_xgb1's best error=0.4908,\tbest estimator my_xgb1's best error=0.4908\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 13, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.4s,\testimator my_xgb1's best error=0.4908,\tbest estimator my_xgb1's best error=0.4908\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 14, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.5s,\testimator my_xgb1's best error=0.4908,\tbest estimator my_xgb1's best error=0.4908\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 15, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.5s,\testimator my_xgb1's best error=0.4908,\tbest estimator my_xgb1's best error=0.4908\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 16, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.5s,\testimator my_xgb1's best error=0.4908,\tbest estimator my_xgb1's best error=0.4908\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 17, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.6s,\testimator my_xgb1's best error=0.4908,\tbest estimator my_xgb1's best error=0.4908\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 18, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.6s,\testimator my_xgb1's best error=0.4908,\tbest estimator my_xgb1's best error=0.4908\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 19, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.6s,\testimator my_xgb1's best error=0.4908,\tbest estimator my_xgb1's best error=0.4908\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 20, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.7s,\testimator my_xgb1's best error=0.4908,\tbest estimator my_xgb1's best error=0.4908\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 21, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.7s,\testimator my_xgb1's best error=0.4908,\tbest estimator my_xgb1's best error=0.4908\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 22, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.8s,\testimator my_xgb1's best error=0.4908,\tbest estimator my_xgb1's best error=0.4908\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 23, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.8s,\testimator my_xgb1's best error=0.4908,\tbest estimator my_xgb1's best error=0.4908\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 24, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.8s,\testimator my_xgb1's best error=0.4908,\tbest estimator my_xgb1's best error=0.4908\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 25, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:27] {2417} INFO -  at 0.9s,\testimator my_xgb1's best error=0.4842,\tbest estimator my_xgb1's best error=0.4842\n",
      "[flaml.automl: 11-23 01:30:27] {2223} INFO - iteration 26, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 0.9s,\testimator my_xgb1's best error=0.4842,\tbest estimator my_xgb1's best error=0.4842\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 27, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 1.0s,\testimator my_xgb1's best error=0.4842,\tbest estimator my_xgb1's best error=0.4842\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 28, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 1.0s,\testimator my_xgb1's best error=0.4842,\tbest estimator my_xgb1's best error=0.4842\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 29, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 1.0s,\testimator my_xgb1's best error=0.4842,\tbest estimator my_xgb1's best error=0.4842\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 30, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 1.1s,\testimator my_xgb1's best error=0.4842,\tbest estimator my_xgb1's best error=0.4842\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 31, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 1.2s,\testimator my_xgb1's best error=0.4842,\tbest estimator my_xgb1's best error=0.4842\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 32, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 1.2s,\testimator my_xgb1's best error=0.4842,\tbest estimator my_xgb1's best error=0.4842\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 33, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 1.3s,\testimator my_xgb1's best error=0.4836,\tbest estimator my_xgb1's best error=0.4836\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 34, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 1.3s,\testimator my_xgb1's best error=0.4836,\tbest estimator my_xgb1's best error=0.4836\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 35, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 1.3s,\testimator my_xgb1's best error=0.4836,\tbest estimator my_xgb1's best error=0.4836\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 36, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 1.4s,\testimator my_xgb1's best error=0.4836,\tbest estimator my_xgb1's best error=0.4836\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 37, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 1.4s,\testimator my_xgb1's best error=0.4836,\tbest estimator my_xgb1's best error=0.4836\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 38, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 1.5s,\testimator my_xgb1's best error=0.4836,\tbest estimator my_xgb1's best error=0.4836\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 39, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 1.5s,\testimator my_xgb1's best error=0.4836,\tbest estimator my_xgb1's best error=0.4836\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 40, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 1.6s,\testimator my_xgb1's best error=0.4836,\tbest estimator my_xgb1's best error=0.4836\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 41, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 1.6s,\testimator my_xgb1's best error=0.4836,\tbest estimator my_xgb1's best error=0.4836\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 42, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 1.6s,\testimator my_xgb1's best error=0.4836,\tbest estimator my_xgb1's best error=0.4836\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 43, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 1.7s,\testimator my_xgb1's best error=0.4836,\tbest estimator my_xgb1's best error=0.4836\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 44, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 1.7s,\testimator my_xgb1's best error=0.4836,\tbest estimator my_xgb1's best error=0.4836\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 45, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 1.8s,\testimator my_xgb1's best error=0.4836,\tbest estimator my_xgb1's best error=0.4836\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 46, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 1.8s,\testimator my_xgb1's best error=0.4836,\tbest estimator my_xgb1's best error=0.4836\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 47, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 1.8s,\testimator my_xgb1's best error=0.4836,\tbest estimator my_xgb1's best error=0.4836\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 48, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 1.8s,\testimator my_xgb1's best error=0.4836,\tbest estimator my_xgb1's best error=0.4836\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 49, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 1.9s,\testimator my_xgb1's best error=0.4836,\tbest estimator my_xgb1's best error=0.4836\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 50, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:28] {2417} INFO -  at 1.9s,\testimator my_xgb1's best error=0.4836,\tbest estimator my_xgb1's best error=0.4836\n",
      "[flaml.automl: 11-23 01:30:28] {2223} INFO - iteration 51, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:29] {2417} INFO -  at 2.0s,\testimator my_xgb1's best error=0.4110,\tbest estimator my_xgb1's best error=0.4110\n",
      "[flaml.automl: 11-23 01:30:29] {2223} INFO - iteration 52, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:29] {2417} INFO -  at 2.0s,\testimator my_xgb1's best error=0.4110,\tbest estimator my_xgb1's best error=0.4110\n",
      "[flaml.automl: 11-23 01:30:29] {2223} INFO - iteration 53, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:29] {2417} INFO -  at 2.0s,\testimator my_xgb1's best error=0.4110,\tbest estimator my_xgb1's best error=0.4110\n",
      "[flaml.automl: 11-23 01:30:29] {2223} INFO - iteration 54, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:29] {2417} INFO -  at 2.1s,\testimator my_xgb1's best error=0.4110,\tbest estimator my_xgb1's best error=0.4110\n",
      "[flaml.automl: 11-23 01:30:29] {2223} INFO - iteration 55, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:29] {2417} INFO -  at 2.1s,\testimator my_xgb1's best error=0.4110,\tbest estimator my_xgb1's best error=0.4110\n",
      "[flaml.automl: 11-23 01:30:29] {2223} INFO - iteration 56, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:29] {2417} INFO -  at 2.2s,\testimator my_xgb1's best error=0.4110,\tbest estimator my_xgb1's best error=0.4110\n",
      "[flaml.automl: 11-23 01:30:29] {2223} INFO - iteration 57, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:29] {2417} INFO -  at 2.3s,\testimator my_xgb1's best error=0.4110,\tbest estimator my_xgb1's best error=0.4110\n",
      "[flaml.automl: 11-23 01:30:29] {2223} INFO - iteration 58, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:29] {2417} INFO -  at 2.3s,\testimator my_xgb1's best error=0.4110,\tbest estimator my_xgb1's best error=0.4110\n",
      "[flaml.automl: 11-23 01:30:29] {2223} INFO - iteration 59, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:29] {2417} INFO -  at 2.3s,\testimator my_xgb1's best error=0.4110,\tbest estimator my_xgb1's best error=0.4110\n",
      "[flaml.automl: 11-23 01:30:29] {2223} INFO - iteration 60, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:29] {2417} INFO -  at 2.4s,\testimator my_xgb1's best error=0.4110,\tbest estimator my_xgb1's best error=0.4110\n",
      "[flaml.automl: 11-23 01:30:29] {2223} INFO - iteration 61, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:29] {2417} INFO -  at 2.4s,\testimator my_xgb1's best error=0.4110,\tbest estimator my_xgb1's best error=0.4110\n",
      "[flaml.automl: 11-23 01:30:29] {2223} INFO - iteration 62, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:29] {2417} INFO -  at 2.5s,\testimator my_xgb1's best error=0.4110,\tbest estimator my_xgb1's best error=0.4110\n",
      "[flaml.automl: 11-23 01:30:29] {2223} INFO - iteration 63, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:29] {2417} INFO -  at 2.5s,\testimator my_xgb1's best error=0.4110,\tbest estimator my_xgb1's best error=0.4110\n",
      "[flaml.automl: 11-23 01:30:29] {2223} INFO - iteration 64, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:29] {2417} INFO -  at 2.6s,\testimator my_xgb1's best error=0.4110,\tbest estimator my_xgb1's best error=0.4110\n",
      "[flaml.automl: 11-23 01:30:29] {2223} INFO - iteration 65, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:29] {2417} INFO -  at 2.6s,\testimator my_xgb1's best error=0.4110,\tbest estimator my_xgb1's best error=0.4110\n",
      "[flaml.automl: 11-23 01:30:29] {2223} INFO - iteration 66, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:29] {2417} INFO -  at 2.6s,\testimator my_xgb1's best error=0.4110,\tbest estimator my_xgb1's best error=0.4110\n",
      "[flaml.automl: 11-23 01:30:29] {2223} INFO - iteration 67, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:29] {2417} INFO -  at 2.8s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:29] {2223} INFO - iteration 68, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:29] {2417} INFO -  at 2.8s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:29] {2223} INFO - iteration 69, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:29] {2417} INFO -  at 2.9s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:29] {2223} INFO - iteration 70, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:30] {2417} INFO -  at 3.0s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:30] {2223} INFO - iteration 71, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:30] {2417} INFO -  at 3.1s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:30] {2223} INFO - iteration 72, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:30] {2417} INFO -  at 3.2s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:30] {2223} INFO - iteration 73, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:30] {2417} INFO -  at 3.4s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:30] {2223} INFO - iteration 74, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:30] {2417} INFO -  at 3.6s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:30] {2223} INFO - iteration 75, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:30] {2417} INFO -  at 3.7s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:30] {2223} INFO - iteration 76, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:31] {2417} INFO -  at 4.0s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:31] {2223} INFO - iteration 77, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:31] {2417} INFO -  at 4.0s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:31] {2223} INFO - iteration 78, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:31] {2417} INFO -  at 4.2s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:31] {2223} INFO - iteration 79, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:31] {2417} INFO -  at 4.4s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:31] {2223} INFO - iteration 80, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:31] {2417} INFO -  at 4.5s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:31] {2223} INFO - iteration 81, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:31] {2417} INFO -  at 4.8s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:31] {2223} INFO - iteration 82, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:31] {2417} INFO -  at 4.9s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:31] {2223} INFO - iteration 83, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:32] {2417} INFO -  at 5.3s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:32] {2223} INFO - iteration 84, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:32] {2417} INFO -  at 5.4s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:32] {2223} INFO - iteration 85, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:32] {2417} INFO -  at 5.6s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:32] {2223} INFO - iteration 86, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:32] {2417} INFO -  at 5.8s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:32] {2223} INFO - iteration 87, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:33] {2417} INFO -  at 6.4s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:33] {2223} INFO - iteration 88, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:33] {2417} INFO -  at 6.5s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:33] {2223} INFO - iteration 89, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:33] {2417} INFO -  at 6.6s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:33] {2223} INFO - iteration 90, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:33] {2417} INFO -  at 6.8s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:33] {2223} INFO - iteration 91, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:34] {2417} INFO -  at 7.2s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:34] {2223} INFO - iteration 92, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:34] {2417} INFO -  at 7.3s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:34] {2223} INFO - iteration 93, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:34] {2417} INFO -  at 7.5s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:34] {2223} INFO - iteration 94, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:34] {2417} INFO -  at 7.6s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:34] {2223} INFO - iteration 95, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:34] {2417} INFO -  at 7.7s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:34] {2223} INFO - iteration 96, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:35] {2417} INFO -  at 8.1s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:35] {2223} INFO - iteration 97, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:35] {2417} INFO -  at 8.1s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:35] {2223} INFO - iteration 98, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:35] {2417} INFO -  at 8.5s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:35] {2223} INFO - iteration 99, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:35] {2417} INFO -  at 8.6s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:35] {2223} INFO - iteration 100, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:35] {2417} INFO -  at 8.7s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:35] {2223} INFO - iteration 101, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:35] {2417} INFO -  at 8.8s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:35] {2223} INFO - iteration 102, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:35] {2417} INFO -  at 8.9s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:36] {2223} INFO - iteration 103, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:36] {2417} INFO -  at 9.0s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:36] {2223} INFO - iteration 104, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:36] {2417} INFO -  at 9.1s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:36] {2223} INFO - iteration 105, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:36] {2417} INFO -  at 9.2s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:36] {2223} INFO - iteration 106, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:36] {2417} INFO -  at 9.4s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:36] {2223} INFO - iteration 107, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:36] {2417} INFO -  at 9.4s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:36] {2223} INFO - iteration 108, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:36] {2417} INFO -  at 9.6s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:36] {2223} INFO - iteration 109, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:37] {2417} INFO -  at 10.0s,\testimator my_xgb1's best error=0.3716,\tbest estimator my_xgb1's best error=0.3716\n",
      "[flaml.automl: 11-23 01:30:37] {2223} INFO - iteration 110, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:37] {2417} INFO -  at 10.1s,\testimator my_xgb1's best error=0.3499,\tbest estimator my_xgb1's best error=0.3499\n",
      "[flaml.automl: 11-23 01:30:37] {2223} INFO - iteration 111, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:37] {2417} INFO -  at 10.2s,\testimator my_xgb1's best error=0.3499,\tbest estimator my_xgb1's best error=0.3499\n",
      "[flaml.automl: 11-23 01:30:37] {2223} INFO - iteration 112, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:37] {2417} INFO -  at 10.3s,\testimator my_xgb1's best error=0.3499,\tbest estimator my_xgb1's best error=0.3499\n",
      "[flaml.automl: 11-23 01:30:37] {2223} INFO - iteration 113, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:37] {2417} INFO -  at 10.4s,\testimator my_xgb1's best error=0.3499,\tbest estimator my_xgb1's best error=0.3499\n",
      "[flaml.automl: 11-23 01:30:37] {2223} INFO - iteration 114, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:37] {2417} INFO -  at 10.4s,\testimator my_xgb1's best error=0.3499,\tbest estimator my_xgb1's best error=0.3499\n",
      "[flaml.automl: 11-23 01:30:37] {2223} INFO - iteration 115, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:37] {2417} INFO -  at 10.4s,\testimator my_xgb1's best error=0.3499,\tbest estimator my_xgb1's best error=0.3499\n",
      "[flaml.automl: 11-23 01:30:37] {2223} INFO - iteration 116, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:37] {2417} INFO -  at 10.5s,\testimator my_xgb1's best error=0.3499,\tbest estimator my_xgb1's best error=0.3499\n",
      "[flaml.automl: 11-23 01:30:37] {2223} INFO - iteration 117, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:37] {2417} INFO -  at 10.6s,\testimator my_xgb1's best error=0.3499,\tbest estimator my_xgb1's best error=0.3499\n",
      "[flaml.automl: 11-23 01:30:37] {2223} INFO - iteration 118, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:37] {2417} INFO -  at 10.7s,\testimator my_xgb1's best error=0.3499,\tbest estimator my_xgb1's best error=0.3499\n",
      "[flaml.automl: 11-23 01:30:37] {2223} INFO - iteration 119, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:37] {2417} INFO -  at 10.7s,\testimator my_xgb1's best error=0.3499,\tbest estimator my_xgb1's best error=0.3499\n",
      "[flaml.automl: 11-23 01:30:37] {2223} INFO - iteration 120, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:37] {2417} INFO -  at 10.8s,\testimator my_xgb1's best error=0.3499,\tbest estimator my_xgb1's best error=0.3499\n",
      "[flaml.automl: 11-23 01:30:37] {2223} INFO - iteration 121, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:37] {2417} INFO -  at 10.8s,\testimator my_xgb1's best error=0.3499,\tbest estimator my_xgb1's best error=0.3499\n",
      "[flaml.automl: 11-23 01:30:37] {2223} INFO - iteration 122, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:38] {2417} INFO -  at 11.0s,\testimator my_xgb1's best error=0.3499,\tbest estimator my_xgb1's best error=0.3499\n",
      "[flaml.automl: 11-23 01:30:38] {2223} INFO - iteration 123, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:38] {2417} INFO -  at 11.1s,\testimator my_xgb1's best error=0.3499,\tbest estimator my_xgb1's best error=0.3499\n",
      "[flaml.automl: 11-23 01:30:38] {2223} INFO - iteration 124, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:38] {2417} INFO -  at 11.2s,\testimator my_xgb1's best error=0.3499,\tbest estimator my_xgb1's best error=0.3499\n",
      "[flaml.automl: 11-23 01:30:38] {2223} INFO - iteration 125, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:38] {2417} INFO -  at 11.3s,\testimator my_xgb1's best error=0.3499,\tbest estimator my_xgb1's best error=0.3499\n",
      "[flaml.automl: 11-23 01:30:38] {2223} INFO - iteration 126, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:38] {2417} INFO -  at 11.4s,\testimator my_xgb1's best error=0.3499,\tbest estimator my_xgb1's best error=0.3499\n",
      "[flaml.automl: 11-23 01:30:38] {2223} INFO - iteration 127, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:38] {2417} INFO -  at 11.6s,\testimator my_xgb1's best error=0.3499,\tbest estimator my_xgb1's best error=0.3499\n",
      "[flaml.automl: 11-23 01:30:38] {2223} INFO - iteration 128, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:38] {2417} INFO -  at 11.6s,\testimator my_xgb1's best error=0.3499,\tbest estimator my_xgb1's best error=0.3499\n",
      "[flaml.automl: 11-23 01:30:38] {2223} INFO - iteration 129, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:38] {2417} INFO -  at 11.7s,\testimator my_xgb1's best error=0.3499,\tbest estimator my_xgb1's best error=0.3499\n",
      "[flaml.automl: 11-23 01:30:38] {2223} INFO - iteration 130, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:38] {2417} INFO -  at 11.8s,\testimator my_xgb1's best error=0.3499,\tbest estimator my_xgb1's best error=0.3499\n",
      "[flaml.automl: 11-23 01:30:38] {2223} INFO - iteration 131, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:38] {2417} INFO -  at 11.8s,\testimator my_xgb1's best error=0.3499,\tbest estimator my_xgb1's best error=0.3499\n",
      "[flaml.automl: 11-23 01:30:38] {2223} INFO - iteration 132, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:38] {2417} INFO -  at 11.9s,\testimator my_xgb1's best error=0.3499,\tbest estimator my_xgb1's best error=0.3499\n",
      "[flaml.automl: 11-23 01:30:38] {2223} INFO - iteration 133, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:39] {2417} INFO -  at 12.0s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:39] {2223} INFO - iteration 134, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:39] {2417} INFO -  at 12.0s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:39] {2223} INFO - iteration 135, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:39] {2417} INFO -  at 12.1s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:39] {2223} INFO - iteration 136, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:39] {2417} INFO -  at 12.2s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:39] {2223} INFO - iteration 137, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:39] {2417} INFO -  at 12.3s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:39] {2223} INFO - iteration 138, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:39] {2417} INFO -  at 12.4s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:39] {2223} INFO - iteration 139, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:39] {2417} INFO -  at 12.5s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:39] {2223} INFO - iteration 140, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:39] {2417} INFO -  at 12.5s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:39] {2223} INFO - iteration 141, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:39] {2417} INFO -  at 12.6s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:39] {2223} INFO - iteration 142, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:39] {2417} INFO -  at 12.7s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:39] {2223} INFO - iteration 143, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:39] {2417} INFO -  at 12.8s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:39] {2223} INFO - iteration 144, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:39] {2417} INFO -  at 12.8s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:39] {2223} INFO - iteration 145, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:40] {2417} INFO -  at 13.0s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:40] {2223} INFO - iteration 146, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:40] {2417} INFO -  at 13.1s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:40] {2223} INFO - iteration 147, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:40] {2417} INFO -  at 13.2s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:40] {2223} INFO - iteration 148, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:40] {2417} INFO -  at 13.2s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:40] {2223} INFO - iteration 149, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:40] {2417} INFO -  at 13.3s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:40] {2223} INFO - iteration 150, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:40] {2417} INFO -  at 13.4s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:40] {2223} INFO - iteration 151, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:40] {2417} INFO -  at 13.5s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:40] {2223} INFO - iteration 152, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:40] {2417} INFO -  at 13.5s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:40] {2223} INFO - iteration 153, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:40] {2417} INFO -  at 13.6s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:40] {2223} INFO - iteration 154, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:40] {2417} INFO -  at 13.7s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:40] {2223} INFO - iteration 155, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:40] {2417} INFO -  at 13.8s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:40] {2223} INFO - iteration 156, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:40] {2417} INFO -  at 13.9s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:40] {2223} INFO - iteration 157, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:41] {2417} INFO -  at 14.0s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:41] {2223} INFO - iteration 158, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:41] {2417} INFO -  at 14.0s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:41] {2223} INFO - iteration 159, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:41] {2417} INFO -  at 14.2s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:41] {2223} INFO - iteration 160, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:41] {2417} INFO -  at 14.6s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:41] {2223} INFO - iteration 161, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:41] {2417} INFO -  at 14.6s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:41] {2223} INFO - iteration 162, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:41] {2417} INFO -  at 14.8s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:41] {2223} INFO - iteration 163, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:41] {2417} INFO -  at 14.9s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:41] {2223} INFO - iteration 164, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:42] {2417} INFO -  at 15.0s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:42] {2223} INFO - iteration 165, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:42] {2417} INFO -  at 15.1s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:42] {2223} INFO - iteration 166, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:42] {2417} INFO -  at 15.2s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:42] {2223} INFO - iteration 167, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:42] {2417} INFO -  at 15.2s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:42] {2223} INFO - iteration 168, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:42] {2417} INFO -  at 15.3s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:42] {2223} INFO - iteration 169, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:42] {2417} INFO -  at 15.4s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:42] {2223} INFO - iteration 170, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:42] {2417} INFO -  at 15.4s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:42] {2223} INFO - iteration 171, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:42] {2417} INFO -  at 15.6s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:42] {2223} INFO - iteration 172, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:42] {2417} INFO -  at 15.6s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:42] {2223} INFO - iteration 173, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:42] {2417} INFO -  at 15.8s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:42] {2223} INFO - iteration 174, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:42] {2417} INFO -  at 15.8s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:42] {2223} INFO - iteration 175, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:42] {2417} INFO -  at 15.9s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:42] {2223} INFO - iteration 176, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:43] {2417} INFO -  at 16.0s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:43] {2223} INFO - iteration 177, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:43] {2417} INFO -  at 16.1s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:43] {2223} INFO - iteration 178, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:43] {2417} INFO -  at 16.1s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:43] {2223} INFO - iteration 179, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:43] {2417} INFO -  at 16.2s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:43] {2223} INFO - iteration 180, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:43] {2417} INFO -  at 16.3s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:43] {2223} INFO - iteration 181, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:43] {2417} INFO -  at 16.4s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:43] {2223} INFO - iteration 182, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:43] {2417} INFO -  at 16.5s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:43] {2223} INFO - iteration 183, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:43] {2417} INFO -  at 16.6s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:43] {2223} INFO - iteration 184, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:43] {2417} INFO -  at 16.7s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:43] {2223} INFO - iteration 185, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:43] {2417} INFO -  at 16.8s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:43] {2223} INFO - iteration 186, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:44] {2417} INFO -  at 17.0s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:44] {2223} INFO - iteration 187, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:44] {2417} INFO -  at 17.0s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:44] {2223} INFO - iteration 188, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:44] {2417} INFO -  at 17.2s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:44] {2223} INFO - iteration 189, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:44] {2417} INFO -  at 17.2s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:44] {2223} INFO - iteration 190, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:44] {2417} INFO -  at 17.3s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:44] {2223} INFO - iteration 191, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:44] {2417} INFO -  at 17.5s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:44] {2223} INFO - iteration 192, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:44] {2417} INFO -  at 17.6s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:44] {2223} INFO - iteration 193, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:44] {2417} INFO -  at 17.6s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:44] {2223} INFO - iteration 194, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:44] {2417} INFO -  at 17.7s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:44] {2223} INFO - iteration 195, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:44] {2417} INFO -  at 17.7s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:44] {2223} INFO - iteration 196, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:45] {2417} INFO -  at 18.1s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:45] {2223} INFO - iteration 197, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:45] {2417} INFO -  at 18.2s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:45] {2223} INFO - iteration 198, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:45] {2417} INFO -  at 18.3s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:45] {2223} INFO - iteration 199, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:45] {2417} INFO -  at 18.4s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:45] {2223} INFO - iteration 200, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:45] {2417} INFO -  at 18.5s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:45] {2223} INFO - iteration 201, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:45] {2417} INFO -  at 18.5s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:45] {2223} INFO - iteration 202, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:45] {2417} INFO -  at 18.6s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:45] {2223} INFO - iteration 203, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:45] {2417} INFO -  at 18.8s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:45] {2223} INFO - iteration 204, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:45] {2417} INFO -  at 18.9s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:45] {2223} INFO - iteration 205, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:46] {2417} INFO -  at 19.0s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:46] {2223} INFO - iteration 206, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:46] {2417} INFO -  at 19.1s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:46] {2223} INFO - iteration 207, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:46] {2417} INFO -  at 19.2s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:46] {2223} INFO - iteration 208, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:46] {2417} INFO -  at 19.3s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:46] {2223} INFO - iteration 209, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:46] {2417} INFO -  at 19.5s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:46] {2223} INFO - iteration 210, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:46] {2417} INFO -  at 19.5s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:46] {2223} INFO - iteration 211, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:46] {2417} INFO -  at 19.7s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:46] {2223} INFO - iteration 212, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:46] {2417} INFO -  at 19.7s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:46] {2223} INFO - iteration 213, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:46] {2417} INFO -  at 19.8s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:46] {2223} INFO - iteration 214, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:46] {2417} INFO -  at 19.8s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:46] {2223} INFO - iteration 215, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:47] {2417} INFO -  at 20.0s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:47] {2223} INFO - iteration 216, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:47] {2417} INFO -  at 20.1s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:47] {2223} INFO - iteration 217, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:47] {2417} INFO -  at 20.2s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:47] {2223} INFO - iteration 218, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:47] {2417} INFO -  at 20.3s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:47] {2223} INFO - iteration 219, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:47] {2417} INFO -  at 20.4s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:47] {2223} INFO - iteration 220, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:47] {2417} INFO -  at 20.6s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:47] {2223} INFO - iteration 221, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:47] {2417} INFO -  at 20.8s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:47] {2223} INFO - iteration 222, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:47] {2417} INFO -  at 20.8s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:47] {2223} INFO - iteration 223, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:47] {2417} INFO -  at 20.9s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:47] {2223} INFO - iteration 224, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:48] {2417} INFO -  at 21.0s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:48] {2223} INFO - iteration 225, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:48] {2417} INFO -  at 21.1s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:48] {2223} INFO - iteration 226, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:48] {2417} INFO -  at 21.3s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:48] {2223} INFO - iteration 227, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:48] {2417} INFO -  at 21.4s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:48] {2223} INFO - iteration 228, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:48] {2417} INFO -  at 21.6s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:48] {2223} INFO - iteration 229, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:48] {2417} INFO -  at 21.6s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:48] {2223} INFO - iteration 230, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:48] {2417} INFO -  at 21.7s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:48] {2223} INFO - iteration 231, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:48] {2417} INFO -  at 21.8s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:48] {2223} INFO - iteration 232, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:49] {2417} INFO -  at 21.9s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:49] {2223} INFO - iteration 233, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:49] {2417} INFO -  at 22.0s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:49] {2223} INFO - iteration 234, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:49] {2417} INFO -  at 22.1s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:49] {2223} INFO - iteration 235, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:49] {2417} INFO -  at 22.2s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:49] {2223} INFO - iteration 236, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:49] {2417} INFO -  at 22.3s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:49] {2223} INFO - iteration 237, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:49] {2417} INFO -  at 22.4s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:49] {2223} INFO - iteration 238, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:49] {2417} INFO -  at 22.5s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:49] {2223} INFO - iteration 239, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:49] {2417} INFO -  at 22.6s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:49] {2223} INFO - iteration 240, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:49] {2417} INFO -  at 22.6s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:49] {2223} INFO - iteration 241, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:49] {2417} INFO -  at 22.8s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:49] {2223} INFO - iteration 242, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:49] {2417} INFO -  at 22.8s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:49] {2223} INFO - iteration 243, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:50] {2417} INFO -  at 23.0s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:50] {2223} INFO - iteration 244, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:50] {2417} INFO -  at 23.2s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:50] {2223} INFO - iteration 245, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:50] {2417} INFO -  at 23.3s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:50] {2223} INFO - iteration 246, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:50] {2417} INFO -  at 23.4s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:50] {2223} INFO - iteration 247, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:50] {2417} INFO -  at 23.5s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:50] {2223} INFO - iteration 248, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:50] {2417} INFO -  at 23.6s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:50] {2223} INFO - iteration 249, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:50] {2417} INFO -  at 23.7s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:50] {2223} INFO - iteration 250, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:50] {2417} INFO -  at 23.7s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:50] {2223} INFO - iteration 251, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:50] {2417} INFO -  at 23.9s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:50] {2223} INFO - iteration 252, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:50] {2417} INFO -  at 23.9s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:51] {2223} INFO - iteration 253, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:51] {2417} INFO -  at 24.0s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:51] {2223} INFO - iteration 254, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:51] {2417} INFO -  at 24.1s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:51] {2223} INFO - iteration 255, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:51] {2417} INFO -  at 24.2s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:51] {2223} INFO - iteration 256, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:51] {2417} INFO -  at 24.3s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:51] {2223} INFO - iteration 257, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:51] {2417} INFO -  at 24.4s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:51] {2223} INFO - iteration 258, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:51] {2417} INFO -  at 24.5s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:51] {2223} INFO - iteration 259, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:51] {2417} INFO -  at 24.6s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:51] {2223} INFO - iteration 260, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:51] {2417} INFO -  at 24.6s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:51] {2223} INFO - iteration 261, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:51] {2417} INFO -  at 24.9s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:51] {2223} INFO - iteration 262, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:52] {2417} INFO -  at 25.0s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:52] {2223} INFO - iteration 263, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:52] {2417} INFO -  at 25.0s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:52] {2223} INFO - iteration 264, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:52] {2417} INFO -  at 25.1s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:52] {2223} INFO - iteration 265, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:52] {2417} INFO -  at 25.2s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:52] {2223} INFO - iteration 266, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:52] {2417} INFO -  at 25.4s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:52] {2223} INFO - iteration 267, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:52] {2417} INFO -  at 25.4s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:52] {2223} INFO - iteration 268, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:52] {2417} INFO -  at 25.5s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:52] {2223} INFO - iteration 269, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:52] {2417} INFO -  at 25.6s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:52] {2223} INFO - iteration 270, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:52] {2417} INFO -  at 25.7s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:52] {2223} INFO - iteration 271, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:52] {2417} INFO -  at 25.8s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:52] {2223} INFO - iteration 272, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:53] {2417} INFO -  at 25.9s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:53] {2223} INFO - iteration 273, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:53] {2417} INFO -  at 26.0s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:53] {2223} INFO - iteration 274, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:53] {2417} INFO -  at 26.2s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:53] {2223} INFO - iteration 275, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:53] {2417} INFO -  at 26.4s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:53] {2223} INFO - iteration 276, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:53] {2417} INFO -  at 26.4s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:53] {2223} INFO - iteration 277, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:53] {2417} INFO -  at 26.5s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:53] {2223} INFO - iteration 278, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:53] {2417} INFO -  at 26.6s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:53] {2223} INFO - iteration 279, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:53] {2417} INFO -  at 26.7s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:53] {2223} INFO - iteration 280, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:53] {2417} INFO -  at 26.8s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:53] {2223} INFO - iteration 281, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:53] {2417} INFO -  at 26.9s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:53] {2223} INFO - iteration 282, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:54] {2417} INFO -  at 26.9s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:54] {2223} INFO - iteration 283, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:54] {2417} INFO -  at 27.0s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:54] {2223} INFO - iteration 284, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:54] {2417} INFO -  at 27.1s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:54] {2223} INFO - iteration 285, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:54] {2417} INFO -  at 27.2s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:54] {2223} INFO - iteration 286, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:54] {2417} INFO -  at 27.3s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:54] {2223} INFO - iteration 287, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:54] {2417} INFO -  at 27.4s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:54] {2223} INFO - iteration 288, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:54] {2417} INFO -  at 27.4s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:54] {2223} INFO - iteration 289, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:54] {2417} INFO -  at 27.6s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:54] {2223} INFO - iteration 290, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:54] {2417} INFO -  at 27.7s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:54] {2223} INFO - iteration 291, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:54] {2417} INFO -  at 27.8s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:54] {2223} INFO - iteration 292, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:54] {2417} INFO -  at 27.8s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:54] {2223} INFO - iteration 293, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:55] {2417} INFO -  at 28.1s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:55] {2223} INFO - iteration 294, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:55] {2417} INFO -  at 28.1s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:55] {2223} INFO - iteration 295, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:55] {2417} INFO -  at 28.2s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:55] {2223} INFO - iteration 296, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:55] {2417} INFO -  at 28.3s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:55] {2223} INFO - iteration 297, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:55] {2417} INFO -  at 28.4s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:55] {2223} INFO - iteration 298, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:55] {2417} INFO -  at 28.5s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:55] {2223} INFO - iteration 299, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:55] {2417} INFO -  at 28.6s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:55] {2223} INFO - iteration 300, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:55] {2417} INFO -  at 28.6s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:55] {2223} INFO - iteration 301, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:55] {2417} INFO -  at 28.7s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:55] {2223} INFO - iteration 302, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:55] {2417} INFO -  at 28.8s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:55] {2223} INFO - iteration 303, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:55] {2417} INFO -  at 28.9s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:55] {2223} INFO - iteration 304, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:56] {2417} INFO -  at 29.0s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:56] {2223} INFO - iteration 305, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:56] {2417} INFO -  at 29.0s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:56] {2223} INFO - iteration 306, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:56] {2417} INFO -  at 29.2s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:56] {2223} INFO - iteration 307, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:56] {2417} INFO -  at 29.3s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:56] {2223} INFO - iteration 308, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:56] {2417} INFO -  at 29.6s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:56] {2223} INFO - iteration 309, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:56] {2417} INFO -  at 29.8s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:56] {2223} INFO - iteration 310, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:56] {2417} INFO -  at 29.8s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:56] {2223} INFO - iteration 311, current learner my_xgb1\n",
      "[flaml.automl: 11-23 01:30:57] {2417} INFO -  at 30.0s,\testimator my_xgb1's best error=0.3347,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:57] {2223} INFO - iteration 312, current learner my_xgb2\n",
      "[flaml.automl: 11-23 01:30:57] {2417} INFO -  at 30.0s,\testimator my_xgb2's best error=4.1611,\tbest estimator my_xgb1's best error=0.3347\n",
      "[flaml.automl: 11-23 01:30:57] {2629} INFO - retrain my_xgb1 for 0.1s\n",
      "[flaml.automl: 11-23 01:30:57] {2634} INFO - retrained model: <xgboost.core.Booster object at 0x7f6d745f0650>\n",
      "[flaml.automl: 11-23 01:30:57] {2014} INFO - fit succeeded\n",
      "[flaml.automl: 11-23 01:30:57] {2016} INFO - Time taken to find the best model: 11.981720209121704\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "# define your customized objective function\n",
    "def logregobj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = 1.0 / (1.0 + np.exp(-preds)) # transform raw leaf weight\n",
    "    grad = preds - labels\n",
    "    hess = preds * (1.0 - preds)\n",
    "    return grad, hess\n",
    "\n",
    "# create customized XGBoost learners class with your objective function\n",
    "from flaml.model import XGBoostEstimator\n",
    "\n",
    "\n",
    "class MyXGB1(XGBoostEstimator):\n",
    "    \"XGBoostEstimator with the logregobj function as the objective function\"\n",
    "\n",
    "    def __init__(self, **config):\n",
    "        super().__init__(objective=logregobj, **config) \n",
    "\n",
    "\n",
    "class MyXGB2(XGBoostEstimator):\n",
    "    \"\"\"XGBoostEstimator with 'reg:squarederror' as the objective function\"\"\"\n",
    "\n",
    "    def __init__(self, **config):\n",
    "        super().__init__(objective='reg:gamma', **config)\n",
    "\n",
    "\n",
    "from flaml import AutoML\n",
    "automl = AutoML()\n",
    "automl.add_learner(learner_name='my_xgb1', learner_class=MyXGB1)\n",
    "automl.add_learner(learner_name='my_xgb2', learner_class=MyXGB2)\n",
    "settings = {\n",
    "    \"time_budget\": 30,  # total running time in seconds\n",
    "    \"metric\": 'r2',  # primary metrics for regression can be chosen from: ['mae','mse','r2']\n",
    "    \"estimator_list\": ['my_xgb1', 'my_xgb2'],  # list of ML learners; we tune lightgbm in this example\n",
    "    \"task\": 'regression',  # task type    \n",
    "    \"log_file_name\": 'houses_experiment_my_xgb.log',  # flaml log file\n",
    "}\n",
    "automl.fit(X_train=X_train, y_train=y_train, **settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparmeter config: {'n_estimators': 28, 'max_leaves': 182, 'max_depth': 0, 'min_child_weight': 0.001, 'learning_rate': 0.2276973644896658, 'subsample': 0.6775148384104485, 'colsample_bylevel': 0.9912902070149149, 'colsample_bytree': 1.0, 'reg_alpha': 0.07330248020902469, 'reg_lambda': 0.36054508770487687}\n",
      "Best r2 on validation data: 0.6653\n",
      "Training duration of best run: 0.09387 s\n",
      "Predicted labels\n",
      "[172378.17 248509.11 156986.72 ... 201823.47 238128.38 273842.53]\n",
      "True labels\n",
      "14740    136900.0\n",
      "10101    241300.0\n",
      "20566    200700.0\n",
      "2670      72500.0\n",
      "15709    460000.0\n",
      "           ...   \n",
      "13132    121200.0\n",
      "8228     137500.0\n",
      "3948     160900.0\n",
      "8522     227300.0\n",
      "16798    265600.0\n",
      "Name: median_house_value, Length: 5160, dtype: float64\n",
      "r2 = 0.6722200251197084\n",
      "mse = 4332761742.09886\n",
      "mae = 43937.87377986465\n"
     ]
    }
   ],
   "source": [
    "print('Best hyperparmeter config:', automl.best_config)\n",
    "print('Best r2 on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
    "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))\n",
    "\n",
    "y_pred = automl.predict(X_test)\n",
    "print(f'Predicted labels\\n{y_pred}')\n",
    "print(f'True labels\\n{y_test}')\n",
    "\n",
    "from flaml.ml import sklearn_metric_loss_score\n",
    "print('r2', '=', 1 - sklearn_metric_loss_score('r2', y_pred, y_test))\n",
    "print('mse', '=', sklearn_metric_loss_score('mse', y_pred, y_test))\n",
    "print('mae', '=', sklearn_metric_loss_score('mae', y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0cfea3304185a9579d09e0953576b57c8581e46e6ebc6dfeb681bc5a511f7544"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('blend': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
