{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/FLAML/blob/main/notebook/autogen_agentchat_groupchat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Generated Agent Chat: Group Chat\n",
    "\n",
    "Modified based on https://github.com/microsoft/FLAML/blob/4ea686af5c3e8ff24d9076a7a626c8b28ab5b1d7/notebook/autogen_multiagent_roleplay_chat.ipynb\n",
    "\n",
    "## Requirements\n",
    "\n",
    "FLAML requires `Python>=3.8`. To run this notebook example, please install flaml with the [autogen] option:\n",
    "```bash\n",
    "pip install flaml[autogen]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# %pip install flaml[autogen]~=2.0.0rc4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/FLAML/docs/reference/autogen/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import autogen\n",
    "\n",
    "config_list_gpt4 = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\", \"gpt4\", \"gpt-4-32k\", \"gpt-4-32k-0314\"],\n",
    "    },\n",
    ")\n",
    "# config_list_gpt35 = autogen.config_list_from_json(\n",
    "#     \"OAI_CONFIG_LIST\",\n",
    "#     filter_dict={\n",
    "#         \"model\": {\n",
    "#             \"gpt-3.5-turbo\",\n",
    "#             \"gpt-3.5-turbo-16k\",\n",
    "#             \"gpt-3.5-turbo-0301\",\n",
    "#             \"chatgpt-35-turbo-0301\",\n",
    "#             \"gpt-35-turbo-v0301\",\n",
    "#         },\n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It first looks for environment variable \"OAI_CONFIG_LIST\" which needs to be a valid json string. If that variable is not found, it then looks for a json file named \"OAI_CONFIG_LIST\". It filters the configs by models (you can filter by other keys as well). Only the gpt-4 models are kept in the list based on the filter condition.\n",
    "\n",
    "The config list looks like the following:\n",
    "```python\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your OpenAI API key here>',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'api_base': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4-32k',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'api_base': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "]\n",
    "```\n",
    "\n",
    "If you open this notebook in colab, you can upload your files by clicking the file icon on the left panel and then choose \"upload file\" icon.\n",
    "\n",
    "You can set the value of config_list in other ways you prefer, e.g., loading from a YAML file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "llm_config = {\"config_list\": config_list_gpt4}\n",
    "room = autogen.Room()\n",
    "chat_manager = autogen.ChatManagerAgent(room=room, max_round=3)\n",
    "human = autogen.GroupChatParticipant(\n",
    "   name=\"Human\",\n",
    "   system_message=\"A human admin.\",\n",
    "   human_input_mode=\"ALWAYS\",\n",
    "   llm_config=False,\n",
    "   chat_manager=chat_manager,\n",
    ")\n",
    "alice = autogen.GroupChatParticipant(\n",
    "    name=\"Alice\",\n",
    "    system_message=autogen.AssistantAgent.DEFAULT_SYSTEM_MESSAGE,\n",
    "    max_consecutive_auto_reply=sys.maxsize,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    chat_manager=chat_manager,\n",
    ")\n",
    "bob = autogen.GroupChatParticipant(\n",
    "    name=\"Bob\",\n",
    "    system_message=\"Code reviewer. Prevent code execution if unsafe or not well documented. Suggest changes. Otherwise, approve and return the final code to execute.\",\n",
    "    max_consecutive_auto_reply=sys.maxsize,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    chat_manager=chat_manager,\n",
    ")\n",
    "\n",
    "room.agents = [human, alice, bob]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mroom\u001b[0m (to chat_manager):\n",
      "\n",
      "find a latest paper about generative agents\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mchat_manager\u001b[0m (to room):\n",
      "\n",
      "find a latest paper about generative agents\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mroom\u001b[0m (to Human):\n",
      "\n",
      "find a latest paper about generative agents\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mroom\u001b[0m (to Alice):\n",
      "\n",
      "find a latest paper about generative agents\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mroom\u001b[0m (to Bob):\n",
      "\n",
      "find a latest paper about generative agents\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mchat_manager\u001b[0m (to Human):\n",
      "\n",
      "You are in a role play game. Read the following conversation.\n",
      "Then select the next role from ['Human', 'Alice', 'Bob'] to play. Only return the role.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mHuman\u001b[0m (to chat_manager):\n",
      "\n",
      "Alice\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mchat_manager\u001b[0m (to Alice):\n",
      "\n",
      "speak\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[{'content': 'You are a helpful AI assistant.\\n    In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute. You must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can\\'t modify your code. So do not suggest incomplete code which requires users to modify. Don\\'t use a code block if it\\'s not intended to be executed by the user.\\n    1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time.\\n    2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly. Solve the task step by step if you need to.\\n    If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don\\'t include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use \\'print\\' function for the output when relevant. Check the execution result returned by the user.\\n    If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can\\'t be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\\n    When you find an answer, verify the answer carefully. If a function for planning is provided, call the function to make plans and verify the execution.\\n    Reply \"TERMINATE\" in the end when everything is done.\\n    ', 'role': 'system'}]\n",
      "\u001b[33mAlice\u001b[0m (to room):\n",
      "\n",
      "As an AI, I can't browse the web, but I can suggest Python code that allows you to do so. You can use Python to perform a Google Scholar search and scrape data from result pages. Here's a simple example using the BeautifulSoup and requests libraries:\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "# Google scholar search URL\n",
      "url = \"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=generative+agents&btnG=\"\n",
      "\n",
      "# Send a request to the website\n",
      "r = requests.get(url)\n",
      "\n",
      "# Get the data from the website\n",
      "webpage = r.text\n",
      "\n",
      "# Create a BeautifulSoup object and specify the parser\n",
      "soup = BeautifulSoup(webpage, 'html.parser')\n",
      "\n",
      "# Find all the research paper titles in the webpage\n",
      "titles = soup.find_all('h3', {'class': 'gs_rt'})\n",
      "\n",
      "# Print the latest paper title\n",
      "print(\"Latest paper about 'Generative Agents': \", titles[0].text)\n",
      "```\n",
      "\n",
      "This code will output the title of the latest paper about 'Generative Agents'. Please kindly note that this code might not always work as expected due to Google's frequent updates to their websites or restrictions for web scraping. In a professional setting, official APIs or databases should be used for finding scientific literature.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mroom\u001b[0m (to Human):\n",
      "\n",
      "As an AI, I can't browse the web, but I can suggest Python code that allows you to do so. You can use Python to perform a Google Scholar search and scrape data from result pages. Here's a simple example using the BeautifulSoup and requests libraries:\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "# Google scholar search URL\n",
      "url = \"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=generative+agents&btnG=\"\n",
      "\n",
      "# Send a request to the website\n",
      "r = requests.get(url)\n",
      "\n",
      "# Get the data from the website\n",
      "webpage = r.text\n",
      "\n",
      "# Create a BeautifulSoup object and specify the parser\n",
      "soup = BeautifulSoup(webpage, 'html.parser')\n",
      "\n",
      "# Find all the research paper titles in the webpage\n",
      "titles = soup.find_all('h3', {'class': 'gs_rt'})\n",
      "\n",
      "# Print the latest paper title\n",
      "print(\"Latest paper about 'Generative Agents': \", titles[0].text)\n",
      "```\n",
      "\n",
      "This code will output the title of the latest paper about 'Generative Agents'. Please kindly note that this code might not always work as expected due to Google's frequent updates to their websites or restrictions for web scraping. In a professional setting, official APIs or databases should be used for finding scientific literature.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mroom\u001b[0m (to Bob):\n",
      "\n",
      "As an AI, I can't browse the web, but I can suggest Python code that allows you to do so. You can use Python to perform a Google Scholar search and scrape data from result pages. Here's a simple example using the BeautifulSoup and requests libraries:\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "# Google scholar search URL\n",
      "url = \"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=generative+agents&btnG=\"\n",
      "\n",
      "# Send a request to the website\n",
      "r = requests.get(url)\n",
      "\n",
      "# Get the data from the website\n",
      "webpage = r.text\n",
      "\n",
      "# Create a BeautifulSoup object and specify the parser\n",
      "soup = BeautifulSoup(webpage, 'html.parser')\n",
      "\n",
      "# Find all the research paper titles in the webpage\n",
      "titles = soup.find_all('h3', {'class': 'gs_rt'})\n",
      "\n",
      "# Print the latest paper title\n",
      "print(\"Latest paper about 'Generative Agents': \", titles[0].text)\n",
      "```\n",
      "\n",
      "This code will output the title of the latest paper about 'Generative Agents'. Please kindly note that this code might not always work as expected due to Google's frequent updates to their websites or restrictions for web scraping. In a professional setting, official APIs or databases should be used for finding scientific literature.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mchat_manager\u001b[0m (to Alice):\n",
      "\n",
      "You are in a role play game. Read the following conversation.\n",
      "Then select the next role from ['Human', 'Alice', 'Bob'] to play. Only return the role.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[{'content': \"You are in a role play game. Read the following conversation.\\nThen select the next role from ['Human', 'Alice', 'Bob'] to play. Only return the role.\", 'role': 'system'}]\n",
      "\u001b[33mAlice\u001b[0m (to chat_manager):\n",
      "\n",
      "Bob\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mchat_manager\u001b[0m (to Bob):\n",
      "\n",
      "speak\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[{'content': 'Code reviewer. Prevent code execution if unsafe or not well documented. Suggest changes. Otherwise, approve and return the final code to execute.', 'role': 'system'}]\n",
      "\u001b[33mBob\u001b[0m (to room):\n",
      "\n",
      "It looks like the code is generally safe to execute. But as noted, it's always best to access official APIs or databases especially in a professional setting in order to avoid any legal issues related to web scraping. Google may also block your IP if it detects you're scraping its pages without permission. \n",
      "\n",
      "Further, the code doesn't handle possible exceptions that could occur while making a request. We should catch any potential exceptions to avoid crashes. Also, if the page HTML structure changes and a \"`<h3>`\" tag or class \"`gs_rt`\" is not found, the code will fail. It is a good practice to check if the data we've scraped contains any elements before trying to access them.\n",
      "\n",
      "Here is the improved version:\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "# Google scholar search URL\n",
      "url = \"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=generative+agents&btnG=\"\n",
      "\n",
      "try: \n",
      "    # Send a request to the website\n",
      "    r = requests.get(url)\n",
      "    r.raise_for_status()  # If the request is successful, no Exception will be raised\n",
      "    \n",
      "    # Get the data from the website\n",
      "    webpage = r.text\n",
      "    \n",
      "    # Create a BeautifulSoup object and specify the parser\n",
      "    soup = BeautifulSoup(webpage, 'html.parser')\n",
      "    \n",
      "    # Find all the research paper titles in the webpage\n",
      "    titles = soup.find_all('h3', {'class': 'gs_rt'})\n",
      "    \n",
      "    # Check if the titles list contain any elements\n",
      "    if titles:\n",
      "        # Print the latest paper title\n",
      "        print(\"Latest paper about 'Generative Agents': \", titles[0].text)\n",
      "    else:\n",
      "        print(\"No paper found.\")\n",
      "except requests.exceptions.RequestException as err:\n",
      "    print(\"Oops: Something went wrong \",err)\n",
      "except Exception as e:\n",
      "    print(\"Oops: \", e)\n",
      "```\n",
      "\n",
      "This modification ensures that we can catch and handle HTTP errors or any other exceptions to prevent crash and make debugging easier. It also checks if any titles were found before trying to display the first one.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mroom\u001b[0m (to Human):\n",
      "\n",
      "It looks like the code is generally safe to execute. But as noted, it's always best to access official APIs or databases especially in a professional setting in order to avoid any legal issues related to web scraping. Google may also block your IP if it detects you're scraping its pages without permission. \n",
      "\n",
      "Further, the code doesn't handle possible exceptions that could occur while making a request. We should catch any potential exceptions to avoid crashes. Also, if the page HTML structure changes and a \"`<h3>`\" tag or class \"`gs_rt`\" is not found, the code will fail. It is a good practice to check if the data we've scraped contains any elements before trying to access them.\n",
      "\n",
      "Here is the improved version:\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "# Google scholar search URL\n",
      "url = \"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=generative+agents&btnG=\"\n",
      "\n",
      "try: \n",
      "    # Send a request to the website\n",
      "    r = requests.get(url)\n",
      "    r.raise_for_status()  # If the request is successful, no Exception will be raised\n",
      "    \n",
      "    # Get the data from the website\n",
      "    webpage = r.text\n",
      "    \n",
      "    # Create a BeautifulSoup object and specify the parser\n",
      "    soup = BeautifulSoup(webpage, 'html.parser')\n",
      "    \n",
      "    # Find all the research paper titles in the webpage\n",
      "    titles = soup.find_all('h3', {'class': 'gs_rt'})\n",
      "    \n",
      "    # Check if the titles list contain any elements\n",
      "    if titles:\n",
      "        # Print the latest paper title\n",
      "        print(\"Latest paper about 'Generative Agents': \", titles[0].text)\n",
      "    else:\n",
      "        print(\"No paper found.\")\n",
      "except requests.exceptions.RequestException as err:\n",
      "    print(\"Oops: Something went wrong \",err)\n",
      "except Exception as e:\n",
      "    print(\"Oops: \", e)\n",
      "```\n",
      "\n",
      "This modification ensures that we can catch and handle HTTP errors or any other exceptions to prevent crash and make debugging easier. It also checks if any titles were found before trying to display the first one.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mroom\u001b[0m (to Alice):\n",
      "\n",
      "It looks like the code is generally safe to execute. But as noted, it's always best to access official APIs or databases especially in a professional setting in order to avoid any legal issues related to web scraping. Google may also block your IP if it detects you're scraping its pages without permission. \n",
      "\n",
      "Further, the code doesn't handle possible exceptions that could occur while making a request. We should catch any potential exceptions to avoid crashes. Also, if the page HTML structure changes and a \"`<h3>`\" tag or class \"`gs_rt`\" is not found, the code will fail. It is a good practice to check if the data we've scraped contains any elements before trying to access them.\n",
      "\n",
      "Here is the improved version:\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "# Google scholar search URL\n",
      "url = \"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=generative+agents&btnG=\"\n",
      "\n",
      "try: \n",
      "    # Send a request to the website\n",
      "    r = requests.get(url)\n",
      "    r.raise_for_status()  # If the request is successful, no Exception will be raised\n",
      "    \n",
      "    # Get the data from the website\n",
      "    webpage = r.text\n",
      "    \n",
      "    # Create a BeautifulSoup object and specify the parser\n",
      "    soup = BeautifulSoup(webpage, 'html.parser')\n",
      "    \n",
      "    # Find all the research paper titles in the webpage\n",
      "    titles = soup.find_all('h3', {'class': 'gs_rt'})\n",
      "    \n",
      "    # Check if the titles list contain any elements\n",
      "    if titles:\n",
      "        # Print the latest paper title\n",
      "        print(\"Latest paper about 'Generative Agents': \", titles[0].text)\n",
      "    else:\n",
      "        print(\"No paper found.\")\n",
      "except requests.exceptions.RequestException as err:\n",
      "    print(\"Oops: Something went wrong \",err)\n",
      "except Exception as e:\n",
      "    print(\"Oops: \", e)\n",
      "```\n",
      "\n",
      "This modification ensures that we can catch and handle HTTP errors or any other exceptions to prevent crash and make debugging easier. It also checks if any titles were found before trying to display the first one.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mchat_manager\u001b[0m (to Human):\n",
      "\n",
      "You are in a role play game. Read the following conversation.\n",
      "Then select the next role from ['Human', 'Alice', 'Bob'] to play. Only return the role.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mHuman\u001b[0m (to chat_manager):\n",
      "\n",
      "Human\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mchat_manager\u001b[0m (to Human):\n",
      "\n",
      "speak\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mHuman\u001b[0m (to room):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Latest paper about 'Generative Agents':  Generative agents for player decision modeling in games\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mroom\u001b[0m (to Alice):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Latest paper about 'Generative Agents':  Generative agents for player decision modeling in games\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mroom\u001b[0m (to Bob):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Latest paper about 'Generative Agents':  Generative agents for player decision modeling in games\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "room.send(\"find a latest paper about generative agents\", chat_manager)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flaml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
