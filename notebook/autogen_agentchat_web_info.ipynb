{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/FLAML/blob/main/notebook/autogen_agentchat_web_info.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Auto Generated Agent Chat: Solving Tasks Requiring Web Info\n",
    "\n",
    "FLAML offers an experimental feature of interactive LLM agents, which can be used to solve various tasks with human or automatic feedback, including tasks that require using tools via code.\n",
    "Please find documentation about this feature [here](https://microsoft.github.io/FLAML/docs/Use-Cases/Auto-Generation#agents-experimental).\n",
    "\n",
    "In this notebook, we demonstrate how to use `AssistantAgent` and `UserProxyAgent` to perform tasks which require acquiring info from the web:\n",
    "* discuss a paper based on its URL.\n",
    "* discuss about stock market.\n",
    "\n",
    "Here `AssistantAgent` is an LLM-based agent that can write Python code (in a Python coding block) for a user to execute for a given task. `UserProxyAgent` is an agent which serves as a proxy for a user to execute the code written by `AssistantAgent`. By setting `human_input_mode` properly, the `UserProxyAgent` can also prompt the user for feedback to `AssistantAgent`. For example, when `human_input_mode` is set to \"TERMINATE\", the `UserProxyAgent` will execute the code written by `AssistantAgent` directly and return the execution results (success or failure and corresponding outputs) to `AssistantAgent`, and prompt the user for feedback when the task is finished. When user feedback is provided, the `UserProxyAgent` will directly pass the feedback to `AssistantAgent`.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "FLAML requires `Python>=3.8`. To run this notebook example, please install flaml with the [autogen] option and docker:\n",
    "```bash\n",
    "pip install flaml[autogen]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T23:40:52.317406Z",
     "iopub.status.busy": "2023-02-13T23:40:52.316561Z",
     "iopub.status.idle": "2023-02-13T23:40:52.321193Z",
     "shell.execute_reply": "2023-02-13T23:40:52.320628Z"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install flaml[autogen]~=2.0.0rc4 docker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/FLAML/docs/reference/autogen/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt4\", \"gpt-4-32k\", \"gpt-4-32k-0314\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "llm_config={\n",
    "    \"request_timeout\": 600,\n",
    "    \"seed\": 42,\n",
    "    \"config_list\": config_list,\n",
    "    \"model\": \"gpt-4-32k\",  # modify if the endpoint you use doesn't support this model\n",
    "    \"temperature\": 0,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It first looks for environment variable \"OAI_CONFIG_LIST\" which needs to be a valid json string. If that variable is not found, it then looks for a json file named \"OAI_CONFIG_LIST\". It filters the configs by models (you can filter by other keys as well). Only the models with matching names are kept in the list based on the filter condition.\n",
    "\n",
    "The config list looks like the following:\n",
    "```python\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4-32k',\n",
    "        'api_key': '<your OpenAI API key here>',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt4',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'api_base': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4-32k-0314',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'api_base': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "]\n",
    "```\n",
    "\n",
    "If you open this notebook in colab, you can upload your files by clicking the file icon on the left panel and then choose \"upload file\" icon.\n",
    "\n",
    "You can set the value of config_list in other ways you prefer, e.g., loading from a YAML file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Agents\n",
    "\n",
    "We construct the assistant agent and the user proxy agent. We specify `human_input_mode` as \"TERMINATE\" in the user proxy agent, which will ask for human feedback when it receives a \"TERMINATE\" signal from the assistant agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an AssistantAgent instance named \"assistant\"\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "# create a UserProxyAgent instance named \"user_proxy\"\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    code_execution_config={\"work_dir\": \"web\"},\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"Reply TERMINATE if the task has been solved at full satisfaction.\n",
    "Otherwise, reply CONTINUE, or the reason why the task is not solved yet.\"\"\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Task: Paper Talk from URL\n",
    "\n",
    "We invoke the `initiate_chat()` method of the user proxy agent to start the conversation. When you run the cell below, you will be prompted to provide feedback after the assistant agent sends a \"TERMINATE\" signal in the end of the message. If you don't provide any feedback (by pressing Enter directly), the conversation will finish. Before the \"TERMINATE\" signal, the user proxy agent will try to execute the code suggested by the assistant agent on behalf of the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "\n",
      "Who should read this paper: https://arxiv.org/abs/2306.01337\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "To determine who should read this paper, let's first extract the abstract and analyze its content. We can use Python with the `requests` and `BeautifulSoup` libraries to do this. Please execute the following code:\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "url = \"https://arxiv.org/abs/2306.01337\"\n",
      "response = requests.get(url)\n",
      "soup = BeautifulSoup(response.text, \"html.parser\")\n",
      "abstract = soup.find(\"blockquote\", {\"class\": \"abstract\"}).text.strip()\n",
      "print(abstract)\n",
      "```\n",
      "\n",
      "After executing the code, I will analyze the abstract and suggest who should read the paper.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Abstract:  Employing Large Language Models (LLMs) to address mathematical problems is an\n",
      "intriguing research endeavor, considering the abundance of math problems\n",
      "expressed in natural language across numerous science and engineering fields.\n",
      "While several prior works have investigated solving elementary mathematics\n",
      "using LLMs, this work explores the frontier of using GPT-4 for solving more\n",
      "complex and challenging math problems. We evaluate various ways of using GPT-4.\n",
      "Some of them are adapted from existing work, and one is MathChat, a\n",
      "conversational problem-solving framework newly proposed in this work. We\n",
      "perform the evaluation on difficult high school competition problems from the\n",
      "MATH dataset, which shows the advantage of the proposed conversational\n",
      "approach.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Based on the abstract, the paper is about using Large Language Models (LLMs), specifically GPT-4, to solve complex mathematical problems. The authors propose a conversational problem-solving framework called MathChat and evaluate it on difficult high school competition problems from the MATH dataset.\n",
      "\n",
      "The target audience for this paper includes:\n",
      "\n",
      "1. Researchers and practitioners in the field of artificial intelligence, specifically those working with large language models like GPT-4.\n",
      "2. Mathematicians and educators interested in the application of AI for solving complex mathematical problems.\n",
      "3. Developers working on AI-based conversational systems or chatbots for problem-solving in various domains.\n",
      "4. Students and researchers in natural language processing, machine learning, and AI who are interested in the intersection of these fields with mathematics.\n",
      "\n",
      "If you belong to any of these categories or have a general interest in AI and its applications, you might find this paper valuable. TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# the assistant receives a message from the user, which contains the task description\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"\"\"\n",
    "Who should read this paper: https://arxiv.org/abs/2306.01337\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Task: Chat about Stock Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Show me the YTD gain of 10 largest technology companies as of today.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "To get the YTD gain of the 10 largest technology companies, we can use a Python script to fetch the data from a financial API like Yahoo Finance. Please execute the following Python code:\n",
      "\n",
      "```python\n",
      "import datetime\n",
      "import requests\n",
      "import pandas as pd\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "def get_top_tech_companies():\n",
      "    url = \"https://www.tradingview.com/markets/stocks-usa/sectorandindustry-industry/technology/\"\n",
      "    response = requests.get(url)\n",
      "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
      "    table = soup.find(\"table\", {\"class\": \"tv-data-table\"})\n",
      "    rows = table.find_all(\"tr\")[1:11]\n",
      "    symbols = [row.find(\"a\").text for row in rows]\n",
      "    return symbols\n",
      "\n",
      "def get_ytd_gain(symbol):\n",
      "    today = datetime.date.today()\n",
      "    start_date = datetime.date(today.year, 1, 1)\n",
      "    url = f\"https://query1.finance.yahoo.com/v7/finance/download/{symbol}?period1={int(start_date.timestamp())}&period2={int(today.timestamp())}&interval=1d&events=history&includeAdjustedClose=true\"\n",
      "    response = requests.get(url)\n",
      "    data = pd.read_csv(pd.StringIO(response.text))\n",
      "    ytd_gain = (data[\"Close\"].iloc[-1] - data[\"Close\"].iloc[0]) / data[\"Close\"].iloc[0] * 100\n",
      "    return ytd_gain\n",
      "\n",
      "top_tech_companies = get_top_tech_companies()\n",
      "ytd_gains = {symbol: get_ytd_gain(symbol) for symbol in top_tech_companies}\n",
      "\n",
      "for symbol, gain in ytd_gains.items():\n",
      "    print(f\"{symbol}: {gain:.2f}%\")\n",
      "```\n",
      "\n",
      "This code will fetch the 10 largest technology companies from TradingView and then calculate their YTD gains using Yahoo Finance data.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/FLAML/notebook/web/tmp_code_2e1e4c6201cb82d42fbeb0754e008d0f.py\", line 24, in <module>\n",
      "    top_tech_companies = get_top_tech_companies()\n",
      "  File \"/workspaces/FLAML/notebook/web/tmp_code_2e1e4c6201cb82d42fbeb0754e008d0f.py\", line 11, in get_top_tech_companies\n",
      "    rows = table.find_all(\"tr\")[1:11]\n",
      "AttributeError: 'NoneType' object has no attribute 'find_all'\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "I apologize for the error. It seems that the website structure has changed, and the script is unable to find the table containing the top technology companies. Let's try an alternative approach using the Yahoo Finance library. Please install the library first by executing:\n",
      "\n",
      "```sh\n",
      "pip install yfinance\n",
      "```\n",
      "\n",
      "After installing the library, please execute the following Python code:\n",
      "\n",
      "```python\n",
      "import yfinance as yf\n",
      "import datetime\n",
      "\n",
      "top_tech_companies = [\n",
      "    \"AAPL\", \"MSFT\", \"GOOGL\", \"GOOG\", \"AMZN\", \"FB\", \"TSLA\", \"NVDA\", \"ASML\", \"ADBE\"\n",
      "]\n",
      "\n",
      "def get_ytd_gain(symbol):\n",
      "    today = datetime.date.today()\n",
      "    start_date = datetime.date(today.year, 1, 1)\n",
      "    stock = yf.Ticker(symbol)\n",
      "    data = stock.history(start=start_date, end=today)\n",
      "    ytd_gain = (data[\"Close\"].iloc[-1] - data[\"Close\"].iloc[0]) / data[\"Close\"].iloc[0] * 100\n",
      "    return ytd_gain\n",
      "\n",
      "ytd_gains = {symbol: get_ytd_gain(symbol) for symbol in top_tech_companies}\n",
      "\n",
      "for symbol, gain in ytd_gains.items():\n",
      "    print(f\"{symbol}: {gain:.2f}%\")\n",
      "```\n",
      "\n",
      "This code uses a predefined list of the 10 largest technology companies and calculates their YTD gains using the Yahoo Finance library.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: yfinance in /home/vscode/.local/lib/python3.9/site-packages (0.2.26)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (1.25.1)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (1.3.3)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (4.12.2)\n",
      "Requirement already satisfied: html5lib>=1.1 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (1.1)\n",
      "Requirement already satisfied: pytz>=2022.5 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (2023.3)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (1.4.4)\n",
      "Requirement already satisfied: lxml>=4.9.1 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (4.9.3)\n",
      "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.9/site-packages (from yfinance) (2.31.0)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (2.3.8)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/vscode/.local/lib/python3.9/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4.1)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.9/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /home/vscode/.local/lib/python3.9/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/vscode/.local/lib/python3.9/site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests>=2.31->yfinance) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests>=2.31->yfinance) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests>=2.31->yfinance) (2.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests>=2.31->yfinance) (3.2.0)\n",
      "\n",
      "FB: No timezone found, symbol may be delisted\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/FLAML/notebook/web/tmp_code_52c69e134e808cf8ba196ac60faede00.py\", line 16, in <module>\n",
      "    ytd_gains = {symbol: get_ytd_gain(symbol) for symbol in top_tech_companies}\n",
      "  File \"/workspaces/FLAML/notebook/web/tmp_code_52c69e134e808cf8ba196ac60faede00.py\", line 16, in <dictcomp>\n",
      "    ytd_gains = {symbol: get_ytd_gain(symbol) for symbol in top_tech_companies}\n",
      "  File \"/workspaces/FLAML/notebook/web/tmp_code_52c69e134e808cf8ba196ac60faede00.py\", line 13, in get_ytd_gain\n",
      "    ytd_gain = (data[\"Close\"].iloc[-1] - data[\"Close\"].iloc[0]) / data[\"Close\"].iloc[0] * 100\n",
      "  File \"/home/vscode/.local/lib/python3.9/site-packages/pandas/core/indexing.py\", line 931, in __getitem__\n",
      "    return self._getitem_axis(maybe_callable, axis=axis)\n",
      "  File \"/home/vscode/.local/lib/python3.9/site-packages/pandas/core/indexing.py\", line 1566, in _getitem_axis\n",
      "    self._validate_integer(key, axis)\n",
      "  File \"/home/vscode/.local/lib/python3.9/site-packages/pandas/core/indexing.py\", line 1500, in _validate_integer\n",
      "    raise IndexError(\"single positional indexer is out-of-bounds\")\n",
      "IndexError: single positional indexer is out-of-bounds\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "I apologize for the error. It seems that there is an issue with the data for the \"FB\" symbol. Let's add a try-except block to handle this issue. Please execute the following Python code:\n",
      "\n",
      "```python\n",
      "import yfinance as yf\n",
      "import datetime\n",
      "\n",
      "top_tech_companies = [\n",
      "    \"AAPL\", \"MSFT\", \"GOOGL\", \"GOOG\", \"AMZN\", \"FB\", \"TSLA\", \"NVDA\", \"ASML\", \"ADBE\"\n",
      "]\n",
      "\n",
      "def get_ytd_gain(symbol):\n",
      "    try:\n",
      "        today = datetime.date.today()\n",
      "        start_date = datetime.date(today.year, 1, 1)\n",
      "        stock = yf.Ticker(symbol)\n",
      "        data = stock.history(start=start_date, end=today)\n",
      "        ytd_gain = (data[\"Close\"].iloc[-1] - data[\"Close\"].iloc[0]) / data[\"Close\"].iloc[0] * 100\n",
      "        return ytd_gain\n",
      "    except Exception as e:\n",
      "        print(f\"Error fetching data for {symbol}: {e}\")\n",
      "        return None\n",
      "\n",
      "ytd_gains = {symbol: get_ytd_gain(symbol) for symbol in top_tech_companies}\n",
      "\n",
      "for symbol, gain in ytd_gains.items():\n",
      "    if gain is not None:\n",
      "        print(f\"{symbol}: {gain:.2f}%\")\n",
      "    else:\n",
      "        print(f\"{symbol}: Data not available\")\n",
      "```\n",
      "\n",
      "This code adds error handling to the `get_ytd_gain` function, so if there is an issue with a specific symbol, it will print an error message and continue with the remaining symbols.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Error fetching data for FB: single positional indexer is out-of-bounds\n",
      "AAPL: 57.03%\n",
      "MSFT: 41.90%\n",
      "GOOGL: 48.77%\n",
      "GOOG: 48.28%\n",
      "AMZN: 54.06%\n",
      "FB: Data not available\n",
      "TSLA: 146.48%\n",
      "NVDA: 226.67%\n",
      "ASML: 31.38%\n",
      "ADBE: 56.97%\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "I'm glad the code executed successfully. Here are the YTD gains for the 10 largest technology companies, except for Facebook (FB), for which data is not available:\n",
      "\n",
      "- AAPL: 57.03%\n",
      "- MSFT: 41.90%\n",
      "- GOOGL: 48.77%\n",
      "- GOOG: 48.28%\n",
      "- AMZN: 54.06%\n",
      "- TSLA: 146.48%\n",
      "- NVDA: 226.67%\n",
      "- ASML: 31.38%\n",
      "- ADBE: 56.97%\n",
      "\n",
      "Please note that these values are subject to change as the market fluctuates. If you need updated values, you can re-run the code.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "FB->META\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "I apologize for the confusion. Facebook has changed its stock symbol from \"FB\" to \"META\" due to the company's rebranding. Let's update the code with the new symbol and execute it again:\n",
      "\n",
      "```python\n",
      "import yfinance as yf\n",
      "import datetime\n",
      "\n",
      "top_tech_companies = [\n",
      "    \"AAPL\", \"MSFT\", \"GOOGL\", \"GOOG\", \"AMZN\", \"META\", \"TSLA\", \"NVDA\", \"ASML\", \"ADBE\"\n",
      "]\n",
      "\n",
      "def get_ytd_gain(symbol):\n",
      "    try:\n",
      "        today = datetime.date.today()\n",
      "        start_date = datetime.date(today.year, 1, 1)\n",
      "        stock = yf.Ticker(symbol)\n",
      "        data = stock.history(start=start_date, end=today)\n",
      "        ytd_gain = (data[\"Close\"].iloc[-1] - data[\"Close\"].iloc[0]) / data[\"Close\"].iloc[0] * 100\n",
      "        return ytd_gain\n",
      "    except Exception as e:\n",
      "        print(f\"Error fetching data for {symbol}: {e}\")\n",
      "        return None\n",
      "\n",
      "ytd_gains = {symbol: get_ytd_gain(symbol) for symbol in top_tech_companies}\n",
      "\n",
      "for symbol, gain in ytd_gains.items():\n",
      "    if gain is not None:\n",
      "        print(f\"{symbol}: {gain:.2f}%\")\n",
      "    else:\n",
      "        print(f\"{symbol}: Data not available\")\n",
      "```\n",
      "\n",
      "This code replaces \"FB\" with \"META\" in the list of top technology companies and calculates the YTD gains for the updated list.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "AAPL: 57.03%\n",
      "MSFT: 41.90%\n",
      "GOOGL: 48.77%\n",
      "GOOG: 48.28%\n",
      "AMZN: 54.06%\n",
      "META: 160.93%\n",
      "TSLA: 146.48%\n",
      "NVDA: 226.67%\n",
      "ASML: 31.38%\n",
      "ADBE: 56.97%\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Great! The code executed successfully, and here are the updated YTD gains for the 10 largest technology companies, including Meta Platforms (formerly Facebook):\n",
      "\n",
      "- AAPL: 57.03%\n",
      "- MSFT: 41.90%\n",
      "- GOOGL: 48.77%\n",
      "- GOOG: 48.28%\n",
      "- AMZN: 54.06%\n",
      "- META: 160.93%\n",
      "- TSLA: 146.48%\n",
      "- NVDA: 226.67%\n",
      "- ASML: 31.38%\n",
      "- ADBE: 56.97%\n",
      "\n",
      "Please note that these values are subject to change as the market fluctuates. If you need updated values, you can re-run the code.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# it is suggested to reset the assistant to clear the state if the new task is not related to the previous one.\n",
    "assistant.reset()\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"\"\"Show me the YTD gain of 10 largest technology companies as of today.\"\"\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2d910cfd2d2a4fc49fc30fbbdc5576a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "454146d0f7224f038689031002906e6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e4ae2b6f5a974fd4bafb6abb9d12ff26",
        "IPY_MODEL_577e1e3cc4db4942b0883577b3b52755",
        "IPY_MODEL_b40bdfb1ac1d4cffb7cefcb870c64d45"
       ],
       "layout": "IPY_MODEL_dc83c7bff2f241309537a8119dfc7555",
       "tabbable": null,
       "tooltip": null
      }
     },
     "577e1e3cc4db4942b0883577b3b52755": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2d910cfd2d2a4fc49fc30fbbdc5576a7",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_74a6ba0c3cbc4051be0a83e152fe1e62",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "6086462a12d54bafa59d3c4566f06cb2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74a6ba0c3cbc4051be0a83e152fe1e62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7d3f3d9e15894d05a4d188ff4f466554": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b40bdfb1ac1d4cffb7cefcb870c64d45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f1355871cc6f4dd4b50d9df5af20e5c8",
       "placeholder": "​",
       "style": "IPY_MODEL_ca245376fd9f4354af6b2befe4af4466",
       "tabbable": null,
       "tooltip": null,
       "value": " 1/1 [00:00&lt;00:00, 44.69it/s]"
      }
     },
     "ca245376fd9f4354af6b2befe4af4466": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dc83c7bff2f241309537a8119dfc7555": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e4ae2b6f5a974fd4bafb6abb9d12ff26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6086462a12d54bafa59d3c4566f06cb2",
       "placeholder": "​",
       "style": "IPY_MODEL_7d3f3d9e15894d05a4d188ff4f466554",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "f1355871cc6f4dd4b50d9df5af20e5c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
