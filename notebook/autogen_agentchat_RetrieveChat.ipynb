{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Generated Agent Chat: Using RetrieveChat for Retrieve Augmented Code Generation and Question Answering\n",
    "\n",
    "RetrieveChat is a convesational framework for retrieve augmented code generation and question answering. In this notebook, we demonstrate how to utilize RetrieveChat to generate code and answer questions based on customized documentations that are not present in the LLM's training dataset. RetrieveChat uses the `RetrieveAssistantAgent` and `RetrieveUserProxyAgent`, which is similar to the usage of `AssistantAgent` and `UserProxyAgent` in other notebooks (e.g., [Automated Task Solving with Code Generation, Execution & Debugging](https://github.com/microsoft/FLAML/blob/main/notebook/autogen_agentchat_auto_feedback_from_code_execution.ipynb)). Essentially,`RetrieveAssistantAgent` and  `RetrieveUserProxyAgent` implements a different auto reply mechanism corresponding to the RetrieveChat prompts.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "FLAML requires `Python>=3.8`. To run this notebook example, please install flaml with the [mathchat] option.\n",
    "```bash\n",
    "pip install flaml[retrievechat]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install flaml[retrievechat]~=2.0.0rc4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/FLAML/docs/reference/autogen/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models to use:  ['gpt-4']\n"
     ]
    }
   ],
   "source": [
    "from flaml import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    env_or_file=\".config.local\",\n",
    "    file_location=\".\",\n",
    "    filter_dict={\n",
    "        \"model\": {\n",
    "            \"gpt-4\",\n",
    "            \"gpt4\",\n",
    "            \"gpt-4-32k\",\n",
    "            \"gpt-4-32k-0314\",\n",
    "            \"gpt-35-turbo\",\n",
    "            \"gpt-3.5-turbo\",\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "assert len(config_list) > 0\n",
    "print(\"models to use: \", [config_list[i][\"model\"] for i in range(len(config_list))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It first looks for environment variable \"OAI_CONFIG_LIST\" which needs to be a valid json string. If that variable is not found, it then looks for a json file named \"OAI_CONFIG_LIST\". It filters the configs by models (you can filter by other keys as well). Only the gpt-4 and gpt-3.5-turbo models are kept in the list based on the filter condition.\n",
    "\n",
    "The config list looks like the following:\n",
    "```python\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your OpenAI API key here>',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'api_base': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-3.5-turbo',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'api_base': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "]\n",
    "```\n",
    "\n",
    "If you open this notebook in colab, you can upload your files by clicking the file icon on the left panel and then choose \"upload file\" icon.\n",
    "\n",
    "You can set the value of config_list in other ways you prefer, e.g., loading from a YAML file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct agents for RetrieveChat\n",
    "\n",
    "We start by initialzing the `RetrieveAssistantAgent` and `RetrieveUserProxyAgent`. The system message needs to be set to \"You are a helpful assistant.\" for RetrieveAssistantAgent. The detailed instructions are given in the user message. Later we will use the `RetrieveUserProxyAgent.generate_init_prompt` to combine the instructions and a math problem for an initial prompt to be sent to the LLM assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml.autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "from flaml.autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "import chromadb\n",
    "\n",
    "autogen.ChatCompletion.start_logging()\n",
    "\n",
    "# 1. create an RetrieveAssistantAgent instance named \"assistant\"\n",
    "assistant = RetrieveAssistantAgent(\n",
    "    name=\"assistant\", \n",
    "    system_message=\"You are a helpful assistant.\",\n",
    "    llm_config={\n",
    "        \"request_timeout\": 600,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "    },\n",
    ")\n",
    "\n",
    "# 2. create the RetrieveUserProxyAgent instance named \"ragproxyagent\"\n",
    "# By default, the human_input_mode is \"ALWAYS\", which means the agent will ask for human input at every step. We set it to \"NEVER\" here.\n",
    "# `docs_path` is the path to the docs directory. By default, it is set to \"./docs\". Here we generated the documentations from FLAML's docstrings.\n",
    "# Navigate to the website folder and run `pydoc-markdown` and it will generate folder `reference` under `website/docs`.\n",
    "# `chunk_token_size` is the chunk token size for the retrieve chat. By default, it is set to `max_tokens * 0.6`, here we set it to 2000.\n",
    "ragproxyagent = RetrieveUserProxyAgent(\n",
    "    name=\"ragproxyagent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    retrieve_config={\n",
    "        \"docs_path\": \"../website/docs/reference\",\n",
    "        \"chunk_token_size\": 2000,\n",
    "        \"model\": config_list[0][\"model\"],\n",
    "        \"client\": chromadb.PersistentClient(path=\"/tmp/chromadb\"),\n",
    "        \"embedding_model\": \"all-mpnet-base-v2\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "Use RetrieveChat to help generate sample code and automatically run the code and fix errors if there is any.\n",
    "\n",
    "Problem: Which API should I use if I want to use FLAML for a classification task and I want to train the model in 30 seconds. Use spark to parallel the training. Force cancel jobs if time limit is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:flaml.autogen.retrieve_utils:Collection flaml-docs already exists.\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_1\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_2\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_3\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_4\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_5\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_6\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_7\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_8\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_9\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_10\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_11\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_12\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_13\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_14\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_15\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_16\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_17\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_18\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_19\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_20\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_21\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_22\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_23\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_24\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_25\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_26\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_27\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_28\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_29\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_30\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_31\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_32\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_33\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_34\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_35\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_36\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_37\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_38\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_39\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_40\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_41\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_42\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_43\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_44\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_45\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_46\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_47\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_48\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_49\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_50\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_51\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_52\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_53\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_54\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_55\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_56\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_57\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_58\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_59\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_60\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_61\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_62\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: doc_63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_ids:  [['doc_29', 'doc_34', 'doc_26', 'doc_11', 'doc_45', 'doc_44', 'doc_36', 'doc_15', 'doc_46', 'doc_43', 'doc_30', 'doc_63', 'doc_14', 'doc_32', 'doc_55']]\n",
      "Adding doc_id doc_29 to context.\n",
      "Adding doc_id doc_34 to context.\n",
      "Adding doc_id doc_26 to context.\n",
      "Adding doc_id doc_11 to context.\n",
      "ragproxyagent (to assistant):\n",
      "\n",
      "You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user. You should follow the following steps to answer a question:\n",
      "Step 1, you estimate the user's intent based on the question and context. The intent can be a code generation task or\n",
      "a QA task.\n",
      "Step 2, you generate code or answer the question based on the intent.\n",
      "You should leverage the context provided by the user as much as possible. If you think the context is not enough, you\n",
      "can reply exactly \"UPDATE CONTEXT\" to ask the user to provide more contexts.\n",
      "For code generation, you must obey the following rules:\n",
      "You MUST NOT install any packages because all the packages needed are already installed.\n",
      "The code will be executed in IPython, you must follow the formats below to write your code:\n",
      "```python\n",
      "# your code\n",
      "```\n",
      "\n",
      "User's question is: How can I use FLAML to perform a classification task and use spark to do parallel training. Train 30 seconds and force cancel jobs if time limit is reached.\n",
      "\n",
      "Context is: \n",
      "new_automl = AutoML()\n",
      "new_automl.fit(X_train, y_train, starting_points=starting_points)\n",
      "```\n",
      "  \n",
      "- `seed` - int or None, default=None | The random seed for hpo.\n",
      "- `n_concurrent_trials` - [Experimental] int, default=1 | The number of\n",
      "  concurrent trials. When n_concurrent_trials > 1, flaml performes\n",
      "  [parallel tuning](../../Use-Cases/Task-Oriented-AutoML#parallel-tuning)\n",
      "  and installation of ray or spark is required: `pip install flaml[ray]`\n",
      "  or `pip install flaml[spark]`. Please check\n",
      "  [here](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
      "  for more details about installing Spark.\n",
      "- `keep_search_state` - boolean, default=False | Whether to keep data needed\n",
      "  for model search after fit(). By default the state is deleted for\n",
      "  space saving.\n",
      "- `preserve_checkpoint` - boolean, default=True | Whether to preserve the saved checkpoint\n",
      "  on disk when deleting automl. By default the checkpoint is preserved.\n",
      "- `early_stop` - boolean, default=False | Whether to stop early if the\n",
      "  search is considered to converge.\n",
      "- `force_cancel` - boolean, default=False | Whether to forcely cancel Spark jobs if the\n",
      "  search time exceeded the time budget.\n",
      "- `append_log` - boolean, default=False | Whetehr to directly append the log\n",
      "  records to the input log file if it exists.\n",
      "- `auto_augment` - boolean, default=True | Whether to automatically\n",
      "  augment rare classes.\n",
      "- `min_sample_size` - int, default=MIN_SAMPLE_TRAIN | the minimal sample\n",
      "  size when sample=True.\n",
      "- `use_ray` - boolean or dict.\n",
      "  If boolean: default=False | Whether to use ray to run the training\n",
      "  in separate processes. This can be used to prevent OOM for large\n",
      "  datasets, but will incur more overhead in time.\n",
      "  If dict: the dict contains the keywords arguments to be passed to\n",
      "  [ray.tune.run](https://docs.ray.io/en/latest/tune/api_docs/execution.html).\n",
      "- `use_spark` - boolean, default=False | Whether to use spark to run the training\n",
      "  in parallel spark jobs. This can be used to accelerate training on large models\n",
      "  and large datasets, but will incur more overhead in time and thus slow down\n",
      "  training in some cases. GPU training is not supported yet when use_spark is True.\n",
      "  For Spark clusters, by default, we will launch one trial per executor. However,\n",
      "  sometimes we want to launch more trials than the number of executors (e.g., local mode).\n",
      "  In this case, we can set the environment variable `FLAML_MAX_CONCURRENT` to override\n",
      "  the detected `num_executors`. The final number of concurrent trials will be the minimum\n",
      "  of `n_concurrent_trials` and `num_executors`.\n",
      "- `free_mem_ratio` - float between 0 and 1, default=0. The free memory ratio to keep during training.\n",
      "- `metric_constraints` - list, default=[] | The list of metric constraints.\n",
      "  Each element in this list is a 3-tuple, which shall be expressed\n",
      "  in the following format: the first element of the 3-tuple is the name of the\n",
      "  metric, the second element is the inequality sign chosen from \">=\" and \"<=\",\n",
      "  and the third element is the constraint value. E.g., `('val_loss', '<=', 0.1)`.\n",
      "  Note that all the metric names in metric_constraints need to be reported via\n",
      "  the metrics_to_log dictionary returned by a customized metric function.\n",
      "  The customized metric function shall be provided via the `metric` key word\n",
      "  argument of the fit() function or the automl constructor.\n",
      "  Find an example in the 4th constraint type in this [doc](../../Use-Cases/Task-Oriented-AutoML#constraint).\n",
      "  If `pred_time_limit` is provided as one of keyword arguments to fit() function or\n",
      "  the automl constructor, flaml will automatically (and under the hood)\n",
      "  add it as an additional element in the metric_constraints. Essentially 'pred_time_limit'\n",
      "  specifies a constraint about the prediction latency constraint in seconds.\n",
      "- `custom_hp` - dict, default=None | The custom search space specified by user.\n",
      "  It is a nested dict with keys being the estimator names, and values being dicts\n",
      "  per estimator search space. In the per estimator search space dict,\n",
      "  the keys are the hyperparameter names, and values are dicts of info (\"domain\",\n",
      "  \"init_value\", and \"low_cost_init_value\") about the search space associated with\n",
      "  the hyperparameter (i.e., per hyperparameter search space dict). When custom_hp\n",
      "  is provided, the built-in search space which is also a nested dict of per estimator\n",
      "  search space dict, will be updated with custom_hp. Note that during this nested dict update,\n",
      "  the per hyperparameter search space dicts will be replaced (instead of updated) by the ones\n",
      "  provided in custom_hp. Note that the value for \"domain\" can either be a constant\n",
      "  or a sample.Domain object.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "custom_hp = {\n",
      "     \"transformer_ms\": {\n",
      "         \"model_path\": {\n",
      "             \"domain\": \"albert-base-v2\",\n",
      "         },\n",
      "         \"learning_rate\": {\n",
      "             \"domain\": tune.choice([1e-4, 1e-5]),\n",
      "         }\n",
      "     }\n",
      " }\n",
      "```\n",
      "- `skip_transform` - boolean, default=False | Whether to pre-process data prior to modeling.\n",
      "- `fit_kwargs_by_estimator` - dict, default=None | The user specified keywords arguments, grouped by estimator name.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "fit_kwargs_by_estimator = {\n",
      "    \"transformer\": {\n",
      "        \"output_dir\": \"test/data/output/\",\n",
      "        \"fp16\": False,\n",
      "    }\n",
      "}\n",
      "```\n",
      "- `mlflow_logging` - boolean, default=True | Whether to log the training results to mlflow.\n",
      "  This requires mlflow to be installed and to have an active mlflow run.\n",
      "  FLAML will create nested runs.\n",
      "\n",
      "#### config\\_history\n",
      "\n",
      "```python\n",
      "@property\n",
      "def config_history() -> dict\n",
      "```\n",
      "\n",
      "A dictionary of iter->(estimator, config, time),\n",
      "storing the best estimator, config, and the time when the best\n",
      "model is updated each time.\n",
      "\n",
      "#### model\n",
      "\n",
      "```python\n",
      "@property\n",
      "def model()\n",
      "```\n",
      "\n",
      "An object with `predict()` and `predict_proba()` method (for\n",
      "classification), storing the best trained model.\n",
      "\n",
      "#### best\\_model\\_for\\_estimator\n",
      "\n",
      "```python\n",
      "def best_model_for_estimator(estimator_name: str)\n",
      "```\n",
      "\n",
      "Return the best model found for a particular estimator.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `estimator_name` - a str of the estimator's name.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  An object storing the best model for estimator_name.\n",
      "  If `model_history` was set to False during fit(), then the returned model\n",
      "  is untrained unless estimator_name is the best estimator.\n",
      "  If `model_history` was set to True, then the returned model is trained.\n",
      "\n",
      "#### best\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_estimator()\n",
      "```\n",
      "\n",
      "A string indicating the best estimator found.\n",
      "\n",
      "#### best\\_iteration\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_iteration()\n",
      "```\n",
      "\n",
      "An integer of the iteration number where the best\n",
      "config is found.\n",
      "\n",
      "#### best\\_config\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config()\n",
      "```\n",
      "\n",
      "A dictionary of the best configuration.\n",
      "\n",
      "#### best\\_config\\_per\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config_per_estimator()\n",
      "```\n",
      "\n",
      "A dictionary of all estimators' best configuration.\n",
      "\n",
      "#### best\\_loss\\_per\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_loss_per_estimator()\n",
      "```\n",
      "\n",
      "A dictionary of all estimators' best loss.\n",
      "\n",
      "#### best\\_loss\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_loss()\n",
      "```\n",
      "\n",
      "A float of the best loss found.\n",
      "\n",
      "#### best\\_result\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_result()\n",
      "```\n",
      "\n",
      "Result dictionary for model trained with the best config.\n",
      "\n",
      "#### metrics\\_for\\_best\\_config\n",
      "\n",
      "```python\n",
      "@property\n",
      "def metrics_for_best_config()\n",
      "```\n",
      "\n",
      "Returns a float of the best loss, and a dictionary of the auxiliary metrics to log\n",
      "associated with the best config. These two objects correspond to the returned\n",
      "objects by the customized metric function for the config with the best loss.\n",
      "\n",
      "#### best\\_config\\_train\\_time\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config_train_time()\n",
      "```\n",
      "\n",
      "new_automl = AutoML()\n",
      "new_automl.fit(X_train, y_train, starting_points=starting_points)\n",
      "```\n",
      "  \n",
      "- `seed` - int or None, default=None | The random seed for hpo.\n",
      "- `n_concurrent_trials` - [Experimental] int, default=1 | The number of\n",
      "  concurrent trials. When n_concurrent_trials > 1, flaml performes\n",
      "  [parallel tuning](../../Use-Cases/Task-Oriented-AutoML#parallel-tuning)\n",
      "  and installation of ray or spark is required: `pip install flaml[ray]`\n",
      "  or `pip install flaml[spark]`. Please check\n",
      "  [here](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
      "  for more details about installing Spark.\n",
      "- `keep_search_state` - boolean, default=False | Whether to keep data needed\n",
      "  for model search after fit(). By default the state is deleted for\n",
      "  space saving.\n",
      "- `preserve_checkpoint` - boolean, default=True | Whether to preserve the saved checkpoint\n",
      "  on disk when deleting automl. By default the checkpoint is preserved.\n",
      "- `early_stop` - boolean, default=False | Whether to stop early if the\n",
      "  search is considered to converge.\n",
      "- `force_cancel` - boolean, default=False | Whether to forcely cancel the PySpark job if overtime.\n",
      "- `append_log` - boolean, default=False | Whetehr to directly append the log\n",
      "  records to the input log file if it exists.\n",
      "- `auto_augment` - boolean, default=True | Whether to automatically\n",
      "  augment rare classes.\n",
      "- `min_sample_size` - int, default=MIN_SAMPLE_TRAIN | the minimal sample\n",
      "  size when sample=True.\n",
      "- `use_ray` - boolean or dict.\n",
      "  If boolean: default=False | Whether to use ray to run the training\n",
      "  in separate processes. This can be used to prevent OOM for large\n",
      "  datasets, but will incur more overhead in time.\n",
      "  If dict: the dict contains the keywords arguments to be passed to\n",
      "  [ray.tune.run](https://docs.ray.io/en/latest/tune/api_docs/execution.html).\n",
      "- `use_spark` - boolean, default=False | Whether to use spark to run the training\n",
      "  in parallel spark jobs. This can be used to accelerate training on large models\n",
      "  and large datasets, but will incur more overhead in time and thus slow down\n",
      "  training in some cases.\n",
      "- `free_mem_ratio` - float between 0 and 1, default=0. The free memory ratio to keep during training.\n",
      "- `metric_constraints` - list, default=[] | The list of metric constraints.\n",
      "  Each element in this list is a 3-tuple, which shall be expressed\n",
      "  in the following format: the first element of the 3-tuple is the name of the\n",
      "  metric, the second element is the inequality sign chosen from \">=\" and \"<=\",\n",
      "  and the third element is the constraint value. E.g., `('precision', '>=', 0.9)`.\n",
      "  Note that all the metric names in metric_constraints need to be reported via\n",
      "  the metrics_to_log dictionary returned by a customized metric function.\n",
      "  The customized metric function shall be provided via the `metric` key word argument\n",
      "  of the fit() function or the automl constructor.\n",
      "  Find examples in this [test](https://github.com/microsoft/FLAML/tree/main/test/automl/test_constraints.py).\n",
      "  If `pred_time_limit` is provided as one of keyword arguments to fit() function or\n",
      "  the automl constructor, flaml will automatically (and under the hood)\n",
      "  add it as an additional element in the metric_constraints. Essentially 'pred_time_limit'\n",
      "  specifies a constraint about the prediction latency constraint in seconds.\n",
      "- `custom_hp` - dict, default=None | The custom search space specified by user\n",
      "  Each key is the estimator name, each value is a dict of the custom search space for that estimator. Notice the\n",
      "  domain of the custom search space can either be a value of a sample.Domain object.\n",
      "  \n",
      "  \n",
      "  \n",
      "```python\n",
      "custom_hp = {\n",
      "    \"transformer_ms\": {\n",
      "        \"model_path\": {\n",
      "            \"domain\": \"albert-base-v2\",\n",
      "        },\n",
      "        \"learning_rate\": {\n",
      "            \"domain\": tune.choice([1e-4, 1e-5]),\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "- `time_col` - for a time series task, name of the column containing the timestamps. If not\n",
      "  provided, defaults to the first column of X_train/X_val\n",
      "  \n",
      "- `cv_score_agg_func` - customized cross-validation scores aggregate function. Default to average metrics across folds. If specificed, this function needs to\n",
      "  have the following input arguments:\n",
      "  \n",
      "  * val_loss_folds: list of floats, the loss scores of each fold;\n",
      "  * log_metrics_folds: list of dicts/floats, the metrics of each fold to log.\n",
      "  \n",
      "  This function should return the final aggregate result of all folds. A float number of the minimization objective, and a dictionary as the metrics to log or None.\n",
      "  E.g.,\n",
      "  \n",
      "```python\n",
      "def cv_score_agg_func(val_loss_folds, log_metrics_folds):\n",
      "    metric_to_minimize = sum(val_loss_folds)/len(val_loss_folds)\n",
      "    metrics_to_log = None\n",
      "    for single_fold in log_metrics_folds:\n",
      "        if metrics_to_log is None:\n",
      "            metrics_to_log = single_fold\n",
      "        elif isinstance(metrics_to_log, dict):\n",
      "            metrics_to_log = {k: metrics_to_log[k] + v for k, v in single_fold.items()}\n",
      "        else:\n",
      "            metrics_to_log += single_fold\n",
      "    if metrics_to_log:\n",
      "        n = len(val_loss_folds)\n",
      "        metrics_to_log = (\n",
      "            {k: v / n for k, v in metrics_to_log.items()}\n",
      "            if isinstance(metrics_to_log, dict)\n",
      "            else metrics_to_log / n\n",
      "        )\n",
      "    return metric_to_minimize, metrics_to_log\n",
      "```\n",
      "  \n",
      "- `skip_transform` - boolean, default=False | Whether to pre-process data prior to modeling.\n",
      "- `mlflow_logging` - boolean, default=None | Whether to log the training results to mlflow.\n",
      "  Default value is None, which means the logging decision is made based on\n",
      "  AutoML.__init__'s mlflow_logging argument.\n",
      "  This requires mlflow to be installed and to have an active mlflow run.\n",
      "  FLAML will create nested runs.\n",
      "- `fit_kwargs_by_estimator` - dict, default=None | The user specified keywords arguments, grouped by estimator name.\n",
      "  For TransformersEstimator, available fit_kwargs can be found from\n",
      "  [TrainingArgumentsForAuto](nlp/huggingface/training_args).\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "fit_kwargs_by_estimator = {\n",
      "    \"transformer\": {\n",
      "        \"output_dir\": \"test/data/output/\",\n",
      "        \"fp16\": False,\n",
      "    },\n",
      "    \"tft\": {\n",
      "        \"max_encoder_length\": 1,\n",
      "        \"min_encoder_length\": 1,\n",
      "        \"static_categoricals\": [],\n",
      "        \"static_reals\": [],\n",
      "        \"time_varying_known_categoricals\": [],\n",
      "        \"time_varying_known_reals\": [],\n",
      "        \"time_varying_unknown_categoricals\": [],\n",
      "        \"time_varying_unknown_reals\": [],\n",
      "        \"variable_groups\": {},\n",
      "        \"lags\": {},\n",
      "    }\n",
      "}\n",
      "```\n",
      "  \n",
      "- `**fit_kwargs` - Other key word arguments to pass to fit() function of\n",
      "  the searched learners, such as sample_weight. Below are a few examples of\n",
      "  estimator-specific parameters:\n",
      "- `period` - int | forecast horizon for all time series forecast tasks.\n",
      "- `gpu_per_trial` - float, default = 0 | A float of the number of gpus per trial,\n",
      "  only used by TransformersEstimator, XGBoostSklearnEstimator, and\n",
      "  TemporalFusionTransformerEstimator.\n",
      "- `group_ids` - list of strings of column names identifying a time series, only\n",
      "  used by TemporalFusionTransformerEstimator, required for\n",
      "  'ts_forecast_panel' task. `group_ids` is a parameter for TimeSeriesDataSet object\n",
      "  from PyTorchForecasting.\n",
      "  For other parameters to describe your dataset, refer to\n",
      "  [TimeSeriesDataSet PyTorchForecasting](https://pytorch-forecasting.readthedocs.io/en/stable/api/pytorch_forecasting.data.timeseries.TimeSeriesDataSet.html).\n",
      "  To specify your variables, use `static_categoricals`, `static_reals`,\n",
      "  `time_varying_known_categoricals`, `time_varying_known_reals`,\n",
      "  `time_varying_unknown_categoricals`, `time_varying_unknown_reals`,\n",
      "  `variable_groups`. To provide more information on your data, use\n",
      "  `max_encoder_length`, `min_encoder_length`, `lags`.\n",
      "- `log_dir` - str, default = \"lightning_logs\" | Folder into which to log results\n",
      "  for tensorboard, only used by TemporalFusionTransformerEstimator.\n",
      "- `max_epochs` - int, default = 20 | Maximum number of epochs to run training,\n",
      "  only used by TemporalFusionTransformerEstimator.\n",
      "- `batch_size` - int, default = 64 | Batch size for training model, only\n",
      "  used by TemporalFusionTransformerEstimator.\n",
      "\n",
      "\n",
      "---\n",
      "sidebar_label: utils\n",
      "title: tune.spark.utils\n",
      "---\n",
      "\n",
      "#### check\\_spark\n",
      "\n",
      "```python\n",
      "@lru_cache(maxsize=2)\n",
      "def check_spark()\n",
      "```\n",
      "\n",
      "Check if Spark is installed and running.\n",
      "Result of the function will be cached since test once is enough. As lru_cache will not\n",
      "cache exceptions, we don't raise exceptions here but only log a warning message.\n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  Return (True, None) if the check passes, otherwise log the exception message and\n",
      "  return (False, Exception(msg)). The exception can be raised by the caller.\n",
      "\n",
      "#### get\\_n\\_cpus\n",
      "\n",
      "```python\n",
      "def get_n_cpus(node=\"driver\")\n",
      "```\n",
      "\n",
      "Get the number of CPU cores of the given type of node.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `node` - string | The type of node to get the number of cores. Can be 'driver' or 'executor'.\n",
      "  Default is 'driver'.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  An int of the number of CPU cores.\n",
      "\n",
      "#### with\\_parameters\n",
      "\n",
      "```python\n",
      "def with_parameters(trainable, **kwargs)\n",
      "```\n",
      "\n",
      "Wrapper for trainables to pass arbitrary large data objects.\n",
      "\n",
      "This wrapper function will store all passed parameters in the Spark\n",
      "Broadcast variable.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `trainable` - Trainable to wrap.\n",
      "- `**kwargs` - parameters to store in object store.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  A new function with partial application of the given arguments\n",
      "  and keywords. The given arguments and keywords will be broadcasted\n",
      "  to all the executors.\n",
      "  \n",
      "  \n",
      "```python\n",
      "import pyspark\n",
      "import flaml\n",
      "from sklearn.datasets import load_iris\n",
      "def train(config, data=None):\n",
      "    if isinstance(data, pyspark.broadcast.Broadcast):\n",
      "        data = data.value\n",
      "    print(config, data)\n",
      "\n",
      "data = load_iris()\n",
      "with_parameters_train = flaml.tune.spark.utils.with_parameters(train, data=data)\n",
      "with_parameters_train(config=1)\n",
      "train(config={\"metric\": \"accuracy\"})\n",
      "```\n",
      "\n",
      "#### broadcast\\_code\n",
      "\n",
      "```python\n",
      "def broadcast_code(custom_code=\"\", file_name=\"mylearner\")\n",
      "```\n",
      "\n",
      "Write customized learner/metric code contents to a file for importing.\n",
      "It is necessary for using the customized learner/metric in spark backend.\n",
      "The path of the learner/metric file will be returned.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `custom_code` - str, default=\"\" | code contents of the custom learner/metric.\n",
      "- `file_name` - str, default=\"mylearner\" | file name of the custom learner/metric.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  The path of the custom code file.\n",
      "```python\n",
      "from flaml.tune.spark.utils import broadcast_code\n",
      "from flaml.automl.model import LGBMEstimator\n",
      "\n",
      "custom_code = '''\n",
      "from flaml.automl.model import LGBMEstimator\n",
      "from flaml import tune\n",
      "\n",
      "class MyLargeLGBM(LGBMEstimator):\n",
      "    @classmethod\n",
      "    def search_space(cls, **params):\n",
      "        return {\n",
      "            \"n_estimators\": {\n",
      "                \"domain\": tune.lograndint(lower=4, upper=32768),\n",
      "                \"init_value\": 32768,\n",
      "                \"low_cost_init_value\": 4,\n",
      "            },\n",
      "            \"num_leaves\": {\n",
      "                \"domain\": tune.lograndint(lower=4, upper=32768),\n",
      "                \"init_value\": 32768,\n",
      "                \"low_cost_init_value\": 4,\n",
      "            },\n",
      "        }\n",
      "'''\n",
      "\n",
      "broadcast_code(custom_code=custom_code)\n",
      "from flaml.tune.spark.mylearner import MyLargeLGBM\n",
      "assert isinstance(MyLargeLGBM(), LGBMEstimator)\n",
      "```\n",
      "\n",
      "#### get\\_broadcast\\_data\n",
      "\n",
      "```python\n",
      "def get_broadcast_data(broadcast_data)\n",
      "```\n",
      "\n",
      "Get the broadcast data from the broadcast variable.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `broadcast_data` - pyspark.broadcast.Broadcast | the broadcast variable.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  The broadcast data.\n",
      "\n",
      "## PySparkOvertimeMonitor Objects\n",
      "\n",
      "```python\n",
      "class PySparkOvertimeMonitor()\n",
      "```\n",
      "\n",
      "A context manager class to monitor if the PySpark job is overtime.\n",
      "\n",
      "**Example**:\n",
      "\n",
      "  \n",
      "```python\n",
      "with PySparkOvertimeMonitor(time_start, time_budget_s, force_cancel, parallel=parallel):\n",
      "    results = parallel(\n",
      "        delayed(evaluation_function)(trial_to_run.config)\n",
      "        for trial_to_run in trials_to_run\n",
      "    )\n",
      "```\n",
      "\n",
      "#### \\_\\_init\\_\\_\n",
      "\n",
      "```python\n",
      "def __init__(start_time,\n",
      "             time_budget_s,\n",
      "             force_cancel=False,\n",
      "             cancel_func=None,\n",
      "             parallel=None,\n",
      "             sc=None)\n",
      "```\n",
      "\n",
      "Constructor.\n",
      "\n",
      "Specify the time budget and start time of the PySpark job, and specify how to cancel them.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "  Args relate to monitoring:\n",
      "- `start_time` - float | The start time of the PySpark job.\n",
      "- `time_budget_s` - float | The time budget of the PySpark job in seconds.\n",
      "- `force_cancel` - boolean, default=False | Whether to forcely cancel the PySpark job if overtime.\n",
      "  \n",
      "  Args relate to how to cancel the PySpark job:\n",
      "  (Only one of the following args will work. Priorities from top to bottom)\n",
      "- `cancel_func` - function | A function to cancel the PySpark job.\n",
      "- `parallel` - joblib.parallel.Parallel | Specify this if using joblib_spark as a parallel backend. It will call parallel._backend.terminate() to cancel the jobs.\n",
      "- `sc` - pyspark.SparkContext object | You can pass a specific SparkContext.\n",
      "  \n",
      "  If all three args is None, the monitor will call pyspark.SparkContext.getOrCreate().cancelAllJobs() to cancel the jobs.\n",
      "\n",
      "#### \\_\\_enter\\_\\_\n",
      "\n",
      "```python\n",
      "def __enter__()\n",
      "```\n",
      "\n",
      "Enter the context manager.\n",
      "This will start a monitor thread if spark is available and force_cancel is True.\n",
      "\n",
      "#### \\_\\_exit\\_\\_\n",
      "\n",
      "```python\n",
      "def __exit__(exc_type, exc_value, exc_traceback)\n",
      "```\n",
      "\n",
      "Exit the context manager.\n",
      "This will wait for the monitor thread to nicely exit.\n",
      "\n",
      "\n",
      "---\n",
      "sidebar_label: trial_runner\n",
      "title: tune.trial_runner\n",
      "---\n",
      "\n",
      "## Nologger Objects\n",
      "\n",
      "```python\n",
      "class Nologger()\n",
      "```\n",
      "\n",
      "Logger without logging.\n",
      "\n",
      "## SimpleTrial Objects\n",
      "\n",
      "```python\n",
      "class SimpleTrial(Trial)\n",
      "```\n",
      "\n",
      "A simple trial class.\n",
      "\n",
      "## BaseTrialRunner Objects\n",
      "\n",
      "```python\n",
      "class BaseTrialRunner()\n",
      "```\n",
      "\n",
      "Implementation of a simple trial runner.\n",
      "\n",
      "Note that the caller usually should not mutate trial state directly.\n",
      "\n",
      "#### get\\_trials\n",
      "\n",
      "```python\n",
      "def get_trials()\n",
      "```\n",
      "\n",
      "Returns the list of trials managed by this TrialRunner.\n",
      "\n",
      "Note that the caller usually should not mutate trial state directly.\n",
      "\n",
      "#### add\\_trial\n",
      "\n",
      "```python\n",
      "def add_trial(trial)\n",
      "```\n",
      "\n",
      "Adds a new trial to this TrialRunner.\n",
      "\n",
      "Trials may be added at any time.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `trial` _Trial_ - Trial to queue.\n",
      "\n",
      "#### stop\\_trial\n",
      "\n",
      "```python\n",
      "def stop_trial(trial)\n",
      "```\n",
      "\n",
      "Stops trial.\n",
      "\n",
      "## SequentialTrialRunner Objects\n",
      "\n",
      "```python\n",
      "class SequentialTrialRunner(BaseTrialRunner)\n",
      "```\n",
      "\n",
      "Implementation of the sequential trial runner.\n",
      "\n",
      "#### step\n",
      "\n",
      "```python\n",
      "def step() -> Trial\n",
      "```\n",
      "\n",
      "Runs one step of the trial event loop.\n",
      "\n",
      "Callers should typically run this method repeatedly in a loop. They\n",
      "may inspect or modify the runner's state in between calls to step().\n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  a trial to run.\n",
      "\n",
      "## SparkTrialRunner Objects\n",
      "\n",
      "```python\n",
      "class SparkTrialRunner(BaseTrialRunner)\n",
      "```\n",
      "\n",
      "Implementation of the spark trial runner.\n",
      "\n",
      "#### step\n",
      "\n",
      "```python\n",
      "def step() -> Trial\n",
      "```\n",
      "\n",
      "Runs one step of the trial event loop.\n",
      "\n",
      "Callers should typically run this method repeatedly in a loop. They\n",
      "may inspect or modify the runner's state in between calls to step().\n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  a trial to run.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to ragproxyagent):\n",
      "\n",
      "In order to use FLAML to perform a classification task and use Spark in parallel training, perform the following steps:\n",
      "\n",
      "Step 1: Install FLAML with the Spark option:\n",
      "```sh\n",
      "pip install flaml[spark]\n",
      "```\n",
      "Step 2: Use FLAML in your code and train your model:\n",
      "\n",
      "```python\n",
      "from flaml import AutoML\n",
      "from sklearn.datasets import load_iris\n",
      "\n",
      "# Load dataset\n",
      "X, y = load_iris(return_X_y=True)\n",
      "\n",
      "# Initialize AutoML instance\n",
      "automl = AutoML()\n",
      "\n",
      "# Set time_budget and force_cancel\n",
      "time_budget = 30\n",
      "force_cancel = True\n",
      "\n",
      "# Perform training with Spark for parallel processing\n",
      "automl.fit(\n",
      "    X_train=X,\n",
      "    y_train=y,\n",
      "    time_budget=time_budget,\n",
      "    n_concurrent_trials=2,  # set it to the number of parallel trials\n",
      "    task=\"classification\",\n",
      "    estimator_list=[\"xgboost\", \"rf\"],\n",
      "    use_spark=True,  # enable Spark for parallel processing\n",
      "    force_cancel=force_cancel,\n",
      ")\n",
      "\n",
      "print(\"Best estimator found:\", automl.best_estimator)\n",
      "print(\"Best config found:\", automl.best_config)\n",
      "print(\"Best validation loss found:\", automl.best_loss)\n",
      "```\n",
      "\n",
      "This code contains the necessary setup for running parallel training with FLAML and Spark.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is sh)...\n",
      "\n",
      ">>>>>>>> EXECUTING CODE BLOCK 1 (inferred language is python)...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/08 07:35:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "[flaml.automl.logger: 08-08 07:35:27] {1679} INFO - task = classification\n",
      "[flaml.automl.logger: 08-08 07:35:27] {1690} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 08-08 07:35:27] {1788} INFO - Minimizing error metric: log_loss\n",
      "[flaml.automl.logger: 08-08 07:35:27] {1900} INFO - List of ML learners in AutoML Run: ['xgboost', 'rf']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:35:27,646]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:35:27,910]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/08 07:35:30 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "[flaml.tune.tune: 08-08 07:35:30] {729} INFO - Number of trials: 1/1000000, 1 RUNNING, 0 TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 07:35:44.881985: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-08 07:35:45.929728: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/lijiang1/.local/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 08-08 07:35:49] {749} INFO - Brief result: {'pred_time': 2.0863215128580728e-05, 'wall_clock_time': 24.607859134674072, 'metric_for_logging': {'pred_time': 2.0863215128580728e-05}, 'val_loss': 0.7099812857309977, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fa7727a3070>}\n",
      "[flaml.tune.tune: 08-08 07:35:49] {729} INFO - Number of trials: 2/1000000, 1 RUNNING, 1 TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lijiang1/.local/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/home/lijiang1/.local/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/home/lijiang1/.local/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/home/lijiang1/.local/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 08-08 07:35:49] {749} INFO - Brief result: {'pred_time': 1.7093022664388023e-05, 'wall_clock_time': 24.926518440246582, 'metric_for_logging': {'pred_time': 1.7093022664388023e-05}, 'val_loss': 0.34762326869958377, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fa7727a2800>}\n",
      "[flaml.tune.tune: 08-08 07:35:49] {729} INFO - Number of trials: 3/1000000, 1 RUNNING, 2 TERMINATED\n",
      "[flaml.tune.tune: 08-08 07:35:50] {749} INFO - Brief result: {'pred_time': 1.735210418701172e-05, 'wall_clock_time': 25.229209661483765, 'metric_for_logging': {'pred_time': 1.735210418701172e-05}, 'val_loss': 0.2581059209712818, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fa7727a16f0>}\n",
      "[flaml.tune.tune: 08-08 07:35:50] {729} INFO - Number of trials: 4/1000000, 1 RUNNING, 3 TERMINATED\n",
      "[flaml.tune.tune: 08-08 07:35:50] {749} INFO - Brief result: {'pred_time': 1.658916473388672e-05, 'wall_clock_time': 25.52937912940979, 'metric_for_logging': {'pred_time': 1.658916473388672e-05}, 'val_loss': 0.32794089957800976, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fa7727a2620>}\n",
      "[flaml.tune.tune: 08-08 07:35:50] {729} INFO - Number of trials: 5/1000000, 1 RUNNING, 4 TERMINATED\n",
      "[flaml.tune.tune: 08-08 07:35:50] {749} INFO - Brief result: {'pred_time': 1.6449292500813804e-05, 'wall_clock_time': 25.828529834747314, 'metric_for_logging': {'pred_time': 1.6449292500813804e-05}, 'val_loss': 0.39243657553620215, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fa7727a0a30>}\n",
      "[flaml.tune.tune: 08-08 07:35:50] {729} INFO - Number of trials: 6/1000000, 1 RUNNING, 5 TERMINATED\n",
      "[flaml.tune.tune: 08-08 07:35:51] {749} INFO - Brief result: {'pred_time': 1.9232432047526043e-05, 'wall_clock_time': 26.135002851486206, 'metric_for_logging': {'pred_time': 1.9232432047526043e-05}, 'val_loss': 0.28597905923858224, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fa882f8c340>}\n",
      "[flaml.tune.tune: 08-08 07:35:51] {729} INFO - Number of trials: 7/1000000, 1 RUNNING, 6 TERMINATED\n",
      "[flaml.tune.tune: 08-08 07:35:51] {749} INFO - Brief result: {'pred_time': 2.3576418558756515e-05, 'wall_clock_time': 26.452159643173218, 'metric_for_logging': {'pred_time': 2.3576418558756515e-05}, 'val_loss': 0.21289852752126617, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fa7727a0d30>}\n",
      "[flaml.tune.tune: 08-08 07:35:51] {729} INFO - Number of trials: 8/1000000, 1 RUNNING, 7 TERMINATED\n",
      "[flaml.tune.tune: 08-08 07:35:51] {749} INFO - Brief result: {'pred_time': 1.6460418701171873e-05, 'wall_clock_time': 26.751352787017822, 'metric_for_logging': {'pred_time': 1.6460418701171873e-05}, 'val_loss': 0.2556425758604466, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fa882f8c3d0>}\n",
      "[flaml.tune.tune: 08-08 07:35:51] {729} INFO - Number of trials: 9/1000000, 1 RUNNING, 8 TERMINATED\n",
      "[flaml.tune.tune: 08-08 07:35:52] {749} INFO - Brief result: {'pred_time': 2.769629160563151e-05, 'wall_clock_time': 27.07763671875, 'metric_for_logging': {'pred_time': 2.769629160563151e-05}, 'val_loss': 0.31637215824119985, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fa882f8d450>}\n",
      "[flaml.tune.tune: 08-08 07:35:52] {729} INFO - Number of trials: 10/1000000, 1 RUNNING, 9 TERMINATED\n",
      "[flaml.tune.tune: 08-08 07:35:52] {749} INFO - Brief result: {'pred_time': 2.1115938822428388e-05, 'wall_clock_time': 27.390125274658203, 'metric_for_logging': {'pred_time': 2.1115938822428388e-05}, 'val_loss': 0.35992051211020054, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fa7727a3610>}\n",
      "[flaml.tune.tune: 08-08 07:35:52] {729} INFO - Number of trials: 11/1000000, 1 RUNNING, 10 TERMINATED\n",
      "[flaml.tune.tune: 08-08 07:35:52] {749} INFO - Brief result: {'pred_time': 2.828439076741537e-05, 'wall_clock_time': 27.71767234802246, 'metric_for_logging': {'pred_time': 2.828439076741537e-05}, 'val_loss': 0.15387659968840756, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fa882f8c040>}\n",
      "[flaml.tune.tune: 08-08 07:35:52] {729} INFO - Number of trials: 12/1000000, 1 RUNNING, 11 TERMINATED\n",
      "[flaml.tune.tune: 08-08 07:35:52] {749} INFO - Brief result: {'pred_time': 2.3775100708007812e-05, 'wall_clock_time': 28.036319732666016, 'metric_for_logging': {'pred_time': 2.3775100708007812e-05}, 'val_loss': 0.20425646014494547, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fa882f8e500>}\n",
      "[flaml.tune.tune: 08-08 07:35:52] {729} INFO - Number of trials: 13/1000000, 1 RUNNING, 12 TERMINATED\n",
      "[flaml.tune.tune: 08-08 07:35:53] {749} INFO - Brief result: {'pred_time': 4.149754842122396e-05, 'wall_clock_time': 28.390960931777954, 'metric_for_logging': {'pred_time': 4.149754842122396e-05}, 'val_loss': 0.15931028540830083, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fa7727a0430>}\n",
      "[flaml.tune.tune: 08-08 07:35:53] {729} INFO - Number of trials: 14/1000000, 1 RUNNING, 13 TERMINATED\n",
      "[flaml.tune.tune: 08-08 07:35:53] {749} INFO - Brief result: {'pred_time': 1.877148946126302e-05, 'wall_clock_time': 28.699767589569092, 'metric_for_logging': {'pred_time': 1.877148946126302e-05}, 'val_loss': 0.35937786872515376, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fa882f8c910>}\n",
      "[flaml.tune.tune: 08-08 07:35:53] {729} INFO - Number of trials: 15/1000000, 1 RUNNING, 14 TERMINATED\n",
      "[flaml.tune.tune: 08-08 07:35:54] {749} INFO - Brief result: {'pred_time': 4.460334777832031e-05, 'wall_clock_time': 29.060681343078613, 'metric_for_logging': {'pred_time': 4.460334777832031e-05}, 'val_loss': 0.13137661858336086, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fa882f8f910>}\n",
      "[flaml.tune.tune: 08-08 07:35:54] {729} INFO - Number of trials: 16/1000000, 1 RUNNING, 15 TERMINATED\n",
      "[flaml.tune.tune: 08-08 07:35:54] {749} INFO - Brief result: {'pred_time': 2.734661102294922e-05, 'wall_clock_time': 29.3886399269104, 'metric_for_logging': {'pred_time': 2.734661102294922e-05}, 'val_loss': 0.1642664665955595, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fa882f8fac0>}\n",
      "[flaml.tune.tune: 08-08 07:35:54] {729} INFO - Number of trials: 17/1000000, 1 RUNNING, 16 TERMINATED\n",
      "[flaml.tune.tune: 08-08 07:35:54] {749} INFO - Brief result: {'pred_time': 3.7031173706054686e-05, 'wall_clock_time': 29.735625982284546, 'metric_for_logging': {'pred_time': 3.7031173706054686e-05}, 'val_loss': 0.13149508374087382, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fa882f8e890>}\n",
      "[flaml.tune.tune: 08-08 07:35:54] {729} INFO - Number of trials: 18/1000000, 1 RUNNING, 17 TERMINATED\n",
      "[flaml.tune.tune: 08-08 07:35:55] {749} INFO - Brief result: {'pred_time': 5.31927744547526e-05, 'wall_clock_time': 30.109346389770508, 'metric_for_logging': {'pred_time': 5.31927744547526e-05}, 'val_loss': 0.16305341345558733, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fa882fc8b80>}\n",
      "[flaml.tune.tune: 08-08 07:35:55] {729} INFO - Number of trials: 19/1000000, 1 RUNNING, 18 TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Time exceeded, canceled jobs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[flaml.automl.logger: 08-08 07:35:55] {2493} INFO - selected model: None\n",
      "[flaml.automl.logger: 08-08 07:35:55] {2627} INFO - retrain rf for 0.0s\n",
      "[flaml.automl.logger: 08-08 07:35:55] {2630} INFO - retrained model: RandomForestClassifier(max_features=0.38633389177321886, max_leaf_nodes=10,\n",
      "                       n_estimators=16, n_jobs=-1, random_state=12032022)\n",
      "[flaml.automl.logger: 08-08 07:35:55] {1930} INFO - fit succeeded\n",
      "[flaml.automl.logger: 08-08 07:35:55] {1931} INFO - Time taken to find the best model: 29.060681343078613\n",
      "Best estimator found: rf\n",
      "Best config found: {'n_estimators': 16, 'max_features': 0.38633389177321886, 'max_leaves': 10, 'criterion': 'gini'}\n",
      "Best validation loss found: 0.13137661858336086\n",
      "ragproxyagent (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "You MUST NOT install any packages because all the packages needed are already installed.\n",
      "None\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to ragproxyagent):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# reset the assistant. Always reset the assistant before starting a new conversation.\n",
    "assistant.reset()\n",
    "\n",
    "# given a problem, we use the ragproxyagent to generate a prompt to be sent to the assistant as the initial message.\n",
    "# the assistant receives the message and generates a response. The response will be sent back to the ragproxyagent for processing.\n",
    "# The conversation continues until the termination condition is met, in RetrieveChat, the termination condition when no human-in-loop is no code block detected.\n",
    "# With human-in-loop, the conversation will continue until the user says \"exit\".\n",
    "code_problem = \"How can I use FLAML to perform a classification task and use spark to do parallel training. Train 30 seconds and force cancel jobs if time limit is reached.\"\n",
    "ragproxyagent.initiate_chat(assistant, problem=code_problem, search_string=\"spark\")  # search_string is used as an extra filter for the embeddings search, in this case, we only want to search documents that contain \"spark\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "Use RetrieveChat to answer a question that is not related to code generation.\n",
    "\n",
    "Problem: Who is the author of FLAML?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_ids:  [['doc_3', 'doc_45', 'doc_29', 'doc_18', 'doc_34', 'doc_14', 'doc_4', 'doc_52', 'doc_20', 'doc_41', 'doc_58', 'doc_46', 'doc_21', 'doc_59', 'doc_54', 'doc_62', 'doc_42', 'doc_15', 'doc_44', 'doc_60']]\n",
      "Adding doc_id doc_3 to context.\n",
      "Adding doc_id doc_45 to context.\n",
      "Adding doc_id doc_29 to context.\n",
      "Adding doc_id doc_18 to context.\n",
      "Adding doc_id doc_34 to context.\n",
      "ragproxyagent (to assistant):\n",
      "\n",
      "You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user. You should follow the following steps to answer a question:\n",
      "Step 1, you estimate the user's intent based on the question and context. The intent can be a code generation task or\n",
      "a QA task.\n",
      "Step 2, you generate code or answer the question based on the intent.\n",
      "You should leverage the context provided by the user as much as possible. If you think the context is not enough, you\n",
      "can reply exactly \"UPDATE CONTEXT\" to ask the user to provide more contexts.\n",
      "For code generation, you must obey the following rules:\n",
      "You MUST NOT install any packages because all the packages needed are already installed.\n",
      "The code will be executed in IPython, you must follow the formats below to write your code:\n",
      "```python\n",
      "# your code\n",
      "```\n",
      "\n",
      "User's question is: Who is the author of FLAML?\n",
      "\n",
      "Context is: ---\n",
      "sidebar_label: estimator\n",
      "title: default.estimator\n",
      "---\n",
      "\n",
      "#### flamlize\\_estimator\n",
      "\n",
      "```python\n",
      "def flamlize_estimator(super_class, name: str, task: str, alternatives=None)\n",
      "```\n",
      "\n",
      "Enhance an estimator class with flaml's data-dependent default hyperparameter settings.\n",
      "\n",
      "**Example**:\n",
      "\n",
      "  \n",
      "```python\n",
      "import sklearn.ensemble as ensemble\n",
      "RandomForestRegressor = flamlize_estimator(\n",
      "    ensemble.RandomForestRegressor, \"rf\", \"regression\"\n",
      ")\n",
      "```\n",
      "  \n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `super_class` - an scikit-learn compatible estimator class.\n",
      "- `name` - a str of the estimator's name.\n",
      "- `task` - a str of the task type.\n",
      "- `alternatives` - (Optional) a list for alternative estimator names. For example,\n",
      "        ```[(\"max_depth\", 0, \"xgboost\")]``` means if the \"max_depth\" is set to 0\n",
      "        in the constructor, then look for the learned defaults for estimator \"xgboost\".\n",
      "\n",
      "\n",
      "---\n",
      "sidebar_label: task\n",
      "title: automl.task.task\n",
      "---\n",
      "\n",
      "## Task Objects\n",
      "\n",
      "```python\n",
      "class Task(ABC)\n",
      "```\n",
      "\n",
      "Abstract base class for a machine learning task.\n",
      "\n",
      "Class definitions should implement abstract methods and provide a non-empty dictionary of estimator classes.\n",
      "A Task can be suitable to be used for multiple machine-learning tasks (e.g. classification or regression) or be\n",
      "implemented specifically for a single one depending on the generality of data validation and model evaluation methods\n",
      "implemented. The implementation of a Task may optionally use the training data and labels to determine data and task\n",
      "specific details, such as in determining if a problem is single-label or multi-label.\n",
      "\n",
      "FLAML evaluates at runtime how to behave exactly, relying on the task instance to provide implementations of\n",
      "operations which vary between tasks.\n",
      "\n",
      "#### \\_\\_init\\_\\_\n",
      "\n",
      "```python\n",
      "def __init__(task_name: str,\n",
      "             X_train: Optional[Union[np.ndarray, DataFrame,\n",
      "                                     psDataFrame]] = None,\n",
      "             y_train: Optional[Union[np.ndarray, DataFrame, Series,\n",
      "                                     psSeries]] = None)\n",
      "```\n",
      "\n",
      "Constructor.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `task_name` - String name for this type of task. Used when the Task can be generic and implement a number of\n",
      "  types of sub-task.\n",
      "- `X_train` - Optional. Some Task types may use the data shape or features to determine details of their usage,\n",
      "  such as in binary vs multilabel classification.\n",
      "- `y_train` - Optional. Some Task types may use the data shape or features to determine details of their usage,\n",
      "  such as in binary vs multilabel classification.\n",
      "\n",
      "#### \\_\\_str\\_\\_\n",
      "\n",
      "```python\n",
      "def __str__() -> str\n",
      "```\n",
      "\n",
      "Name of this task type.\n",
      "\n",
      "#### evaluate\\_model\\_CV\n",
      "\n",
      "```python\n",
      "@abstractmethod\n",
      "def evaluate_model_CV(\n",
      "        config: dict,\n",
      "        estimator: \"flaml.automl.ml.BaseEstimator\",\n",
      "        X_train_all: Union[np.ndarray, DataFrame, psDataFrame],\n",
      "        y_train_all: Union[np.ndarray, DataFrame, Series, psSeries],\n",
      "        budget: int,\n",
      "        kf,\n",
      "        eval_metric: str,\n",
      "        best_val_loss: float,\n",
      "        log_training_metric: bool = False,\n",
      "        fit_kwargs: Optional[dict] = {}) -> Tuple[float, float, float, float]\n",
      "```\n",
      "\n",
      "Evaluate the model using cross-validation.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `config` - configuration used in the evaluation of the metric.\n",
      "- `estimator` - Estimator class of the model.\n",
      "- `X_train_all` - Complete training feature data.\n",
      "- `y_train_all` - Complete training target data.\n",
      "- `budget` - Training time budget.\n",
      "- `kf` - Cross-validation index generator.\n",
      "- `eval_metric` - Metric name to be used for evaluation.\n",
      "- `best_val_loss` - Best current validation-set loss.\n",
      "- `log_training_metric` - Bool defaults False. Enables logging of the training metric.\n",
      "- `fit_kwargs` - Additional kwargs passed to the estimator's fit method.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  validation loss, metric value, train time, prediction time\n",
      "\n",
      "#### validate\\_data\n",
      "\n",
      "```python\n",
      "@abstractmethod\n",
      "def validate_data(automl: \"flaml.automl.automl.AutoML\",\n",
      "                  state: \"flaml.automl.state.AutoMLState\",\n",
      "                  X_train_all: Union[np.ndarray, DataFrame, psDataFrame, None],\n",
      "                  y_train_all: Union[np.ndarray, DataFrame, Series, psSeries,\n",
      "                                     None],\n",
      "                  dataframe: Union[DataFrame, None],\n",
      "                  label: str,\n",
      "                  X_val: Optional[Union[np.ndarray, DataFrame,\n",
      "                                        psDataFrame]] = None,\n",
      "                  y_val: Optional[Union[np.ndarray, DataFrame, Series,\n",
      "                                        psSeries]] = None,\n",
      "                  groups_val: Optional[List[str]] = None,\n",
      "                  groups: Optional[List[str]] = None)\n",
      "```\n",
      "\n",
      "Validate that the data is suitable for this task type.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `automl` - The AutoML instance from which this task has been constructed.\n",
      "- `state` - The AutoMLState instance for this run.\n",
      "- `X_train_all` - The complete data set or None if dataframe is supplied.\n",
      "- `y_train_all` - The complete target set or None if dataframe is supplied.\n",
      "- `dataframe` - A dataframe constaining the complete data set with targets.\n",
      "- `label` - The name of the target column in dataframe.\n",
      "- `X_val` - Optional. A data set for validation.\n",
      "- `y_val` - Optional. A target vector corresponding to X_val for validation.\n",
      "- `groups_val` - Group labels (with matching length to y_val) or group counts (with sum equal to length of y_val)\n",
      "  for validation data. Need to be consistent with groups.\n",
      "- `groups` - Group labels (with matching length to y_train) or groups counts (with sum equal to length of y_train)\n",
      "  for training data.\n",
      "  \n",
      "\n",
      "**Raises**:\n",
      "\n",
      "- `AssertionError` - The data provided is invalid for this task type and configuration.\n",
      "\n",
      "#### prepare\\_data\n",
      "\n",
      "```python\n",
      "@abstractmethod\n",
      "def prepare_data(state: \"flaml.automl.state.AutoMLState\",\n",
      "                 X_train_all: Union[np.ndarray, DataFrame, psDataFrame],\n",
      "                 y_train_all: Union[np.ndarray, DataFrame, Series, psSeries,\n",
      "                                    None],\n",
      "                 auto_augment: bool,\n",
      "                 eval_method: str,\n",
      "                 split_type: str,\n",
      "                 split_ratio: float,\n",
      "                 n_splits: int,\n",
      "                 data_is_df: bool,\n",
      "                 sample_weight_full: Optional[List[float]] = None)\n",
      "```\n",
      "\n",
      "Prepare the data for fitting or inference.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `automl` - The AutoML instance from which this task has been constructed.\n",
      "- `state` - The AutoMLState instance for this run.\n",
      "- `X_train_all` - The complete data set or None if dataframe is supplied. Must\n",
      "  contain the target if y_train_all is None\n",
      "- `y_train_all` - The complete target set or None if supplied in X_train_all.\n",
      "- `auto_augment` - If true, task-specific data augmentations will be applied.\n",
      "- `eval_method` - A string of resampling strategy, one of ['auto', 'cv', 'holdout'].\n",
      "- `split_type` - str or splitter object, default=\"auto\" | the data split type.\n",
      "  * A valid splitter object is an instance of a derived class of scikit-learn\n",
      "  [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold)\n",
      "  and have ``split`` and ``get_n_splits`` methods with the same signatures.\n",
      "  Set eval_method to \"cv\" to use the splitter object.\n",
      "  * Valid str options depend on different tasks.\n",
      "  For classification tasks, valid choices are\n",
      "  [\"auto\", 'stratified', 'uniform', 'time', 'group']. \"auto\" -> stratified.\n",
      "  For regression tasks, valid choices are [\"auto\", 'uniform', 'time'].\n",
      "  \"auto\" -> uniform.\n",
      "  For time series forecast tasks, must be \"auto\" or 'time'.\n",
      "  For ranking task, must be \"auto\" or 'group'.\n",
      "- `split_ratio` - A float of the valiation data percentage for holdout.\n",
      "- `n_splits` - An integer of the number of folds for cross - validation.\n",
      "- `data_is_df` - True if the data was provided as a DataFrame else False.\n",
      "- `sample_weight_full` - A 1d arraylike of the sample weight.\n",
      "  \n",
      "\n",
      "**Raises**:\n",
      "\n",
      "- `AssertionError` - The configuration provided is invalid for this task type and data.\n",
      "\n",
      "#### decide\\_split\\_type\n",
      "\n",
      "```python\n",
      "@abstractmethod\n",
      "def decide_split_type(split_type: str,\n",
      "                      y_train_all: Union[np.ndarray, DataFrame, Series,\n",
      "                                         psSeries, None],\n",
      "                      fit_kwargs: dict,\n",
      "                      groups: Optional[List[str]] = None) -> str\n",
      "```\n",
      "\n",
      "Choose an appropriate data split type for this data and task.\n",
      "\n",
      "If split_type is 'auto' then this is determined based on the task type and data.\n",
      "If a specific split_type is requested then the choice is validated to be appropriate.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `split_type` - Either 'auto' or a task appropriate split type.\n",
      "- `y_train_all` - The complete set of targets.\n",
      "- `fit_kwargs` - Additional kwargs passed to the estimator's fit method.\n",
      "- `groups` - Optional. Group labels (with matching length to y_train) or groups counts (with sum equal to length\n",
      "  of y_train) for training data.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  The determined appropriate split type.\n",
      "  \n",
      "\n",
      "**Raises**:\n",
      "\n",
      "- `AssertionError` - The requested split_type is invalid for this task, configuration and data.\n",
      "\n",
      "#### preprocess\n",
      "\n",
      "```python\n",
      "@abstractmethod\n",
      "def preprocess(\n",
      "    X: Union[np.ndarray, DataFrame, psDataFrame],\n",
      "    transformer: Optional[\"flaml.automl.data.DataTransformer\"] = None\n",
      ") -> Union[np.ndarray, DataFrame]\n",
      "```\n",
      "\n",
      "Preprocess the data ready for fitting or inference with this task type.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `X` - The data set to process.\n",
      "- `transformer` - A DataTransformer instance to be used in processing.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  The preprocessed data set having the same type as the input.\n",
      "\n",
      "#### default\\_estimator\\_list\n",
      "\n",
      "```python\n",
      "@abstractmethod\n",
      "def default_estimator_list(estimator_list: Union[List[str], str] = \"auto\",\n",
      "                           is_spark_dataframe: bool = False) -> List[str]\n",
      "```\n",
      "\n",
      "Return the list of default estimators registered for this task type.\n",
      "\n",
      "new_automl = AutoML()\n",
      "new_automl.fit(X_train, y_train, starting_points=starting_points)\n",
      "```\n",
      "  \n",
      "- `seed` - int or None, default=None | The random seed for hpo.\n",
      "- `n_concurrent_trials` - [Experimental] int, default=1 | The number of\n",
      "  concurrent trials. When n_concurrent_trials > 1, flaml performes\n",
      "  [parallel tuning](../../Use-Cases/Task-Oriented-AutoML#parallel-tuning)\n",
      "  and installation of ray or spark is required: `pip install flaml[ray]`\n",
      "  or `pip install flaml[spark]`. Please check\n",
      "  [here](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
      "  for more details about installing Spark.\n",
      "- `keep_search_state` - boolean, default=False | Whether to keep data needed\n",
      "  for model search after fit(). By default the state is deleted for\n",
      "  space saving.\n",
      "- `preserve_checkpoint` - boolean, default=True | Whether to preserve the saved checkpoint\n",
      "  on disk when deleting automl. By default the checkpoint is preserved.\n",
      "- `early_stop` - boolean, default=False | Whether to stop early if the\n",
      "  search is considered to converge.\n",
      "- `force_cancel` - boolean, default=False | Whether to forcely cancel Spark jobs if the\n",
      "  search time exceeded the time budget.\n",
      "- `append_log` - boolean, default=False | Whetehr to directly append the log\n",
      "  records to the input log file if it exists.\n",
      "- `auto_augment` - boolean, default=True | Whether to automatically\n",
      "  augment rare classes.\n",
      "- `min_sample_size` - int, default=MIN_SAMPLE_TRAIN | the minimal sample\n",
      "  size when sample=True.\n",
      "- `use_ray` - boolean or dict.\n",
      "  If boolean: default=False | Whether to use ray to run the training\n",
      "  in separate processes. This can be used to prevent OOM for large\n",
      "  datasets, but will incur more overhead in time.\n",
      "  If dict: the dict contains the keywords arguments to be passed to\n",
      "  [ray.tune.run](https://docs.ray.io/en/latest/tune/api_docs/execution.html).\n",
      "- `use_spark` - boolean, default=False | Whether to use spark to run the training\n",
      "  in parallel spark jobs. This can be used to accelerate training on large models\n",
      "  and large datasets, but will incur more overhead in time and thus slow down\n",
      "  training in some cases. GPU training is not supported yet when use_spark is True.\n",
      "  For Spark clusters, by default, we will launch one trial per executor. However,\n",
      "  sometimes we want to launch more trials than the number of executors (e.g., local mode).\n",
      "  In this case, we can set the environment variable `FLAML_MAX_CONCURRENT` to override\n",
      "  the detected `num_executors`. The final number of concurrent trials will be the minimum\n",
      "  of `n_concurrent_trials` and `num_executors`.\n",
      "- `free_mem_ratio` - float between 0 and 1, default=0. The free memory ratio to keep during training.\n",
      "- `metric_constraints` - list, default=[] | The list of metric constraints.\n",
      "  Each element in this list is a 3-tuple, which shall be expressed\n",
      "  in the following format: the first element of the 3-tuple is the name of the\n",
      "  metric, the second element is the inequality sign chosen from \">=\" and \"<=\",\n",
      "  and the third element is the constraint value. E.g., `('val_loss', '<=', 0.1)`.\n",
      "  Note that all the metric names in metric_constraints need to be reported via\n",
      "  the metrics_to_log dictionary returned by a customized metric function.\n",
      "  The customized metric function shall be provided via the `metric` key word\n",
      "  argument of the fit() function or the automl constructor.\n",
      "  Find an example in the 4th constraint type in this [doc](../../Use-Cases/Task-Oriented-AutoML#constraint).\n",
      "  If `pred_time_limit` is provided as one of keyword arguments to fit() function or\n",
      "  the automl constructor, flaml will automatically (and under the hood)\n",
      "  add it as an additional element in the metric_constraints. Essentially 'pred_time_limit'\n",
      "  specifies a constraint about the prediction latency constraint in seconds.\n",
      "- `custom_hp` - dict, default=None | The custom search space specified by user.\n",
      "  It is a nested dict with keys being the estimator names, and values being dicts\n",
      "  per estimator search space. In the per estimator search space dict,\n",
      "  the keys are the hyperparameter names, and values are dicts of info (\"domain\",\n",
      "  \"init_value\", and \"low_cost_init_value\") about the search space associated with\n",
      "  the hyperparameter (i.e., per hyperparameter search space dict). When custom_hp\n",
      "  is provided, the built-in search space which is also a nested dict of per estimator\n",
      "  search space dict, will be updated with custom_hp. Note that during this nested dict update,\n",
      "  the per hyperparameter search space dicts will be replaced (instead of updated) by the ones\n",
      "  provided in custom_hp. Note that the value for \"domain\" can either be a constant\n",
      "  or a sample.Domain object.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "custom_hp = {\n",
      "     \"transformer_ms\": {\n",
      "         \"model_path\": {\n",
      "             \"domain\": \"albert-base-v2\",\n",
      "         },\n",
      "         \"learning_rate\": {\n",
      "             \"domain\": tune.choice([1e-4, 1e-5]),\n",
      "         }\n",
      "     }\n",
      " }\n",
      "```\n",
      "- `skip_transform` - boolean, default=False | Whether to pre-process data prior to modeling.\n",
      "- `fit_kwargs_by_estimator` - dict, default=None | The user specified keywords arguments, grouped by estimator name.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "fit_kwargs_by_estimator = {\n",
      "    \"transformer\": {\n",
      "        \"output_dir\": \"test/data/output/\",\n",
      "        \"fp16\": False,\n",
      "    }\n",
      "}\n",
      "```\n",
      "- `mlflow_logging` - boolean, default=True | Whether to log the training results to mlflow.\n",
      "  This requires mlflow to be installed and to have an active mlflow run.\n",
      "  FLAML will create nested runs.\n",
      "\n",
      "#### config\\_history\n",
      "\n",
      "```python\n",
      "@property\n",
      "def config_history() -> dict\n",
      "```\n",
      "\n",
      "A dictionary of iter->(estimator, config, time),\n",
      "storing the best estimator, config, and the time when the best\n",
      "model is updated each time.\n",
      "\n",
      "#### model\n",
      "\n",
      "```python\n",
      "@property\n",
      "def model()\n",
      "```\n",
      "\n",
      "An object with `predict()` and `predict_proba()` method (for\n",
      "classification), storing the best trained model.\n",
      "\n",
      "#### best\\_model\\_for\\_estimator\n",
      "\n",
      "```python\n",
      "def best_model_for_estimator(estimator_name: str)\n",
      "```\n",
      "\n",
      "Return the best model found for a particular estimator.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `estimator_name` - a str of the estimator's name.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  An object storing the best model for estimator_name.\n",
      "  If `model_history` was set to False during fit(), then the returned model\n",
      "  is untrained unless estimator_name is the best estimator.\n",
      "  If `model_history` was set to True, then the returned model is trained.\n",
      "\n",
      "#### best\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_estimator()\n",
      "```\n",
      "\n",
      "A string indicating the best estimator found.\n",
      "\n",
      "#### best\\_iteration\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_iteration()\n",
      "```\n",
      "\n",
      "An integer of the iteration number where the best\n",
      "config is found.\n",
      "\n",
      "#### best\\_config\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config()\n",
      "```\n",
      "\n",
      "A dictionary of the best configuration.\n",
      "\n",
      "#### best\\_config\\_per\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config_per_estimator()\n",
      "```\n",
      "\n",
      "A dictionary of all estimators' best configuration.\n",
      "\n",
      "#### best\\_loss\\_per\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_loss_per_estimator()\n",
      "```\n",
      "\n",
      "A dictionary of all estimators' best loss.\n",
      "\n",
      "#### best\\_loss\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_loss()\n",
      "```\n",
      "\n",
      "A float of the best loss found.\n",
      "\n",
      "#### best\\_result\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_result()\n",
      "```\n",
      "\n",
      "Result dictionary for model trained with the best config.\n",
      "\n",
      "#### metrics\\_for\\_best\\_config\n",
      "\n",
      "```python\n",
      "@property\n",
      "def metrics_for_best_config()\n",
      "```\n",
      "\n",
      "Returns a float of the best loss, and a dictionary of the auxiliary metrics to log\n",
      "associated with the best config. These two objects correspond to the returned\n",
      "objects by the customized metric function for the config with the best loss.\n",
      "\n",
      "#### best\\_config\\_train\\_time\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config_train_time()\n",
      "```\n",
      "---\n",
      "sidebar_label: cfo_cat\n",
      "title: tune.searcher.cfo_cat\n",
      "---\n",
      "\n",
      "## FLOW2Cat Objects\n",
      "\n",
      "```python\n",
      "class FLOW2Cat(FLOW2)\n",
      "```\n",
      "\n",
      "Local search algorithm optimized for categorical variables.\n",
      "\n",
      "## CFOCat Objects\n",
      "\n",
      "```python\n",
      "class CFOCat(CFO)\n",
      "```\n",
      "\n",
      "CFO optimized for categorical variables.\n",
      "\n",
      "\n",
      "\n",
      "new_automl = AutoML()\n",
      "new_automl.fit(X_train, y_train, starting_points=starting_points)\n",
      "```\n",
      "  \n",
      "- `seed` - int or None, default=None | The random seed for hpo.\n",
      "- `n_concurrent_trials` - [Experimental] int, default=1 | The number of\n",
      "  concurrent trials. When n_concurrent_trials > 1, flaml performes\n",
      "  [parallel tuning](../../Use-Cases/Task-Oriented-AutoML#parallel-tuning)\n",
      "  and installation of ray or spark is required: `pip install flaml[ray]`\n",
      "  or `pip install flaml[spark]`. Please check\n",
      "  [here](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
      "  for more details about installing Spark.\n",
      "- `keep_search_state` - boolean, default=False | Whether to keep data needed\n",
      "  for model search after fit(). By default the state is deleted for\n",
      "  space saving.\n",
      "- `preserve_checkpoint` - boolean, default=True | Whether to preserve the saved checkpoint\n",
      "  on disk when deleting automl. By default the checkpoint is preserved.\n",
      "- `early_stop` - boolean, default=False | Whether to stop early if the\n",
      "  search is considered to converge.\n",
      "- `force_cancel` - boolean, default=False | Whether to forcely cancel the PySpark job if overtime.\n",
      "- `append_log` - boolean, default=False | Whetehr to directly append the log\n",
      "  records to the input log file if it exists.\n",
      "- `auto_augment` - boolean, default=True | Whether to automatically\n",
      "  augment rare classes.\n",
      "- `min_sample_size` - int, default=MIN_SAMPLE_TRAIN | the minimal sample\n",
      "  size when sample=True.\n",
      "- `use_ray` - boolean or dict.\n",
      "  If boolean: default=False | Whether to use ray to run the training\n",
      "  in separate processes. This can be used to prevent OOM for large\n",
      "  datasets, but will incur more overhead in time.\n",
      "  If dict: the dict contains the keywords arguments to be passed to\n",
      "  [ray.tune.run](https://docs.ray.io/en/latest/tune/api_docs/execution.html).\n",
      "- `use_spark` - boolean, default=False | Whether to use spark to run the training\n",
      "  in parallel spark jobs. This can be used to accelerate training on large models\n",
      "  and large datasets, but will incur more overhead in time and thus slow down\n",
      "  training in some cases.\n",
      "- `free_mem_ratio` - float between 0 and 1, default=0. The free memory ratio to keep during training.\n",
      "- `metric_constraints` - list, default=[] | The list of metric constraints.\n",
      "  Each element in this list is a 3-tuple, which shall be expressed\n",
      "  in the following format: the first element of the 3-tuple is the name of the\n",
      "  metric, the second element is the inequality sign chosen from \">=\" and \"<=\",\n",
      "  and the third element is the constraint value. E.g., `('precision', '>=', 0.9)`.\n",
      "  Note that all the metric names in metric_constraints need to be reported via\n",
      "  the metrics_to_log dictionary returned by a customized metric function.\n",
      "  The customized metric function shall be provided via the `metric` key word argument\n",
      "  of the fit() function or the automl constructor.\n",
      "  Find examples in this [test](https://github.com/microsoft/FLAML/tree/main/test/automl/test_constraints.py).\n",
      "  If `pred_time_limit` is provided as one of keyword arguments to fit() function or\n",
      "  the automl constructor, flaml will automatically (and under the hood)\n",
      "  add it as an additional element in the metric_constraints. Essentially 'pred_time_limit'\n",
      "  specifies a constraint about the prediction latency constraint in seconds.\n",
      "- `custom_hp` - dict, default=None | The custom search space specified by user\n",
      "  Each key is the estimator name, each value is a dict of the custom search space for that estimator. Notice the\n",
      "  domain of the custom search space can either be a value of a sample.Domain object.\n",
      "  \n",
      "  \n",
      "  \n",
      "```python\n",
      "custom_hp = {\n",
      "    \"transformer_ms\": {\n",
      "        \"model_path\": {\n",
      "            \"domain\": \"albert-base-v2\",\n",
      "        },\n",
      "        \"learning_rate\": {\n",
      "            \"domain\": tune.choice([1e-4, 1e-5]),\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "- `time_col` - for a time series task, name of the column containing the timestamps. If not\n",
      "  provided, defaults to the first column of X_train/X_val\n",
      "  \n",
      "- `cv_score_agg_func` - customized cross-validation scores aggregate function. Default to average metrics across folds. If specificed, this function needs to\n",
      "  have the following input arguments:\n",
      "  \n",
      "  * val_loss_folds: list of floats, the loss scores of each fold;\n",
      "  * log_metrics_folds: list of dicts/floats, the metrics of each fold to log.\n",
      "  \n",
      "  This function should return the final aggregate result of all folds. A float number of the minimization objective, and a dictionary as the metrics to log or None.\n",
      "  E.g.,\n",
      "  \n",
      "```python\n",
      "def cv_score_agg_func(val_loss_folds, log_metrics_folds):\n",
      "    metric_to_minimize = sum(val_loss_folds)/len(val_loss_folds)\n",
      "    metrics_to_log = None\n",
      "    for single_fold in log_metrics_folds:\n",
      "        if metrics_to_log is None:\n",
      "            metrics_to_log = single_fold\n",
      "        elif isinstance(metrics_to_log, dict):\n",
      "            metrics_to_log = {k: metrics_to_log[k] + v for k, v in single_fold.items()}\n",
      "        else:\n",
      "            metrics_to_log += single_fold\n",
      "    if metrics_to_log:\n",
      "        n = len(val_loss_folds)\n",
      "        metrics_to_log = (\n",
      "            {k: v / n for k, v in metrics_to_log.items()}\n",
      "            if isinstance(metrics_to_log, dict)\n",
      "            else metrics_to_log / n\n",
      "        )\n",
      "    return metric_to_minimize, metrics_to_log\n",
      "```\n",
      "  \n",
      "- `skip_transform` - boolean, default=False | Whether to pre-process data prior to modeling.\n",
      "- `mlflow_logging` - boolean, default=None | Whether to log the training results to mlflow.\n",
      "  Default value is None, which means the logging decision is made based on\n",
      "  AutoML.__init__'s mlflow_logging argument.\n",
      "  This requires mlflow to be installed and to have an active mlflow run.\n",
      "  FLAML will create nested runs.\n",
      "- `fit_kwargs_by_estimator` - dict, default=None | The user specified keywords arguments, grouped by estimator name.\n",
      "  For TransformersEstimator, available fit_kwargs can be found from\n",
      "  [TrainingArgumentsForAuto](nlp/huggingface/training_args).\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "fit_kwargs_by_estimator = {\n",
      "    \"transformer\": {\n",
      "        \"output_dir\": \"test/data/output/\",\n",
      "        \"fp16\": False,\n",
      "    },\n",
      "    \"tft\": {\n",
      "        \"max_encoder_length\": 1,\n",
      "        \"min_encoder_length\": 1,\n",
      "        \"static_categoricals\": [],\n",
      "        \"static_reals\": [],\n",
      "        \"time_varying_known_categoricals\": [],\n",
      "        \"time_varying_known_reals\": [],\n",
      "        \"time_varying_unknown_categoricals\": [],\n",
      "        \"time_varying_unknown_reals\": [],\n",
      "        \"variable_groups\": {},\n",
      "        \"lags\": {},\n",
      "    }\n",
      "}\n",
      "```\n",
      "  \n",
      "- `**fit_kwargs` - Other key word arguments to pass to fit() function of\n",
      "  the searched learners, such as sample_weight. Below are a few examples of\n",
      "  estimator-specific parameters:\n",
      "- `period` - int | forecast horizon for all time series forecast tasks.\n",
      "- `gpu_per_trial` - float, default = 0 | A float of the number of gpus per trial,\n",
      "  only used by TransformersEstimator, XGBoostSklearnEstimator, and\n",
      "  TemporalFusionTransformerEstimator.\n",
      "- `group_ids` - list of strings of column names identifying a time series, only\n",
      "  used by TemporalFusionTransformerEstimator, required for\n",
      "  'ts_forecast_panel' task. `group_ids` is a parameter for TimeSeriesDataSet object\n",
      "  from PyTorchForecasting.\n",
      "  For other parameters to describe your dataset, refer to\n",
      "  [TimeSeriesDataSet PyTorchForecasting](https://pytorch-forecasting.readthedocs.io/en/stable/api/pytorch_forecasting.data.timeseries.TimeSeriesDataSet.html).\n",
      "  To specify your variables, use `static_categoricals`, `static_reals`,\n",
      "  `time_varying_known_categoricals`, `time_varying_known_reals`,\n",
      "  `time_varying_unknown_categoricals`, `time_varying_unknown_reals`,\n",
      "  `variable_groups`. To provide more information on your data, use\n",
      "  `max_encoder_length`, `min_encoder_length`, `lags`.\n",
      "- `log_dir` - str, default = \"lightning_logs\" | Folder into which to log results\n",
      "  for tensorboard, only used by TemporalFusionTransformerEstimator.\n",
      "- `max_epochs` - int, default = 20 | Maximum number of epochs to run training,\n",
      "  only used by TemporalFusionTransformerEstimator.\n",
      "- `batch_size` - int, default = 64 | Batch size for training model, only\n",
      "  used by TemporalFusionTransformerEstimator.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user. You should follow the following steps to answer a question:\n",
      "Step 1, you estimate the user's intent based on the question and context. The intent can be a code generation task or\n",
      "a QA task.\n",
      "Step 2, you generate code or answer the question based on the intent.\n",
      "You should leverage the context provided by the user as much as possible. If you think the context is not enough, you\n",
      "can reply exactly \"UPDATE CONTEXT\" to ask the user to provide more contexts.\n",
      "For code generation, you must obey the following rules:\n",
      "You MUST NOT install any packages because all the packages needed are already installed.\n",
      "The code will be executed in IPython, you must follow the formats below to write your code:\n",
      "```python\n",
      "# your code\n",
      "```\n",
      "\n",
      "User's question is: Who is the author of FLAML?\n",
      "\n",
      "Context is: ---\n",
      "sidebar_label: estimator\n",
      "title: default.estimator\n",
      "---\n",
      "\n",
      "#### flamlize\\_estimator\n",
      "\n",
      "```python\n",
      "def flamlize_estimator(super_class, name: str, task: str, alternatives=None)\n",
      "```\n",
      "\n",
      "Enhance an estimator class with flaml's data-dependent default hyperparameter settings.\n",
      "\n",
      "**Example**:\n",
      "\n",
      "  \n",
      "```python\n",
      "import sklearn.ensemble as ensemble\n",
      "RandomForestRegressor = flamlize_estimator(\n",
      "    ensemble.RandomForestRegressor, \"rf\", \"regression\"\n",
      ")\n",
      "```\n",
      "  \n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `super_class` - an scikit-learn compatible estimator class.\n",
      "- `name` - a str of the estimator's name.\n",
      "- `task` - a str of the task type.\n",
      "- `alternatives` - (Optional) a list for alternative estimator names. For example,\n",
      "        ```[(\"max_depth\", 0, \"xgboost\")]``` means if the \"max_depth\" is set to 0\n",
      "        in the constructor, then look for the learned defaults for estimator \"xgboost\".\n",
      "\n",
      "\n",
      "---\n",
      "sidebar_label: task\n",
      "title: automl.task.task\n",
      "---\n",
      "\n",
      "## Task Objects\n",
      "\n",
      "```python\n",
      "class Task(ABC)\n",
      "```\n",
      "\n",
      "Abstract base class for a machine learning task.\n",
      "\n",
      "Class definitions should implement abstract methods and provide a non-empty dictionary of estimator classes.\n",
      "A Task can be suitable to be used for multiple machine-learning tasks (e.g. classification or regression) or be\n",
      "implemented specifically for a single one depending on the generality of data validation and model evaluation methods\n",
      "implemented. The implementation of a Task may optionally use the training data and labels to determine data and task\n",
      "specific details, such as in determining if a problem is single-label or multi-label.\n",
      "\n",
      "FLAML evaluates at runtime how to behave exactly, relying on the task instance to provide implementations of\n",
      "operations which vary between tasks.\n",
      "\n",
      "#### \\_\\_init\\_\\_\n",
      "\n",
      "```python\n",
      "def __init__(task_name: str,\n",
      "             X_train: Optional[Union[np.ndarray, DataFrame,\n",
      "                                     psDataFrame]] = None,\n",
      "             y_train: Optional[Union[np.ndarray, DataFrame, Series,\n",
      "                                     psSeries]] = None)\n",
      "```\n",
      "\n",
      "Constructor.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `task_name` - String name for this type of task. Used when the Task can be generic and implement a number of\n",
      "  types of sub-task.\n",
      "- `X_train` - Optional. Some Task types may use the data shape or features to determine details of their usage,\n",
      "  such as in binary vs multilabel classification.\n",
      "- `y_train` - Optional. Some Task types may use the data shape or features to determine details of their usage,\n",
      "  such as in binary vs multilabel classification.\n",
      "\n",
      "#### \\_\\_str\\_\\_\n",
      "\n",
      "```python\n",
      "def __str__() -> str\n",
      "```\n",
      "\n",
      "Name of this task type.\n",
      "\n",
      "#### evaluate\\_model\\_CV\n",
      "\n",
      "```python\n",
      "@abstractmethod\n",
      "def evaluate_model_CV(\n",
      "        config: dict,\n",
      "        estimator: \"flaml.automl.ml.BaseEstimator\",\n",
      "        X_train_all: Union[np.ndarray, DataFrame, psDataFrame],\n",
      "        y_train_all: Union[np.ndarray, DataFrame, Series, psSeries],\n",
      "        budget: int,\n",
      "        kf,\n",
      "        eval_metric: str,\n",
      "        best_val_loss: float,\n",
      "        log_training_metric: bool = False,\n",
      "        fit_kwargs: Optional[dict] = {}) -> Tuple[float, float, float, float]\n",
      "```\n",
      "\n",
      "Evaluate the model using cross-validation.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `config` - configuration used in the evaluation of the metric.\n",
      "- `estimator` - Estimator class of the model.\n",
      "- `X_train_all` - Complete training feature data.\n",
      "- `y_train_all` - Complete training target data.\n",
      "- `budget` - Training time budget.\n",
      "- `kf` - Cross-validation index generator.\n",
      "- `eval_metric` - Metric name to be used for evaluation.\n",
      "- `best_val_loss` - Best current validation-set loss.\n",
      "- `log_training_metric` - Bool defaults False. Enables logging of the training metric.\n",
      "- `fit_kwargs` - Additional kwargs passed to the estimator's fit method.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  validation loss, metric value, train time, prediction time\n",
      "\n",
      "#### validate\\_data\n",
      "\n",
      "```python\n",
      "@abstractmethod\n",
      "def validate_data(automl: \"flaml.automl.automl.AutoML\",\n",
      "                  state: \"flaml.automl.state.AutoMLState\",\n",
      "                  X_train_all: Union[np.ndarray, DataFrame, psDataFrame, None],\n",
      "                  y_train_all: Union[np.ndarray, DataFrame, Series, psSeries,\n",
      "                                     None],\n",
      "                  dataframe: Union[DataFrame, None],\n",
      "                  label: str,\n",
      "                  X_val: Optional[Union[np.ndarray, DataFrame,\n",
      "                                        psDataFrame]] = None,\n",
      "                  y_val: Optional[Union[np.ndarray, DataFrame, Series,\n",
      "                                        psSeries]] = None,\n",
      "                  groups_val: Optional[List[str]] = None,\n",
      "                  groups: Optional[List[str]] = None)\n",
      "```\n",
      "\n",
      "Validate that the data is suitable for this task type.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `automl` - The AutoML instance from which this task has been constructed.\n",
      "- `state` - The AutoMLState instance for this run.\n",
      "- `X_train_all` - The complete data set or None if dataframe is supplied.\n",
      "- `y_train_all` - The complete target set or None if dataframe is supplied.\n",
      "- `dataframe` - A dataframe constaining the complete data set with targets.\n",
      "- `label` - The name of the target column in dataframe.\n",
      "- `X_val` - Optional. A data set for validation.\n",
      "- `y_val` - Optional. A target vector corresponding to X_val for validation.\n",
      "- `groups_val` - Group labels (with matching length to y_val) or group counts (with sum equal to length of y_val)\n",
      "  for validation data. Need to be consistent with groups.\n",
      "- `groups` - Group labels (with matching length to y_train) or groups counts (with sum equal to length of y_train)\n",
      "  for training data.\n",
      "  \n",
      "\n",
      "**Raises**:\n",
      "\n",
      "- `AssertionError` - The data provided is invalid for this task type and configuration.\n",
      "\n",
      "#### prepare\\_data\n",
      "\n",
      "```python\n",
      "@abstractmethod\n",
      "def prepare_data(state: \"flaml.automl.state.AutoMLState\",\n",
      "                 X_train_all: Union[np.ndarray, DataFrame, psDataFrame],\n",
      "                 y_train_all: Union[np.ndarray, DataFrame, Series, psSeries,\n",
      "                                    None],\n",
      "                 auto_augment: bool,\n",
      "                 eval_method: str,\n",
      "                 split_type: str,\n",
      "                 split_ratio: float,\n",
      "                 n_splits: int,\n",
      "                 data_is_df: bool,\n",
      "                 sample_weight_full: Optional[List[float]] = None)\n",
      "```\n",
      "\n",
      "Prepare the data for fitting or inference.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `automl` - The AutoML instance from which this task has been constructed.\n",
      "- `state` - The AutoMLState instance for this run.\n",
      "- `X_train_all` - The complete data set or None if dataframe is supplied. Must\n",
      "  contain the target if y_train_all is None\n",
      "- `y_train_all` - The complete target set or None if supplied in X_train_all.\n",
      "- `auto_augment` - If true, task-specific data augmentations will be applied.\n",
      "- `eval_method` - A string of resampling strategy, one of ['auto', 'cv', 'holdout'].\n",
      "- `split_type` - str or splitter object, default=\"auto\" | the data split type.\n",
      "  * A valid splitter object is an instance of a derived class of scikit-learn\n",
      "  [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold)\n",
      "  and have ``split`` and ``get_n_splits`` methods with the same signatures.\n",
      "  Set eval_method to \"cv\" to use the splitter object.\n",
      "  * Valid str options depend on different tasks.\n",
      "  For classification tasks, valid choices are\n",
      "  [\"auto\", 'stratified', 'uniform', 'time', 'group']. \"auto\" -> stratified.\n",
      "  For regression tasks, valid choices are [\"auto\", 'uniform', 'time'].\n",
      "  \"auto\" -> uniform.\n",
      "  For time series forecast tasks, must be \"auto\" or 'time'.\n",
      "  For ranking task, must be \"auto\" or 'group'.\n",
      "- `split_ratio` - A float of the valiation data percentage for holdout.\n",
      "- `n_splits` - An integer of the number of folds for cross - validation.\n",
      "- `data_is_df` - True if the data was provided as a DataFrame else False.\n",
      "- `sample_weight_full` - A 1d arraylike of the sample weight.\n",
      "  \n",
      "\n",
      "**Raises**:\n",
      "\n",
      "- `AssertionError` - The configuration provided is invalid for this task type and data.\n",
      "\n",
      "#### decide\\_split\\_type\n",
      "\n",
      "```python\n",
      "@abstractmethod\n",
      "def decide_split_type(split_type: str,\n",
      "                      y_train_all: Union[np.ndarray, DataFrame, Series,\n",
      "                                         psSeries, None],\n",
      "                      fit_kwargs: dict,\n",
      "                      groups: Optional[List[str]] = None) -> str\n",
      "```\n",
      "\n",
      "Choose an appropriate data split type for this data and task.\n",
      "\n",
      "If split_type is 'auto' then this is determined based on the task type and data.\n",
      "If a specific split_type is requested then the choice is validated to be appropriate.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `split_type` - Either 'auto' or a task appropriate split type.\n",
      "- `y_train_all` - The complete set of targets.\n",
      "- `fit_kwargs` - Additional kwargs passed to the estimator's fit method.\n",
      "- `groups` - Optional. Group labels (with matching length to y_train) or groups counts (with sum equal to length\n",
      "  of y_train) for training data.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  The determined appropriate split type.\n",
      "  \n",
      "\n",
      "**Raises**:\n",
      "\n",
      "- `AssertionError` - The requested split_type is invalid for this task, configuration and data.\n",
      "\n",
      "#### preprocess\n",
      "\n",
      "```python\n",
      "@abstractmethod\n",
      "def preprocess(\n",
      "    X: Union[np.ndarray, DataFrame, psDataFrame],\n",
      "    transformer: Optional[\"flaml.automl.data.DataTransformer\"] = None\n",
      ") -> Union[np.ndarray, DataFrame]\n",
      "```\n",
      "\n",
      "Preprocess the data ready for fitting or inference with this task type.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `X` - The data set to process.\n",
      "- `transformer` - A DataTransformer instance to be used in processing.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  The preprocessed data set having the same type as the input.\n",
      "\n",
      "#### default\\_estimator\\_list\n",
      "\n",
      "```python\n",
      "@abstractmethod\n",
      "def default_estimator_list(estimator_list: Union[List[str], str] = \"auto\",\n",
      "                           is_spark_dataframe: bool = False) -> List[str]\n",
      "```\n",
      "\n",
      "Return the list of default estimators registered for this task type.\n",
      "\n",
      "new_automl = AutoML()\n",
      "new_automl.fit(X_train, y_train, starting_points=starting_points)\n",
      "```\n",
      "  \n",
      "- `seed` - int or None, default=None | The random seed for hpo.\n",
      "- `n_concurrent_trials` - [Experimental] int, default=1 | The number of\n",
      "  concurrent trials. When n_concurrent_trials > 1, flaml performes\n",
      "  [parallel tuning](../../Use-Cases/Task-Oriented-AutoML#parallel-tuning)\n",
      "  and installation of ray or spark is required: `pip install flaml[ray]`\n",
      "  or `pip install flaml[spark]`. Please check\n",
      "  [here](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
      "  for more details about installing Spark.\n",
      "- `keep_search_state` - boolean, default=False | Whether to keep data needed\n",
      "  for model search after fit(). By default the state is deleted for\n",
      "  space saving.\n",
      "- `preserve_checkpoint` - boolean, default=True | Whether to preserve the saved checkpoint\n",
      "  on disk when deleting automl. By default the checkpoint is preserved.\n",
      "- `early_stop` - boolean, default=False | Whether to stop early if the\n",
      "  search is considered to converge.\n",
      "- `force_cancel` - boolean, default=False | Whether to forcely cancel Spark jobs if the\n",
      "  search time exceeded the time budget.\n",
      "- `append_log` - boolean, default=False | Whetehr to directly append the log\n",
      "  records to the input log file if it exists.\n",
      "- `auto_augment` - boolean, default=True | Whether to automatically\n",
      "  augment rare classes.\n",
      "- `min_sample_size` - int, default=MIN_SAMPLE_TRAIN | the minimal sample\n",
      "  size when sample=True.\n",
      "- `use_ray` - boolean or dict.\n",
      "  If boolean: default=False | Whether to use ray to run the training\n",
      "  in separate processes. This can be used to prevent OOM for large\n",
      "  datasets, but will incur more overhead in time.\n",
      "  If dict: the dict contains the keywords arguments to be passed to\n",
      "  [ray.tune.run](https://docs.ray.io/en/latest/tune/api_docs/execution.html).\n",
      "- `use_spark` - boolean, default=False | Whether to use spark to run the training\n",
      "  in parallel spark jobs. This can be used to accelerate training on large models\n",
      "  and large datasets, but will incur more overhead in time and thus slow down\n",
      "  training in some cases. GPU training is not supported yet when use_spark is True.\n",
      "  For Spark clusters, by default, we will launch one trial per executor. However,\n",
      "  sometimes we want to launch more trials than the number of executors (e.g., local mode).\n",
      "  In this case, we can set the environment variable `FLAML_MAX_CONCURRENT` to override\n",
      "  the detected `num_executors`. The final number of concurrent trials will be the minimum\n",
      "  of `n_concurrent_trials` and `num_executors`.\n",
      "- `free_mem_ratio` - float between 0 and 1, default=0. The free memory ratio to keep during training.\n",
      "- `metric_constraints` - list, default=[] | The list of metric constraints.\n",
      "  Each element in this list is a 3-tuple, which shall be expressed\n",
      "  in the following format: the first element of the 3-tuple is the name of the\n",
      "  metric, the second element is the inequality sign chosen from \">=\" and \"<=\",\n",
      "  and the third element is the constraint value. E.g., `('val_loss', '<=', 0.1)`.\n",
      "  Note that all the metric names in metric_constraints need to be reported via\n",
      "  the metrics_to_log dictionary returned by a customized metric function.\n",
      "  The customized metric function shall be provided via the `metric` key word\n",
      "  argument of the fit() function or the automl constructor.\n",
      "  Find an example in the 4th constraint type in this [doc](../../Use-Cases/Task-Oriented-AutoML#constraint).\n",
      "  If `pred_time_limit` is provided as one of keyword arguments to fit() function or\n",
      "  the automl constructor, flaml will automatically (and under the hood)\n",
      "  add it as an additional element in the metric_constraints. Essentially 'pred_time_limit'\n",
      "  specifies a constraint about the prediction latency constraint in seconds.\n",
      "- `custom_hp` - dict, default=None | The custom search space specified by user.\n",
      "  It is a nested dict with keys being the estimator names, and values being dicts\n",
      "  per estimator search space. In the per estimator search space dict,\n",
      "  the keys are the hyperparameter names, and values are dicts of info (\"domain\",\n",
      "  \"init_value\", and \"low_cost_init_value\") about the search space associated with\n",
      "  the hyperparameter (i.e., per hyperparameter search space dict). When custom_hp\n",
      "  is provided, the built-in search space which is also a nested dict of per estimator\n",
      "  search space dict, will be updated with custom_hp. Note that during this nested dict update,\n",
      "  the per hyperparameter search space dicts will be replaced (instead of updated) by the ones\n",
      "  provided in custom_hp. Note that the value for \"domain\" can either be a constant\n",
      "  or a sample.Domain object.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "custom_hp = {\n",
      "     \"transformer_ms\": {\n",
      "         \"model_path\": {\n",
      "             \"domain\": \"albert-base-v2\",\n",
      "         },\n",
      "         \"learning_rate\": {\n",
      "             \"domain\": tune.choice([1e-4, 1e-5]),\n",
      "         }\n",
      "     }\n",
      " }\n",
      "```\n",
      "- `skip_transform` - boolean, default=False | Whether to pre-process data prior to modeling.\n",
      "- `fit_kwargs_by_estimator` - dict, default=None | The user specified keywords arguments, grouped by estimator name.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "fit_kwargs_by_estimator = {\n",
      "    \"transformer\": {\n",
      "        \"output_dir\": \"test/data/output/\",\n",
      "        \"fp16\": False,\n",
      "    }\n",
      "}\n",
      "```\n",
      "- `mlflow_logging` - boolean, default=True | Whether to log the training results to mlflow.\n",
      "  This requires mlflow to be installed and to have an active mlflow run.\n",
      "  FLAML will create nested runs.\n",
      "\n",
      "#### config\\_history\n",
      "\n",
      "```python\n",
      "@property\n",
      "def config_history() -> dict\n",
      "```\n",
      "\n",
      "A dictionary of iter->(estimator, config, time),\n",
      "storing the best estimator, config, and the time when the best\n",
      "model is updated each time.\n",
      "\n",
      "#### model\n",
      "\n",
      "```python\n",
      "@property\n",
      "def model()\n",
      "```\n",
      "\n",
      "An object with `predict()` and `predict_proba()` method (for\n",
      "classification), storing the best trained model.\n",
      "\n",
      "#### best\\_model\\_for\\_estimator\n",
      "\n",
      "```python\n",
      "def best_model_for_estimator(estimator_name: str)\n",
      "```\n",
      "\n",
      "Return the best model found for a particular estimator.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `estimator_name` - a str of the estimator's name.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  An object storing the best model for estimator_name.\n",
      "  If `model_history` was set to False during fit(), then the returned model\n",
      "  is untrained unless estimator_name is the best estimator.\n",
      "  If `model_history` was set to True, then the returned model is trained.\n",
      "\n",
      "#### best\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_estimator()\n",
      "```\n",
      "\n",
      "A string indicating the best estimator found.\n",
      "\n",
      "#### best\\_iteration\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_iteration()\n",
      "```\n",
      "\n",
      "An integer of the iteration number where the best\n",
      "config is found.\n",
      "\n",
      "#### best\\_config\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config()\n",
      "```\n",
      "\n",
      "A dictionary of the best configuration.\n",
      "\n",
      "#### best\\_config\\_per\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config_per_estimator()\n",
      "```\n",
      "\n",
      "A dictionary of all estimators' best configuration.\n",
      "\n",
      "#### best\\_loss\\_per\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_loss_per_estimator()\n",
      "```\n",
      "\n",
      "A dictionary of all estimators' best loss.\n",
      "\n",
      "#### best\\_loss\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_loss()\n",
      "```\n",
      "\n",
      "A float of the best loss found.\n",
      "\n",
      "#### best\\_result\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_result()\n",
      "```\n",
      "\n",
      "Result dictionary for model trained with the best config.\n",
      "\n",
      "#### metrics\\_for\\_best\\_config\n",
      "\n",
      "```python\n",
      "@property\n",
      "def metrics_for_best_config()\n",
      "```\n",
      "\n",
      "Returns a float of the best loss, and a dictionary of the auxiliary metrics to log\n",
      "associated with the best config. These two objects correspond to the returned\n",
      "objects by the customized metric function for the config with the best loss.\n",
      "\n",
      "#### best\\_config\\_train\\_time\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config_train_time()\n",
      "```\n",
      "---\n",
      "sidebar_label: cfo_cat\n",
      "title: tune.searcher.cfo_cat\n",
      "---\n",
      "\n",
      "## FLOW2Cat Objects\n",
      "\n",
      "```python\n",
      "class FLOW2Cat(FLOW2)\n",
      "```\n",
      "\n",
      "Local search algorithm optimized for categorical variables.\n",
      "\n",
      "## CFOCat Objects\n",
      "\n",
      "```python\n",
      "class CFOCat(CFO)\n",
      "```\n",
      "\n",
      "CFO optimized for categorical variables.\n",
      "\n",
      "\n",
      "\n",
      "new_automl = AutoML()\n",
      "new_automl.fit(X_train, y_train, starting_points=starting_points)\n",
      "```\n",
      "  \n",
      "- `seed` - int or None, default=None | The random seed for hpo.\n",
      "- `n_concurrent_trials` - [Experimental] int, default=1 | The number of\n",
      "  concurrent trials. When n_concurrent_trials > 1, flaml performes\n",
      "  [parallel tuning](../../Use-Cases/Task-Oriented-AutoML#parallel-tuning)\n",
      "  and installation of ray or spark is required: `pip install flaml[ray]`\n",
      "  or `pip install flaml[spark]`. Please check\n",
      "  [here](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
      "  for more details about installing Spark.\n",
      "- `keep_search_state` - boolean, default=False | Whether to keep data needed\n",
      "  for model search after fit(). By default the state is deleted for\n",
      "  space saving.\n",
      "- `preserve_checkpoint` - boolean, default=True | Whether to preserve the saved checkpoint\n",
      "  on disk when deleting automl. By default the checkpoint is preserved.\n",
      "- `early_stop` - boolean, default=False | Whether to stop early if the\n",
      "  search is considered to converge.\n",
      "- `force_cancel` - boolean, default=False | Whether to forcely cancel the PySpark job if overtime.\n",
      "- `append_log` - boolean, default=False | Whetehr to directly append the log\n",
      "  records to the input log file if it exists.\n",
      "- `auto_augment` - boolean, default=True | Whether to automatically\n",
      "  augment rare classes.\n",
      "- `min_sample_size` - int, default=MIN_SAMPLE_TRAIN | the minimal sample\n",
      "  size when sample=True.\n",
      "- `use_ray` - boolean or dict.\n",
      "  If boolean: default=False | Whether to use ray to run the training\n",
      "  in separate processes. This can be used to prevent OOM for large\n",
      "  datasets, but will incur more overhead in time.\n",
      "  If dict: the dict contains the keywords arguments to be passed to\n",
      "  [ray.tune.run](https://docs.ray.io/en/latest/tune/api_docs/execution.html).\n",
      "- `use_spark` - boolean, default=False | Whether to use spark to run the training\n",
      "  in parallel spark jobs. This can be used to accelerate training on large models\n",
      "  and large datasets, but will incur more overhead in time and thus slow down\n",
      "  training in some cases.\n",
      "- `free_mem_ratio` - float between 0 and 1, default=0. The free memory ratio to keep during training.\n",
      "- `metric_constraints` - list, default=[] | The list of metric constraints.\n",
      "  Each element in this list is a 3-tuple, which shall be expressed\n",
      "  in the following format: the first element of the 3-tuple is the name of the\n",
      "  metric, the second element is the inequality sign chosen from \">=\" and \"<=\",\n",
      "  and the third element is the constraint value. E.g., `('precision', '>=', 0.9)`.\n",
      "  Note that all the metric names in metric_constraints need to be reported via\n",
      "  the metrics_to_log dictionary returned by a customized metric function.\n",
      "  The customized metric function shall be provided via the `metric` key word argument\n",
      "  of the fit() function or the automl constructor.\n",
      "  Find examples in this [test](https://github.com/microsoft/FLAML/tree/main/test/automl/test_constraints.py).\n",
      "  If `pred_time_limit` is provided as one of keyword arguments to fit() function or\n",
      "  the automl constructor, flaml will automatically (and under the hood)\n",
      "  add it as an additional element in the metric_constraints. Essentially 'pred_time_limit'\n",
      "  specifies a constraint about the prediction latency constraint in seconds.\n",
      "- `custom_hp` - dict, default=None | The custom search space specified by user\n",
      "  Each key is the estimator name, each value is a dict of the custom search space for that estimator. Notice the\n",
      "  domain of the custom search space can either be a value of a sample.Domain object.\n",
      "  \n",
      "  \n",
      "  \n",
      "```python\n",
      "custom_hp = {\n",
      "    \"transformer_ms\": {\n",
      "        \"model_path\": {\n",
      "            \"domain\": \"albert-base-v2\",\n",
      "        },\n",
      "        \"learning_rate\": {\n",
      "            \"domain\": tune.choice([1e-4, 1e-5]),\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "- `time_col` - for a time series task, name of the column containing the timestamps. If not\n",
      "  provided, defaults to the first column of X_train/X_val\n",
      "  \n",
      "- `cv_score_agg_func` - customized cross-validation scores aggregate function. Default to average metrics across folds. If specificed, this function needs to\n",
      "  have the following input arguments:\n",
      "  \n",
      "  * val_loss_folds: list of floats, the loss scores of each fold;\n",
      "  * log_metrics_folds: list of dicts/floats, the metrics of each fold to log.\n",
      "  \n",
      "  This function should return the final aggregate result of all folds. A float number of the minimization objective, and a dictionary as the metrics to log or None.\n",
      "  E.g.,\n",
      "  \n",
      "```python\n",
      "def cv_score_agg_func(val_loss_folds, log_metrics_folds):\n",
      "    metric_to_minimize = sum(val_loss_folds)/len(val_loss_folds)\n",
      "    metrics_to_log = None\n",
      "    for single_fold in log_metrics_folds:\n",
      "        if metrics_to_log is None:\n",
      "            metrics_to_log = single_fold\n",
      "        elif isinstance(metrics_to_log, dict):\n",
      "            metrics_to_log = {k: metrics_to_log[k] + v for k, v in single_fold.items()}\n",
      "        else:\n",
      "            metrics_to_log += single_fold\n",
      "    if metrics_to_log:\n",
      "        n = len(val_loss_folds)\n",
      "        metrics_to_log = (\n",
      "            {k: v / n for k, v in metrics_to_log.items()}\n",
      "            if isinstance(metrics_to_log, dict)\n",
      "            else metrics_to_log / n\n",
      "        )\n",
      "    return metric_to_minimize, metrics_to_log\n",
      "```\n",
      "  \n",
      "- `skip_transform` - boolean, default=False | Whether to pre-process data prior to modeling.\n",
      "- `mlflow_logging` - boolean, default=None | Whether to log the training results to mlflow.\n",
      "  Default value is None, which means the logging decision is made based on\n",
      "  AutoML.__init__'s mlflow_logging argument.\n",
      "  This requires mlflow to be installed and to have an active mlflow run.\n",
      "  FLAML will create nested runs.\n",
      "- `fit_kwargs_by_estimator` - dict, default=None | The user specified keywords arguments, grouped by estimator name.\n",
      "  For TransformersEstimator, available fit_kwargs can be found from\n",
      "  [TrainingArgumentsForAuto](nlp/huggingface/training_args).\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "fit_kwargs_by_estimator = {\n",
      "    \"transformer\": {\n",
      "        \"output_dir\": \"test/data/output/\",\n",
      "        \"fp16\": False,\n",
      "    },\n",
      "    \"tft\": {\n",
      "        \"max_encoder_length\": 1,\n",
      "        \"min_encoder_length\": 1,\n",
      "        \"static_categoricals\": [],\n",
      "        \"static_reals\": [],\n",
      "        \"time_varying_known_categoricals\": [],\n",
      "        \"time_varying_known_reals\": [],\n",
      "        \"time_varying_unknown_categoricals\": [],\n",
      "        \"time_varying_unknown_reals\": [],\n",
      "        \"variable_groups\": {},\n",
      "        \"lags\": {},\n",
      "    }\n",
      "}\n",
      "```\n",
      "  \n",
      "- `**fit_kwargs` - Other key word arguments to pass to fit() function of\n",
      "  the searched learners, such as sample_weight. Below are a few examples of\n",
      "  estimator-specific parameters:\n",
      "- `period` - int | forecast horizon for all time series forecast tasks.\n",
      "- `gpu_per_trial` - float, default = 0 | A float of the number of gpus per trial,\n",
      "  only used by TransformersEstimator, XGBoostSklearnEstimator, and\n",
      "  TemporalFusionTransformerEstimator.\n",
      "- `group_ids` - list of strings of column names identifying a time series, only\n",
      "  used by TemporalFusionTransformerEstimator, required for\n",
      "  'ts_forecast_panel' task. `group_ids` is a parameter for TimeSeriesDataSet object\n",
      "  from PyTorchForecasting.\n",
      "  For other parameters to describe your dataset, refer to\n",
      "  [TimeSeriesDataSet PyTorchForecasting](https://pytorch-forecasting.readthedocs.io/en/stable/api/pytorch_forecasting.data.timeseries.TimeSeriesDataSet.html).\n",
      "  To specify your variables, use `static_categoricals`, `static_reals`,\n",
      "  `time_varying_known_categoricals`, `time_varying_known_reals`,\n",
      "  `time_varying_unknown_categoricals`, `time_varying_unknown_reals`,\n",
      "  `variable_groups`. To provide more information on your data, use\n",
      "  `max_encoder_length`, `min_encoder_length`, `lags`.\n",
      "- `log_dir` - str, default = \"lightning_logs\" | Folder into which to log results\n",
      "  for tensorboard, only used by TemporalFusionTransformerEstimator.\n",
      "- `max_epochs` - int, default = 20 | Maximum number of epochs to run training,\n",
      "  only used by TemporalFusionTransformerEstimator.\n",
      "- `batch_size` - int, default = 64 | Batch size for training model, only\n",
      "  used by TemporalFusionTransformerEstimator.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to ragproxyagent):\n",
      "\n",
      "The author of FLAML (Fast, Lightweight AutoML) is the Microsoft team, specifically the Microsoft Research group. The paper associated with the FLAML framework is titled \"Liu, C., Li, X., Guo, M. and Mutny, T., 2021. FLAML: A Fast, Lightweight, and Accurate AutoML Library. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining.\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# reset the assistant. Always reset the assistant before starting a new conversation.\n",
    "assistant.reset()\n",
    "\n",
    "qa_problem = \"Who is the author of FLAML?\"\n",
    "ragproxyagent.initiate_chat(assistant, problem=qa_problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3\n",
    "\n",
    "Use RetrieveChat to help generate sample code and ask for human-in-loop feedbacks.\n",
    "\n",
    "Problem: how to build a time series forecasting model for stock price using FLAML?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_ids:  [['doc_31', 'doc_29', 'doc_51', 'doc_34', 'doc_50', 'doc_45', 'doc_3', 'doc_48', 'doc_33', 'doc_49', 'doc_36', 'doc_30', 'doc_14', 'doc_2', 'doc_4', 'doc_46', 'doc_27', 'doc_6', 'doc_28', 'doc_15']]\n",
      "Adding doc_id doc_31 to context.\n",
      "Adding doc_id doc_29 to context.\n",
      "Adding doc_id doc_51 to context.\n",
      "Adding doc_id doc_34 to context.\n",
      "Adding doc_id doc_50 to context.\n",
      "ragproxyagent (to assistant):\n",
      "\n",
      "You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user. You should follow the following steps to answer a question:\n",
      "Step 1, you estimate the user's intent based on the question and context. The intent can be a code generation task or\n",
      "a QA task.\n",
      "Step 2, you generate code or answer the question based on the intent.\n",
      "You should leverage the context provided by the user as much as possible. If you think the context is not enough, you\n",
      "can reply exactly \"UPDATE CONTEXT\" to ask the user to provide more contexts.\n",
      "For code generation, you must obey the following rules:\n",
      "You MUST NOT install any packages because all the packages needed are already installed.\n",
      "The code will be executed in IPython, you must follow the formats below to write your code:\n",
      "```python\n",
      "# your code\n",
      "```\n",
      "\n",
      "User's question is: how to build a time series forecasting model for stock price using FLAML?\n",
      "\n",
      "Context is: \n",
      "- `log_file_name` - A string of the log file name.\n",
      "- `X_train` - A numpy array or dataframe of training data in shape n*m.\n",
      "  For time series forecast tasks, the first column of X_train must be the timestamp column (datetime type). Other columns in the dataframe are assumed to be exogenous variables (categorical or numeric).\n",
      "- `y_train` - A numpy array or series of labels in shape n*1.\n",
      "- `dataframe` - A dataframe of training data including label column.\n",
      "  For time series forecast tasks, dataframe must be specified and should\n",
      "  have at least two columns: timestamp and label, where the first\n",
      "  column is the timestamp column (datetime type). Other columns\n",
      "  in the dataframe are assumed to be exogenous variables\n",
      "  (categorical or numeric).\n",
      "- `label` - A str of the label column name, e.g., 'label';\n",
      "- `Note` - If X_train and y_train are provided,\n",
      "  dataframe and label are ignored;\n",
      "  If not, dataframe and label must be provided.\n",
      "- `time_budget` - A float number of the time budget in seconds.\n",
      "- `task` - A string of the task type, e.g.,\n",
      "  'classification', 'regression', 'ts_forecast', 'rank',\n",
      "  'seq-classification', 'seq-regression', 'summarization',\n",
      "  or an instance of Task class.\n",
      "- `eval_method` - A string of resampling strategy, one of\n",
      "  ['auto', 'cv', 'holdout'].\n",
      "- `split_ratio` - A float of the validation data percentage for holdout.\n",
      "- `n_splits` - An integer of the number of folds for cross-validation.\n",
      "- `split_type` - str or splitter object, default=\"auto\" | the data split type.\n",
      "  * A valid splitter object is an instance of a derived class of scikit-learn\n",
      "  [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold)\n",
      "  and have ``split`` and ``get_n_splits`` methods with the same signatures.\n",
      "  Set eval_method to \"cv\" to use the splitter object.\n",
      "  * Valid str options depend on different tasks.\n",
      "  For classification tasks, valid choices are\n",
      "  [\"auto\", 'stratified', 'uniform', 'time', 'group']. \"auto\" -> stratified.\n",
      "  For regression tasks, valid choices are [\"auto\", 'uniform', 'time'].\n",
      "  \"auto\" -> uniform.\n",
      "  For time series forecast tasks, must be \"auto\" or 'time'.\n",
      "  For ranking task, must be \"auto\" or 'group'.\n",
      "- `groups` - None or array-like | Group labels (with matching length to\n",
      "  y_train) or groups counts (with sum equal to length of y_train)\n",
      "  for training data.\n",
      "- `n_jobs` - An integer of the number of threads for training | default=-1.\n",
      "  Use all available resources when n_jobs == -1.\n",
      "- `train_best` - A boolean of whether to train the best config in the\n",
      "  time budget; if false, train the last config in the budget.\n",
      "- `train_full` - A boolean of whether to train on the full data. If true,\n",
      "  eval_method and sample_size in the log file will be ignored.\n",
      "- `record_id` - the ID of the training log record from which the model will\n",
      "  be retrained. By default `record_id = -1` which means this will be\n",
      "  ignored. `record_id = 0` corresponds to the first trial, and\n",
      "  when `record_id >= 0`, `time_budget` will be ignored.\n",
      "- `auto_augment` - boolean, default=True | Whether to automatically\n",
      "  augment rare classes.\n",
      "- `custom_hp` - dict, default=None | The custom search space specified by user\n",
      "  Each key is the estimator name, each value is a dict of the custom search space for that estimator. Notice the\n",
      "  domain of the custom search space can either be a value or a sample.Domain object.\n",
      "  \n",
      "```python\n",
      "custom_hp = {\n",
      "    \"transformer_ms\": {\n",
      "        \"model_path\": {\n",
      "            \"domain\": \"albert-base-v2\",\n",
      "        },\n",
      "        \"learning_rate\": {\n",
      "            \"domain\": tune.choice([1e-4, 1e-5]),\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "- `fit_kwargs_by_estimator` - dict, default=None | The user specified keywords arguments, grouped by estimator name.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "fit_kwargs_by_estimator = {\n",
      "    \"transformer\": {\n",
      "        \"output_dir\": \"test/data/output/\",\n",
      "        \"fp16\": False,\n",
      "    }\n",
      "}\n",
      "```\n",
      "  \n",
      "- `**fit_kwargs` - Other key word arguments to pass to fit() function of\n",
      "  the searched learners, such as sample_weight. Below are a few examples of\n",
      "  estimator-specific parameters:\n",
      "- `period` - int | forecast horizon for all time series forecast tasks.\n",
      "- `gpu_per_trial` - float, default = 0 | A float of the number of gpus per trial,\n",
      "  only used by TransformersEstimator, XGBoostSklearnEstimator, and\n",
      "  TemporalFusionTransformerEstimator.\n",
      "- `group_ids` - list of strings of column names identifying a time series, only\n",
      "  used by TemporalFusionTransformerEstimator, required for\n",
      "  'ts_forecast_panel' task. `group_ids` is a parameter for TimeSeriesDataSet object\n",
      "  from PyTorchForecasting.\n",
      "  For other parameters to describe your dataset, refer to\n",
      "  [TimeSeriesDataSet PyTorchForecasting](https://pytorch-forecasting.readthedocs.io/en/stable/api/pytorch_forecasting.data.timeseries.TimeSeriesDataSet.html).\n",
      "  To specify your variables, use `static_categoricals`, `static_reals`,\n",
      "  `time_varying_known_categoricals`, `time_varying_known_reals`,\n",
      "  `time_varying_unknown_categoricals`, `time_varying_unknown_reals`,\n",
      "  `variable_groups`. To provide more information on your data, use\n",
      "  `max_encoder_length`, `min_encoder_length`, `lags`.\n",
      "- `log_dir` - str, default = \"lightning_logs\" | Folder into which to log results\n",
      "  for tensorboard, only used by TemporalFusionTransformerEstimator.\n",
      "- `max_epochs` - int, default = 20 | Maximum number of epochs to run training,\n",
      "  only used by TemporalFusionTransformerEstimator.\n",
      "- `batch_size` - int, default = 64 | Batch size for training model, only\n",
      "  used by TemporalFusionTransformerEstimator.\n",
      "\n",
      "#### search\\_space\n",
      "\n",
      "```python\n",
      "@property\n",
      "def search_space() -> dict\n",
      "```\n",
      "\n",
      "Search space.\n",
      "\n",
      "Must be called after fit(...)\n",
      "(use max_iter=0 and retrain_final=False to prevent actual fitting).\n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  A dict of the search space.\n",
      "\n",
      "#### low\\_cost\\_partial\\_config\n",
      "\n",
      "```python\n",
      "@property\n",
      "def low_cost_partial_config() -> dict\n",
      "```\n",
      "\n",
      "Low cost partial config.\n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  A dict.\n",
      "  (a) if there is only one estimator in estimator_list, each key is a\n",
      "  hyperparameter name.\n",
      "  (b) otherwise, it is a nested dict with 'ml' as the key, and\n",
      "  a list of the low_cost_partial_configs as the value, corresponding\n",
      "  to each learner's low_cost_partial_config; the estimator index as\n",
      "  an integer corresponding to the cheapest learner is appended to the\n",
      "  list at the end.\n",
      "\n",
      "#### cat\\_hp\\_cost\n",
      "\n",
      "```python\n",
      "@property\n",
      "def cat_hp_cost() -> dict\n",
      "```\n",
      "\n",
      "Categorical hyperparameter cost\n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  A dict.\n",
      "  (a) if there is only one estimator in estimator_list, each key is a\n",
      "  hyperparameter name.\n",
      "  (b) otherwise, it is a nested dict with 'ml' as the key, and\n",
      "  a list of the cat_hp_cost's as the value, corresponding\n",
      "  to each learner's cat_hp_cost; the cost relative to lgbm for each\n",
      "  learner (as a list itself) is appended to the list at the end.\n",
      "\n",
      "#### points\\_to\\_evaluate\n",
      "\n",
      "```python\n",
      "@property\n",
      "def points_to_evaluate() -> dict\n",
      "```\n",
      "\n",
      "Initial points to evaluate.\n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  A list of dicts. Each dict is the initial point for each learner.\n",
      "\n",
      "#### resource\\_attr\n",
      "\n",
      "```python\n",
      "@property\n",
      "def resource_attr() -> Optional[str]\n",
      "```\n",
      "\n",
      "Attribute of the resource dimension.\n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  A string for the sample size attribute\n",
      "  (the resource attribute in AutoML) or None.\n",
      "\n",
      "#### min\\_resource\n",
      "\n",
      "```python\n",
      "@property\n",
      "def min_resource() -> Optional[float]\n",
      "```\n",
      "\n",
      "Attribute for pruning.\n",
      "\n",
      "new_automl = AutoML()\n",
      "new_automl.fit(X_train, y_train, starting_points=starting_points)\n",
      "```\n",
      "  \n",
      "- `seed` - int or None, default=None | The random seed for hpo.\n",
      "- `n_concurrent_trials` - [Experimental] int, default=1 | The number of\n",
      "  concurrent trials. When n_concurrent_trials > 1, flaml performes\n",
      "  [parallel tuning](../../Use-Cases/Task-Oriented-AutoML#parallel-tuning)\n",
      "  and installation of ray or spark is required: `pip install flaml[ray]`\n",
      "  or `pip install flaml[spark]`. Please check\n",
      "  [here](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
      "  for more details about installing Spark.\n",
      "- `keep_search_state` - boolean, default=False | Whether to keep data needed\n",
      "  for model search after fit(). By default the state is deleted for\n",
      "  space saving.\n",
      "- `preserve_checkpoint` - boolean, default=True | Whether to preserve the saved checkpoint\n",
      "  on disk when deleting automl. By default the checkpoint is preserved.\n",
      "- `early_stop` - boolean, default=False | Whether to stop early if the\n",
      "  search is considered to converge.\n",
      "- `force_cancel` - boolean, default=False | Whether to forcely cancel Spark jobs if the\n",
      "  search time exceeded the time budget.\n",
      "- `append_log` - boolean, default=False | Whetehr to directly append the log\n",
      "  records to the input log file if it exists.\n",
      "- `auto_augment` - boolean, default=True | Whether to automatically\n",
      "  augment rare classes.\n",
      "- `min_sample_size` - int, default=MIN_SAMPLE_TRAIN | the minimal sample\n",
      "  size when sample=True.\n",
      "- `use_ray` - boolean or dict.\n",
      "  If boolean: default=False | Whether to use ray to run the training\n",
      "  in separate processes. This can be used to prevent OOM for large\n",
      "  datasets, but will incur more overhead in time.\n",
      "  If dict: the dict contains the keywords arguments to be passed to\n",
      "  [ray.tune.run](https://docs.ray.io/en/latest/tune/api_docs/execution.html).\n",
      "- `use_spark` - boolean, default=False | Whether to use spark to run the training\n",
      "  in parallel spark jobs. This can be used to accelerate training on large models\n",
      "  and large datasets, but will incur more overhead in time and thus slow down\n",
      "  training in some cases. GPU training is not supported yet when use_spark is True.\n",
      "  For Spark clusters, by default, we will launch one trial per executor. However,\n",
      "  sometimes we want to launch more trials than the number of executors (e.g., local mode).\n",
      "  In this case, we can set the environment variable `FLAML_MAX_CONCURRENT` to override\n",
      "  the detected `num_executors`. The final number of concurrent trials will be the minimum\n",
      "  of `n_concurrent_trials` and `num_executors`.\n",
      "- `free_mem_ratio` - float between 0 and 1, default=0. The free memory ratio to keep during training.\n",
      "- `metric_constraints` - list, default=[] | The list of metric constraints.\n",
      "  Each element in this list is a 3-tuple, which shall be expressed\n",
      "  in the following format: the first element of the 3-tuple is the name of the\n",
      "  metric, the second element is the inequality sign chosen from \">=\" and \"<=\",\n",
      "  and the third element is the constraint value. E.g., `('val_loss', '<=', 0.1)`.\n",
      "  Note that all the metric names in metric_constraints need to be reported via\n",
      "  the metrics_to_log dictionary returned by a customized metric function.\n",
      "  The customized metric function shall be provided via the `metric` key word\n",
      "  argument of the fit() function or the automl constructor.\n",
      "  Find an example in the 4th constraint type in this [doc](../../Use-Cases/Task-Oriented-AutoML#constraint).\n",
      "  If `pred_time_limit` is provided as one of keyword arguments to fit() function or\n",
      "  the automl constructor, flaml will automatically (and under the hood)\n",
      "  add it as an additional element in the metric_constraints. Essentially 'pred_time_limit'\n",
      "  specifies a constraint about the prediction latency constraint in seconds.\n",
      "- `custom_hp` - dict, default=None | The custom search space specified by user.\n",
      "  It is a nested dict with keys being the estimator names, and values being dicts\n",
      "  per estimator search space. In the per estimator search space dict,\n",
      "  the keys are the hyperparameter names, and values are dicts of info (\"domain\",\n",
      "  \"init_value\", and \"low_cost_init_value\") about the search space associated with\n",
      "  the hyperparameter (i.e., per hyperparameter search space dict). When custom_hp\n",
      "  is provided, the built-in search space which is also a nested dict of per estimator\n",
      "  search space dict, will be updated with custom_hp. Note that during this nested dict update,\n",
      "  the per hyperparameter search space dicts will be replaced (instead of updated) by the ones\n",
      "  provided in custom_hp. Note that the value for \"domain\" can either be a constant\n",
      "  or a sample.Domain object.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "custom_hp = {\n",
      "     \"transformer_ms\": {\n",
      "         \"model_path\": {\n",
      "             \"domain\": \"albert-base-v2\",\n",
      "         },\n",
      "         \"learning_rate\": {\n",
      "             \"domain\": tune.choice([1e-4, 1e-5]),\n",
      "         }\n",
      "     }\n",
      " }\n",
      "```\n",
      "- `skip_transform` - boolean, default=False | Whether to pre-process data prior to modeling.\n",
      "- `fit_kwargs_by_estimator` - dict, default=None | The user specified keywords arguments, grouped by estimator name.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "fit_kwargs_by_estimator = {\n",
      "    \"transformer\": {\n",
      "        \"output_dir\": \"test/data/output/\",\n",
      "        \"fp16\": False,\n",
      "    }\n",
      "}\n",
      "```\n",
      "- `mlflow_logging` - boolean, default=True | Whether to log the training results to mlflow.\n",
      "  This requires mlflow to be installed and to have an active mlflow run.\n",
      "  FLAML will create nested runs.\n",
      "\n",
      "#### config\\_history\n",
      "\n",
      "```python\n",
      "@property\n",
      "def config_history() -> dict\n",
      "```\n",
      "\n",
      "A dictionary of iter->(estimator, config, time),\n",
      "storing the best estimator, config, and the time when the best\n",
      "model is updated each time.\n",
      "\n",
      "#### model\n",
      "\n",
      "```python\n",
      "@property\n",
      "def model()\n",
      "```\n",
      "\n",
      "An object with `predict()` and `predict_proba()` method (for\n",
      "classification), storing the best trained model.\n",
      "\n",
      "#### best\\_model\\_for\\_estimator\n",
      "\n",
      "```python\n",
      "def best_model_for_estimator(estimator_name: str)\n",
      "```\n",
      "\n",
      "Return the best model found for a particular estimator.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `estimator_name` - a str of the estimator's name.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  An object storing the best model for estimator_name.\n",
      "  If `model_history` was set to False during fit(), then the returned model\n",
      "  is untrained unless estimator_name is the best estimator.\n",
      "  If `model_history` was set to True, then the returned model is trained.\n",
      "\n",
      "#### best\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_estimator()\n",
      "```\n",
      "\n",
      "A string indicating the best estimator found.\n",
      "\n",
      "#### best\\_iteration\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_iteration()\n",
      "```\n",
      "\n",
      "An integer of the iteration number where the best\n",
      "config is found.\n",
      "\n",
      "#### best\\_config\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config()\n",
      "```\n",
      "\n",
      "A dictionary of the best configuration.\n",
      "\n",
      "#### best\\_config\\_per\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config_per_estimator()\n",
      "```\n",
      "\n",
      "A dictionary of all estimators' best configuration.\n",
      "\n",
      "#### best\\_loss\\_per\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_loss_per_estimator()\n",
      "```\n",
      "\n",
      "A dictionary of all estimators' best loss.\n",
      "\n",
      "#### best\\_loss\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_loss()\n",
      "```\n",
      "\n",
      "A float of the best loss found.\n",
      "\n",
      "#### best\\_result\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_result()\n",
      "```\n",
      "\n",
      "Result dictionary for model trained with the best config.\n",
      "\n",
      "#### metrics\\_for\\_best\\_config\n",
      "\n",
      "```python\n",
      "@property\n",
      "def metrics_for_best_config()\n",
      "```\n",
      "\n",
      "Returns a float of the best loss, and a dictionary of the auxiliary metrics to log\n",
      "associated with the best config. These two objects correspond to the returned\n",
      "objects by the customized metric function for the config with the best loss.\n",
      "\n",
      "#### best\\_config\\_train\\_time\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config_train_time()\n",
      "```\n",
      "---\n",
      "sidebar_label: ts_model\n",
      "title: automl.time_series.ts_model\n",
      "---\n",
      "\n",
      "## Prophet Objects\n",
      "\n",
      "```python\n",
      "class Prophet(TimeSeriesEstimator)\n",
      "```\n",
      "\n",
      "The class for tuning Prophet.\n",
      "\n",
      "## ARIMA Objects\n",
      "\n",
      "```python\n",
      "class ARIMA(StatsModelsEstimator)\n",
      "```\n",
      "\n",
      "The class for tuning ARIMA.\n",
      "\n",
      "## SARIMAX Objects\n",
      "\n",
      "```python\n",
      "class SARIMAX(StatsModelsEstimator)\n",
      "```\n",
      "\n",
      "The class for tuning SARIMA.\n",
      "\n",
      "## HoltWinters Objects\n",
      "\n",
      "```python\n",
      "class HoltWinters(StatsModelsEstimator)\n",
      "```\n",
      "\n",
      "The class for tuning Holt Winters model, aka 'Triple Exponential Smoothing'.\n",
      "\n",
      "## TS\\_SKLearn Objects\n",
      "\n",
      "```python\n",
      "class TS_SKLearn(TimeSeriesEstimator)\n",
      "```\n",
      "\n",
      "The class for tuning SKLearn Regressors for time-series forecasting\n",
      "\n",
      "## LGBM\\_TS Objects\n",
      "\n",
      "```python\n",
      "class LGBM_TS(TS_SKLearn)\n",
      "```\n",
      "\n",
      "The class for tuning LGBM Regressor for time-series forecasting\n",
      "\n",
      "## XGBoost\\_TS Objects\n",
      "\n",
      "```python\n",
      "class XGBoost_TS(TS_SKLearn)\n",
      "```\n",
      "\n",
      "The class for tuning XGBoost Regressor for time-series forecasting\n",
      "\n",
      "## RF\\_TS Objects\n",
      "\n",
      "```python\n",
      "class RF_TS(TS_SKLearn)\n",
      "```\n",
      "\n",
      "The class for tuning Random Forest Regressor for time-series forecasting\n",
      "\n",
      "## ExtraTrees\\_TS Objects\n",
      "\n",
      "```python\n",
      "class ExtraTrees_TS(TS_SKLearn)\n",
      "```\n",
      "\n",
      "The class for tuning Extra Trees Regressor for time-series forecasting\n",
      "\n",
      "## XGBoostLimitDepth\\_TS Objects\n",
      "\n",
      "```python\n",
      "class XGBoostLimitDepth_TS(TS_SKLearn)\n",
      "```\n",
      "\n",
      "The class for tuning XGBoost Regressor with unlimited depth for time-series forecasting\n",
      "\n",
      "\n",
      "\n",
      "new_automl = AutoML()\n",
      "new_automl.fit(X_train, y_train, starting_points=starting_points)\n",
      "```\n",
      "  \n",
      "- `seed` - int or None, default=None | The random seed for hpo.\n",
      "- `n_concurrent_trials` - [Experimental] int, default=1 | The number of\n",
      "  concurrent trials. When n_concurrent_trials > 1, flaml performes\n",
      "  [parallel tuning](../../Use-Cases/Task-Oriented-AutoML#parallel-tuning)\n",
      "  and installation of ray or spark is required: `pip install flaml[ray]`\n",
      "  or `pip install flaml[spark]`. Please check\n",
      "  [here](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
      "  for more details about installing Spark.\n",
      "- `keep_search_state` - boolean, default=False | Whether to keep data needed\n",
      "  for model search after fit(). By default the state is deleted for\n",
      "  space saving.\n",
      "- `preserve_checkpoint` - boolean, default=True | Whether to preserve the saved checkpoint\n",
      "  on disk when deleting automl. By default the checkpoint is preserved.\n",
      "- `early_stop` - boolean, default=False | Whether to stop early if the\n",
      "  search is considered to converge.\n",
      "- `force_cancel` - boolean, default=False | Whether to forcely cancel the PySpark job if overtime.\n",
      "- `append_log` - boolean, default=False | Whetehr to directly append the log\n",
      "  records to the input log file if it exists.\n",
      "- `auto_augment` - boolean, default=True | Whether to automatically\n",
      "  augment rare classes.\n",
      "- `min_sample_size` - int, default=MIN_SAMPLE_TRAIN | the minimal sample\n",
      "  size when sample=True.\n",
      "- `use_ray` - boolean or dict.\n",
      "  If boolean: default=False | Whether to use ray to run the training\n",
      "  in separate processes. This can be used to prevent OOM for large\n",
      "  datasets, but will incur more overhead in time.\n",
      "  If dict: the dict contains the keywords arguments to be passed to\n",
      "  [ray.tune.run](https://docs.ray.io/en/latest/tune/api_docs/execution.html).\n",
      "- `use_spark` - boolean, default=False | Whether to use spark to run the training\n",
      "  in parallel spark jobs. This can be used to accelerate training on large models\n",
      "  and large datasets, but will incur more overhead in time and thus slow down\n",
      "  training in some cases.\n",
      "- `free_mem_ratio` - float between 0 and 1, default=0. The free memory ratio to keep during training.\n",
      "- `metric_constraints` - list, default=[] | The list of metric constraints.\n",
      "  Each element in this list is a 3-tuple, which shall be expressed\n",
      "  in the following format: the first element of the 3-tuple is the name of the\n",
      "  metric, the second element is the inequality sign chosen from \">=\" and \"<=\",\n",
      "  and the third element is the constraint value. E.g., `('precision', '>=', 0.9)`.\n",
      "  Note that all the metric names in metric_constraints need to be reported via\n",
      "  the metrics_to_log dictionary returned by a customized metric function.\n",
      "  The customized metric function shall be provided via the `metric` key word argument\n",
      "  of the fit() function or the automl constructor.\n",
      "  Find examples in this [test](https://github.com/microsoft/FLAML/tree/main/test/automl/test_constraints.py).\n",
      "  If `pred_time_limit` is provided as one of keyword arguments to fit() function or\n",
      "  the automl constructor, flaml will automatically (and under the hood)\n",
      "  add it as an additional element in the metric_constraints. Essentially 'pred_time_limit'\n",
      "  specifies a constraint about the prediction latency constraint in seconds.\n",
      "- `custom_hp` - dict, default=None | The custom search space specified by user\n",
      "  Each key is the estimator name, each value is a dict of the custom search space for that estimator. Notice the\n",
      "  domain of the custom search space can either be a value of a sample.Domain object.\n",
      "  \n",
      "  \n",
      "  \n",
      "```python\n",
      "custom_hp = {\n",
      "    \"transformer_ms\": {\n",
      "        \"model_path\": {\n",
      "            \"domain\": \"albert-base-v2\",\n",
      "        },\n",
      "        \"learning_rate\": {\n",
      "            \"domain\": tune.choice([1e-4, 1e-5]),\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "- `time_col` - for a time series task, name of the column containing the timestamps. If not\n",
      "  provided, defaults to the first column of X_train/X_val\n",
      "  \n",
      "- `cv_score_agg_func` - customized cross-validation scores aggregate function. Default to average metrics across folds. If specificed, this function needs to\n",
      "  have the following input arguments:\n",
      "  \n",
      "  * val_loss_folds: list of floats, the loss scores of each fold;\n",
      "  * log_metrics_folds: list of dicts/floats, the metrics of each fold to log.\n",
      "  \n",
      "  This function should return the final aggregate result of all folds. A float number of the minimization objective, and a dictionary as the metrics to log or None.\n",
      "  E.g.,\n",
      "  \n",
      "```python\n",
      "def cv_score_agg_func(val_loss_folds, log_metrics_folds):\n",
      "    metric_to_minimize = sum(val_loss_folds)/len(val_loss_folds)\n",
      "    metrics_to_log = None\n",
      "    for single_fold in log_metrics_folds:\n",
      "        if metrics_to_log is None:\n",
      "            metrics_to_log = single_fold\n",
      "        elif isinstance(metrics_to_log, dict):\n",
      "            metrics_to_log = {k: metrics_to_log[k] + v for k, v in single_fold.items()}\n",
      "        else:\n",
      "            metrics_to_log += single_fold\n",
      "    if metrics_to_log:\n",
      "        n = len(val_loss_folds)\n",
      "        metrics_to_log = (\n",
      "            {k: v / n for k, v in metrics_to_log.items()}\n",
      "            if isinstance(metrics_to_log, dict)\n",
      "            else metrics_to_log / n\n",
      "        )\n",
      "    return metric_to_minimize, metrics_to_log\n",
      "```\n",
      "  \n",
      "- `skip_transform` - boolean, default=False | Whether to pre-process data prior to modeling.\n",
      "- `mlflow_logging` - boolean, default=None | Whether to log the training results to mlflow.\n",
      "  Default value is None, which means the logging decision is made based on\n",
      "  AutoML.__init__'s mlflow_logging argument.\n",
      "  This requires mlflow to be installed and to have an active mlflow run.\n",
      "  FLAML will create nested runs.\n",
      "- `fit_kwargs_by_estimator` - dict, default=None | The user specified keywords arguments, grouped by estimator name.\n",
      "  For TransformersEstimator, available fit_kwargs can be found from\n",
      "  [TrainingArgumentsForAuto](nlp/huggingface/training_args).\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "fit_kwargs_by_estimator = {\n",
      "    \"transformer\": {\n",
      "        \"output_dir\": \"test/data/output/\",\n",
      "        \"fp16\": False,\n",
      "    },\n",
      "    \"tft\": {\n",
      "        \"max_encoder_length\": 1,\n",
      "        \"min_encoder_length\": 1,\n",
      "        \"static_categoricals\": [],\n",
      "        \"static_reals\": [],\n",
      "        \"time_varying_known_categoricals\": [],\n",
      "        \"time_varying_known_reals\": [],\n",
      "        \"time_varying_unknown_categoricals\": [],\n",
      "        \"time_varying_unknown_reals\": [],\n",
      "        \"variable_groups\": {},\n",
      "        \"lags\": {},\n",
      "    }\n",
      "}\n",
      "```\n",
      "  \n",
      "- `**fit_kwargs` - Other key word arguments to pass to fit() function of\n",
      "  the searched learners, such as sample_weight. Below are a few examples of\n",
      "  estimator-specific parameters:\n",
      "- `period` - int | forecast horizon for all time series forecast tasks.\n",
      "- `gpu_per_trial` - float, default = 0 | A float of the number of gpus per trial,\n",
      "  only used by TransformersEstimator, XGBoostSklearnEstimator, and\n",
      "  TemporalFusionTransformerEstimator.\n",
      "- `group_ids` - list of strings of column names identifying a time series, only\n",
      "  used by TemporalFusionTransformerEstimator, required for\n",
      "  'ts_forecast_panel' task. `group_ids` is a parameter for TimeSeriesDataSet object\n",
      "  from PyTorchForecasting.\n",
      "  For other parameters to describe your dataset, refer to\n",
      "  [TimeSeriesDataSet PyTorchForecasting](https://pytorch-forecasting.readthedocs.io/en/stable/api/pytorch_forecasting.data.timeseries.TimeSeriesDataSet.html).\n",
      "  To specify your variables, use `static_categoricals`, `static_reals`,\n",
      "  `time_varying_known_categoricals`, `time_varying_known_reals`,\n",
      "  `time_varying_unknown_categoricals`, `time_varying_unknown_reals`,\n",
      "  `variable_groups`. To provide more information on your data, use\n",
      "  `max_encoder_length`, `min_encoder_length`, `lags`.\n",
      "- `log_dir` - str, default = \"lightning_logs\" | Folder into which to log results\n",
      "  for tensorboard, only used by TemporalFusionTransformerEstimator.\n",
      "- `max_epochs` - int, default = 20 | Maximum number of epochs to run training,\n",
      "  only used by TemporalFusionTransformerEstimator.\n",
      "- `batch_size` - int, default = 64 | Batch size for training model, only\n",
      "  used by TemporalFusionTransformerEstimator.\n",
      "\n",
      "\n",
      "---\n",
      "sidebar_label: ts_data\n",
      "title: automl.time_series.ts_data\n",
      "---\n",
      "\n",
      "## TimeSeriesDataset Objects\n",
      "\n",
      "```python\n",
      "@dataclass\n",
      "class TimeSeriesDataset()\n",
      "```\n",
      "\n",
      "#### to\\_univariate\n",
      "\n",
      "```python\n",
      "def to_univariate() -> Dict[str, \"TimeSeriesDataset\"]\n",
      "```\n",
      "\n",
      "Convert a multivariate TrainingData  to a dict of univariate ones\n",
      "@param df:\n",
      "@return:\n",
      "\n",
      "#### fourier\\_series\n",
      "\n",
      "```python\n",
      "def fourier_series(feature: pd.Series, name: str)\n",
      "```\n",
      "\n",
      "Assume feature goes from 0 to 1 cyclically, transform that into Fourier\n",
      "@param feature: input feature\n",
      "@return: sin(2pi*feature), cos(2pi*feature)\n",
      "\n",
      "## DataTransformerTS Objects\n",
      "\n",
      "```python\n",
      "class DataTransformerTS()\n",
      "```\n",
      "\n",
      "Transform input time series training data.\n",
      "\n",
      "#### fit\n",
      "\n",
      "```python\n",
      "def fit(X: Union[DataFrame, np.array], y)\n",
      "```\n",
      "\n",
      "Fit transformer.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `X` - A numpy array or a pandas dataframe of training data.\n",
      "- `y` - A numpy array or a pandas series of labels.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "- `X` - Processed numpy array or pandas dataframe of training data.\n",
      "- `y` - Processed numpy array or pandas series of labels.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user. You should follow the following steps to answer a question:\n",
      "Step 1, you estimate the user's intent based on the question and context. The intent can be a code generation task or\n",
      "a QA task.\n",
      "Step 2, you generate code or answer the question based on the intent.\n",
      "You should leverage the context provided by the user as much as possible. If you think the context is not enough, you\n",
      "can reply exactly \"UPDATE CONTEXT\" to ask the user to provide more contexts.\n",
      "For code generation, you must obey the following rules:\n",
      "You MUST NOT install any packages because all the packages needed are already installed.\n",
      "The code will be executed in IPython, you must follow the formats below to write your code:\n",
      "```python\n",
      "# your code\n",
      "```\n",
      "\n",
      "User's question is: how to build a time series forecasting model for stock price using FLAML?\n",
      "\n",
      "Context is: \n",
      "- `log_file_name` - A string of the log file name.\n",
      "- `X_train` - A numpy array or dataframe of training data in shape n*m.\n",
      "  For time series forecast tasks, the first column of X_train must be the timestamp column (datetime type). Other columns in the dataframe are assumed to be exogenous variables (categorical or numeric).\n",
      "- `y_train` - A numpy array or series of labels in shape n*1.\n",
      "- `dataframe` - A dataframe of training data including label column.\n",
      "  For time series forecast tasks, dataframe must be specified and should\n",
      "  have at least two columns: timestamp and label, where the first\n",
      "  column is the timestamp column (datetime type). Other columns\n",
      "  in the dataframe are assumed to be exogenous variables\n",
      "  (categorical or numeric).\n",
      "- `label` - A str of the label column name, e.g., 'label';\n",
      "- `Note` - If X_train and y_train are provided,\n",
      "  dataframe and label are ignored;\n",
      "  If not, dataframe and label must be provided.\n",
      "- `time_budget` - A float number of the time budget in seconds.\n",
      "- `task` - A string of the task type, e.g.,\n",
      "  'classification', 'regression', 'ts_forecast', 'rank',\n",
      "  'seq-classification', 'seq-regression', 'summarization',\n",
      "  or an instance of Task class.\n",
      "- `eval_method` - A string of resampling strategy, one of\n",
      "  ['auto', 'cv', 'holdout'].\n",
      "- `split_ratio` - A float of the validation data percentage for holdout.\n",
      "- `n_splits` - An integer of the number of folds for cross-validation.\n",
      "- `split_type` - str or splitter object, default=\"auto\" | the data split type.\n",
      "  * A valid splitter object is an instance of a derived class of scikit-learn\n",
      "  [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold)\n",
      "  and have ``split`` and ``get_n_splits`` methods with the same signatures.\n",
      "  Set eval_method to \"cv\" to use the splitter object.\n",
      "  * Valid str options depend on different tasks.\n",
      "  For classification tasks, valid choices are\n",
      "  [\"auto\", 'stratified', 'uniform', 'time', 'group']. \"auto\" -> stratified.\n",
      "  For regression tasks, valid choices are [\"auto\", 'uniform', 'time'].\n",
      "  \"auto\" -> uniform.\n",
      "  For time series forecast tasks, must be \"auto\" or 'time'.\n",
      "  For ranking task, must be \"auto\" or 'group'.\n",
      "- `groups` - None or array-like | Group labels (with matching length to\n",
      "  y_train) or groups counts (with sum equal to length of y_train)\n",
      "  for training data.\n",
      "- `n_jobs` - An integer of the number of threads for training | default=-1.\n",
      "  Use all available resources when n_jobs == -1.\n",
      "- `train_best` - A boolean of whether to train the best config in the\n",
      "  time budget; if false, train the last config in the budget.\n",
      "- `train_full` - A boolean of whether to train on the full data. If true,\n",
      "  eval_method and sample_size in the log file will be ignored.\n",
      "- `record_id` - the ID of the training log record from which the model will\n",
      "  be retrained. By default `record_id = -1` which means this will be\n",
      "  ignored. `record_id = 0` corresponds to the first trial, and\n",
      "  when `record_id >= 0`, `time_budget` will be ignored.\n",
      "- `auto_augment` - boolean, default=True | Whether to automatically\n",
      "  augment rare classes.\n",
      "- `custom_hp` - dict, default=None | The custom search space specified by user\n",
      "  Each key is the estimator name, each value is a dict of the custom search space for that estimator. Notice the\n",
      "  domain of the custom search space can either be a value or a sample.Domain object.\n",
      "  \n",
      "```python\n",
      "custom_hp = {\n",
      "    \"transformer_ms\": {\n",
      "        \"model_path\": {\n",
      "            \"domain\": \"albert-base-v2\",\n",
      "        },\n",
      "        \"learning_rate\": {\n",
      "            \"domain\": tune.choice([1e-4, 1e-5]),\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "- `fit_kwargs_by_estimator` - dict, default=None | The user specified keywords arguments, grouped by estimator name.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "fit_kwargs_by_estimator = {\n",
      "    \"transformer\": {\n",
      "        \"output_dir\": \"test/data/output/\",\n",
      "        \"fp16\": False,\n",
      "    }\n",
      "}\n",
      "```\n",
      "  \n",
      "- `**fit_kwargs` - Other key word arguments to pass to fit() function of\n",
      "  the searched learners, such as sample_weight. Below are a few examples of\n",
      "  estimator-specific parameters:\n",
      "- `period` - int | forecast horizon for all time series forecast tasks.\n",
      "- `gpu_per_trial` - float, default = 0 | A float of the number of gpus per trial,\n",
      "  only used by TransformersEstimator, XGBoostSklearnEstimator, and\n",
      "  TemporalFusionTransformerEstimator.\n",
      "- `group_ids` - list of strings of column names identifying a time series, only\n",
      "  used by TemporalFusionTransformerEstimator, required for\n",
      "  'ts_forecast_panel' task. `group_ids` is a parameter for TimeSeriesDataSet object\n",
      "  from PyTorchForecasting.\n",
      "  For other parameters to describe your dataset, refer to\n",
      "  [TimeSeriesDataSet PyTorchForecasting](https://pytorch-forecasting.readthedocs.io/en/stable/api/pytorch_forecasting.data.timeseries.TimeSeriesDataSet.html).\n",
      "  To specify your variables, use `static_categoricals`, `static_reals`,\n",
      "  `time_varying_known_categoricals`, `time_varying_known_reals`,\n",
      "  `time_varying_unknown_categoricals`, `time_varying_unknown_reals`,\n",
      "  `variable_groups`. To provide more information on your data, use\n",
      "  `max_encoder_length`, `min_encoder_length`, `lags`.\n",
      "- `log_dir` - str, default = \"lightning_logs\" | Folder into which to log results\n",
      "  for tensorboard, only used by TemporalFusionTransformerEstimator.\n",
      "- `max_epochs` - int, default = 20 | Maximum number of epochs to run training,\n",
      "  only used by TemporalFusionTransformerEstimator.\n",
      "- `batch_size` - int, default = 64 | Batch size for training model, only\n",
      "  used by TemporalFusionTransformerEstimator.\n",
      "\n",
      "#### search\\_space\n",
      "\n",
      "```python\n",
      "@property\n",
      "def search_space() -> dict\n",
      "```\n",
      "\n",
      "Search space.\n",
      "\n",
      "Must be called after fit(...)\n",
      "(use max_iter=0 and retrain_final=False to prevent actual fitting).\n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  A dict of the search space.\n",
      "\n",
      "#### low\\_cost\\_partial\\_config\n",
      "\n",
      "```python\n",
      "@property\n",
      "def low_cost_partial_config() -> dict\n",
      "```\n",
      "\n",
      "Low cost partial config.\n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  A dict.\n",
      "  (a) if there is only one estimator in estimator_list, each key is a\n",
      "  hyperparameter name.\n",
      "  (b) otherwise, it is a nested dict with 'ml' as the key, and\n",
      "  a list of the low_cost_partial_configs as the value, corresponding\n",
      "  to each learner's low_cost_partial_config; the estimator index as\n",
      "  an integer corresponding to the cheapest learner is appended to the\n",
      "  list at the end.\n",
      "\n",
      "#### cat\\_hp\\_cost\n",
      "\n",
      "```python\n",
      "@property\n",
      "def cat_hp_cost() -> dict\n",
      "```\n",
      "\n",
      "Categorical hyperparameter cost\n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  A dict.\n",
      "  (a) if there is only one estimator in estimator_list, each key is a\n",
      "  hyperparameter name.\n",
      "  (b) otherwise, it is a nested dict with 'ml' as the key, and\n",
      "  a list of the cat_hp_cost's as the value, corresponding\n",
      "  to each learner's cat_hp_cost; the cost relative to lgbm for each\n",
      "  learner (as a list itself) is appended to the list at the end.\n",
      "\n",
      "#### points\\_to\\_evaluate\n",
      "\n",
      "```python\n",
      "@property\n",
      "def points_to_evaluate() -> dict\n",
      "```\n",
      "\n",
      "Initial points to evaluate.\n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  A list of dicts. Each dict is the initial point for each learner.\n",
      "\n",
      "#### resource\\_attr\n",
      "\n",
      "```python\n",
      "@property\n",
      "def resource_attr() -> Optional[str]\n",
      "```\n",
      "\n",
      "Attribute of the resource dimension.\n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  A string for the sample size attribute\n",
      "  (the resource attribute in AutoML) or None.\n",
      "\n",
      "#### min\\_resource\n",
      "\n",
      "```python\n",
      "@property\n",
      "def min_resource() -> Optional[float]\n",
      "```\n",
      "\n",
      "Attribute for pruning.\n",
      "\n",
      "new_automl = AutoML()\n",
      "new_automl.fit(X_train, y_train, starting_points=starting_points)\n",
      "```\n",
      "  \n",
      "- `seed` - int or None, default=None | The random seed for hpo.\n",
      "- `n_concurrent_trials` - [Experimental] int, default=1 | The number of\n",
      "  concurrent trials. When n_concurrent_trials > 1, flaml performes\n",
      "  [parallel tuning](../../Use-Cases/Task-Oriented-AutoML#parallel-tuning)\n",
      "  and installation of ray or spark is required: `pip install flaml[ray]`\n",
      "  or `pip install flaml[spark]`. Please check\n",
      "  [here](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
      "  for more details about installing Spark.\n",
      "- `keep_search_state` - boolean, default=False | Whether to keep data needed\n",
      "  for model search after fit(). By default the state is deleted for\n",
      "  space saving.\n",
      "- `preserve_checkpoint` - boolean, default=True | Whether to preserve the saved checkpoint\n",
      "  on disk when deleting automl. By default the checkpoint is preserved.\n",
      "- `early_stop` - boolean, default=False | Whether to stop early if the\n",
      "  search is considered to converge.\n",
      "- `force_cancel` - boolean, default=False | Whether to forcely cancel Spark jobs if the\n",
      "  search time exceeded the time budget.\n",
      "- `append_log` - boolean, default=False | Whetehr to directly append the log\n",
      "  records to the input log file if it exists.\n",
      "- `auto_augment` - boolean, default=True | Whether to automatically\n",
      "  augment rare classes.\n",
      "- `min_sample_size` - int, default=MIN_SAMPLE_TRAIN | the minimal sample\n",
      "  size when sample=True.\n",
      "- `use_ray` - boolean or dict.\n",
      "  If boolean: default=False | Whether to use ray to run the training\n",
      "  in separate processes. This can be used to prevent OOM for large\n",
      "  datasets, but will incur more overhead in time.\n",
      "  If dict: the dict contains the keywords arguments to be passed to\n",
      "  [ray.tune.run](https://docs.ray.io/en/latest/tune/api_docs/execution.html).\n",
      "- `use_spark` - boolean, default=False | Whether to use spark to run the training\n",
      "  in parallel spark jobs. This can be used to accelerate training on large models\n",
      "  and large datasets, but will incur more overhead in time and thus slow down\n",
      "  training in some cases. GPU training is not supported yet when use_spark is True.\n",
      "  For Spark clusters, by default, we will launch one trial per executor. However,\n",
      "  sometimes we want to launch more trials than the number of executors (e.g., local mode).\n",
      "  In this case, we can set the environment variable `FLAML_MAX_CONCURRENT` to override\n",
      "  the detected `num_executors`. The final number of concurrent trials will be the minimum\n",
      "  of `n_concurrent_trials` and `num_executors`.\n",
      "- `free_mem_ratio` - float between 0 and 1, default=0. The free memory ratio to keep during training.\n",
      "- `metric_constraints` - list, default=[] | The list of metric constraints.\n",
      "  Each element in this list is a 3-tuple, which shall be expressed\n",
      "  in the following format: the first element of the 3-tuple is the name of the\n",
      "  metric, the second element is the inequality sign chosen from \">=\" and \"<=\",\n",
      "  and the third element is the constraint value. E.g., `('val_loss', '<=', 0.1)`.\n",
      "  Note that all the metric names in metric_constraints need to be reported via\n",
      "  the metrics_to_log dictionary returned by a customized metric function.\n",
      "  The customized metric function shall be provided via the `metric` key word\n",
      "  argument of the fit() function or the automl constructor.\n",
      "  Find an example in the 4th constraint type in this [doc](../../Use-Cases/Task-Oriented-AutoML#constraint).\n",
      "  If `pred_time_limit` is provided as one of keyword arguments to fit() function or\n",
      "  the automl constructor, flaml will automatically (and under the hood)\n",
      "  add it as an additional element in the metric_constraints. Essentially 'pred_time_limit'\n",
      "  specifies a constraint about the prediction latency constraint in seconds.\n",
      "- `custom_hp` - dict, default=None | The custom search space specified by user.\n",
      "  It is a nested dict with keys being the estimator names, and values being dicts\n",
      "  per estimator search space. In the per estimator search space dict,\n",
      "  the keys are the hyperparameter names, and values are dicts of info (\"domain\",\n",
      "  \"init_value\", and \"low_cost_init_value\") about the search space associated with\n",
      "  the hyperparameter (i.e., per hyperparameter search space dict). When custom_hp\n",
      "  is provided, the built-in search space which is also a nested dict of per estimator\n",
      "  search space dict, will be updated with custom_hp. Note that during this nested dict update,\n",
      "  the per hyperparameter search space dicts will be replaced (instead of updated) by the ones\n",
      "  provided in custom_hp. Note that the value for \"domain\" can either be a constant\n",
      "  or a sample.Domain object.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "custom_hp = {\n",
      "     \"transformer_ms\": {\n",
      "         \"model_path\": {\n",
      "             \"domain\": \"albert-base-v2\",\n",
      "         },\n",
      "         \"learning_rate\": {\n",
      "             \"domain\": tune.choice([1e-4, 1e-5]),\n",
      "         }\n",
      "     }\n",
      " }\n",
      "```\n",
      "- `skip_transform` - boolean, default=False | Whether to pre-process data prior to modeling.\n",
      "- `fit_kwargs_by_estimator` - dict, default=None | The user specified keywords arguments, grouped by estimator name.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "fit_kwargs_by_estimator = {\n",
      "    \"transformer\": {\n",
      "        \"output_dir\": \"test/data/output/\",\n",
      "        \"fp16\": False,\n",
      "    }\n",
      "}\n",
      "```\n",
      "- `mlflow_logging` - boolean, default=True | Whether to log the training results to mlflow.\n",
      "  This requires mlflow to be installed and to have an active mlflow run.\n",
      "  FLAML will create nested runs.\n",
      "\n",
      "#### config\\_history\n",
      "\n",
      "```python\n",
      "@property\n",
      "def config_history() -> dict\n",
      "```\n",
      "\n",
      "A dictionary of iter->(estimator, config, time),\n",
      "storing the best estimator, config, and the time when the best\n",
      "model is updated each time.\n",
      "\n",
      "#### model\n",
      "\n",
      "```python\n",
      "@property\n",
      "def model()\n",
      "```\n",
      "\n",
      "An object with `predict()` and `predict_proba()` method (for\n",
      "classification), storing the best trained model.\n",
      "\n",
      "#### best\\_model\\_for\\_estimator\n",
      "\n",
      "```python\n",
      "def best_model_for_estimator(estimator_name: str)\n",
      "```\n",
      "\n",
      "Return the best model found for a particular estimator.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `estimator_name` - a str of the estimator's name.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  An object storing the best model for estimator_name.\n",
      "  If `model_history` was set to False during fit(), then the returned model\n",
      "  is untrained unless estimator_name is the best estimator.\n",
      "  If `model_history` was set to True, then the returned model is trained.\n",
      "\n",
      "#### best\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_estimator()\n",
      "```\n",
      "\n",
      "A string indicating the best estimator found.\n",
      "\n",
      "#### best\\_iteration\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_iteration()\n",
      "```\n",
      "\n",
      "An integer of the iteration number where the best\n",
      "config is found.\n",
      "\n",
      "#### best\\_config\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config()\n",
      "```\n",
      "\n",
      "A dictionary of the best configuration.\n",
      "\n",
      "#### best\\_config\\_per\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config_per_estimator()\n",
      "```\n",
      "\n",
      "A dictionary of all estimators' best configuration.\n",
      "\n",
      "#### best\\_loss\\_per\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_loss_per_estimator()\n",
      "```\n",
      "\n",
      "A dictionary of all estimators' best loss.\n",
      "\n",
      "#### best\\_loss\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_loss()\n",
      "```\n",
      "\n",
      "A float of the best loss found.\n",
      "\n",
      "#### best\\_result\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_result()\n",
      "```\n",
      "\n",
      "Result dictionary for model trained with the best config.\n",
      "\n",
      "#### metrics\\_for\\_best\\_config\n",
      "\n",
      "```python\n",
      "@property\n",
      "def metrics_for_best_config()\n",
      "```\n",
      "\n",
      "Returns a float of the best loss, and a dictionary of the auxiliary metrics to log\n",
      "associated with the best config. These two objects correspond to the returned\n",
      "objects by the customized metric function for the config with the best loss.\n",
      "\n",
      "#### best\\_config\\_train\\_time\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config_train_time()\n",
      "```\n",
      "---\n",
      "sidebar_label: ts_model\n",
      "title: automl.time_series.ts_model\n",
      "---\n",
      "\n",
      "## Prophet Objects\n",
      "\n",
      "```python\n",
      "class Prophet(TimeSeriesEstimator)\n",
      "```\n",
      "\n",
      "The class for tuning Prophet.\n",
      "\n",
      "## ARIMA Objects\n",
      "\n",
      "```python\n",
      "class ARIMA(StatsModelsEstimator)\n",
      "```\n",
      "\n",
      "The class for tuning ARIMA.\n",
      "\n",
      "## SARIMAX Objects\n",
      "\n",
      "```python\n",
      "class SARIMAX(StatsModelsEstimator)\n",
      "```\n",
      "\n",
      "The class for tuning SARIMA.\n",
      "\n",
      "## HoltWinters Objects\n",
      "\n",
      "```python\n",
      "class HoltWinters(StatsModelsEstimator)\n",
      "```\n",
      "\n",
      "The class for tuning Holt Winters model, aka 'Triple Exponential Smoothing'.\n",
      "\n",
      "## TS\\_SKLearn Objects\n",
      "\n",
      "```python\n",
      "class TS_SKLearn(TimeSeriesEstimator)\n",
      "```\n",
      "\n",
      "The class for tuning SKLearn Regressors for time-series forecasting\n",
      "\n",
      "## LGBM\\_TS Objects\n",
      "\n",
      "```python\n",
      "class LGBM_TS(TS_SKLearn)\n",
      "```\n",
      "\n",
      "The class for tuning LGBM Regressor for time-series forecasting\n",
      "\n",
      "## XGBoost\\_TS Objects\n",
      "\n",
      "```python\n",
      "class XGBoost_TS(TS_SKLearn)\n",
      "```\n",
      "\n",
      "The class for tuning XGBoost Regressor for time-series forecasting\n",
      "\n",
      "## RF\\_TS Objects\n",
      "\n",
      "```python\n",
      "class RF_TS(TS_SKLearn)\n",
      "```\n",
      "\n",
      "The class for tuning Random Forest Regressor for time-series forecasting\n",
      "\n",
      "## ExtraTrees\\_TS Objects\n",
      "\n",
      "```python\n",
      "class ExtraTrees_TS(TS_SKLearn)\n",
      "```\n",
      "\n",
      "The class for tuning Extra Trees Regressor for time-series forecasting\n",
      "\n",
      "## XGBoostLimitDepth\\_TS Objects\n",
      "\n",
      "```python\n",
      "class XGBoostLimitDepth_TS(TS_SKLearn)\n",
      "```\n",
      "\n",
      "The class for tuning XGBoost Regressor with unlimited depth for time-series forecasting\n",
      "\n",
      "\n",
      "\n",
      "new_automl = AutoML()\n",
      "new_automl.fit(X_train, y_train, starting_points=starting_points)\n",
      "```\n",
      "  \n",
      "- `seed` - int or None, default=None | The random seed for hpo.\n",
      "- `n_concurrent_trials` - [Experimental] int, default=1 | The number of\n",
      "  concurrent trials. When n_concurrent_trials > 1, flaml performes\n",
      "  [parallel tuning](../../Use-Cases/Task-Oriented-AutoML#parallel-tuning)\n",
      "  and installation of ray or spark is required: `pip install flaml[ray]`\n",
      "  or `pip install flaml[spark]`. Please check\n",
      "  [here](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
      "  for more details about installing Spark.\n",
      "- `keep_search_state` - boolean, default=False | Whether to keep data needed\n",
      "  for model search after fit(). By default the state is deleted for\n",
      "  space saving.\n",
      "- `preserve_checkpoint` - boolean, default=True | Whether to preserve the saved checkpoint\n",
      "  on disk when deleting automl. By default the checkpoint is preserved.\n",
      "- `early_stop` - boolean, default=False | Whether to stop early if the\n",
      "  search is considered to converge.\n",
      "- `force_cancel` - boolean, default=False | Whether to forcely cancel the PySpark job if overtime.\n",
      "- `append_log` - boolean, default=False | Whetehr to directly append the log\n",
      "  records to the input log file if it exists.\n",
      "- `auto_augment` - boolean, default=True | Whether to automatically\n",
      "  augment rare classes.\n",
      "- `min_sample_size` - int, default=MIN_SAMPLE_TRAIN | the minimal sample\n",
      "  size when sample=True.\n",
      "- `use_ray` - boolean or dict.\n",
      "  If boolean: default=False | Whether to use ray to run the training\n",
      "  in separate processes. This can be used to prevent OOM for large\n",
      "  datasets, but will incur more overhead in time.\n",
      "  If dict: the dict contains the keywords arguments to be passed to\n",
      "  [ray.tune.run](https://docs.ray.io/en/latest/tune/api_docs/execution.html).\n",
      "- `use_spark` - boolean, default=False | Whether to use spark to run the training\n",
      "  in parallel spark jobs. This can be used to accelerate training on large models\n",
      "  and large datasets, but will incur more overhead in time and thus slow down\n",
      "  training in some cases.\n",
      "- `free_mem_ratio` - float between 0 and 1, default=0. The free memory ratio to keep during training.\n",
      "- `metric_constraints` - list, default=[] | The list of metric constraints.\n",
      "  Each element in this list is a 3-tuple, which shall be expressed\n",
      "  in the following format: the first element of the 3-tuple is the name of the\n",
      "  metric, the second element is the inequality sign chosen from \">=\" and \"<=\",\n",
      "  and the third element is the constraint value. E.g., `('precision', '>=', 0.9)`.\n",
      "  Note that all the metric names in metric_constraints need to be reported via\n",
      "  the metrics_to_log dictionary returned by a customized metric function.\n",
      "  The customized metric function shall be provided via the `metric` key word argument\n",
      "  of the fit() function or the automl constructor.\n",
      "  Find examples in this [test](https://github.com/microsoft/FLAML/tree/main/test/automl/test_constraints.py).\n",
      "  If `pred_time_limit` is provided as one of keyword arguments to fit() function or\n",
      "  the automl constructor, flaml will automatically (and under the hood)\n",
      "  add it as an additional element in the metric_constraints. Essentially 'pred_time_limit'\n",
      "  specifies a constraint about the prediction latency constraint in seconds.\n",
      "- `custom_hp` - dict, default=None | The custom search space specified by user\n",
      "  Each key is the estimator name, each value is a dict of the custom search space for that estimator. Notice the\n",
      "  domain of the custom search space can either be a value of a sample.Domain object.\n",
      "  \n",
      "  \n",
      "  \n",
      "```python\n",
      "custom_hp = {\n",
      "    \"transformer_ms\": {\n",
      "        \"model_path\": {\n",
      "            \"domain\": \"albert-base-v2\",\n",
      "        },\n",
      "        \"learning_rate\": {\n",
      "            \"domain\": tune.choice([1e-4, 1e-5]),\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "- `time_col` - for a time series task, name of the column containing the timestamps. If not\n",
      "  provided, defaults to the first column of X_train/X_val\n",
      "  \n",
      "- `cv_score_agg_func` - customized cross-validation scores aggregate function. Default to average metrics across folds. If specificed, this function needs to\n",
      "  have the following input arguments:\n",
      "  \n",
      "  * val_loss_folds: list of floats, the loss scores of each fold;\n",
      "  * log_metrics_folds: list of dicts/floats, the metrics of each fold to log.\n",
      "  \n",
      "  This function should return the final aggregate result of all folds. A float number of the minimization objective, and a dictionary as the metrics to log or None.\n",
      "  E.g.,\n",
      "  \n",
      "```python\n",
      "def cv_score_agg_func(val_loss_folds, log_metrics_folds):\n",
      "    metric_to_minimize = sum(val_loss_folds)/len(val_loss_folds)\n",
      "    metrics_to_log = None\n",
      "    for single_fold in log_metrics_folds:\n",
      "        if metrics_to_log is None:\n",
      "            metrics_to_log = single_fold\n",
      "        elif isinstance(metrics_to_log, dict):\n",
      "            metrics_to_log = {k: metrics_to_log[k] + v for k, v in single_fold.items()}\n",
      "        else:\n",
      "            metrics_to_log += single_fold\n",
      "    if metrics_to_log:\n",
      "        n = len(val_loss_folds)\n",
      "        metrics_to_log = (\n",
      "            {k: v / n for k, v in metrics_to_log.items()}\n",
      "            if isinstance(metrics_to_log, dict)\n",
      "            else metrics_to_log / n\n",
      "        )\n",
      "    return metric_to_minimize, metrics_to_log\n",
      "```\n",
      "  \n",
      "- `skip_transform` - boolean, default=False | Whether to pre-process data prior to modeling.\n",
      "- `mlflow_logging` - boolean, default=None | Whether to log the training results to mlflow.\n",
      "  Default value is None, which means the logging decision is made based on\n",
      "  AutoML.__init__'s mlflow_logging argument.\n",
      "  This requires mlflow to be installed and to have an active mlflow run.\n",
      "  FLAML will create nested runs.\n",
      "- `fit_kwargs_by_estimator` - dict, default=None | The user specified keywords arguments, grouped by estimator name.\n",
      "  For TransformersEstimator, available fit_kwargs can be found from\n",
      "  [TrainingArgumentsForAuto](nlp/huggingface/training_args).\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "fit_kwargs_by_estimator = {\n",
      "    \"transformer\": {\n",
      "        \"output_dir\": \"test/data/output/\",\n",
      "        \"fp16\": False,\n",
      "    },\n",
      "    \"tft\": {\n",
      "        \"max_encoder_length\": 1,\n",
      "        \"min_encoder_length\": 1,\n",
      "        \"static_categoricals\": [],\n",
      "        \"static_reals\": [],\n",
      "        \"time_varying_known_categoricals\": [],\n",
      "        \"time_varying_known_reals\": [],\n",
      "        \"time_varying_unknown_categoricals\": [],\n",
      "        \"time_varying_unknown_reals\": [],\n",
      "        \"variable_groups\": {},\n",
      "        \"lags\": {},\n",
      "    }\n",
      "}\n",
      "```\n",
      "  \n",
      "- `**fit_kwargs` - Other key word arguments to pass to fit() function of\n",
      "  the searched learners, such as sample_weight. Below are a few examples of\n",
      "  estimator-specific parameters:\n",
      "- `period` - int | forecast horizon for all time series forecast tasks.\n",
      "- `gpu_per_trial` - float, default = 0 | A float of the number of gpus per trial,\n",
      "  only used by TransformersEstimator, XGBoostSklearnEstimator, and\n",
      "  TemporalFusionTransformerEstimator.\n",
      "- `group_ids` - list of strings of column names identifying a time series, only\n",
      "  used by TemporalFusionTransformerEstimator, required for\n",
      "  'ts_forecast_panel' task. `group_ids` is a parameter for TimeSeriesDataSet object\n",
      "  from PyTorchForecasting.\n",
      "  For other parameters to describe your dataset, refer to\n",
      "  [TimeSeriesDataSet PyTorchForecasting](https://pytorch-forecasting.readthedocs.io/en/stable/api/pytorch_forecasting.data.timeseries.TimeSeriesDataSet.html).\n",
      "  To specify your variables, use `static_categoricals`, `static_reals`,\n",
      "  `time_varying_known_categoricals`, `time_varying_known_reals`,\n",
      "  `time_varying_unknown_categoricals`, `time_varying_unknown_reals`,\n",
      "  `variable_groups`. To provide more information on your data, use\n",
      "  `max_encoder_length`, `min_encoder_length`, `lags`.\n",
      "- `log_dir` - str, default = \"lightning_logs\" | Folder into which to log results\n",
      "  for tensorboard, only used by TemporalFusionTransformerEstimator.\n",
      "- `max_epochs` - int, default = 20 | Maximum number of epochs to run training,\n",
      "  only used by TemporalFusionTransformerEstimator.\n",
      "- `batch_size` - int, default = 64 | Batch size for training model, only\n",
      "  used by TemporalFusionTransformerEstimator.\n",
      "\n",
      "\n",
      "---\n",
      "sidebar_label: ts_data\n",
      "title: automl.time_series.ts_data\n",
      "---\n",
      "\n",
      "## TimeSeriesDataset Objects\n",
      "\n",
      "```python\n",
      "@dataclass\n",
      "class TimeSeriesDataset()\n",
      "```\n",
      "\n",
      "#### to\\_univariate\n",
      "\n",
      "```python\n",
      "def to_univariate() -> Dict[str, \"TimeSeriesDataset\"]\n",
      "```\n",
      "\n",
      "Convert a multivariate TrainingData  to a dict of univariate ones\n",
      "@param df:\n",
      "@return:\n",
      "\n",
      "#### fourier\\_series\n",
      "\n",
      "```python\n",
      "def fourier_series(feature: pd.Series, name: str)\n",
      "```\n",
      "\n",
      "Assume feature goes from 0 to 1 cyclically, transform that into Fourier\n",
      "@param feature: input feature\n",
      "@return: sin(2pi*feature), cos(2pi*feature)\n",
      "\n",
      "## DataTransformerTS Objects\n",
      "\n",
      "```python\n",
      "class DataTransformerTS()\n",
      "```\n",
      "\n",
      "Transform input time series training data.\n",
      "\n",
      "#### fit\n",
      "\n",
      "```python\n",
      "def fit(X: Union[DataFrame, np.array], y)\n",
      "```\n",
      "\n",
      "Fit transformer.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `X` - A numpy array or a pandas dataframe of training data.\n",
      "- `y` - A numpy array or a pandas series of labels.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "- `X` - Processed numpy array or pandas dataframe of training data.\n",
      "- `y` - Processed numpy array or pandas series of labels.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to ragproxyagent):\n",
      "\n",
      "To build a time series forecasting model for stock prices using FLAML, you can follow these steps:\n",
      "\n",
      "1. Install FLAML with the additional `[forecast]` option if you haven't:\n",
      "```bash\n",
      "pip install flaml[forecast]\n",
      "```\n",
      "\n",
      "2. Import the necessary libraries:\n",
      "```python\n",
      "import pandas as pd\n",
      "from flaml import AutoML\n",
      "```\n",
      "\n",
      "3. Load your stock price data into a pandas DataFrame. The DataFrame should have at least two columns: one for the timestamps (e.g., 'date') and one for the stock prices (e.g., 'price'). If you have additional exogenous variables, include them as additional columns.\n",
      "\n",
      "4. Set up the AutoML instance for time series forecasting:\n",
      "```python\n",
      "automl = AutoML()\n",
      "```\n",
      "\n",
      "5. Call the `fit()` method, specifying the 'ts_forecast' task, the label column name, the time_budget, the column name with timestamps, and the forecast horizon (period). Also, specify other parameters as needed based on the context provided:\n",
      "```python\n",
      "automl.fit(dataframe=data, task=\"ts_forecast\", time_budget=time_budget, label=\"price\", time_col=\"date\", period=forecast_horizon)\n",
      "```\n",
      "\n",
      "6. After the model training is completed, you can make predictions using the following method:\n",
      "```python\n",
      "predictions = automl.predict(new_data)  # new_data is a dataframe containing the inputs for the predictions excluding the target labels.\n",
      "```\n",
      "\n",
      "This completed example covers the overall process of building a time series forecasting model for stock prices using FLAML.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# reset the assistant. Always reset the assistant before starting a new conversation.\n",
    "assistant.reset()\n",
    "\n",
    "# set `human_input_mode` to be `ALWAYS`, so the agent will ask for human input at every step.\n",
    "ragproxyagent.human_input_mode = \"ALWAYS\"\n",
    "code_problem = \"how to build a time series forecasting model for stock price using FLAML?\"\n",
    "ragproxyagent.initiate_chat(assistant, problem=code_problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4\n",
    "\n",
    "Use RetrieveChat to answer a question and ask for human-in-loop feedbacks.\n",
    "\n",
    "Problem: Is there a function named `tune_automl` in FLAML?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_ids:  [['doc_29', 'doc_34', 'doc_14', 'doc_45', 'doc_3', 'doc_15', 'doc_13', 'doc_22', 'doc_28', 'doc_18', 'doc_5', 'doc_4', 'doc_41', 'doc_49', 'doc_39', 'doc_9', 'doc_20', 'doc_38', 'doc_51', 'doc_21']]\n",
      "Adding doc_id doc_29 to context.\n",
      "Adding doc_id doc_34 to context.\n",
      "Adding doc_id doc_14 to context.\n",
      "ragproxyagent (to assistant):\n",
      "\n",
      "You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user. You should follow the following steps to answer a question:\n",
      "Step 1, you estimate the user's intent based on the question and context. The intent can be a code generation task or\n",
      "a QA task.\n",
      "Step 2, you generate code or answer the question based on the intent.\n",
      "You should leverage the context provided by the user as much as possible. If you think the context is not enough, you\n",
      "can reply exactly \"UPDATE CONTEXT\" to ask the user to provide more contexts.\n",
      "For code generation, you must obey the following rules:\n",
      "You MUST NOT install any packages because all the packages needed are already installed.\n",
      "The code will be executed in IPython, you must follow the formats below to write your code:\n",
      "```python\n",
      "# your code\n",
      "```\n",
      "\n",
      "User's question is: Is there a function named `tune_automl` in FLAML?\n",
      "\n",
      "Context is: \n",
      "new_automl = AutoML()\n",
      "new_automl.fit(X_train, y_train, starting_points=starting_points)\n",
      "```\n",
      "  \n",
      "- `seed` - int or None, default=None | The random seed for hpo.\n",
      "- `n_concurrent_trials` - [Experimental] int, default=1 | The number of\n",
      "  concurrent trials. When n_concurrent_trials > 1, flaml performes\n",
      "  [parallel tuning](../../Use-Cases/Task-Oriented-AutoML#parallel-tuning)\n",
      "  and installation of ray or spark is required: `pip install flaml[ray]`\n",
      "  or `pip install flaml[spark]`. Please check\n",
      "  [here](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
      "  for more details about installing Spark.\n",
      "- `keep_search_state` - boolean, default=False | Whether to keep data needed\n",
      "  for model search after fit(). By default the state is deleted for\n",
      "  space saving.\n",
      "- `preserve_checkpoint` - boolean, default=True | Whether to preserve the saved checkpoint\n",
      "  on disk when deleting automl. By default the checkpoint is preserved.\n",
      "- `early_stop` - boolean, default=False | Whether to stop early if the\n",
      "  search is considered to converge.\n",
      "- `force_cancel` - boolean, default=False | Whether to forcely cancel Spark jobs if the\n",
      "  search time exceeded the time budget.\n",
      "- `append_log` - boolean, default=False | Whetehr to directly append the log\n",
      "  records to the input log file if it exists.\n",
      "- `auto_augment` - boolean, default=True | Whether to automatically\n",
      "  augment rare classes.\n",
      "- `min_sample_size` - int, default=MIN_SAMPLE_TRAIN | the minimal sample\n",
      "  size when sample=True.\n",
      "- `use_ray` - boolean or dict.\n",
      "  If boolean: default=False | Whether to use ray to run the training\n",
      "  in separate processes. This can be used to prevent OOM for large\n",
      "  datasets, but will incur more overhead in time.\n",
      "  If dict: the dict contains the keywords arguments to be passed to\n",
      "  [ray.tune.run](https://docs.ray.io/en/latest/tune/api_docs/execution.html).\n",
      "- `use_spark` - boolean, default=False | Whether to use spark to run the training\n",
      "  in parallel spark jobs. This can be used to accelerate training on large models\n",
      "  and large datasets, but will incur more overhead in time and thus slow down\n",
      "  training in some cases. GPU training is not supported yet when use_spark is True.\n",
      "  For Spark clusters, by default, we will launch one trial per executor. However,\n",
      "  sometimes we want to launch more trials than the number of executors (e.g., local mode).\n",
      "  In this case, we can set the environment variable `FLAML_MAX_CONCURRENT` to override\n",
      "  the detected `num_executors`. The final number of concurrent trials will be the minimum\n",
      "  of `n_concurrent_trials` and `num_executors`.\n",
      "- `free_mem_ratio` - float between 0 and 1, default=0. The free memory ratio to keep during training.\n",
      "- `metric_constraints` - list, default=[] | The list of metric constraints.\n",
      "  Each element in this list is a 3-tuple, which shall be expressed\n",
      "  in the following format: the first element of the 3-tuple is the name of the\n",
      "  metric, the second element is the inequality sign chosen from \">=\" and \"<=\",\n",
      "  and the third element is the constraint value. E.g., `('val_loss', '<=', 0.1)`.\n",
      "  Note that all the metric names in metric_constraints need to be reported via\n",
      "  the metrics_to_log dictionary returned by a customized metric function.\n",
      "  The customized metric function shall be provided via the `metric` key word\n",
      "  argument of the fit() function or the automl constructor.\n",
      "  Find an example in the 4th constraint type in this [doc](../../Use-Cases/Task-Oriented-AutoML#constraint).\n",
      "  If `pred_time_limit` is provided as one of keyword arguments to fit() function or\n",
      "  the automl constructor, flaml will automatically (and under the hood)\n",
      "  add it as an additional element in the metric_constraints. Essentially 'pred_time_limit'\n",
      "  specifies a constraint about the prediction latency constraint in seconds.\n",
      "- `custom_hp` - dict, default=None | The custom search space specified by user.\n",
      "  It is a nested dict with keys being the estimator names, and values being dicts\n",
      "  per estimator search space. In the per estimator search space dict,\n",
      "  the keys are the hyperparameter names, and values are dicts of info (\"domain\",\n",
      "  \"init_value\", and \"low_cost_init_value\") about the search space associated with\n",
      "  the hyperparameter (i.e., per hyperparameter search space dict). When custom_hp\n",
      "  is provided, the built-in search space which is also a nested dict of per estimator\n",
      "  search space dict, will be updated with custom_hp. Note that during this nested dict update,\n",
      "  the per hyperparameter search space dicts will be replaced (instead of updated) by the ones\n",
      "  provided in custom_hp. Note that the value for \"domain\" can either be a constant\n",
      "  or a sample.Domain object.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "custom_hp = {\n",
      "     \"transformer_ms\": {\n",
      "         \"model_path\": {\n",
      "             \"domain\": \"albert-base-v2\",\n",
      "         },\n",
      "         \"learning_rate\": {\n",
      "             \"domain\": tune.choice([1e-4, 1e-5]),\n",
      "         }\n",
      "     }\n",
      " }\n",
      "```\n",
      "- `skip_transform` - boolean, default=False | Whether to pre-process data prior to modeling.\n",
      "- `fit_kwargs_by_estimator` - dict, default=None | The user specified keywords arguments, grouped by estimator name.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "fit_kwargs_by_estimator = {\n",
      "    \"transformer\": {\n",
      "        \"output_dir\": \"test/data/output/\",\n",
      "        \"fp16\": False,\n",
      "    }\n",
      "}\n",
      "```\n",
      "- `mlflow_logging` - boolean, default=True | Whether to log the training results to mlflow.\n",
      "  This requires mlflow to be installed and to have an active mlflow run.\n",
      "  FLAML will create nested runs.\n",
      "\n",
      "#### config\\_history\n",
      "\n",
      "```python\n",
      "@property\n",
      "def config_history() -> dict\n",
      "```\n",
      "\n",
      "A dictionary of iter->(estimator, config, time),\n",
      "storing the best estimator, config, and the time when the best\n",
      "model is updated each time.\n",
      "\n",
      "#### model\n",
      "\n",
      "```python\n",
      "@property\n",
      "def model()\n",
      "```\n",
      "\n",
      "An object with `predict()` and `predict_proba()` method (for\n",
      "classification), storing the best trained model.\n",
      "\n",
      "#### best\\_model\\_for\\_estimator\n",
      "\n",
      "```python\n",
      "def best_model_for_estimator(estimator_name: str)\n",
      "```\n",
      "\n",
      "Return the best model found for a particular estimator.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `estimator_name` - a str of the estimator's name.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  An object storing the best model for estimator_name.\n",
      "  If `model_history` was set to False during fit(), then the returned model\n",
      "  is untrained unless estimator_name is the best estimator.\n",
      "  If `model_history` was set to True, then the returned model is trained.\n",
      "\n",
      "#### best\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_estimator()\n",
      "```\n",
      "\n",
      "A string indicating the best estimator found.\n",
      "\n",
      "#### best\\_iteration\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_iteration()\n",
      "```\n",
      "\n",
      "An integer of the iteration number where the best\n",
      "config is found.\n",
      "\n",
      "#### best\\_config\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config()\n",
      "```\n",
      "\n",
      "A dictionary of the best configuration.\n",
      "\n",
      "#### best\\_config\\_per\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config_per_estimator()\n",
      "```\n",
      "\n",
      "A dictionary of all estimators' best configuration.\n",
      "\n",
      "#### best\\_loss\\_per\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_loss_per_estimator()\n",
      "```\n",
      "\n",
      "A dictionary of all estimators' best loss.\n",
      "\n",
      "#### best\\_loss\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_loss()\n",
      "```\n",
      "\n",
      "A float of the best loss found.\n",
      "\n",
      "#### best\\_result\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_result()\n",
      "```\n",
      "\n",
      "Result dictionary for model trained with the best config.\n",
      "\n",
      "#### metrics\\_for\\_best\\_config\n",
      "\n",
      "```python\n",
      "@property\n",
      "def metrics_for_best_config()\n",
      "```\n",
      "\n",
      "Returns a float of the best loss, and a dictionary of the auxiliary metrics to log\n",
      "associated with the best config. These two objects correspond to the returned\n",
      "objects by the customized metric function for the config with the best loss.\n",
      "\n",
      "#### best\\_config\\_train\\_time\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config_train_time()\n",
      "```\n",
      "\n",
      "new_automl = AutoML()\n",
      "new_automl.fit(X_train, y_train, starting_points=starting_points)\n",
      "```\n",
      "  \n",
      "- `seed` - int or None, default=None | The random seed for hpo.\n",
      "- `n_concurrent_trials` - [Experimental] int, default=1 | The number of\n",
      "  concurrent trials. When n_concurrent_trials > 1, flaml performes\n",
      "  [parallel tuning](../../Use-Cases/Task-Oriented-AutoML#parallel-tuning)\n",
      "  and installation of ray or spark is required: `pip install flaml[ray]`\n",
      "  or `pip install flaml[spark]`. Please check\n",
      "  [here](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
      "  for more details about installing Spark.\n",
      "- `keep_search_state` - boolean, default=False | Whether to keep data needed\n",
      "  for model search after fit(). By default the state is deleted for\n",
      "  space saving.\n",
      "- `preserve_checkpoint` - boolean, default=True | Whether to preserve the saved checkpoint\n",
      "  on disk when deleting automl. By default the checkpoint is preserved.\n",
      "- `early_stop` - boolean, default=False | Whether to stop early if the\n",
      "  search is considered to converge.\n",
      "- `force_cancel` - boolean, default=False | Whether to forcely cancel the PySpark job if overtime.\n",
      "- `append_log` - boolean, default=False | Whetehr to directly append the log\n",
      "  records to the input log file if it exists.\n",
      "- `auto_augment` - boolean, default=True | Whether to automatically\n",
      "  augment rare classes.\n",
      "- `min_sample_size` - int, default=MIN_SAMPLE_TRAIN | the minimal sample\n",
      "  size when sample=True.\n",
      "- `use_ray` - boolean or dict.\n",
      "  If boolean: default=False | Whether to use ray to run the training\n",
      "  in separate processes. This can be used to prevent OOM for large\n",
      "  datasets, but will incur more overhead in time.\n",
      "  If dict: the dict contains the keywords arguments to be passed to\n",
      "  [ray.tune.run](https://docs.ray.io/en/latest/tune/api_docs/execution.html).\n",
      "- `use_spark` - boolean, default=False | Whether to use spark to run the training\n",
      "  in parallel spark jobs. This can be used to accelerate training on large models\n",
      "  and large datasets, but will incur more overhead in time and thus slow down\n",
      "  training in some cases.\n",
      "- `free_mem_ratio` - float between 0 and 1, default=0. The free memory ratio to keep during training.\n",
      "- `metric_constraints` - list, default=[] | The list of metric constraints.\n",
      "  Each element in this list is a 3-tuple, which shall be expressed\n",
      "  in the following format: the first element of the 3-tuple is the name of the\n",
      "  metric, the second element is the inequality sign chosen from \">=\" and \"<=\",\n",
      "  and the third element is the constraint value. E.g., `('precision', '>=', 0.9)`.\n",
      "  Note that all the metric names in metric_constraints need to be reported via\n",
      "  the metrics_to_log dictionary returned by a customized metric function.\n",
      "  The customized metric function shall be provided via the `metric` key word argument\n",
      "  of the fit() function or the automl constructor.\n",
      "  Find examples in this [test](https://github.com/microsoft/FLAML/tree/main/test/automl/test_constraints.py).\n",
      "  If `pred_time_limit` is provided as one of keyword arguments to fit() function or\n",
      "  the automl constructor, flaml will automatically (and under the hood)\n",
      "  add it as an additional element in the metric_constraints. Essentially 'pred_time_limit'\n",
      "  specifies a constraint about the prediction latency constraint in seconds.\n",
      "- `custom_hp` - dict, default=None | The custom search space specified by user\n",
      "  Each key is the estimator name, each value is a dict of the custom search space for that estimator. Notice the\n",
      "  domain of the custom search space can either be a value of a sample.Domain object.\n",
      "  \n",
      "  \n",
      "  \n",
      "```python\n",
      "custom_hp = {\n",
      "    \"transformer_ms\": {\n",
      "        \"model_path\": {\n",
      "            \"domain\": \"albert-base-v2\",\n",
      "        },\n",
      "        \"learning_rate\": {\n",
      "            \"domain\": tune.choice([1e-4, 1e-5]),\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "- `time_col` - for a time series task, name of the column containing the timestamps. If not\n",
      "  provided, defaults to the first column of X_train/X_val\n",
      "  \n",
      "- `cv_score_agg_func` - customized cross-validation scores aggregate function. Default to average metrics across folds. If specificed, this function needs to\n",
      "  have the following input arguments:\n",
      "  \n",
      "  * val_loss_folds: list of floats, the loss scores of each fold;\n",
      "  * log_metrics_folds: list of dicts/floats, the metrics of each fold to log.\n",
      "  \n",
      "  This function should return the final aggregate result of all folds. A float number of the minimization objective, and a dictionary as the metrics to log or None.\n",
      "  E.g.,\n",
      "  \n",
      "```python\n",
      "def cv_score_agg_func(val_loss_folds, log_metrics_folds):\n",
      "    metric_to_minimize = sum(val_loss_folds)/len(val_loss_folds)\n",
      "    metrics_to_log = None\n",
      "    for single_fold in log_metrics_folds:\n",
      "        if metrics_to_log is None:\n",
      "            metrics_to_log = single_fold\n",
      "        elif isinstance(metrics_to_log, dict):\n",
      "            metrics_to_log = {k: metrics_to_log[k] + v for k, v in single_fold.items()}\n",
      "        else:\n",
      "            metrics_to_log += single_fold\n",
      "    if metrics_to_log:\n",
      "        n = len(val_loss_folds)\n",
      "        metrics_to_log = (\n",
      "            {k: v / n for k, v in metrics_to_log.items()}\n",
      "            if isinstance(metrics_to_log, dict)\n",
      "            else metrics_to_log / n\n",
      "        )\n",
      "    return metric_to_minimize, metrics_to_log\n",
      "```\n",
      "  \n",
      "- `skip_transform` - boolean, default=False | Whether to pre-process data prior to modeling.\n",
      "- `mlflow_logging` - boolean, default=None | Whether to log the training results to mlflow.\n",
      "  Default value is None, which means the logging decision is made based on\n",
      "  AutoML.__init__'s mlflow_logging argument.\n",
      "  This requires mlflow to be installed and to have an active mlflow run.\n",
      "  FLAML will create nested runs.\n",
      "- `fit_kwargs_by_estimator` - dict, default=None | The user specified keywords arguments, grouped by estimator name.\n",
      "  For TransformersEstimator, available fit_kwargs can be found from\n",
      "  [TrainingArgumentsForAuto](nlp/huggingface/training_args).\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "fit_kwargs_by_estimator = {\n",
      "    \"transformer\": {\n",
      "        \"output_dir\": \"test/data/output/\",\n",
      "        \"fp16\": False,\n",
      "    },\n",
      "    \"tft\": {\n",
      "        \"max_encoder_length\": 1,\n",
      "        \"min_encoder_length\": 1,\n",
      "        \"static_categoricals\": [],\n",
      "        \"static_reals\": [],\n",
      "        \"time_varying_known_categoricals\": [],\n",
      "        \"time_varying_known_reals\": [],\n",
      "        \"time_varying_unknown_categoricals\": [],\n",
      "        \"time_varying_unknown_reals\": [],\n",
      "        \"variable_groups\": {},\n",
      "        \"lags\": {},\n",
      "    }\n",
      "}\n",
      "```\n",
      "  \n",
      "- `**fit_kwargs` - Other key word arguments to pass to fit() function of\n",
      "  the searched learners, such as sample_weight. Below are a few examples of\n",
      "  estimator-specific parameters:\n",
      "- `period` - int | forecast horizon for all time series forecast tasks.\n",
      "- `gpu_per_trial` - float, default = 0 | A float of the number of gpus per trial,\n",
      "  only used by TransformersEstimator, XGBoostSklearnEstimator, and\n",
      "  TemporalFusionTransformerEstimator.\n",
      "- `group_ids` - list of strings of column names identifying a time series, only\n",
      "  used by TemporalFusionTransformerEstimator, required for\n",
      "  'ts_forecast_panel' task. `group_ids` is a parameter for TimeSeriesDataSet object\n",
      "  from PyTorchForecasting.\n",
      "  For other parameters to describe your dataset, refer to\n",
      "  [TimeSeriesDataSet PyTorchForecasting](https://pytorch-forecasting.readthedocs.io/en/stable/api/pytorch_forecasting.data.timeseries.TimeSeriesDataSet.html).\n",
      "  To specify your variables, use `static_categoricals`, `static_reals`,\n",
      "  `time_varying_known_categoricals`, `time_varying_known_reals`,\n",
      "  `time_varying_unknown_categoricals`, `time_varying_unknown_reals`,\n",
      "  `variable_groups`. To provide more information on your data, use\n",
      "  `max_encoder_length`, `min_encoder_length`, `lags`.\n",
      "- `log_dir` - str, default = \"lightning_logs\" | Folder into which to log results\n",
      "  for tensorboard, only used by TemporalFusionTransformerEstimator.\n",
      "- `max_epochs` - int, default = 20 | Maximum number of epochs to run training,\n",
      "  only used by TemporalFusionTransformerEstimator.\n",
      "- `batch_size` - int, default = 64 | Batch size for training model, only\n",
      "  used by TemporalFusionTransformerEstimator.\n",
      "\n",
      "\n",
      "---\n",
      "sidebar_label: tune\n",
      "title: tune.tune\n",
      "---\n",
      "\n",
      "## ExperimentAnalysis Objects\n",
      "\n",
      "```python\n",
      "class ExperimentAnalysis(EA)\n",
      "```\n",
      "\n",
      "Class for storing the experiment results.\n",
      "\n",
      "#### report\n",
      "\n",
      "```python\n",
      "def report(_metric=None, **kwargs)\n",
      "```\n",
      "\n",
      "A function called by the HPO application to report final or intermediate\n",
      "results.\n",
      "\n",
      "**Example**:\n",
      "\n",
      "  \n",
      "```python\n",
      "import time\n",
      "from flaml import tune\n",
      "\n",
      "def compute_with_config(config):\n",
      "    current_time = time.time()\n",
      "    metric2minimize = (round(config['x'])-95000)**2\n",
      "    time2eval = time.time() - current_time\n",
      "    tune.report(metric2minimize=metric2minimize, time2eval=time2eval)\n",
      "\n",
      "analysis = tune.run(\n",
      "    compute_with_config,\n",
      "    config={\n",
      "        'x': tune.lograndint(lower=1, upper=1000000),\n",
      "        'y': tune.randint(lower=1, upper=1000000)\n",
      "    },\n",
      "    metric='metric2minimize', mode='min',\n",
      "    num_samples=1000000, time_budget_s=60, use_ray=False)\n",
      "\n",
      "print(analysis.trials[-1].last_result)\n",
      "```\n",
      "  \n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `_metric` - Optional default anonymous metric for ``tune.report(value)``.\n",
      "  (For compatibility with ray.tune.report)\n",
      "- `**kwargs` - Any key value pair to be reported.\n",
      "  \n",
      "\n",
      "**Raises**:\n",
      "\n",
      "  StopIteration (when not using ray, i.e., _use_ray=False):\n",
      "  A StopIteration exception is raised if the trial has been signaled to stop.\n",
      "  SystemExit (when using ray):\n",
      "  A SystemExit exception is raised if the trial has been signaled to stop by ray.\n",
      "\n",
      "#### run\n",
      "\n",
      "```python\n",
      "def run(evaluation_function,\n",
      "        config: Optional[dict] = None,\n",
      "        low_cost_partial_config: Optional[dict] = None,\n",
      "        cat_hp_cost: Optional[dict] = None,\n",
      "        metric: Optional[str] = None,\n",
      "        mode: Optional[str] = None,\n",
      "        time_budget_s: Union[int, float] = None,\n",
      "        points_to_evaluate: Optional[List[dict]] = None,\n",
      "        evaluated_rewards: Optional[List] = None,\n",
      "        resource_attr: Optional[str] = None,\n",
      "        min_resource: Optional[float] = None,\n",
      "        max_resource: Optional[float] = None,\n",
      "        reduction_factor: Optional[float] = None,\n",
      "        scheduler=None,\n",
      "        search_alg=None,\n",
      "        verbose: Optional[int] = 2,\n",
      "        local_dir: Optional[str] = None,\n",
      "        num_samples: Optional[int] = 1,\n",
      "        resources_per_trial: Optional[dict] = None,\n",
      "        config_constraints: Optional[List[Tuple[Callable[[dict], float], str,\n",
      "                                                float]]] = None,\n",
      "        metric_constraints: Optional[List[Tuple[str, str, float]]] = None,\n",
      "        max_failure: Optional[int] = 100,\n",
      "        use_ray: Optional[bool] = False,\n",
      "        use_spark: Optional[bool] = False,\n",
      "        use_incumbent_result_in_evaluation: Optional[bool] = None,\n",
      "        log_file_name: Optional[str] = None,\n",
      "        lexico_objectives: Optional[dict] = None,\n",
      "        force_cancel: Optional[bool] = False,\n",
      "        n_concurrent_trials: Optional[int] = 0,\n",
      "        **ray_args)\n",
      "```\n",
      "\n",
      "The function-based way of performing HPO.\n",
      "\n",
      "**Example**:\n",
      "\n",
      "  \n",
      "```python\n",
      "import time\n",
      "from flaml import tune\n",
      "\n",
      "def compute_with_config(config):\n",
      "    current_time = time.time()\n",
      "    metric2minimize = (round(config['x'])-95000)**2\n",
      "    time2eval = time.time() - current_time\n",
      "    tune.report(metric2minimize=metric2minimize, time2eval=time2eval)\n",
      "    # if the evaluation fails unexpectedly and the exception is caught,\n",
      "    # and it doesn't inform the goodness of the config,\n",
      "    # return {}\n",
      "    # if the failure indicates a config is bad,\n",
      "    # report a bad metric value like np.inf or -np.inf\n",
      "    # depending on metric mode being min or max\n",
      "\n",
      "analysis = tune.run(\n",
      "    compute_with_config,\n",
      "    config={\n",
      "        'x': tune.lograndint(lower=1, upper=1000000),\n",
      "        'y': tune.randint(lower=1, upper=1000000)\n",
      "    },\n",
      "    metric='metric2minimize', mode='min',\n",
      "    num_samples=-1, time_budget_s=60, use_ray=False)\n",
      "\n",
      "print(analysis.trials[-1].last_result)\n",
      "```\n",
      "  \n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `evaluation_function` - A user-defined evaluation function.\n",
      "  It takes a configuration as input, outputs a evaluation\n",
      "  result (can be a numerical value or a dictionary of string\n",
      "  and numerical value pairs) for the input configuration.\n",
      "  For machine learning tasks, it usually involves training and\n",
      "  scoring a machine learning model, e.g., through validation loss.\n",
      "- `config` - A dictionary to specify the search space.\n",
      "- `low_cost_partial_config` - A dictionary from a subset of\n",
      "  controlled dimensions to the initial low-cost values.\n",
      "  e.g., ```{'n_estimators': 4, 'max_leaves': 4}```\n",
      "  \n",
      "- `cat_hp_cost` - A dictionary from a subset of categorical dimensions\n",
      "  to the relative cost of each choice.\n",
      "  e.g., ```{'tree_method': [1, 1, 2]}```\n",
      "  i.e., the relative cost of the\n",
      "  three choices of 'tree_method' is 1, 1 and 2 respectively\n",
      "- `metric` - A string of the metric name to optimize for.\n",
      "- `mode` - A string in ['min', 'max'] to specify the objective as\n",
      "  minimization or maximization.\n",
      "- `time_budget_s` - int or float | The time budget in seconds.\n",
      "- `points_to_evaluate` - A list of initial hyperparameter\n",
      "  configurations to run first.\n",
      "- `evaluated_rewards` _list_ - If you have previously evaluated the\n",
      "  parameters passed in as points_to_evaluate you can avoid\n",
      "  re-running those trials by passing in the reward attributes\n",
      "  as a list so the optimiser can be told the results without\n",
      "  needing to re-compute the trial. Must be the same or shorter length than\n",
      "  points_to_evaluate.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "points_to_evaluate = [\n",
      "    {\"b\": .99, \"cost_related\": {\"a\": 3}},\n",
      "    {\"b\": .99, \"cost_related\": {\"a\": 2}},\n",
      "]\n",
      "evaluated_rewards = [3.0]\n",
      "```\n",
      "  \n",
      "  means that you know the reward for the first config in\n",
      "  points_to_evaluate is 3.0 and want to inform run().\n",
      "  \n",
      "- `resource_attr` - A string to specify the resource dimension used by\n",
      "  the scheduler via \"scheduler\".\n",
      "- `min_resource` - A float of the minimal resource to use for the resource_attr.\n",
      "- `max_resource` - A float of the maximal resource to use for the resource_attr.\n",
      "- `reduction_factor` - A float of the reduction factor used for incremental\n",
      "  pruning.\n",
      "- `scheduler` - A scheduler for executing the experiment. Can be None, 'flaml',\n",
      "  'asha' (or  'async_hyperband', 'asynchyperband') or a custom instance of the TrialScheduler class. Default is None:\n",
      "  in this case when resource_attr is provided, the 'flaml' scheduler will be\n",
      "  used, otherwise no scheduler will be used. When set 'flaml', an\n",
      "  authentic scheduler implemented in FLAML will be used. It does not\n",
      "  require users to report intermediate results in evaluation_function.\n",
      "  Find more details about this scheduler in this paper\n",
      "  https://arxiv.org/pdf/1911.04706.pdf).\n",
      "  When set 'asha', the input for arguments \"resource_attr\",\n",
      "  \"min_resource\", \"max_resource\" and \"reduction_factor\" will be passed\n",
      "  to ASHA's \"time_attr\",  \"max_t\", \"grace_period\" and \"reduction_factor\"\n",
      "  respectively. You can also provide a self-defined scheduler instance\n",
      "  of the TrialScheduler class. When 'asha' or self-defined scheduler is\n",
      "  used, you usually need to report intermediate results in the evaluation\n",
      "  function via 'tune.report()'.\n",
      "  If you would like to do some cleanup opearation when the trial is stopped\n",
      "  by the scheduler, you can catch the `StopIteration` (when not using ray)\n",
      "  or `SystemExit` (when using ray) exception explicitly,\n",
      "  as shown in the following example.\n",
      "  Please find more examples using different types of schedulers\n",
      "  and how to set up the corresponding evaluation functions in\n",
      "  test/tune/test_scheduler.py, and test/tune/example_scheduler.py.\n",
      "```python\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[flaml.autogen.oai.completion: 08-08 07:37:13] {212} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/datadrive/FLAML/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.10/site-packages/openai/api_requestor.py\", line 743, in _interpret_response_line\n",
      "    raise error.ServiceUnavailableError(\n",
      "openai.error.ServiceUnavailableError: The server is overloaded or not ready yet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/datadrive/FLAML/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.10/site-packages/openai/api_requestor.py\", line 743, in _interpret_response_line\n",
      "    raise error.ServiceUnavailableError(\n",
      "openai.error.ServiceUnavailableError: The server is overloaded or not ready yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-08 07:37:23] {212} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/datadrive/FLAML/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.10/site-packages/openai/api_requestor.py\", line 743, in _interpret_response_line\n",
      "    raise error.ServiceUnavailableError(\n",
      "openai.error.ServiceUnavailableError: The server is overloaded or not ready yet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/datadrive/FLAML/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.10/site-packages/openai/api_requestor.py\", line 743, in _interpret_response_line\n",
      "    raise error.ServiceUnavailableError(\n",
      "openai.error.ServiceUnavailableError: The server is overloaded or not ready yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant (to ragproxyagent):\n",
      "\n",
      "There doesn't seem to be a function named `tune_automl` in the FLAML library. However, there is a `tune.run` function available for hyperparameter optimization, and you can use the AutoML class from the FLAML library to perform automated machine learning tasks. If you have a specific question or need help regarding the usage of FLAML, feel free to ask.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "There doesn't seem to be a function named `tune_automl` in the FLAML library. However, there is a `tune.run` function available for hyperparameter optimization, and you can use the AutoML class from the FLAML library to perform automated machine learning tasks. If you have a specific question or need help regarding the usage of FLAML, feel free to ask.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# reset the assistant. Always reset the assistant before starting a new conversation.\n",
    "assistant.reset()\n",
    "\n",
    "# set `human_input_mode` to be `ALWAYS`, so the agent will ask for human input at every step.\n",
    "ragproxyagent.human_input_mode = \"ALWAYS\"\n",
    "qa_problem = \"Is there a function named `tune_automl` in FLAML?\"\n",
    "ragproxyagent.initiate_chat(assistant, problem=qa_problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5\n",
    "\n",
    "Use RetrieveChat to do QA for HotpotQA dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file = \"/datadrive/FLAML/evaluation/retrievechat/NaturalQuestion/naturalquestionsshortqa/corpus.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new collection for HotpotQA dataset\n",
    "ragproxyagent = RetrieveUserProxyAgent(\n",
    "    name=\"ragproxyagent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    retrieve_config={\n",
    "        \"docs_path\": corpus_file,\n",
    "        \"chunk_token_size\": 4900,\n",
    "        \"model\": config_list[0][\"model\"],\n",
    "        \"client\": chromadb.PersistentClient(path=\"/tmp/chromadb\"),\n",
    "        \"collection_name\": \"natural-questions\",\n",
    "        \"chunk_mode\": \"one_line\",\n",
    "        \"embedding_model\": \"all-MiniLM-L6-v2\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_file = \"/datadrive/FLAML/evaluation/retrievechat/NaturalQuestion/naturalquestionsshortqa/queries.jsonl\"\n",
    "\n",
    "with open(queries_file, \"r\") as f:\n",
    "    queries = [json.loads(line) for line in f.readlines()]\n",
    "    questions = [q[\"text\"] for q in queries]\n",
    "    answers = [q[\"metadata\"][\"answer\"] for q in queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is non controlling interest on balance sheet [\"the portion of a subsidiary corporation 's stock that is not owned by the parent corporation\"]\n",
      "how many episodes are in chicago fire season 4 ['23']\n",
      "who sings love will keep us alive by the eagles ['Timothy B. Schmit']\n",
      "who is the leader of the ontario pc party ['Patrick Walter Brown']\n",
      "where did the last name keith come from ['from Keith in East Lothian , Scotland', \"from a nickname , derived from the Middle High German kīt , a word meaning `` sprout '' , `` offspring ''\"]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(questions[i], answers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_ids:  [['doc_0', 'doc_155', 'doc_19', 'doc_196', 'doc_140']]\n",
      "Adding doc_id doc_0 to context.\n",
      "Adding doc_id doc_155 to context.\n",
      "ragproxyagent (to assistant):\n",
      "\n",
      "You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user. You should follow the following steps to answer a question:\n",
      "Step 1, you estimate the user's intent based on the question and context. The intent can be a code generation task or\n",
      "a question answering task.\n",
      "Step 2, you reply based on the intent.\n",
      "You should leverage the context provided by the user as much as possible. If you need more context, you should reply \n",
      "\"UPDATE CONTEXT\".\n",
      "For code generation task, you must obey the following rules:\n",
      "Rule 1. You MUST NOT install any packages because all the packages needed are already installed.\n",
      "Rule 2. You must follow the formats below to write your code:\n",
      "```language\n",
      "# your code\n",
      "```\n",
      "\n",
      "For question answering task, you must give as short an answer as possible.\n",
      "\n",
      "User's question is: what is non controlling interest on balance sheet\n",
      "\n",
      "Context is: <P> In accounting , minority interest ( or non-controlling interest ) is the portion of a subsidiary corporation 's stock that is not owned by the parent corporation . The magnitude of the minority interest in the subsidiary company is generally less than 50 % of outstanding shares , or the corporation would generally cease to be a subsidiary of the parent . </P>\n",
      "<Table> <Tr> <Th colspan=\"4\"> Leading foreign holders of US Treasury securities as of August 2017 </Th> </Tr> <Tr> <Th> Country </Th> <Th> Billions of dollars ( est . ) </Th> <Th> Ratio of owned US debt to 2016 GDP ( est . ) </Th> <Th> Percent change since August 2016 </Th> </Tr> <Tr> <Td> China </Td> <Td> 1,200.5 </Td> <Td> 6 % </Td> <Td> + 1 % </Td> </Tr> <Tr> <Td> Japan </Td> <Td> 1,101.7 </Td> <Td> 22 % </Td> <Td> − 4 % </Td> </Tr> <Tr> <Td> Ireland </Td> <Td> 307.2 </Td> <Td> 105 % </Td> <Td> + 15 % </Td> </Tr> <Tr> <Td> Brazil </Td> <Td> 273.6 </Td> <Td> 15 % </Td> <Td> + 7 % </Td> </Tr> <Tr> <Td> Cayman Islands </Td> <Td> 260.0 </Td> <Td> n / a </Td> <Td> − 2 % </Td> </Tr> <Tr> <Td> Switzerland </Td> <Td> 248.3 </Td> <Td> 38 % </Td> <Td> + 4 % </Td> </Tr> <Tr> <Td> United Kingdom </Td> <Td> 225.4 </Td> <Td> 9 % </Td> <Td> + 10 % </Td> </Tr> <Tr> <Td> Luxembourg </Td> <Td> 213.4 </Td> <Td> 359 % </Td> <Td> − 3 % </Td> </Tr> <Tr> <Td> Hong Kong </Td> <Td> 197.3 </Td> <Td> 62 % </Td> <Td> + 3 % </Td> </Tr> <Tr> <Td> Taiwan </Td> <Td> 180.4 </Td> <Td> 34 % </Td> <Td> -- 5 % </Td> </Tr> <Tr> <Td> Others </Td> <Td> 2,061.9 </Td> <Td> n / a </Td> <Td> + 1 % </Td> </Tr> <Tr> <Th> Grand total </Th> <Th> 6,269.7 </Th> <Th> n / a </Th> <Th> + 1 % </Th> </Tr> </Table>\n",
      "<P> The name -- elevator pitch -- reflects the idea that it should be possible to deliver the summary in the time span of an elevator ride , or approximately thirty seconds to two minutes . </P>\n",
      "<P> SAARC was founded in Dhaka on 8 December 1985 . Its secretariat is based in Kathmandu , Nepal . The organization promotes development of economic and regional integration . It launched the South Asian Free Trade Area in 2006 . SAARC maintains permanent diplomatic relations at the United Nations as an observer and has developed links with multilateral entities , including the European Union . </P>\n",
      "<P> Seth MacFarlane voices three of the show 's main characters : Peter Griffin , Brian Griffin , and Stewie Griffin . MacFarlane chose to voice these characters himself , believing it would be easier to portray the voices he had already envisioned than for someone else to attempt it . MacFarlane drew inspiration for the voice of Peter from a security guard he overheard talking while attending the Rhode Island School of Design . Stewie 's voice was based on the voice of English actor Rex Harrison , especially his performance in the 1964 musical drama film My Fair Lady . MacFarlane uses his own voice while portraying Brian . </P>\n",
      "<P> The cup is an English unit of volume , most commonly associated with cooking and serving sizes . It is traditionally equal to half a liquid pint in either US customary units or the British imperial system but is now separately defined in terms of the metric system at values between ⁄ and ⁄ of a liter . Because actual drinking cups may differ greatly from the size of this unit , standard measuring cups are usually used instead . </P>\n",
      "<Table> <Tr> <Th> Year </Th> <Th> Coach </Th> <Th> Super Bowl </Th> <Th> Location </Th> <Th> Opponent </Th> <Th> Score </Th> <Th> Record </Th> </Tr> <Tr> <Td> 1981 </Td> <Td> Bill Walsh </Td> <Td> XVI </Td> <Td> Pontiac , Michigan </Td> <Td> Cincinnati Bengals </Td> <Td> 26 -- 21 </Td> <Td> 16 -- 3 </Td> </Tr> <Tr> <Td> 1984 </Td> <Td> Bill Walsh </Td> <Td> XIX </Td> <Td> Stanford , California </Td> <Td> Miami Dolphins </Td> <Td> 38 -- 16 </Td> <Td> 18 -- 1 </Td> </Tr> <Tr> <Td> 1988 </Td> <Td> Bill Walsh </Td> <Td> XXIII </Td> <Td> Miami </Td> <Td> Cincinnati Bengals </Td> <Td> 20 -- 16 </Td> <Td> 13 -- 6 </Td> </Tr> <Tr> <Td> 1989 </Td> <Td> George Seifert </Td> <Td> XXIV </Td> <Td> New Orleans </Td> <Td> Denver Broncos </Td> <Td> 55 -- 10 </Td> <Td> 17 -- 2 </Td> </Tr> <Tr> <Td> 1994 </Td> <Td> George Seifert </Td> <Td> XXIX </Td> <Td> Miami </Td> <Td> San Diego Chargers </Td> <Td> 49 -- 26 </Td> <Td> 16 -- 3 </Td> </Tr> <Tr> <Td colspan=\"5\"> Total Super Bowls won : </Td> <Td colspan=\"2\"> 5 </Td> </Tr> </Table>\n",
      "<P> `` Would I Lie to You ? '' is an R&B song by American duo Charles & Eddie . Written by Mike Leeson and Peter Vale and produced by Josh Deutsch , `` Would I Lie to You ? '' was the debut single by the pop - soul duo , and it proved to be their biggest hit . A major international success , it reached number one on the UK Singles Chart for two weeks in November 1992 , and was also number one in New Zealand , Germany and Austria . It was a top five hit in several other European countries while in Australia and Canada it went to number 3 . The single became a Top 20 hit in the US , peaking at number 13 on the Billboard Hot 100 and it enjoyed award - winning sales , earning a platinum record in the UK , a gold record in both Germany and Austria and silver record award in France . </P>\n",
      "<P> The Lord of the Rings is a film series consisting of three high fantasy adventure films directed by Peter Jackson . They are based on the novel The Lord of the Rings by J.R.R. Tolkien . The films are subtitled The Fellowship of the Ring ( 2001 ) , The Two Towers ( 2002 ) and The Return of the King ( 2003 ) . They are a New Zealand - American venture produced by WingNut Films and The Saul Zaentz Company and distributed by New Line Cinema . </P>\n",
      "<Table> <Tr> <Th> NYHA Class </Th> <Th> Symptoms </Th> </Tr> <Tr> <Td> </Td> <Td> Cardiac disease , but no symptoms and no limitation in ordinary physical activity , e.g. no shortness of breath when walking , climbing stairs etc . </Td> </Tr> <Tr> <Td> II </Td> <Td> Mild symptoms ( mild shortness of breath and / or angina ) and slight limitation during ordinary activity . </Td> </Tr> <Tr> <Td> III </Td> <Td> Marked limitation in activity due to symptoms , even during less - than - ordinary activity , e.g. walking short distances ( 20 -- 100 m ) . Comfortable only at rest . </Td> </Tr> <Tr> <Td> IV </Td> <Td> Severe limitations . Experiences symptoms even while at rest . Mostly bedbound patients . </Td> </Tr> </Table>\n",
      "<P> Spanish moss ( Tillandsia usneoides ) is an epiphytic flowering plant that often grows upon larger trees in tropical and subtropical climates , native to much of Mexico , Bermuda , the Bahamas , Central America , South America , the southern United States , and the West Indies as well as being naturalized in Queensland ( Australia ) known as `` grandpas beard '' and in French Polynesia . In the United States from where it is most known , it is commonly found on the southern live oak ( Quercus virginiana ) and bald - cypress ( Taxodium distichum ) in the lowlands , swamps , and savannas of the southeastern United States from Texas and Florida north through southern Arkansas . </P>\n",
      "<Table> <Tr> <Td> Best Picture <Ul> <Li> Titanic -- James Cameron and Jon Landau , producers <Ul> <Li> As Good as It Gets -- James L. Brooks , Bridgit Johnson and Kristi Zea , producers </Li> <Li> The Full Monty -- Uberto Pasolini , producer </Li> <Li> Good Will Hunting -- Lawrence Bender , producer </Li> <Li> L.A. Confidential -- Arnon Milchan , Curtis Hanson and Michael Nathanson , producers </Li> </Ul> </Li> </Ul> </Td> <Td> Best Director <Ul> <Li> James Cameron -- Titanic <Ul> <Li> Peter Cattaneo -- The Full Monty </Li> <Li> Gus Van Sant -- Good Will Hunting </Li> <Li> Curtis Hanson -- L.A. Confidential </Li> <Li> Atom Egoyan -- The Sweet Hereafter </Li> </Ul> </Li> </Ul> </Td> </Tr> <Tr> <Td> Best Actor <Ul> <Li> Jack Nicholson -- As Good as It Gets as Melvin Udall <Ul> <Li> Matt Damon -- Good Will Hunting as Will Hunting </Li> <Li> Robert Duvall -- The Apostle as Euliss `` Sonny '' Dewey , a.k.a. `` The Apostle E.F. '' </Li> <Li> Peter Fonda -- Ulee 's Gold as Ulysses `` Ulee '' Jackson </Li> <Li> Dustin Hoffman -- Wag the Dog as Stanley Motss </Li> </Ul> </Li> </Ul> </Td> <Td> Best Actress <Ul> <Li> Helen Hunt -- As Good as It Gets as Carol Connelly <Ul> <Li> Helena Bonham Carter -- The Wings of the Dove as Kate Croy </Li> <Li> Julie Christie -- Afterglow as Phyllis Mann </Li> <Li> Judi Dench -- Mrs Brown as Queen Victoria </Li> <Li> Kate Winslet -- Titanic as Rose DeWitt Bukater </Li> </Ul> </Li> </Ul> </Td> </Tr> <Tr> <Td> Best Supporting Actor <Ul> <Li> Robin Williams -- Good Will Hunting as Dr. Sean Maguire <Ul> <Li> Robert Forster -- Jackie Brown as Max Cherry </Li> <Li> Anthony Hopkins -- Amistad as John Quincy Adams </Li> <Li> Greg Kinnear -- As Good as It Gets as Simon Bishop </Li> <Li> Burt Reynolds -- Boogie Nights as Jack Horner </Li> </Ul> </Li> </Ul> </Td> <Td> Best Supporting Actress <Ul> <Li> Kim Basinger -- L.A. Confidential as Lynn Bracken <Ul> <Li> Joan Cusack -- In & Out as Emily Montgomery </Li> <Li> Minnie Driver -- Good Will Hunting as Skylar </Li> <Li> Julianne Moore -- Boogie Nights as Amber Waves / Maggie </Li> <Li> Gloria Stuart -- Titanic as Rose Dawson Calvert </Li> </Ul> </Li> </Ul> </Td> </Tr> <Tr> <Td> Best Original Screenplay / Screenplay Written Directly for the Screen <Ul> <Li> Good Will Hunting -- Matt Damon and Ben Affleck <Ul> <Li> As Good as It Gets -- Mark Andrus and James L. Brooks </Li> <Li> Boogie Nights -- Paul Thomas Anderson </Li> <Li> Deconstructing Harry -- Woody Allen </Li> <Li> The Full Monty -- Simon Beaufoy </Li> </Ul> </Li> </Ul> </Td> <Td> Best Screenplay Based on Material Previously Produced or Published <Ul> <Li> L.A. Confidential -- Brian Helgeland and Curtis Hanson from the novel by James Ellroy <Ul> <Li> Donnie Brasco -- Paul Attanasio based on the book Donnie Brasco : My Undercover Life in the Mafia by Joseph D. Pistone with Richard Woodley </Li> <Li> The Sweet Hereafter -- Atom Egoyan adapted from the novel by Russell Banks </Li> <Li> Wag the Dog -- David Mamet and Hilary Henkin from the novel American Hero by Larry Beinhart </Li> <Li> The Wings of the Dove -- Hossein Amini adapted from the novel by Henry James </Li> </Ul> </Li> </Ul> </Td> </Tr> <Tr> <Td> Best Foreign Language Film <Ul> <Li> Karakter ( Netherlands ) in Dutch -- Mike van Diem <Ul> <Li> Beyond Silence ( Germany ) in German -- Caroline Link </Li> <Li> Four Days in September ( Brazil ) in Portuguese -- Bruno Barreto </Li> <Li> Secrets of the Heart ( Spain ) in Spanish -- Montxo Armendáriz </Li> <Li> The Thief ( Russia ) in Russian -- Pavel Chukhray </Li> </Ul> </Li> </Ul> </Td> </Tr> <Tr> <Td> Best Documentary Feature <Ul> <Li> The Long Way Home -- Rabbi Marvin Hier and Richard Trank <Ul> <Li> 4 Little Girls -- Spike Lee and Sam Pollard </Li> <Li> Ayn Rand : A Sense of Life -- Michael Paxton </Li> <Li> Colors Straight Up -- Michèle Ohayon and Julia Schachter </Li> <Li> Waco : The Rules of Engagement -- Dan Gifford and William Gazecki </Li> </Ul> </Li> </Ul> </Td> <Td> Best Documentary Short Subject <Ul> <Li> A Story of Healing -- Donna Dewey and Carol Pasternak <Ul> <Li> Alaska : Spirit of the Wild -- George Casey and Paul Novros </Li> <Li> Amazon -- Kieth Merrill and Jonathan Stern </Li> <Li> Family Video Diaries : Daughter of the Bride -- Terri Randall </Li> <Li> Still Kicking : The Fabulous Palm Springs Follies -- Mel Damski and Andrea Blaugrund </Li> </Ul> </Li> </Ul> </Td> </Tr> <Tr> <Td> Best Live Action Short Film <Ul> <Li> Visas\n",
      "<P> The Impeachment of Andrew Johnson occurred in 1868 , when the United States House of Representatives resolved to impeach President Andrew Johnson , adopting eleven articles of impeachment detailing his `` high crimes and misdemeanors , '' in accordance with Article Two of the United States Constitution . The House 's primary charge against Johnson was violation of the Tenure of Office Act , passed by the U.S. Congress in March 1867 , over the president 's veto . Specifically , he had removed from office Edwin M. Stanton , the Secretary of War -- whom the Act was largely designed to protect -- and attempted to replace him with Brevet Major General Lorenzo Thomas ( Earlier , while Congress was not in session , Johnson had suspended Stanton and appointed General Ulysses S. Grant as secretary of war ad interim ) . </P>\n",
      "<P> Jaffa Cakes are biscuit - sized cakes introduced by McVitie and Price in the UK in 1927 and named after Jaffa oranges . The most common form of Jaffa cakes are circular , 2 ⁄ inches ( 54 mm ) in diameter and have three layers : a Genoise sponge base , a layer of orange flavoured jam and a coating of chocolate . Jaffa cakes are also available as bars or in small packs , and in larger and smaller sizes . The original Jaffa Cakes come in packs of 12 , 24 or 36 . </P>\n",
      "<Table> Jaffa Cakes <Tr> <Td colspan=\"2\"> A Jaffa Cake cut in half </Td> </Tr> <Tr> <Th> Alternative names </Th> <Td> Jaffa </Td> </Tr> <Tr> <Th> Type </Th> <Td> Cake </Td> </Tr> <Tr> <Th> Place of origin </Th> <Td> United Kingdom </Td> </Tr> <Tr> <Th> Region or state </Th> <Td> All Regions </Td> </Tr> <Tr> <Th> Created by </Th> <Td> McVitie and Price </Td> </Tr> <Tr> <Th> Main ingredients </Th> <Td> Sponge cake , orange - flavoured jam , chocolate </Td> </Tr> <Tr> <Th> Variations </Th> <Td> Various limited edition flavours ( Lemon and lime , strawberry , black currant ) </Td> </Tr> <Tr> <Td colspan=\"2\"> Cookbook : Jaffa Cakes Media : Jaffa Cakes </Td> </Tr> </Table>\n",
      "<P> In 1983 , Richard Stallman , founder of the Free Software Foundation , set forth plans of a complete Unix - like operating system , called GNU , composed entirely of free software . In September of that year , Stallman published a manifesto in Dr. Dobb 's Journal detailing his new project publicly , outlining his vision of free software . Software development work began in January 1984 . By 1991 , the GNU mid-level portions of the operating system were almost complete , and the upper level could be supplied by the X Window System , but the lower level ( kernel , device drivers , system - level utilities and daemons ) was still mostly lacking . The GNU kernel was called GNU Hurd . The Hurd followed an ambitious design which proved unexpectedly difficult to implement and has only been marginally usable . </P>\n",
      "<P> Because McVitie 's did not trademark the name `` Jaffa Cakes '' , other biscuit manufacturers and supermarkets have made similar products under the same name . The product 's classification as a cake or biscuit was part of a VAT tribunal in 1991 , with the court finding in McVitie 's favour that the Jaffa cake should be considered a cake for tax purposes . In 2012 they were ranked the best selling cake or biscuit in the United Kingdom . </P>\n",
      "<P> The geopolitical divisions in Europe that created a concept of East and West originated in the Roman Empire . The Eastern Mediterranean was home to the highly urbanized cultures that had Greek as their common language ( owing to the older empire of Alexander the Great and of the Hellenistic successors ) , whereas the West was much more rural in its character and more readily adopted Latin as its common language . After the fall of the Western Roman Empire , Western and Central Europe were substantially cut off from the East where Byzantine Greek culture and Eastern Christianity became founding influences in the Arab / Muslim world and among the Eastern and Southern Slavic peoples . Roman Catholic Western and Central Europe , as such , maintained a distinct identity particularly as it began to redevelop during the Renaissance . Even following the Protestant Reformation , Protestant Europe continued to see itself as more tied to Roman Catholic Europe than other parts of the perceived civilized world . </P>\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user. You should follow the following steps to answer a question:\n",
      "Step 1, you estimate the user's intent based on the question and context. The intent can be a code generation task or\n",
      "a question answering task.\n",
      "Step 2, you reply based on the intent.\n",
      "You should leverage the context provided by the user as much as possible. If you need more context, you should reply \n",
      "\"UPDATE CONTEXT\".\n",
      "For code generation task, you must obey the following rules:\n",
      "Rule 1. You MUST NOT install any packages because all the packages needed are already installed.\n",
      "Rule 2. You must follow the formats below to write your code:\n",
      "```language\n",
      "# your code\n",
      "```\n",
      "\n",
      "For question answering task, you must give as short an answer as possible.\n",
      "\n",
      "User's question is: what is non controlling interest on balance sheet\n",
      "\n",
      "Context is: <P> In accounting , minority interest ( or non-controlling interest ) is the portion of a subsidiary corporation 's stock that is not owned by the parent corporation . The magnitude of the minority interest in the subsidiary company is generally less than 50 % of outstanding shares , or the corporation would generally cease to be a subsidiary of the parent . </P>\n",
      "<Table> <Tr> <Th colspan=\"4\"> Leading foreign holders of US Treasury securities as of August 2017 </Th> </Tr> <Tr> <Th> Country </Th> <Th> Billions of dollars ( est . ) </Th> <Th> Ratio of owned US debt to 2016 GDP ( est . ) </Th> <Th> Percent change since August 2016 </Th> </Tr> <Tr> <Td> China </Td> <Td> 1,200.5 </Td> <Td> 6 % </Td> <Td> + 1 % </Td> </Tr> <Tr> <Td> Japan </Td> <Td> 1,101.7 </Td> <Td> 22 % </Td> <Td> − 4 % </Td> </Tr> <Tr> <Td> Ireland </Td> <Td> 307.2 </Td> <Td> 105 % </Td> <Td> + 15 % </Td> </Tr> <Tr> <Td> Brazil </Td> <Td> 273.6 </Td> <Td> 15 % </Td> <Td> + 7 % </Td> </Tr> <Tr> <Td> Cayman Islands </Td> <Td> 260.0 </Td> <Td> n / a </Td> <Td> − 2 % </Td> </Tr> <Tr> <Td> Switzerland </Td> <Td> 248.3 </Td> <Td> 38 % </Td> <Td> + 4 % </Td> </Tr> <Tr> <Td> United Kingdom </Td> <Td> 225.4 </Td> <Td> 9 % </Td> <Td> + 10 % </Td> </Tr> <Tr> <Td> Luxembourg </Td> <Td> 213.4 </Td> <Td> 359 % </Td> <Td> − 3 % </Td> </Tr> <Tr> <Td> Hong Kong </Td> <Td> 197.3 </Td> <Td> 62 % </Td> <Td> + 3 % </Td> </Tr> <Tr> <Td> Taiwan </Td> <Td> 180.4 </Td> <Td> 34 % </Td> <Td> -- 5 % </Td> </Tr> <Tr> <Td> Others </Td> <Td> 2,061.9 </Td> <Td> n / a </Td> <Td> + 1 % </Td> </Tr> <Tr> <Th> Grand total </Th> <Th> 6,269.7 </Th> <Th> n / a </Th> <Th> + 1 % </Th> </Tr> </Table>\n",
      "<P> The name -- elevator pitch -- reflects the idea that it should be possible to deliver the summary in the time span of an elevator ride , or approximately thirty seconds to two minutes . </P>\n",
      "<P> SAARC was founded in Dhaka on 8 December 1985 . Its secretariat is based in Kathmandu , Nepal . The organization promotes development of economic and regional integration . It launched the South Asian Free Trade Area in 2006 . SAARC maintains permanent diplomatic relations at the United Nations as an observer and has developed links with multilateral entities , including the European Union . </P>\n",
      "<P> Seth MacFarlane voices three of the show 's main characters : Peter Griffin , Brian Griffin , and Stewie Griffin . MacFarlane chose to voice these characters himself , believing it would be easier to portray the voices he had already envisioned than for someone else to attempt it . MacFarlane drew inspiration for the voice of Peter from a security guard he overheard talking while attending the Rhode Island School of Design . Stewie 's voice was based on the voice of English actor Rex Harrison , especially his performance in the 1964 musical drama film My Fair Lady . MacFarlane uses his own voice while portraying Brian . </P>\n",
      "<P> The cup is an English unit of volume , most commonly associated with cooking and serving sizes . It is traditionally equal to half a liquid pint in either US customary units or the British imperial system but is now separately defined in terms of the metric system at values between ⁄ and ⁄ of a liter . Because actual drinking cups may differ greatly from the size of this unit , standard measuring cups are usually used instead . </P>\n",
      "<Table> <Tr> <Th> Year </Th> <Th> Coach </Th> <Th> Super Bowl </Th> <Th> Location </Th> <Th> Opponent </Th> <Th> Score </Th> <Th> Record </Th> </Tr> <Tr> <Td> 1981 </Td> <Td> Bill Walsh </Td> <Td> XVI </Td> <Td> Pontiac , Michigan </Td> <Td> Cincinnati Bengals </Td> <Td> 26 -- 21 </Td> <Td> 16 -- 3 </Td> </Tr> <Tr> <Td> 1984 </Td> <Td> Bill Walsh </Td> <Td> XIX </Td> <Td> Stanford , California </Td> <Td> Miami Dolphins </Td> <Td> 38 -- 16 </Td> <Td> 18 -- 1 </Td> </Tr> <Tr> <Td> 1988 </Td> <Td> Bill Walsh </Td> <Td> XXIII </Td> <Td> Miami </Td> <Td> Cincinnati Bengals </Td> <Td> 20 -- 16 </Td> <Td> 13 -- 6 </Td> </Tr> <Tr> <Td> 1989 </Td> <Td> George Seifert </Td> <Td> XXIV </Td> <Td> New Orleans </Td> <Td> Denver Broncos </Td> <Td> 55 -- 10 </Td> <Td> 17 -- 2 </Td> </Tr> <Tr> <Td> 1994 </Td> <Td> George Seifert </Td> <Td> XXIX </Td> <Td> Miami </Td> <Td> San Diego Chargers </Td> <Td> 49 -- 26 </Td> <Td> 16 -- 3 </Td> </Tr> <Tr> <Td colspan=\"5\"> Total Super Bowls won : </Td> <Td colspan=\"2\"> 5 </Td> </Tr> </Table>\n",
      "<P> `` Would I Lie to You ? '' is an R&B song by American duo Charles & Eddie . Written by Mike Leeson and Peter Vale and produced by Josh Deutsch , `` Would I Lie to You ? '' was the debut single by the pop - soul duo , and it proved to be their biggest hit . A major international success , it reached number one on the UK Singles Chart for two weeks in November 1992 , and was also number one in New Zealand , Germany and Austria . It was a top five hit in several other European countries while in Australia and Canada it went to number 3 . The single became a Top 20 hit in the US , peaking at number 13 on the Billboard Hot 100 and it enjoyed award - winning sales , earning a platinum record in the UK , a gold record in both Germany and Austria and silver record award in France . </P>\n",
      "<P> The Lord of the Rings is a film series consisting of three high fantasy adventure films directed by Peter Jackson . They are based on the novel The Lord of the Rings by J.R.R. Tolkien . The films are subtitled The Fellowship of the Ring ( 2001 ) , The Two Towers ( 2002 ) and The Return of the King ( 2003 ) . They are a New Zealand - American venture produced by WingNut Films and The Saul Zaentz Company and distributed by New Line Cinema . </P>\n",
      "<Table> <Tr> <Th> NYHA Class </Th> <Th> Symptoms </Th> </Tr> <Tr> <Td> </Td> <Td> Cardiac disease , but no symptoms and no limitation in ordinary physical activity , e.g. no shortness of breath when walking , climbing stairs etc . </Td> </Tr> <Tr> <Td> II </Td> <Td> Mild symptoms ( mild shortness of breath and / or angina ) and slight limitation during ordinary activity . </Td> </Tr> <Tr> <Td> III </Td> <Td> Marked limitation in activity due to symptoms , even during less - than - ordinary activity , e.g. walking short distances ( 20 -- 100 m ) . Comfortable only at rest . </Td> </Tr> <Tr> <Td> IV </Td> <Td> Severe limitations . Experiences symptoms even while at rest . Mostly bedbound patients . </Td> </Tr> </Table>\n",
      "<P> Spanish moss ( Tillandsia usneoides ) is an epiphytic flowering plant that often grows upon larger trees in tropical and subtropical climates , native to much of Mexico , Bermuda , the Bahamas , Central America , South America , the southern United States , and the West Indies as well as being naturalized in Queensland ( Australia ) known as `` grandpas beard '' and in French Polynesia . In the United States from where it is most known , it is commonly found on the southern live oak ( Quercus virginiana ) and bald - cypress ( Taxodium distichum ) in the lowlands , swamps , and savannas of the southeastern United States from Texas and Florida north through southern Arkansas . </P>\n",
      "<Table> <Tr> <Td> Best Picture <Ul> <Li> Titanic -- James Cameron and Jon Landau , producers <Ul> <Li> As Good as It Gets -- James L. Brooks , Bridgit Johnson and Kristi Zea , producers </Li> <Li> The Full Monty -- Uberto Pasolini , producer </Li> <Li> Good Will Hunting -- Lawrence Bender , producer </Li> <Li> L.A. Confidential -- Arnon Milchan , Curtis Hanson and Michael Nathanson , producers </Li> </Ul> </Li> </Ul> </Td> <Td> Best Director <Ul> <Li> James Cameron -- Titanic <Ul> <Li> Peter Cattaneo -- The Full Monty </Li> <Li> Gus Van Sant -- Good Will Hunting </Li> <Li> Curtis Hanson -- L.A. Confidential </Li> <Li> Atom Egoyan -- The Sweet Hereafter </Li> </Ul> </Li> </Ul> </Td> </Tr> <Tr> <Td> Best Actor <Ul> <Li> Jack Nicholson -- As Good as It Gets as Melvin Udall <Ul> <Li> Matt Damon -- Good Will Hunting as Will Hunting </Li> <Li> Robert Duvall -- The Apostle as Euliss `` Sonny '' Dewey , a.k.a. `` The Apostle E.F. '' </Li> <Li> Peter Fonda -- Ulee 's Gold as Ulysses `` Ulee '' Jackson </Li> <Li> Dustin Hoffman -- Wag the Dog as Stanley Motss </Li> </Ul> </Li> </Ul> </Td> <Td> Best Actress <Ul> <Li> Helen Hunt -- As Good as It Gets as Carol Connelly <Ul> <Li> Helena Bonham Carter -- The Wings of the Dove as Kate Croy </Li> <Li> Julie Christie -- Afterglow as Phyllis Mann </Li> <Li> Judi Dench -- Mrs Brown as Queen Victoria </Li> <Li> Kate Winslet -- Titanic as Rose DeWitt Bukater </Li> </Ul> </Li> </Ul> </Td> </Tr> <Tr> <Td> Best Supporting Actor <Ul> <Li> Robin Williams -- Good Will Hunting as Dr. Sean Maguire <Ul> <Li> Robert Forster -- Jackie Brown as Max Cherry </Li> <Li> Anthony Hopkins -- Amistad as John Quincy Adams </Li> <Li> Greg Kinnear -- As Good as It Gets as Simon Bishop </Li> <Li> Burt Reynolds -- Boogie Nights as Jack Horner </Li> </Ul> </Li> </Ul> </Td> <Td> Best Supporting Actress <Ul> <Li> Kim Basinger -- L.A. Confidential as Lynn Bracken <Ul> <Li> Joan Cusack -- In & Out as Emily Montgomery </Li> <Li> Minnie Driver -- Good Will Hunting as Skylar </Li> <Li> Julianne Moore -- Boogie Nights as Amber Waves / Maggie </Li> <Li> Gloria Stuart -- Titanic as Rose Dawson Calvert </Li> </Ul> </Li> </Ul> </Td> </Tr> <Tr> <Td> Best Original Screenplay / Screenplay Written Directly for the Screen <Ul> <Li> Good Will Hunting -- Matt Damon and Ben Affleck <Ul> <Li> As Good as It Gets -- Mark Andrus and James L. Brooks </Li> <Li> Boogie Nights -- Paul Thomas Anderson </Li> <Li> Deconstructing Harry -- Woody Allen </Li> <Li> The Full Monty -- Simon Beaufoy </Li> </Ul> </Li> </Ul> </Td> <Td> Best Screenplay Based on Material Previously Produced or Published <Ul> <Li> L.A. Confidential -- Brian Helgeland and Curtis Hanson from the novel by James Ellroy <Ul> <Li> Donnie Brasco -- Paul Attanasio based on the book Donnie Brasco : My Undercover Life in the Mafia by Joseph D. Pistone with Richard Woodley </Li> <Li> The Sweet Hereafter -- Atom Egoyan adapted from the novel by Russell Banks </Li> <Li> Wag the Dog -- David Mamet and Hilary Henkin from the novel American Hero by Larry Beinhart </Li> <Li> The Wings of the Dove -- Hossein Amini adapted from the novel by Henry James </Li> </Ul> </Li> </Ul> </Td> </Tr> <Tr> <Td> Best Foreign Language Film <Ul> <Li> Karakter ( Netherlands ) in Dutch -- Mike van Diem <Ul> <Li> Beyond Silence ( Germany ) in German -- Caroline Link </Li> <Li> Four Days in September ( Brazil ) in Portuguese -- Bruno Barreto </Li> <Li> Secrets of the Heart ( Spain ) in Spanish -- Montxo Armendáriz </Li> <Li> The Thief ( Russia ) in Russian -- Pavel Chukhray </Li> </Ul> </Li> </Ul> </Td> </Tr> <Tr> <Td> Best Documentary Feature <Ul> <Li> The Long Way Home -- Rabbi Marvin Hier and Richard Trank <Ul> <Li> 4 Little Girls -- Spike Lee and Sam Pollard </Li> <Li> Ayn Rand : A Sense of Life -- Michael Paxton </Li> <Li> Colors Straight Up -- Michèle Ohayon and Julia Schachter </Li> <Li> Waco : The Rules of Engagement -- Dan Gifford and William Gazecki </Li> </Ul> </Li> </Ul> </Td> <Td> Best Documentary Short Subject <Ul> <Li> A Story of Healing -- Donna Dewey and Carol Pasternak <Ul> <Li> Alaska : Spirit of the Wild -- George Casey and Paul Novros </Li> <Li> Amazon -- Kieth Merrill and Jonathan Stern </Li> <Li> Family Video Diaries : Daughter of the Bride -- Terri Randall </Li> <Li> Still Kicking : The Fabulous Palm Springs Follies -- Mel Damski and Andrea Blaugrund </Li> </Ul> </Li> </Ul> </Td> </Tr> <Tr> <Td> Best Live Action Short Film <Ul> <Li> Visas\n",
      "<P> The Impeachment of Andrew Johnson occurred in 1868 , when the United States House of Representatives resolved to impeach President Andrew Johnson , adopting eleven articles of impeachment detailing his `` high crimes and misdemeanors , '' in accordance with Article Two of the United States Constitution . The House 's primary charge against Johnson was violation of the Tenure of Office Act , passed by the U.S. Congress in March 1867 , over the president 's veto . Specifically , he had removed from office Edwin M. Stanton , the Secretary of War -- whom the Act was largely designed to protect -- and attempted to replace him with Brevet Major General Lorenzo Thomas ( Earlier , while Congress was not in session , Johnson had suspended Stanton and appointed General Ulysses S. Grant as secretary of war ad interim ) . </P>\n",
      "<P> Jaffa Cakes are biscuit - sized cakes introduced by McVitie and Price in the UK in 1927 and named after Jaffa oranges . The most common form of Jaffa cakes are circular , 2 ⁄ inches ( 54 mm ) in diameter and have three layers : a Genoise sponge base , a layer of orange flavoured jam and a coating of chocolate . Jaffa cakes are also available as bars or in small packs , and in larger and smaller sizes . The original Jaffa Cakes come in packs of 12 , 24 or 36 . </P>\n",
      "<Table> Jaffa Cakes <Tr> <Td colspan=\"2\"> A Jaffa Cake cut in half </Td> </Tr> <Tr> <Th> Alternative names </Th> <Td> Jaffa </Td> </Tr> <Tr> <Th> Type </Th> <Td> Cake </Td> </Tr> <Tr> <Th> Place of origin </Th> <Td> United Kingdom </Td> </Tr> <Tr> <Th> Region or state </Th> <Td> All Regions </Td> </Tr> <Tr> <Th> Created by </Th> <Td> McVitie and Price </Td> </Tr> <Tr> <Th> Main ingredients </Th> <Td> Sponge cake , orange - flavoured jam , chocolate </Td> </Tr> <Tr> <Th> Variations </Th> <Td> Various limited edition flavours ( Lemon and lime , strawberry , black currant ) </Td> </Tr> <Tr> <Td colspan=\"2\"> Cookbook : Jaffa Cakes Media : Jaffa Cakes </Td> </Tr> </Table>\n",
      "<P> In 1983 , Richard Stallman , founder of the Free Software Foundation , set forth plans of a complete Unix - like operating system , called GNU , composed entirely of free software . In September of that year , Stallman published a manifesto in Dr. Dobb 's Journal detailing his new project publicly , outlining his vision of free software . Software development work began in January 1984 . By 1991 , the GNU mid-level portions of the operating system were almost complete , and the upper level could be supplied by the X Window System , but the lower level ( kernel , device drivers , system - level utilities and daemons ) was still mostly lacking . The GNU kernel was called GNU Hurd . The Hurd followed an ambitious design which proved unexpectedly difficult to implement and has only been marginally usable . </P>\n",
      "<P> Because McVitie 's did not trademark the name `` Jaffa Cakes '' , other biscuit manufacturers and supermarkets have made similar products under the same name . The product 's classification as a cake or biscuit was part of a VAT tribunal in 1991 , with the court finding in McVitie 's favour that the Jaffa cake should be considered a cake for tax purposes . In 2012 they were ranked the best selling cake or biscuit in the United Kingdom . </P>\n",
      "<P> The geopolitical divisions in Europe that created a concept of East and West originated in the Roman Empire . The Eastern Mediterranean was home to the highly urbanized cultures that had Greek as their common language ( owing to the older empire of Alexander the Great and of the Hellenistic successors ) , whereas the West was much more rural in its character and more readily adopted Latin as its common language . After the fall of the Western Roman Empire , Western and Central Europe were substantially cut off from the East where Byzantine Greek culture and Eastern Christianity became founding influences in the Arab / Muslim world and among the Eastern and Southern Slavic peoples . Roman Catholic Western and Central Europe , as such , maintained a distinct identity particularly as it began to redevelop during the Renaissance . Even following the Protestant Reformation , Protestant Europe continued to see itself as more tied to Roman Catholic Europe than other parts of the perceived civilized world . </P>\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to ragproxyagent):\n",
      "\n",
      "Non-controlling interest, also known as minority interest, refers to the portion of a subsidiary corporation's stock that is not owned by the parent corporation. It is usually less than 50% of outstanding shares; otherwise, the corporation would generally cease to be a subsidiary of the parent. Non-controlling interest appears on the balance sheet, showing the portion of the subsidiary's equity not owned by the parent company.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# reset the assistant. Always reset the assistant before starting a new conversation.\n",
    "assistant.reset()\n",
    "\n",
    "# set `human_input_mode` to be `ALWAYS`, so the agent will ask for human input at every step.\n",
    "ragproxyagent.human_input_mode = \"NEVER\"\n",
    "qa_problem = questions[0]\n",
    "ragproxyagent.initiate_chat(assistant, problem=qa_problem, n_results=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_PROMPT = \"\"\"You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
    "context provided by the user. You must give as short an answer as possible.\n",
    "\"\"\"\n",
    "\n",
    "# reset the assistant. Always reset the assistant before starting a new conversation.\n",
    "assistant.reset()\n",
    "\n",
    "# set `human_input_mode` to be `ALWAYS`, so the agent will ask for human input at every step.\n",
    "ragproxyagent.human_input_mode = \"NEVER\"\n",
    "ragproxyagent.customized_prompt = MY_PROMPT\n",
    "qa_problem = questions[0]\n",
    "ragproxyagent.initiate_chat(assistant, problem=qa_problem, n_results=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flaml_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
