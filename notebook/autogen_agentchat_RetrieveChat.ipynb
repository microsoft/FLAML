{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Generated Agent Chat: Using RetrieveChat for Retrieve Augmented Code Generation and Question Answering\n",
    "\n",
    "RetrieveChat is a convesational framework for retrieve augmented code generation and question answering. In this notebook, we demonstrate how to utilize RetrieveChat to generate code and answer questions based on customized documentations that are not present in the LLM's training dataset. RetrieveChat uses the `RetrieveAssistantAgent` and `RetrieveUserProxyAgent`, which is similar to the usage of `AssistantAgent` and `UserProxyAgent` in other notebooks (e.g., [Automated Task Solving with Code Generation, Execution & Debugging](https://github.com/microsoft/FLAML/blob/main/notebook/autogen_agentchat_auto_feedback_from_code_execution.ipynb)). Essentially,`RetrieveAssistantAgent` and  `RetrieveUserProxyAgent` implements a different auto reply mechanism corresponding to the RetrieveChat prompts.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "FLAML requires `Python>=3.8`. To run this notebook example, please install flaml with the [mathchat] option.\n",
    "```bash\n",
    "pip install flaml[retrievechat]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install flaml[retrievechat]~=2.0.0rc5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/FLAML/docs/reference/autogen/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models to use:  ['gpt-4']\n"
     ]
    }
   ],
   "source": [
    "from flaml import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    env_or_file=\".config.local\",\n",
    "    file_location=\".\",\n",
    "    filter_dict={\n",
    "        \"model\": {\n",
    "            \"gpt-4\",\n",
    "            \"gpt4\",\n",
    "            \"gpt-4-32k\",\n",
    "            \"gpt-4-32k-0314\",\n",
    "            \"gpt-35-turbo\",\n",
    "            \"gpt-3.5-turbo\",\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "assert len(config_list) > 0\n",
    "print(\"models to use: \", [config_list[i][\"model\"] for i in range(len(config_list))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It first looks for environment variable \"OAI_CONFIG_LIST\" which needs to be a valid json string. If that variable is not found, it then looks for a json file named \"OAI_CONFIG_LIST\". It filters the configs by models (you can filter by other keys as well). Only the gpt-4 and gpt-3.5-turbo models are kept in the list based on the filter condition.\n",
    "\n",
    "The config list looks like the following:\n",
    "```python\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your OpenAI API key here>',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'api_base': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-3.5-turbo',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'api_base': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "]\n",
    "```\n",
    "\n",
    "If you open this notebook in colab, you can upload your files by clicking the file icon on the left panel and then choose \"upload file\" icon.\n",
    "\n",
    "You can set the value of config_list in other ways you prefer, e.g., loading from a YAML file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct agents for RetrieveChat\n",
    "\n",
    "We start by initialzing the `RetrieveAssistantAgent` and `RetrieveUserProxyAgent`. The system message needs to be set to \"You are a helpful assistant.\" for RetrieveAssistantAgent. The detailed instructions are given in the user message. Later we will use the `RetrieveUserProxyAgent.generate_init_prompt` to combine the instructions and a math problem for an initial prompt to be sent to the LLM assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml.autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "from flaml.autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "import chromadb\n",
    "\n",
    "autogen.ChatCompletion.start_logging()\n",
    "\n",
    "# 1. create an RetrieveAssistantAgent instance named \"assistant\"\n",
    "assistant = RetrieveAssistantAgent(\n",
    "    name=\"assistant\", \n",
    "    system_message=\"You are a helpful assistant.\",\n",
    "    llm_config={\n",
    "        \"request_timeout\": 600,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "    },\n",
    ")\n",
    "\n",
    "# 2. create the RetrieveUserProxyAgent instance named \"ragproxyagent\"\n",
    "# By default, the human_input_mode is \"ALWAYS\", which means the agent will ask for human input at every step. We set it to \"NEVER\" here.\n",
    "# `docs_path` is the path to the docs directory. By default, it is set to \"./docs\". Here we generated the documentations from FLAML's docstrings.\n",
    "# Navigate to the website folder and run `pydoc-markdown` and it will generate folder `reference` under `website/docs`.\n",
    "# `chunk_token_size` is the chunk token size for the retrieve chat. By default, it is set to `max_tokens * 0.6`, here we set it to 2000.\n",
    "ragproxyagent = RetrieveUserProxyAgent(\n",
    "    name=\"ragproxyagent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    retrieve_config={\n",
    "        \"docs_path\": \"../website/docs/reference\",\n",
    "        \"chunk_token_size\": 2000,\n",
    "        \"model\": config_list[0][\"model\"],\n",
    "        \"client\": chromadb.PersistentClient(path=\"/tmp/chromadb\"),\n",
    "        \"embedding_model\": \"all-mpnet-base-v2\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "Use RetrieveChat to help generate sample code and automatically run the code and fix errors if there is any.\n",
    "\n",
    "Problem: Which API should I use if I want to use FLAML for a classification task and I want to train the model in 30 seconds. Use spark to parallel the training. Force cancel jobs if time limit is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:flaml.autogen.retrieve_utils:Collection flaml-docs already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_ids:  [['doc_35', 'doc_40', 'doc_14', 'doc_21', 'doc_15', 'doc_51', 'doc_44', 'doc_52', 'doc_41', 'doc_45', 'doc_13', 'doc_61', 'doc_38', 'doc_36', 'doc_8']]\n",
      "\u001b[32mAdding doc_id doc_35 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_40 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_14 to context.\u001b[0m\n",
      "\u001b[33mragproxyagent\u001b[0m (to assistant):\n",
      "\n",
      "You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user. You should follow the following steps to answer a question:\n",
      "Step 1, you estimate the user's intent based on the question and context. The intent can be a code generation task or\n",
      "a question answering task.\n",
      "Step 2, you reply based on the intent.\n",
      "You should leverage the context provided by the user as much as possible. If you need more context, you should reply\n",
      "\"UPDATE CONTEXT\".\n",
      "For code generation task, you must obey the following rules:\n",
      "Rule 1. You MUST NOT install any packages because all the packages needed are already installed.\n",
      "Rule 2. You must follow the formats below to write your code:\n",
      "```language\n",
      "# your code\n",
      "```\n",
      "\n",
      "For question answering task, you must give as short an answer as possible.\n",
      "\n",
      "User's question is: How can I use FLAML to perform a classification task and use spark to do parallel training. Train 30 seconds and force cancel jobs if time limit is reached.\n",
      "\n",
      "Context is: \n",
      "new_automl = AutoML()\n",
      "new_automl.fit(X_train, y_train, starting_points=starting_points)\n",
      "```\n",
      "  \n",
      "- `seed` - int or None, default=None | The random seed for hpo.\n",
      "- `n_concurrent_trials` - [Experimental] int, default=1 | The number of\n",
      "  concurrent trials. When n_concurrent_trials > 1, flaml performes\n",
      "  [parallel tuning](../../Use-Cases/Task-Oriented-AutoML#parallel-tuning)\n",
      "  and installation of ray or spark is required: `pip install flaml[ray]`\n",
      "  or `pip install flaml[spark]`. Please check\n",
      "  [here](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
      "  for more details about installing Spark.\n",
      "- `keep_search_state` - boolean, default=False | Whether to keep data needed\n",
      "  for model search after fit(). By default the state is deleted for\n",
      "  space saving.\n",
      "- `preserve_checkpoint` - boolean, default=True | Whether to preserve the saved checkpoint\n",
      "  on disk when deleting automl. By default the checkpoint is preserved.\n",
      "- `early_stop` - boolean, default=False | Whether to stop early if the\n",
      "  search is considered to converge.\n",
      "- `force_cancel` - boolean, default=False | Whether to forcely cancel Spark jobs if the\n",
      "  search time exceeded the time budget.\n",
      "- `append_log` - boolean, default=False | Whetehr to directly append the log\n",
      "  records to the input log file if it exists.\n",
      "- `auto_augment` - boolean, default=True | Whether to automatically\n",
      "  augment rare classes.\n",
      "- `min_sample_size` - int, default=MIN_SAMPLE_TRAIN | the minimal sample\n",
      "  size when sample=True.\n",
      "- `use_ray` - boolean or dict.\n",
      "  If boolean: default=False | Whether to use ray to run the training\n",
      "  in separate processes. This can be used to prevent OOM for large\n",
      "  datasets, but will incur more overhead in time.\n",
      "  If dict: the dict contains the keywords arguments to be passed to\n",
      "  [ray.tune.run](https://docs.ray.io/en/latest/tune/api_docs/execution.html).\n",
      "- `use_spark` - boolean, default=False | Whether to use spark to run the training\n",
      "  in parallel spark jobs. This can be used to accelerate training on large models\n",
      "  and large datasets, but will incur more overhead in time and thus slow down\n",
      "  training in some cases. GPU training is not supported yet when use_spark is True.\n",
      "  For Spark clusters, by default, we will launch one trial per executor. However,\n",
      "  sometimes we want to launch more trials than the number of executors (e.g., local mode).\n",
      "  In this case, we can set the environment variable `FLAML_MAX_CONCURRENT` to override\n",
      "  the detected `num_executors`. The final number of concurrent trials will be the minimum\n",
      "  of `n_concurrent_trials` and `num_executors`.\n",
      "- `free_mem_ratio` - float between 0 and 1, default=0. The free memory ratio to keep during training.\n",
      "- `metric_constraints` - list, default=[] | The list of metric constraints.\n",
      "  Each element in this list is a 3-tuple, which shall be expressed\n",
      "  in the following format: the first element of the 3-tuple is the name of the\n",
      "  metric, the second element is the inequality sign chosen from \">=\" and \"<=\",\n",
      "  and the third element is the constraint value. E.g., `('val_loss', '<=', 0.1)`.\n",
      "  Note that all the metric names in metric_constraints need to be reported via\n",
      "  the metrics_to_log dictionary returned by a customized metric function.\n",
      "  The customized metric function shall be provided via the `metric` key word\n",
      "  argument of the fit() function or the automl constructor.\n",
      "  Find an example in the 4th constraint type in this [doc](../../Use-Cases/Task-Oriented-AutoML#constraint).\n",
      "  If `pred_time_limit` is provided as one of keyword arguments to fit() function or\n",
      "  the automl constructor, flaml will automatically (and under the hood)\n",
      "  add it as an additional element in the metric_constraints. Essentially 'pred_time_limit'\n",
      "  specifies a constraint about the prediction latency constraint in seconds.\n",
      "- `custom_hp` - dict, default=None | The custom search space specified by user.\n",
      "  It is a nested dict with keys being the estimator names, and values being dicts\n",
      "  per estimator search space. In the per estimator search space dict,\n",
      "  the keys are the hyperparameter names, and values are dicts of info (\"domain\",\n",
      "  \"init_value\", and \"low_cost_init_value\") about the search space associated with\n",
      "  the hyperparameter (i.e., per hyperparameter search space dict). When custom_hp\n",
      "  is provided, the built-in search space which is also a nested dict of per estimator\n",
      "  search space dict, will be updated with custom_hp. Note that during this nested dict update,\n",
      "  the per hyperparameter search space dicts will be replaced (instead of updated) by the ones\n",
      "  provided in custom_hp. Note that the value for \"domain\" can either be a constant\n",
      "  or a sample.Domain object.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "custom_hp = {\n",
      "     \"transformer_ms\": {\n",
      "         \"model_path\": {\n",
      "             \"domain\": \"albert-base-v2\",\n",
      "         },\n",
      "         \"learning_rate\": {\n",
      "             \"domain\": tune.choice([1e-4, 1e-5]),\n",
      "         }\n",
      "     }\n",
      " }\n",
      "```\n",
      "- `skip_transform` - boolean, default=False | Whether to pre-process data prior to modeling.\n",
      "- `fit_kwargs_by_estimator` - dict, default=None | The user specified keywords arguments, grouped by estimator name.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "fit_kwargs_by_estimator = {\n",
      "    \"transformer\": {\n",
      "        \"output_dir\": \"test/data/output/\",\n",
      "        \"fp16\": False,\n",
      "    }\n",
      "}\n",
      "```\n",
      "- `mlflow_logging` - boolean, default=True | Whether to log the training results to mlflow.\n",
      "  This requires mlflow to be installed and to have an active mlflow run.\n",
      "  FLAML will create nested runs.\n",
      "\n",
      "#### config\\_history\n",
      "\n",
      "```python\n",
      "@property\n",
      "def config_history() -> dict\n",
      "```\n",
      "\n",
      "A dictionary of iter->(estimator, config, time),\n",
      "storing the best estimator, config, and the time when the best\n",
      "model is updated each time.\n",
      "\n",
      "#### model\n",
      "\n",
      "```python\n",
      "@property\n",
      "def model()\n",
      "```\n",
      "\n",
      "An object with `predict()` and `predict_proba()` method (for\n",
      "classification), storing the best trained model.\n",
      "\n",
      "#### best\\_model\\_for\\_estimator\n",
      "\n",
      "```python\n",
      "def best_model_for_estimator(estimator_name: str)\n",
      "```\n",
      "\n",
      "Return the best model found for a particular estimator.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `estimator_name` - a str of the estimator's name.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  An object storing the best model for estimator_name.\n",
      "  If `model_history` was set to False during fit(), then the returned model\n",
      "  is untrained unless estimator_name is the best estimator.\n",
      "  If `model_history` was set to True, then the returned model is trained.\n",
      "\n",
      "#### best\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_estimator()\n",
      "```\n",
      "\n",
      "A string indicating the best estimator found.\n",
      "\n",
      "#### best\\_iteration\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_iteration()\n",
      "```\n",
      "\n",
      "An integer of the iteration number where the best\n",
      "config is found.\n",
      "\n",
      "#### best\\_config\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config()\n",
      "```\n",
      "\n",
      "A dictionary of the best configuration.\n",
      "\n",
      "#### best\\_config\\_per\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config_per_estimator()\n",
      "```\n",
      "\n",
      "A dictionary of all estimators' best configuration.\n",
      "\n",
      "#### best\\_loss\\_per\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_loss_per_estimator()\n",
      "```\n",
      "\n",
      "A dictionary of all estimators' best loss.\n",
      "\n",
      "#### best\\_loss\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_loss()\n",
      "```\n",
      "\n",
      "A float of the best loss found.\n",
      "\n",
      "#### best\\_result\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_result()\n",
      "```\n",
      "\n",
      "Result dictionary for model trained with the best config.\n",
      "\n",
      "#### metrics\\_for\\_best\\_config\n",
      "\n",
      "new_automl = AutoML()\n",
      "new_automl.fit(X_train, y_train, starting_points=starting_points)\n",
      "```\n",
      "  \n",
      "- `seed` - int or None, default=None | The random seed for hpo.\n",
      "- `n_concurrent_trials` - [Experimental] int, default=1 | The number of\n",
      "  concurrent trials. When n_concurrent_trials > 1, flaml performes\n",
      "  [parallel tuning](../../Use-Cases/Task-Oriented-AutoML#parallel-tuning)\n",
      "  and installation of ray or spark is required: `pip install flaml[ray]`\n",
      "  or `pip install flaml[spark]`. Please check\n",
      "  [here](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
      "  for more details about installing Spark.\n",
      "- `keep_search_state` - boolean, default=False | Whether to keep data needed\n",
      "  for model search after fit(). By default the state is deleted for\n",
      "  space saving.\n",
      "- `preserve_checkpoint` - boolean, default=True | Whether to preserve the saved checkpoint\n",
      "  on disk when deleting automl. By default the checkpoint is preserved.\n",
      "- `early_stop` - boolean, default=False | Whether to stop early if the\n",
      "  search is considered to converge.\n",
      "- `force_cancel` - boolean, default=False | Whether to forcely cancel the PySpark job if overtime.\n",
      "- `append_log` - boolean, default=False | Whetehr to directly append the log\n",
      "  records to the input log file if it exists.\n",
      "- `auto_augment` - boolean, default=True | Whether to automatically\n",
      "  augment rare classes.\n",
      "- `min_sample_size` - int, default=MIN_SAMPLE_TRAIN | the minimal sample\n",
      "  size when sample=True.\n",
      "- `use_ray` - boolean or dict.\n",
      "  If boolean: default=False | Whether to use ray to run the training\n",
      "  in separate processes. This can be used to prevent OOM for large\n",
      "  datasets, but will incur more overhead in time.\n",
      "  If dict: the dict contains the keywords arguments to be passed to\n",
      "  [ray.tune.run](https://docs.ray.io/en/latest/tune/api_docs/execution.html).\n",
      "- `use_spark` - boolean, default=False | Whether to use spark to run the training\n",
      "  in parallel spark jobs. This can be used to accelerate training on large models\n",
      "  and large datasets, but will incur more overhead in time and thus slow down\n",
      "  training in some cases.\n",
      "- `free_mem_ratio` - float between 0 and 1, default=0. The free memory ratio to keep during training.\n",
      "- `metric_constraints` - list, default=[] | The list of metric constraints.\n",
      "  Each element in this list is a 3-tuple, which shall be expressed\n",
      "  in the following format: the first element of the 3-tuple is the name of the\n",
      "  metric, the second element is the inequality sign chosen from \">=\" and \"<=\",\n",
      "  and the third element is the constraint value. E.g., `('precision', '>=', 0.9)`.\n",
      "  Note that all the metric names in metric_constraints need to be reported via\n",
      "  the metrics_to_log dictionary returned by a customized metric function.\n",
      "  The customized metric function shall be provided via the `metric` key word argument\n",
      "  of the fit() function or the automl constructor.\n",
      "  Find examples in this [test](https://github.com/microsoft/FLAML/tree/main/test/automl/test_constraints.py).\n",
      "  If `pred_time_limit` is provided as one of keyword arguments to fit() function or\n",
      "  the automl constructor, flaml will automatically (and under the hood)\n",
      "  add it as an additional element in the metric_constraints. Essentially 'pred_time_limit'\n",
      "  specifies a constraint about the prediction latency constraint in seconds.\n",
      "- `custom_hp` - dict, default=None | The custom search space specified by user\n",
      "  Each key is the estimator name, each value is a dict of the custom search space for that estimator. Notice the\n",
      "  domain of the custom search space can either be a value of a sample.Domain object.\n",
      "  \n",
      "  \n",
      "  \n",
      "```python\n",
      "custom_hp = {\n",
      "    \"transformer_ms\": {\n",
      "        \"model_path\": {\n",
      "            \"domain\": \"albert-base-v2\",\n",
      "        },\n",
      "        \"learning_rate\": {\n",
      "            \"domain\": tune.choice([1e-4, 1e-5]),\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "- `time_col` - for a time series task, name of the column containing the timestamps. If not\n",
      "  provided, defaults to the first column of X_train/X_val\n",
      "  \n",
      "- `cv_score_agg_func` - customized cross-validation scores aggregate function. Default to average metrics across folds. If specificed, this function needs to\n",
      "  have the following input arguments:\n",
      "  \n",
      "  * val_loss_folds: list of floats, the loss scores of each fold;\n",
      "  * log_metrics_folds: list of dicts/floats, the metrics of each fold to log.\n",
      "  \n",
      "  This function should return the final aggregate result of all folds. A float number of the minimization objective, and a dictionary as the metrics to log or None.\n",
      "  E.g.,\n",
      "  \n",
      "```python\n",
      "def cv_score_agg_func(val_loss_folds, log_metrics_folds):\n",
      "    metric_to_minimize = sum(val_loss_folds)/len(val_loss_folds)\n",
      "    metrics_to_log = None\n",
      "    for single_fold in log_metrics_folds:\n",
      "        if metrics_to_log is None:\n",
      "            metrics_to_log = single_fold\n",
      "        elif isinstance(metrics_to_log, dict):\n",
      "            metrics_to_log = {k: metrics_to_log[k] + v for k, v in single_fold.items()}\n",
      "        else:\n",
      "            metrics_to_log += single_fold\n",
      "    if metrics_to_log:\n",
      "        n = len(val_loss_folds)\n",
      "        metrics_to_log = (\n",
      "            {k: v / n for k, v in metrics_to_log.items()}\n",
      "            if isinstance(metrics_to_log, dict)\n",
      "            else metrics_to_log / n\n",
      "        )\n",
      "    return metric_to_minimize, metrics_to_log\n",
      "```\n",
      "  \n",
      "- `skip_transform` - boolean, default=False | Whether to pre-process data prior to modeling.\n",
      "- `mlflow_logging` - boolean, default=None | Whether to log the training results to mlflow.\n",
      "  Default value is None, which means the logging decision is made based on\n",
      "  AutoML.__init__'s mlflow_logging argument.\n",
      "  This requires mlflow to be installed and to have an active mlflow run.\n",
      "  FLAML will create nested runs.\n",
      "- `fit_kwargs_by_estimator` - dict, default=None | The user specified keywords arguments, grouped by estimator name.\n",
      "  For TransformersEstimator, available fit_kwargs can be found from\n",
      "  [TrainingArgumentsForAuto](nlp/huggingface/training_args).\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "fit_kwargs_by_estimator = {\n",
      "    \"transformer\": {\n",
      "        \"output_dir\": \"test/data/output/\",\n",
      "        \"fp16\": False,\n",
      "    },\n",
      "    \"tft\": {\n",
      "        \"max_encoder_length\": 1,\n",
      "        \"min_encoder_length\": 1,\n",
      "        \"static_categoricals\": [],\n",
      "        \"static_reals\": [],\n",
      "        \"time_varying_known_categoricals\": [],\n",
      "        \"time_varying_known_reals\": [],\n",
      "        \"time_varying_unknown_categoricals\": [],\n",
      "        \"time_varying_unknown_reals\": [],\n",
      "        \"variable_groups\": {},\n",
      "        \"lags\": {},\n",
      "    }\n",
      "}\n",
      "```\n",
      "  \n",
      "- `**fit_kwargs` - Other key word arguments to pass to fit() function of\n",
      "  the searched learners, such as sample_weight. Below are a few examples of\n",
      "  estimator-specific parameters:\n",
      "- `period` - int | forecast horizon for all time series forecast tasks.\n",
      "- `gpu_per_trial` - float, default = 0 | A float of the number of gpus per trial,\n",
      "  only used by TransformersEstimator, XGBoostSklearnEstimator, and\n",
      "  TemporalFusionTransformerEstimator.\n",
      "- `group_ids` - list of strings of column names identifying a time series, only\n",
      "  used by TemporalFusionTransformerEstimator, required for\n",
      "  'ts_forecast_panel' task. `group_ids` is a parameter for TimeSeriesDataSet object\n",
      "  from PyTorchForecasting.\n",
      "  For other parameters to describe your dataset, refer to\n",
      "  [TimeSeriesDataSet PyTorchForecasting](https://pytorch-forecasting.readthedocs.io/en/stable/api/pytorch_forecasting.data.timeseries.TimeSeriesDataSet.html).\n",
      "  To specify your variables, use `static_categoricals`, `static_reals`,\n",
      "  `time_varying_known_categoricals`, `time_varying_known_reals`,\n",
      "  `time_varying_unknown_categoricals`, `time_varying_unknown_reals`,\n",
      "  `variable_groups`. To provide more information on your data, use\n",
      "  `max_encoder_length`, `min_encoder_length`, `lags`.\n",
      "- `log_dir` - str, default = \"lightning_logs\" | Folder into which to log results\n",
      "  for tensorboard, only used by TemporalFusionTransformerEstimator.\n",
      "- `max_epochs` - int, default = 20 | Maximum number of epochs to run training,\n",
      "  only used by TemporalFusionTransformerEstimator.\n",
      "- `batch_size` - int, default = 64 | Batch size for training model, only\n",
      "  used by TemporalFusionTransformerEstimator.\n",
      "\n",
      "\n",
      "from flaml import BlendSearch\n",
      "algo = BlendSearch(metric='val_loss', mode='min',\n",
      "        space=search_space,\n",
      "        low_cost_partial_config=low_cost_partial_config)\n",
      "for i in range(10):\n",
      "    analysis = tune.run(compute_with_config,\n",
      "        search_alg=algo, use_ray=False)\n",
      "    print(analysis.trials[-1].last_result)\n",
      "```\n",
      "  \n",
      "- `verbose` - 0, 1, 2, or 3. If ray or spark backend is used, their verbosity will be\n",
      "  affected by this argument. 0 = silent, 1 = only status updates,\n",
      "  2 = status and brief trial results, 3 = status and detailed trial results.\n",
      "  Defaults to 2.\n",
      "- `local_dir` - A string of the local dir to save ray logs if ray backend is\n",
      "  used; or a local dir to save the tuning log.\n",
      "- `num_samples` - An integer of the number of configs to try. Defaults to 1.\n",
      "- `resources_per_trial` - A dictionary of the hardware resources to allocate\n",
      "  per trial, e.g., `{'cpu': 1}`. It is only valid when using ray backend\n",
      "  (by setting 'use_ray = True'). It shall be used when you need to do\n",
      "  [parallel tuning](../../Use-Cases/Tune-User-Defined-Function#parallel-tuning).\n",
      "- `config_constraints` - A list of config constraints to be satisfied.\n",
      "  e.g., ```config_constraints = [(mem_size, '<=', 1024**3)]```\n",
      "  \n",
      "  mem_size is a function which produces a float number for the bytes\n",
      "  needed for a config.\n",
      "  It is used to skip configs which do not fit in memory.\n",
      "- `metric_constraints` - A list of metric constraints to be satisfied.\n",
      "  e.g., `['precision', '>=', 0.9]`. The sign can be \">=\" or \"<=\".\n",
      "- `max_failure` - int | the maximal consecutive number of failures to sample\n",
      "  a trial before the tuning is terminated.\n",
      "- `use_ray` - A boolean of whether to use ray as the backend.\n",
      "- `use_spark` - A boolean of whether to use spark as the backend.\n",
      "- `log_file_name` - A string of the log file name. Default to None.\n",
      "  When set to None:\n",
      "  if local_dir is not given, no log file is created;\n",
      "  if local_dir is given, the log file name will be autogenerated under local_dir.\n",
      "  Only valid when verbose > 0 or use_ray is True.\n",
      "- `lexico_objectives` - dict, default=None | It specifics information needed to perform multi-objective\n",
      "  optimization with lexicographic preferences. When lexico_objectives is not None, the arguments metric,\n",
      "  mode, will be invalid, and flaml's tune uses CFO\n",
      "  as the `search_alg`, which makes the input (if provided) `search_alg' invalid.\n",
      "  This dictionary shall contain the following fields of key-value pairs:\n",
      "  - \"metrics\":  a list of optimization objectives with the orders reflecting the priorities/preferences of the\n",
      "  objectives.\n",
      "  - \"modes\" (optional): a list of optimization modes (each mode either \"min\" or \"max\") corresponding to the\n",
      "  objectives in the metric list. If not provided, we use \"min\" as the default mode for all the objectives.\n",
      "  - \"targets\" (optional): a dictionary to specify the optimization targets on the objectives. The keys are the\n",
      "  metric names (provided in \"metric\"), and the values are the numerical target values.\n",
      "  - \"tolerances\" (optional): a dictionary to specify the optimality tolerances on objectives. The keys are the metric names (provided in \"metrics\"), and the values are the absolute/percentage tolerance in the form of numeric/string.\n",
      "  E.g.,\n",
      "```python\n",
      "lexico_objectives = {\n",
      "    \"metrics\": [\"error_rate\", \"pred_time\"],\n",
      "    \"modes\": [\"min\", \"min\"],\n",
      "    \"tolerances\": {\"error_rate\": 0.01, \"pred_time\": 0.0},\n",
      "    \"targets\": {\"error_rate\": 0.0},\n",
      "}\n",
      "```\n",
      "  We also support percentage tolerance.\n",
      "  E.g.,\n",
      "```python\n",
      "lexico_objectives = {\n",
      "    \"metrics\": [\"error_rate\", \"pred_time\"],\n",
      "    \"modes\": [\"min\", \"min\"],\n",
      "    \"tolerances\": {\"error_rate\": \"5%\", \"pred_time\": \"0%\"},\n",
      "    \"targets\": {\"error_rate\": 0.0},\n",
      "}\n",
      "```\n",
      "- `force_cancel` - boolean, default=False | Whether to forcely cancel the PySpark job if overtime.\n",
      "- `n_concurrent_trials` - int, default=0 | The number of concurrent trials when perform hyperparameter\n",
      "  tuning with Spark. Only valid when use_spark=True and spark is required:\n",
      "  `pip install flaml[spark]`. Please check\n",
      "  [here](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
      "  for more details about installing Spark. When tune.run() is called from AutoML, it will be\n",
      "  overwritten by the value of `n_concurrent_trials` in AutoML. When <= 0, the concurrent trials\n",
      "  will be set to the number of executors.\n",
      "- `**ray_args` - keyword arguments to pass to ray.tune.run().\n",
      "  Only valid when use_ray=True.\n",
      "\n",
      "## Tuner Objects\n",
      "\n",
      "```python\n",
      "class Tuner()\n",
      "```\n",
      "\n",
      "Tuner is the class-based way of launching hyperparameter tuning jobs compatible with Ray Tune 2.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `trainable` - A user-defined evaluation function.\n",
      "  It takes a configuration as input, outputs a evaluation\n",
      "  result (can be a numerical value or a dictionary of string\n",
      "  and numerical value pairs) for the input configuration.\n",
      "  For machine learning tasks, it usually involves training and\n",
      "  scoring a machine learning model, e.g., through validation loss.\n",
      "- `param_space` - Search space of the tuning job.\n",
      "  One thing to note is that both preprocessor and dataset can be tuned here.\n",
      "- `tune_config` - Tuning algorithm specific configs.\n",
      "  Refer to ray.tune.tune_config.TuneConfig for more info.\n",
      "- `run_config` - Runtime configuration that is specific to individual trials.\n",
      "  If passed, this will overwrite the run config passed to the Trainer,\n",
      "  if applicable. Refer to ray.air.config.RunConfig for more info.\n",
      "  \n",
      "  Usage pattern:\n",
      "  \n",
      "  .. code-block:: python\n",
      "  \n",
      "  from sklearn.datasets import load_breast_cancer\n",
      "  \n",
      "  from ray import tune\n",
      "  from ray.data import from_pandas\n",
      "  from ray.air.config import RunConfig, ScalingConfig\n",
      "  from ray.train.xgboost import XGBoostTrainer\n",
      "  from ray.tune.tuner import Tuner\n",
      "  \n",
      "  def get_dataset():\n",
      "  data_raw = load_breast_cancer(as_frame=True)\n",
      "  dataset_df = data_raw[\"data\"]\n",
      "  dataset_df[\"target\"] = data_raw[\"target\"]\n",
      "  dataset = from_pandas(dataset_df)\n",
      "  return dataset\n",
      "  \n",
      "  trainer = XGBoostTrainer(\n",
      "  label_column=\"target\",\n",
      "  params={},\n",
      "- `datasets={\"train\"` - get_dataset()},\n",
      "  )\n",
      "  \n",
      "  param_space = {\n",
      "- `\"scaling_config\"` - ScalingConfig(\n",
      "  num_workers=tune.grid_search([2, 4]),\n",
      "  resources_per_worker={\n",
      "- `\"CPU\"` - tune.grid_search([1, 2]),\n",
      "  },\n",
      "  ),\n",
      "  # You can even grid search various datasets in Tune.\n",
      "  # \"datasets\": {\n",
      "  #     \"train\": tune.grid_search(\n",
      "  #         [ds1, ds2]\n",
      "  #     ),\n",
      "  # },\n",
      "- `\"params\"` - {\n",
      "- `\"objective\"` - \"binary:logistic\",\n",
      "- `\"tree_method\"` - \"approx\",\n",
      "- `\"eval_metric\"` - [\"logloss\", \"error\"],\n",
      "- `\"eta\"` - tune.loguniform(1e-4, 1e-1),\n",
      "- `\"subsample\"` - tune.uniform(0.5, 1.0),\n",
      "- `\"max_depth\"` - tune.randint(1, 9),\n",
      "  },\n",
      "  }\n",
      "  tuner = Tuner(trainable=trainer, param_space=param_space,\n",
      "  run_config=RunConfig(name=\"my_tune_run\"))\n",
      "  analysis = tuner.fit()\n",
      "  \n",
      "  To retry a failed tune run, you can then do\n",
      "  \n",
      "  .. code-block:: python\n",
      "  \n",
      "  tuner = Tuner.restore(experiment_checkpoint_dir)\n",
      "  tuner.fit()\n",
      "  \n",
      "  ``experiment_checkpoint_dir`` can be easily located near the end of the\n",
      "  console output of your first failed run.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to ragproxyagent):\n",
      "\n",
      "To use FLAML for a classification task and use Spark for parallel training with a 30-second time limit and forcible job cancellation, you can follow the code below:\n",
      "\n",
      "```python\n",
      "from flaml import AutoML\n",
      "from sklearn.datasets import load_iris\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "# Load dataset\n",
      "data = load_iris()\n",
      "X_train, X_test, y_train, y_test = train_test_split(\n",
      "    data.data, data.target, test_size=0.2, random_state=42)\n",
      "\n",
      "# Set up the AutoML instance and fit the model\n",
      "automl = AutoML()\n",
      "automl.fit(\n",
      "    X_train, y_train, \n",
      "    task='classification', \n",
      "    time_budget=30, \n",
      "    n_concurrent_trials=4,  # Set number of parallel trials\n",
      "    use_spark=True,  # Enable parallel training with Spark\n",
      "    force_cancel=True,  # Enable force cancellation for jobs running overtime\n",
      ")\n",
      "\n",
      "# Predict\n",
      "y_pred = automl.predict(X_test)\n",
      "\n",
      "# Get the best model's information\n",
      "print(\"Best model:\", automl.best_estimator)\n",
      "print(\"Best model's config:\", automl.best_config)\n",
      "```\n",
      "\n",
      "Please make sure to have Spark installed by running:\n",
      "\n",
      "```bash\n",
      "pip install flaml[spark]\n",
      "```\n",
      "\n",
      "This code will set up an AutoML instance, perform a classification task, and train the model with a 30-second time limit using Spark for parallel training. If a job takes longer than the allowed time, it will be forcibly canceled.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/10 10:40:56 WARN Utils: Your hostname, DESKTOP-TTKT4BA resolves to a loopback address: 127.0.1.1; using 172.30.239.248 instead (on interface eth0)\n",
      "23/08/10 10:40:56 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/10 10:40:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "[flaml.automl.logger: 08-10 10:41:02] {1679} INFO - task = classification\n",
      "[flaml.automl.logger: 08-10 10:41:02] {1690} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 08-10 10:41:02] {1788} INFO - Minimizing error metric: log_loss\n",
      "[flaml.automl.logger: 08-10 10:41:02] {1900} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 10:41:02,208]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 10:41:02,482]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/10 10:41:04 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "[flaml.tune.tune: 08-10 10:41:04] {729} INFO - Number of trials: 1/1000000, 1 RUNNING, 0 TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 10:41:15.110399: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-10 10:41:15.178614: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-10 10:41:16.407118: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 08-10 10:41:20] {749} INFO - Brief result: {'pred_time': 1.484354337056478e-05, 'wall_clock_time': 26.359704971313477, 'metric_for_logging': {'pred_time': 1.484354337056478e-05}, 'val_loss': 0.669533807616872, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7f70a91af070>}\n",
      "[flaml.tune.tune: 08-10 10:41:20] {729} INFO - Number of trials: 2/1000000, 1 RUNNING, 1 TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 08-10 10:41:20] {749} INFO - Brief result: {'pred_time': 3.1558672587076825e-05, 'wall_clock_time': 26.8810076713562, 'metric_for_logging': {'pred_time': 3.1558672587076825e-05}, 'val_loss': 0.4315668469952459, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f70a91afd30>}\n",
      "[flaml.tune.tune: 08-10 10:41:20] {729} INFO - Number of trials: 3/1000000, 1 RUNNING, 2 TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 08-10 10:41:22] {749} INFO - Brief result: {'pred_time': 4.839897155761719e-05, 'wall_clock_time': 28.937474250793457, 'metric_for_logging': {'pred_time': 4.839897155761719e-05}, 'val_loss': 0.18647493060299933, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7f70a91af9a0>}\n",
      "[flaml.tune.tune: 08-10 10:41:22] {729} INFO - Number of trials: 4/1000000, 1 RUNNING, 3 TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lijiang1/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 08-10 10:41:23] {749} INFO - Brief result: {'pred_time': 5.043943723042806e-05, 'wall_clock_time': 29.686672925949097, 'metric_for_logging': {'pred_time': 5.043943723042806e-05}, 'val_loss': 0.7215296790003777, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f70a88e35e0>}\n",
      "[flaml.tune.tune: 08-10 10:41:23] {729} INFO - Number of trials: 5/1000000, 1 RUNNING, 4 TERMINATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lijiang1/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/home/lijiang1/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/home/lijiang1/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/home/lijiang1/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "Time exceeded, canceled jobs                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[flaml.automl.logger: 08-10 10:41:24] {2493} INFO - selected model: None\n",
      "[flaml.automl.logger: 08-10 10:41:24] {2627} INFO - retrain catboost for 0.4s\n",
      "[flaml.automl.logger: 08-10 10:41:24] {2630} INFO - retrained model: <catboost.core.CatBoostClassifier object at 0x7f70a91afdc0>\n",
      "[flaml.automl.logger: 08-10 10:41:24] {1930} INFO - fit succeeded\n",
      "[flaml.automl.logger: 08-10 10:41:24] {1931} INFO - Time taken to find the best model: 28.937474250793457\n",
      "Best model: catboost\n",
      "Best model's config: {'early_stopping_rounds': 10, 'learning_rate': 0.09999999999999996, 'n_estimators': 47}\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 1 (inferred language is bash)...\u001b[0m\n",
      "\u001b[33mragproxyagent\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "None\n",
      "You MUST NOT install any packages because all the packages needed are already installed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to ragproxyagent):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# reset the assistant. Always reset the assistant before starting a new conversation.\n",
    "assistant.reset()\n",
    "\n",
    "# given a problem, we use the ragproxyagent to generate a prompt to be sent to the assistant as the initial message.\n",
    "# the assistant receives the message and generates a response. The response will be sent back to the ragproxyagent for processing.\n",
    "# The conversation continues until the termination condition is met, in RetrieveChat, the termination condition when no human-in-loop is no code block detected.\n",
    "# With human-in-loop, the conversation will continue until the user says \"exit\".\n",
    "code_problem = \"How can I use FLAML to perform a classification task and use spark to do parallel training. Train 30 seconds and force cancel jobs if time limit is reached.\"\n",
    "ragproxyagent.initiate_chat(assistant, problem=code_problem, search_string=\"spark\")  # search_string is used as an extra filter for the embeddings search, in this case, we only want to search documents that contain \"spark\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "Use RetrieveChat to answer a question that is not related to code generation.\n",
    "\n",
    "Problem: Who is the author of FLAML?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_ids:  [['doc_58', 'doc_51', 'doc_35', 'doc_3', 'doc_22', 'doc_40', 'doc_14', 'doc_13', 'doc_59', 'doc_52', 'doc_1', 'doc_6', 'doc_28', 'doc_56', 'doc_29', 'doc_2', 'doc_55', 'doc_44', 'doc_19', 'doc_32']]\n",
      "\u001b[32mAdding doc_id doc_58 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_51 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_51 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_35 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_3 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_22 to context.\u001b[0m\n",
      "\u001b[33mragproxyagent\u001b[0m (to assistant):\n",
      "\n",
      "You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user. You should follow the following steps to answer a question:\n",
      "Step 1, you estimate the user's intent based on the question and context. The intent can be a code generation task or\n",
      "a question answering task.\n",
      "Step 2, you reply based on the intent.\n",
      "You should leverage the context provided by the user as much as possible. If you need more context, you should reply\n",
      "\"UPDATE CONTEXT\".\n",
      "For code generation task, you must obey the following rules:\n",
      "Rule 1. You MUST NOT install any packages because all the packages needed are already installed.\n",
      "Rule 2. You must follow the formats below to write your code:\n",
      "```language\n",
      "# your code\n",
      "```\n",
      "\n",
      "For question answering task, you must give as short an answer as possible.\n",
      "\n",
      "User's question is: Who is the author of FLAML?\n",
      "\n",
      "Context is: ---\n",
      "sidebar_label: estimator\n",
      "title: default.estimator\n",
      "---\n",
      "\n",
      "#### flamlize\\_estimator\n",
      "\n",
      "```python\n",
      "def flamlize_estimator(super_class, name: str, task: str, alternatives=None)\n",
      "```\n",
      "\n",
      "Enhance an estimator class with flaml's data-dependent default hyperparameter settings.\n",
      "\n",
      "**Example**:\n",
      "\n",
      "  \n",
      "```python\n",
      "import sklearn.ensemble as ensemble\n",
      "RandomForestRegressor = flamlize_estimator(\n",
      "    ensemble.RandomForestRegressor, \"rf\", \"regression\"\n",
      ")\n",
      "```\n",
      "  \n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `super_class` - an scikit-learn compatible estimator class.\n",
      "- `name` - a str of the estimator's name.\n",
      "- `task` - a str of the task type.\n",
      "- `alternatives` - (Optional) a list for alternative estimator names. For example,\n",
      "  ```[(\"max_depth\", 0, \"xgboost\")]``` means if the \"max_depth\" is set to 0\n",
      "  in the constructor, then look for the learned defaults for estimator \"xgboost\".\n",
      "\n",
      "\n",
      "---\n",
      "sidebar_label: task\n",
      "title: automl.task.task\n",
      "---\n",
      "\n",
      "## Task Objects\n",
      "\n",
      "```python\n",
      "class Task(ABC)\n",
      "```\n",
      "\n",
      "Abstract base class for a machine learning task.\n",
      "\n",
      "Class definitions should implement abstract methods and provide a non-empty dictionary of estimator classes.\n",
      "A Task can be suitable to be used for multiple machine-learning tasks (e.g. classification or regression) or be\n",
      "implemented specifically for a single one depending on the generality of data validation and model evaluation methods\n",
      "implemented. The implementation of a Task may optionally use the training data and labels to determine data and task\n",
      "specific details, such as in determining if a problem is single-label or multi-label.\n",
      "\n",
      "FLAML evaluates at runtime how to behave exactly, relying on the task instance to provide implementations of\n",
      "operations which vary between tasks.\n",
      "\n",
      "#### \\_\\_init\\_\\_\n",
      "\n",
      "```python\n",
      "def __init__(task_name: str, X_train: Optional[Union[np.ndarray, DataFrame, psDataFrame]] = None, y_train: Optional[Union[np.ndarray, DataFrame, Series, psSeries]] = None)\n",
      "```\n",
      "\n",
      "Constructor.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `task_name` - String name for this type of task. Used when the Task can be generic and implement a number of\n",
      "  types of sub-task.\n",
      "- `X_train` - Optional. Some Task types may use the data shape or features to determine details of their usage,\n",
      "  such as in binary vs multilabel classification.\n",
      "- `y_train` - Optional. Some Task types may use the data shape or features to determine details of their usage,\n",
      "  such as in binary vs multilabel classification.\n",
      "\n",
      "#### \\_\\_str\\_\\_\n",
      "\n",
      "```python\n",
      "def __str__() -> str\n",
      "```\n",
      "\n",
      "Name of this task type.\n",
      "\n",
      "#### evaluate\\_model\\_CV\n",
      "\n",
      "```python\n",
      "@abstractmethod\n",
      "def evaluate_model_CV(config: dict, estimator: \"flaml.automl.ml.BaseEstimator\", X_train_all: Union[np.ndarray, DataFrame, psDataFrame], y_train_all: Union[np.ndarray, DataFrame, Series, psSeries], budget: int, kf, eval_metric: str, best_val_loss: float, log_training_metric: bool = False, fit_kwargs: Optional[dict] = {}) -> Tuple[float, float, float, float]\n",
      "```\n",
      "\n",
      "Evaluate the model using cross-validation.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `config` - configuration used in the evaluation of the metric.\n",
      "- `estimator` - Estimator class of the model.\n",
      "- `X_train_all` - Complete training feature data.\n",
      "- `y_train_all` - Complete training target data.\n",
      "- `budget` - Training time budget.\n",
      "- `kf` - Cross-validation index generator.\n",
      "- `eval_metric` - Metric name to be used for evaluation.\n",
      "- `best_val_loss` - Best current validation-set loss.\n",
      "- `log_training_metric` - Bool defaults False. Enables logging of the training metric.\n",
      "- `fit_kwargs` - Additional kwargs passed to the estimator's fit method.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  validation loss, metric value, train time, prediction time\n",
      "\n",
      "#### validate\\_data\n",
      "\n",
      "```python\n",
      "@abstractmethod\n",
      "def validate_data(automl: \"flaml.automl.automl.AutoML\", state: \"flaml.automl.state.AutoMLState\", X_train_all: Union[np.ndarray, DataFrame, psDataFrame, None], y_train_all: Union[np.ndarray, DataFrame, Series, psSeries, None], dataframe: Union[DataFrame, None], label: str, X_val: Optional[Union[np.ndarray, DataFrame, psDataFrame]] = None, y_val: Optional[Union[np.ndarray, DataFrame, Series, psSeries]] = None, groups_val: Optional[List[str]] = None, groups: Optional[List[str]] = None)\n",
      "```\n",
      "\n",
      "Validate that the data is suitable for this task type.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `automl` - The AutoML instance from which this task has been constructed.\n",
      "- `state` - The AutoMLState instance for this run.\n",
      "- `X_train_all` - The complete data set or None if dataframe is supplied.\n",
      "- `y_train_all` - The complete target set or None if dataframe is supplied.\n",
      "- `dataframe` - A dataframe constaining the complete data set with targets.\n",
      "- `label` - The name of the target column in dataframe.\n",
      "- `X_val` - Optional. A data set for validation.\n",
      "- `y_val` - Optional. A target vector corresponding to X_val for validation.\n",
      "- `groups_val` - Group labels (with matching length to y_val) or group counts (with sum equal to length of y_val)\n",
      "  for validation data. Need to be consistent with groups.\n",
      "- `groups` - Group labels (with matching length to y_train) or groups counts (with sum equal to length of y_train)\n",
      "  for training data.\n",
      "  \n",
      "\n",
      "**Raises**:\n",
      "\n",
      "- `AssertionError` - The data provided is invalid for this task type and configuration.\n",
      "\n",
      "#### prepare\\_data\n",
      "\n",
      "```python\n",
      "@abstractmethod\n",
      "def prepare_data(state: \"flaml.automl.state.AutoMLState\", X_train_all: Union[np.ndarray, DataFrame, psDataFrame], y_train_all: Union[np.ndarray, DataFrame, Series, psSeries, None], auto_augment: bool, eval_method: str, split_type: str, split_ratio: float, n_splits: int, data_is_df: bool, sample_weight_full: Optional[List[float]] = None)\n",
      "```\n",
      "\n",
      "Prepare the data for fitting or inference.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `automl` - The AutoML instance from which this task has been constructed.\n",
      "- `state` - The AutoMLState instance for this run.\n",
      "- `X_train_all` - The complete data set or None if dataframe is supplied. Must\n",
      "  contain the target if y_train_all is None\n",
      "- `y_train_all` - The complete target set or None if supplied in X_train_all.\n",
      "- `auto_augment` - If true, task-specific data augmentations will be applied.\n",
      "- `eval_method` - A string of resampling strategy, one of ['auto', 'cv', 'holdout'].\n",
      "- `split_type` - str or splitter object, default=\"auto\" | the data split type.\n",
      "  * A valid splitter object is an instance of a derived class of scikit-learn\n",
      "  [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold)\n",
      "  and have ``split`` and ``get_n_splits`` methods with the same signatures.\n",
      "  Set eval_method to \"cv\" to use the splitter object.\n",
      "  * Valid str options depend on different tasks.\n",
      "  For classification tasks, valid choices are\n",
      "  [\"auto\", 'stratified', 'uniform', 'time', 'group']. \"auto\" -> stratified.\n",
      "  For regression tasks, valid choices are [\"auto\", 'uniform', 'time'].\n",
      "  \"auto\" -> uniform.\n",
      "  For time series forecast tasks, must be \"auto\" or 'time'.\n",
      "  For ranking task, must be \"auto\" or 'group'.\n",
      "- `split_ratio` - A float of the valiation data percentage for holdout.\n",
      "- `n_splits` - An integer of the number of folds for cross - validation.\n",
      "- `data_is_df` - True if the data was provided as a DataFrame else False.\n",
      "- `sample_weight_full` - A 1d arraylike of the sample weight.\n",
      "  \n",
      "\n",
      "**Raises**:\n",
      "\n",
      "- `AssertionError` - The configuration provided is invalid for this task type and data.\n",
      "\n",
      "#### decide\\_split\\_type\n",
      "\n",
      "```python\n",
      "@abstractmethod\n",
      "def decide_split_type(split_type: str, y_train_all: Union[np.ndarray, DataFrame, Series, psSeries, None], fit_kwargs: dict, groups: Optional[List[str]] = None) -> str\n",
      "```\n",
      "\n",
      "Choose an appropriate data split type for this data and task.\n",
      "\n",
      "If split_type is 'auto' then this is determined based on the task type and data.\n",
      "If a specific split_type is requested then the choice is validated to be appropriate.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `split_type` - Either 'auto' or a task appropriate split type.\n",
      "- `y_train_all` - The complete set of targets.\n",
      "- `fit_kwargs` - Additional kwargs passed to the estimator's fit method.\n",
      "- `groups` - Optional. Group labels (with matching length to y_train) or groups counts (with sum equal to length\n",
      "  of y_train) for training data.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  The determined appropriate split type.\n",
      "  \n",
      "\n",
      "**Raises**:\n",
      "\n",
      "- `AssertionError` - The requested split_type is invalid for this task, configuration and data.\n",
      "\n",
      "#### preprocess\n",
      "\n",
      "```python\n",
      "@abstractmethod\n",
      "def preprocess(X: Union[np.ndarray, DataFrame, psDataFrame], transformer: Optional[\"flaml.automl.data.DataTransformer\"] = None) -> Union[np.ndarray, DataFrame]\n",
      "```\n",
      "\n",
      "Preprocess the data ready for fitting or inference with this task type.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `X` - The data set to process.\n",
      "- `transformer` - A DataTransformer instance to be used in processing.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  The preprocessed data set having the same type as the input.\n",
      "\n",
      "#### default\\_estimator\\_list\n",
      "\n",
      "```python\n",
      "@abstractmethod\n",
      "def default_estimator_list(estimator_list: Union[List[str], str] = \"auto\", is_spark_dataframe: bool = False) -> List[str]\n",
      "```\n",
      "\n",
      "Return the list of default estimators registered for this task type.\n",
      "\n",
      "If 'auto' is provided then the default list is returned, else the provided list will be validated given this task\n",
      "type.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "new_automl = AutoML()\n",
      "new_automl.fit(X_train, y_train, starting_points=starting_points)\n",
      "```\n",
      "  \n",
      "- `seed` - int or None, default=None | The random seed for hpo.\n",
      "- `n_concurrent_trials` - [Experimental] int, default=1 | The number of\n",
      "  concurrent trials. When n_concurrent_trials > 1, flaml performes\n",
      "  [parallel tuning](../../Use-Cases/Task-Oriented-AutoML#parallel-tuning)\n",
      "  and installation of ray or spark is required: `pip install flaml[ray]`\n",
      "  or `pip install flaml[spark]`. Please check\n",
      "  [here](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
      "  for more details about installing Spark.\n",
      "- `keep_search_state` - boolean, default=False | Whether to keep data needed\n",
      "  for model search after fit(). By default the state is deleted for\n",
      "  space saving.\n",
      "- `preserve_checkpoint` - boolean, default=True | Whether to preserve the saved checkpoint\n",
      "  on disk when deleting automl. By default the checkpoint is preserved.\n",
      "- `early_stop` - boolean, default=False | Whether to stop early if the\n",
      "  search is considered to converge.\n",
      "- `force_cancel` - boolean, default=False | Whether to forcely cancel Spark jobs if the\n",
      "  search time exceeded the time budget.\n",
      "- `append_log` - boolean, default=False | Whetehr to directly append the log\n",
      "  records to the input log file if it exists.\n",
      "- `auto_augment` - boolean, default=True | Whether to automatically\n",
      "  augment rare classes.\n",
      "- `min_sample_size` - int, default=MIN_SAMPLE_TRAIN | the minimal sample\n",
      "  size when sample=True.\n",
      "- `use_ray` - boolean or dict.\n",
      "  If boolean: default=False | Whether to use ray to run the training\n",
      "  in separate processes. This can be used to prevent OOM for large\n",
      "  datasets, but will incur more overhead in time.\n",
      "  If dict: the dict contains the keywords arguments to be passed to\n",
      "  [ray.tune.run](https://docs.ray.io/en/latest/tune/api_docs/execution.html).\n",
      "- `use_spark` - boolean, default=False | Whether to use spark to run the training\n",
      "  in parallel spark jobs. This can be used to accelerate training on large models\n",
      "  and large datasets, but will incur more overhead in time and thus slow down\n",
      "  training in some cases. GPU training is not supported yet when use_spark is True.\n",
      "  For Spark clusters, by default, we will launch one trial per executor. However,\n",
      "  sometimes we want to launch more trials than the number of executors (e.g., local mode).\n",
      "  In this case, we can set the environment variable `FLAML_MAX_CONCURRENT` to override\n",
      "  the detected `num_executors`. The final number of concurrent trials will be the minimum\n",
      "  of `n_concurrent_trials` and `num_executors`.\n",
      "- `free_mem_ratio` - float between 0 and 1, default=0. The free memory ratio to keep during training.\n",
      "- `metric_constraints` - list, default=[] | The list of metric constraints.\n",
      "  Each element in this list is a 3-tuple, which shall be expressed\n",
      "  in the following format: the first element of the 3-tuple is the name of the\n",
      "  metric, the second element is the inequality sign chosen from \">=\" and \"<=\",\n",
      "  and the third element is the constraint value. E.g., `('val_loss', '<=', 0.1)`.\n",
      "  Note that all the metric names in metric_constraints need to be reported via\n",
      "  the metrics_to_log dictionary returned by a customized metric function.\n",
      "  The customized metric function shall be provided via the `metric` key word\n",
      "  argument of the fit() function or the automl constructor.\n",
      "  Find an example in the 4th constraint type in this [doc](../../Use-Cases/Task-Oriented-AutoML#constraint).\n",
      "  If `pred_time_limit` is provided as one of keyword arguments to fit() function or\n",
      "  the automl constructor, flaml will automatically (and under the hood)\n",
      "  add it as an additional element in the metric_constraints. Essentially 'pred_time_limit'\n",
      "  specifies a constraint about the prediction latency constraint in seconds.\n",
      "- `custom_hp` - dict, default=None | The custom search space specified by user.\n",
      "  It is a nested dict with keys being the estimator names, and values being dicts\n",
      "  per estimator search space. In the per estimator search space dict,\n",
      "  the keys are the hyperparameter names, and values are dicts of info (\"domain\",\n",
      "  \"init_value\", and \"low_cost_init_value\") about the search space associated with\n",
      "  the hyperparameter (i.e., per hyperparameter search space dict). When custom_hp\n",
      "  is provided, the built-in search space which is also a nested dict of per estimator\n",
      "  search space dict, will be updated with custom_hp. Note that during this nested dict update,\n",
      "  the per hyperparameter search space dicts will be replaced (instead of updated) by the ones\n",
      "  provided in custom_hp. Note that the value for \"domain\" can either be a constant\n",
      "  or a sample.Domain object.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "custom_hp = {\n",
      "     \"transformer_ms\": {\n",
      "         \"model_path\": {\n",
      "             \"domain\": \"albert-base-v2\",\n",
      "         },\n",
      "         \"learning_rate\": {\n",
      "             \"domain\": tune.choice([1e-4, 1e-5]),\n",
      "         }\n",
      "     }\n",
      " }\n",
      "```\n",
      "- `skip_transform` - boolean, default=False | Whether to pre-process data prior to modeling.\n",
      "- `fit_kwargs_by_estimator` - dict, default=None | The user specified keywords arguments, grouped by estimator name.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "fit_kwargs_by_estimator = {\n",
      "    \"transformer\": {\n",
      "        \"output_dir\": \"test/data/output/\",\n",
      "        \"fp16\": False,\n",
      "    }\n",
      "}\n",
      "```\n",
      "- `mlflow_logging` - boolean, default=True | Whether to log the training results to mlflow.\n",
      "  This requires mlflow to be installed and to have an active mlflow run.\n",
      "  FLAML will create nested runs.\n",
      "\n",
      "#### config\\_history\n",
      "\n",
      "```python\n",
      "@property\n",
      "def config_history() -> dict\n",
      "```\n",
      "\n",
      "A dictionary of iter->(estimator, config, time),\n",
      "storing the best estimator, config, and the time when the best\n",
      "model is updated each time.\n",
      "\n",
      "#### model\n",
      "\n",
      "```python\n",
      "@property\n",
      "def model()\n",
      "```\n",
      "\n",
      "An object with `predict()` and `predict_proba()` method (for\n",
      "classification), storing the best trained model.\n",
      "\n",
      "#### best\\_model\\_for\\_estimator\n",
      "\n",
      "```python\n",
      "def best_model_for_estimator(estimator_name: str)\n",
      "```\n",
      "\n",
      "Return the best model found for a particular estimator.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `estimator_name` - a str of the estimator's name.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  An object storing the best model for estimator_name.\n",
      "  If `model_history` was set to False during fit(), then the returned model\n",
      "  is untrained unless estimator_name is the best estimator.\n",
      "  If `model_history` was set to True, then the returned model is trained.\n",
      "\n",
      "#### best\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_estimator()\n",
      "```\n",
      "\n",
      "A string indicating the best estimator found.\n",
      "\n",
      "#### best\\_iteration\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_iteration()\n",
      "```\n",
      "\n",
      "An integer of the iteration number where the best\n",
      "config is found.\n",
      "\n",
      "#### best\\_config\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config()\n",
      "```\n",
      "\n",
      "A dictionary of the best configuration.\n",
      "\n",
      "#### best\\_config\\_per\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config_per_estimator()\n",
      "```\n",
      "\n",
      "A dictionary of all estimators' best configuration.\n",
      "\n",
      "#### best\\_loss\\_per\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_loss_per_estimator()\n",
      "```\n",
      "\n",
      "A dictionary of all estimators' best loss.\n",
      "\n",
      "#### best\\_loss\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_loss()\n",
      "```\n",
      "\n",
      "A float of the best loss found.\n",
      "\n",
      "#### best\\_result\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_result()\n",
      "```\n",
      "\n",
      "Result dictionary for model trained with the best config.\n",
      "\n",
      "#### metrics\\_for\\_best\\_config\n",
      "---\n",
      "sidebar_label: user_proxy_agent\n",
      "title: autogen.agent.user_proxy_agent\n",
      "---\n",
      "\n",
      "## UserProxyAgent Objects\n",
      "\n",
      "```python\n",
      "class UserProxyAgent(Agent)\n",
      "```\n",
      "\n",
      "(Experimental) A proxy agent for the user, that can execute code and provide feedback to the other agents.\n",
      "\n",
      "#### \\_\\_init\\_\\_\n",
      "\n",
      "```python\n",
      "def __init__(name: str, system_message: Optional[str] = \"\", work_dir: Optional[str] = None, human_input_mode: Optional[str] = \"ALWAYS\", function_map: Optional[Dict[str, Callable]] = {}, max_consecutive_auto_reply: Optional[int] = None, is_termination_msg: Optional[Callable[[Dict], bool]] = None, use_docker: Optional[Union[List[str], str, bool]] = True, timeout: Optional[int] = 600, **config, ,)\n",
      "```\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `name` _str_ - name of the agent.\n",
      "- `system_message` _str_ - system message for the agent.\n",
      "- `work_dir` _Optional, str_ - The working directory for the code execution.\n",
      "  If None, a default working directory will be used.\n",
      "  The default working directory is the \"extensions\" directory under\n",
      "  \"path_to_flaml/autogen\".\n",
      "- `human_input_mode` _str_ - whether to ask for human inputs every time a message is received.\n",
      "  Possible values are \"ALWAYS\", \"TERMINATE\", \"NEVER\".\n",
      "  (1) When \"ALWAYS\", the agent prompts for human input every time a message is received.\n",
      "  Under this mode, the conversation stops when the human input is \"exit\",\n",
      "  or when is_termination_msg is True and there is no human input.\n",
      "  (2) When \"TERMINATE\", the agent only prompts for human input only when a termination message is received or\n",
      "  the number of auto reply reaches the max_consecutive_auto_reply.\n",
      "  (3) When \"NEVER\", the agent will never prompt for human input. Under this mode, the conversation stops\n",
      "  when the number of auto reply reaches the max_consecutive_auto_reply or when is_termination_msg is True.\n",
      "- `function_map` _dict[str, callable]_ - Mapping function names (passed to openai) to callable functions.\n",
      "- `max_consecutive_auto_reply` _int_ - the maximum number of consecutive auto replies.\n",
      "  default to None (no limit provided, class attribute MAX_CONSECUTIVE_AUTO_REPLY will be used as the limit in this case).\n",
      "  The limit only plays a role when human_input_mode is not \"ALWAYS\".\n",
      "- `is_termination_msg` _function_ - a function that takes a message in the form of a dictionary and returns a boolean value indicating if this received message is a termination message.\n",
      "  The dict can contain the following keys: \"content\", \"role\", \"name\", \"function_call\".\n",
      "- `use_docker` _Optional, list, str or bool_ - The docker image to use for code execution.\n",
      "  If a list or a str of image name(s) is provided, the code will be executed in a docker container\n",
      "  with the first image successfully pulled.\n",
      "  If None, False or empty, the code will be executed in the current environment.\n",
      "  Default is True, which will be converted into a list.\n",
      "  If the code is executed in the current environment,\n",
      "  the code must be trusted.\n",
      "- `timeout` _Optional, int_ - The maximum execution time in seconds.\n",
      "- `**config` _dict_ - other configurations.\n",
      "\n",
      "#### use\\_docker\n",
      "\n",
      "```python\n",
      "@property\n",
      "def use_docker() -> Union[bool, str]\n",
      "```\n",
      "\n",
      "bool value of whether to use docker to execute the code,\n",
      "or str value of the docker image name to use.\n",
      "\n",
      "#### execute\\_code\n",
      "\n",
      "```python\n",
      "def execute_code(code_blocks)\n",
      "```\n",
      "\n",
      "Execute the code and return the result.\n",
      "\n",
      "#### auto\\_reply\n",
      "\n",
      "```python\n",
      "def auto_reply(message: dict, sender, default_reply=\"\")\n",
      "```\n",
      "\n",
      "Generate an auto reply.\n",
      "\n",
      "#### receive\n",
      "\n",
      "```python\n",
      "def receive(message: Union[Dict, str], sender)\n",
      "```\n",
      "\n",
      "Receive a message from the sender agent.\n",
      "Once a message is received, this function sends a reply to the sender or simply stop.\n",
      "The reply can be generated automatically or entered manually by a human.\n",
      "\n",
      "#### generate\\_init\\_prompt\n",
      "\n",
      "```python\n",
      "def generate_init_prompt(*args, **kwargs) -> Union[str, Dict]\n",
      "```\n",
      "\n",
      "Generate the initial prompt for the agent.\n",
      "\n",
      "Override this function to customize the initial prompt based on user's request.\n",
      "\n",
      "#### initiate\\_chat\n",
      "\n",
      "```python\n",
      "def initiate_chat(recipient, *args, **kwargs)\n",
      "```\n",
      "\n",
      "Initiate a chat with the receiver agent.\n",
      "\n",
      "`generate_init_prompt` is called to generate the initial prompt for the agent.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `receiver` - the receiver agent.\n",
      "- `*args` - any additional arguments.\n",
      "- `**kwargs` - any additional keyword arguments.\n",
      "\n",
      "#### register\\_function\n",
      "\n",
      "```python\n",
      "def register_function(function_map: Dict[str, Callable])\n",
      "```\n",
      "\n",
      "Register functions to the agent.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `function_map` - a dictionary mapping function names to functions.\n",
      "\n",
      "\n",
      "---\n",
      "sidebar_label: cfo_cat\n",
      "title: tune.searcher.cfo_cat\n",
      "---\n",
      "\n",
      "## FLOW2Cat Objects\n",
      "\n",
      "```python\n",
      "class FLOW2Cat(FLOW2)\n",
      "```\n",
      "\n",
      "Local search algorithm optimized for categorical variables.\n",
      "\n",
      "## CFOCat Objects\n",
      "\n",
      "```python\n",
      "class CFOCat(CFO)\n",
      "```\n",
      "\n",
      "CFO optimized for categorical variables.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to ragproxyagent):\n",
      "\n",
      "The author of FLAML is Chi Wang, who is a principal researcher at Microsoft Research.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# reset the assistant. Always reset the assistant before starting a new conversation.\n",
    "assistant.reset()\n",
    "\n",
    "qa_problem = \"Who is the author of FLAML?\"\n",
    "ragproxyagent.initiate_chat(assistant, problem=qa_problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3\n",
    "\n",
    "Use RetrieveChat to help generate sample code and ask for human-in-loop feedbacks.\n",
    "\n",
    "Problem: how to build a time series forecasting model for stock price using FLAML?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_ids:  [['doc_37', 'doc_35', 'doc_46', 'doc_40', 'doc_49', 'doc_51', 'doc_58', 'doc_48', 'doc_14', 'doc_39', 'doc_47', 'doc_41', 'doc_13', 'doc_60', 'doc_52', 'doc_59', 'doc_43', 'doc_10', 'doc_34', 'doc_33']]\n",
      "\u001b[32mAdding doc_id doc_37 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_35 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_46 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_35 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_46 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_40 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_49 to context.\u001b[0m\n",
      "\u001b[33mragproxyagent\u001b[0m (to assistant):\n",
      "\n",
      "You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user. You should follow the following steps to answer a question:\n",
      "Step 1, you estimate the user's intent based on the question and context. The intent can be a code generation task or\n",
      "a question answering task.\n",
      "Step 2, you reply based on the intent.\n",
      "You should leverage the context provided by the user as much as possible. If you need more context, you should reply\n",
      "\"UPDATE CONTEXT\".\n",
      "For code generation task, you must obey the following rules:\n",
      "Rule 1. You MUST NOT install any packages because all the packages needed are already installed.\n",
      "Rule 2. You must follow the formats below to write your code:\n",
      "```language\n",
      "# your code\n",
      "```\n",
      "\n",
      "For question answering task, you must give as short an answer as possible.\n",
      "\n",
      "User's question is: how to build a time series forecasting model for stock price using FLAML?\n",
      "\n",
      "Context is: \n",
      "- `log_file_name` - A string of the log file name.\n",
      "- `X_train` - A numpy array or dataframe of training data in shape n*m.\n",
      "  For time series forecast tasks, the first column of X_train must be the timestamp column (datetime type). Other columns in the dataframe are assumed to be exogenous variables (categorical or numeric).\n",
      "- `y_train` - A numpy array or series of labels in shape n*1.\n",
      "- `dataframe` - A dataframe of training data including label column.\n",
      "  For time series forecast tasks, dataframe must be specified and should\n",
      "  have at least two columns: timestamp and label, where the first\n",
      "  column is the timestamp column (datetime type). Other columns\n",
      "  in the dataframe are assumed to be exogenous variables\n",
      "  (categorical or numeric).\n",
      "- `label` - A str of the label column name, e.g., 'label';\n",
      "- `Note` - If X_train and y_train are provided,\n",
      "  dataframe and label are ignored;\n",
      "  If not, dataframe and label must be provided.\n",
      "- `time_budget` - A float number of the time budget in seconds.\n",
      "- `task` - A string of the task type, e.g.,\n",
      "  'classification', 'regression', 'ts_forecast', 'rank',\n",
      "  'seq-classification', 'seq-regression', 'summarization',\n",
      "  or an instance of Task class.\n",
      "- `eval_method` - A string of resampling strategy, one of\n",
      "  ['auto', 'cv', 'holdout'].\n",
      "- `split_ratio` - A float of the validation data percentage for holdout.\n",
      "- `n_splits` - An integer of the number of folds for cross-validation.\n",
      "- `split_type` - str or splitter object, default=\"auto\" | the data split type.\n",
      "  * A valid splitter object is an instance of a derived class of scikit-learn\n",
      "  [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold)\n",
      "  and have ``split`` and ``get_n_splits`` methods with the same signatures.\n",
      "  Set eval_method to \"cv\" to use the splitter object.\n",
      "  * Valid str options depend on different tasks.\n",
      "  For classification tasks, valid choices are\n",
      "  [\"auto\", 'stratified', 'uniform', 'time', 'group']. \"auto\" -> stratified.\n",
      "  For regression tasks, valid choices are [\"auto\", 'uniform', 'time'].\n",
      "  \"auto\" -> uniform.\n",
      "  For time series forecast tasks, must be \"auto\" or 'time'.\n",
      "  For ranking task, must be \"auto\" or 'group'.\n",
      "- `groups` - None or array-like | Group labels (with matching length to\n",
      "  y_train) or groups counts (with sum equal to length of y_train)\n",
      "  for training data.\n",
      "- `n_jobs` - An integer of the number of threads for training | default=-1.\n",
      "  Use all available resources when n_jobs == -1.\n",
      "- `train_best` - A boolean of whether to train the best config in the\n",
      "  time budget; if false, train the last config in the budget.\n",
      "- `train_full` - A boolean of whether to train on the full data. If true,\n",
      "  eval_method and sample_size in the log file will be ignored.\n",
      "- `record_id` - the ID of the training log record from which the model will\n",
      "  be retrained. By default `record_id = -1` which means this will be\n",
      "  ignored. `record_id = 0` corresponds to the first trial, and\n",
      "  when `record_id >= 0`, `time_budget` will be ignored.\n",
      "- `auto_augment` - boolean, default=True | Whether to automatically\n",
      "  augment rare classes.\n",
      "- `custom_hp` - dict, default=None | The custom search space specified by user\n",
      "  Each key is the estimator name, each value is a dict of the custom search space for that estimator. Notice the\n",
      "  domain of the custom search space can either be a value or a sample.Domain object.\n",
      "  \n",
      "```python\n",
      "custom_hp = {\n",
      "    \"transformer_ms\": {\n",
      "        \"model_path\": {\n",
      "            \"domain\": \"albert-base-v2\",\n",
      "        },\n",
      "        \"learning_rate\": {\n",
      "            \"domain\": tune.choice([1e-4, 1e-5]),\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "- `fit_kwargs_by_estimator` - dict, default=None | The user specified keywords arguments, grouped by estimator name.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "fit_kwargs_by_estimator = {\n",
      "    \"transformer\": {\n",
      "        \"output_dir\": \"test/data/output/\",\n",
      "        \"fp16\": False,\n",
      "    }\n",
      "}\n",
      "```\n",
      "  \n",
      "- `**fit_kwargs` - Other key word arguments to pass to fit() function of\n",
      "  the searched learners, such as sample_weight. Below are a few examples of\n",
      "  estimator-specific parameters:\n",
      "- `period` - int | forecast horizon for all time series forecast tasks.\n",
      "- `gpu_per_trial` - float, default = 0 | A float of the number of gpus per trial,\n",
      "  only used by TransformersEstimator, XGBoostSklearnEstimator, and\n",
      "  TemporalFusionTransformerEstimator.\n",
      "- `group_ids` - list of strings of column names identifying a time series, only\n",
      "  used by TemporalFusionTransformerEstimator, required for\n",
      "  'ts_forecast_panel' task. `group_ids` is a parameter for TimeSeriesDataSet object\n",
      "  from PyTorchForecasting.\n",
      "  For other parameters to describe your dataset, refer to\n",
      "  [TimeSeriesDataSet PyTorchForecasting](https://pytorch-forecasting.readthedocs.io/en/stable/api/pytorch_forecasting.data.timeseries.TimeSeriesDataSet.html).\n",
      "  To specify your variables, use `static_categoricals`, `static_reals`,\n",
      "  `time_varying_known_categoricals`, `time_varying_known_reals`,\n",
      "  `time_varying_unknown_categoricals`, `time_varying_unknown_reals`,\n",
      "  `variable_groups`. To provide more information on your data, use\n",
      "  `max_encoder_length`, `min_encoder_length`, `lags`.\n",
      "- `log_dir` - str, default = \"lightning_logs\" | Folder into which to log results\n",
      "  for tensorboard, only used by TemporalFusionTransformerEstimator.\n",
      "- `max_epochs` - int, default = 20 | Maximum number of epochs to run training,\n",
      "  only used by TemporalFusionTransformerEstimator.\n",
      "- `batch_size` - int, default = 64 | Batch size for training model, only\n",
      "  used by TemporalFusionTransformerEstimator.\n",
      "\n",
      "#### search\\_space\n",
      "\n",
      "```python\n",
      "@property\n",
      "def search_space() -> dict\n",
      "```\n",
      "\n",
      "Search space.\n",
      "\n",
      "Must be called after fit(...)\n",
      "(use max_iter=0 and retrain_final=False to prevent actual fitting).\n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  A dict of the search space.\n",
      "\n",
      "#### low\\_cost\\_partial\\_config\n",
      "\n",
      "```python\n",
      "@property\n",
      "def low_cost_partial_config() -> dict\n",
      "```\n",
      "\n",
      "Low cost partial config.\n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  A dict.\n",
      "  (a) if there is only one estimator in estimator_list, each key is a\n",
      "  hyperparameter name.\n",
      "  (b) otherwise, it is a nested dict with 'ml' as the key, and\n",
      "  a list of the low_cost_partial_configs as the value, corresponding\n",
      "  to each learner's low_cost_partial_config; the estimator index as\n",
      "  an integer corresponding to the cheapest learner is appended to the\n",
      "  list at the end.\n",
      "\n",
      "#### cat\\_hp\\_cost\n",
      "\n",
      "```python\n",
      "@property\n",
      "def cat_hp_cost() -> dict\n",
      "```\n",
      "\n",
      "Categorical hyperparameter cost\n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  A dict.\n",
      "  (a) if there is only one estimator in estimator_list, each key is a\n",
      "  hyperparameter name.\n",
      "  (b) otherwise, it is a nested dict with 'ml' as the key, and\n",
      "  a list of the cat_hp_cost's as the value, corresponding\n",
      "  to each learner's cat_hp_cost; the cost relative to lgbm for each\n",
      "  learner (as a list itself) is appended to the list at the end.\n",
      "\n",
      "#### points\\_to\\_evaluate\n",
      "\n",
      "```python\n",
      "@property\n",
      "def points_to_evaluate() -> dict\n",
      "```\n",
      "\n",
      "Initial points to evaluate.\n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  A list of dicts. Each dict is the initial point for each learner.\n",
      "\n",
      "#### resource\\_attr\n",
      "\n",
      "```python\n",
      "@property\n",
      "def resource_attr() -> Optional[str]\n",
      "```\n",
      "\n",
      "Attribute of the resource dimension.\n",
      "\n",
      "new_automl = AutoML()\n",
      "new_automl.fit(X_train, y_train, starting_points=starting_points)\n",
      "```\n",
      "  \n",
      "- `seed` - int or None, default=None | The random seed for hpo.\n",
      "- `n_concurrent_trials` - [Experimental] int, default=1 | The number of\n",
      "  concurrent trials. When n_concurrent_trials > 1, flaml performes\n",
      "  [parallel tuning](../../Use-Cases/Task-Oriented-AutoML#parallel-tuning)\n",
      "  and installation of ray or spark is required: `pip install flaml[ray]`\n",
      "  or `pip install flaml[spark]`. Please check\n",
      "  [here](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
      "  for more details about installing Spark.\n",
      "- `keep_search_state` - boolean, default=False | Whether to keep data needed\n",
      "  for model search after fit(). By default the state is deleted for\n",
      "  space saving.\n",
      "- `preserve_checkpoint` - boolean, default=True | Whether to preserve the saved checkpoint\n",
      "  on disk when deleting automl. By default the checkpoint is preserved.\n",
      "- `early_stop` - boolean, default=False | Whether to stop early if the\n",
      "  search is considered to converge.\n",
      "- `force_cancel` - boolean, default=False | Whether to forcely cancel Spark jobs if the\n",
      "  search time exceeded the time budget.\n",
      "- `append_log` - boolean, default=False | Whetehr to directly append the log\n",
      "  records to the input log file if it exists.\n",
      "- `auto_augment` - boolean, default=True | Whether to automatically\n",
      "  augment rare classes.\n",
      "- `min_sample_size` - int, default=MIN_SAMPLE_TRAIN | the minimal sample\n",
      "  size when sample=True.\n",
      "- `use_ray` - boolean or dict.\n",
      "  If boolean: default=False | Whether to use ray to run the training\n",
      "  in separate processes. This can be used to prevent OOM for large\n",
      "  datasets, but will incur more overhead in time.\n",
      "  If dict: the dict contains the keywords arguments to be passed to\n",
      "  [ray.tune.run](https://docs.ray.io/en/latest/tune/api_docs/execution.html).\n",
      "- `use_spark` - boolean, default=False | Whether to use spark to run the training\n",
      "  in parallel spark jobs. This can be used to accelerate training on large models\n",
      "  and large datasets, but will incur more overhead in time and thus slow down\n",
      "  training in some cases. GPU training is not supported yet when use_spark is True.\n",
      "  For Spark clusters, by default, we will launch one trial per executor. However,\n",
      "  sometimes we want to launch more trials than the number of executors (e.g., local mode).\n",
      "  In this case, we can set the environment variable `FLAML_MAX_CONCURRENT` to override\n",
      "  the detected `num_executors`. The final number of concurrent trials will be the minimum\n",
      "  of `n_concurrent_trials` and `num_executors`.\n",
      "- `free_mem_ratio` - float between 0 and 1, default=0. The free memory ratio to keep during training.\n",
      "- `metric_constraints` - list, default=[] | The list of metric constraints.\n",
      "  Each element in this list is a 3-tuple, which shall be expressed\n",
      "  in the following format: the first element of the 3-tuple is the name of the\n",
      "  metric, the second element is the inequality sign chosen from \">=\" and \"<=\",\n",
      "  and the third element is the constraint value. E.g., `('val_loss', '<=', 0.1)`.\n",
      "  Note that all the metric names in metric_constraints need to be reported via\n",
      "  the metrics_to_log dictionary returned by a customized metric function.\n",
      "  The customized metric function shall be provided via the `metric` key word\n",
      "  argument of the fit() function or the automl constructor.\n",
      "  Find an example in the 4th constraint type in this [doc](../../Use-Cases/Task-Oriented-AutoML#constraint).\n",
      "  If `pred_time_limit` is provided as one of keyword arguments to fit() function or\n",
      "  the automl constructor, flaml will automatically (and under the hood)\n",
      "  add it as an additional element in the metric_constraints. Essentially 'pred_time_limit'\n",
      "  specifies a constraint about the prediction latency constraint in seconds.\n",
      "- `custom_hp` - dict, default=None | The custom search space specified by user.\n",
      "  It is a nested dict with keys being the estimator names, and values being dicts\n",
      "  per estimator search space. In the per estimator search space dict,\n",
      "  the keys are the hyperparameter names, and values are dicts of info (\"domain\",\n",
      "  \"init_value\", and \"low_cost_init_value\") about the search space associated with\n",
      "  the hyperparameter (i.e., per hyperparameter search space dict). When custom_hp\n",
      "  is provided, the built-in search space which is also a nested dict of per estimator\n",
      "  search space dict, will be updated with custom_hp. Note that during this nested dict update,\n",
      "  the per hyperparameter search space dicts will be replaced (instead of updated) by the ones\n",
      "  provided in custom_hp. Note that the value for \"domain\" can either be a constant\n",
      "  or a sample.Domain object.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "custom_hp = {\n",
      "     \"transformer_ms\": {\n",
      "         \"model_path\": {\n",
      "             \"domain\": \"albert-base-v2\",\n",
      "         },\n",
      "         \"learning_rate\": {\n",
      "             \"domain\": tune.choice([1e-4, 1e-5]),\n",
      "         }\n",
      "     }\n",
      " }\n",
      "```\n",
      "- `skip_transform` - boolean, default=False | Whether to pre-process data prior to modeling.\n",
      "- `fit_kwargs_by_estimator` - dict, default=None | The user specified keywords arguments, grouped by estimator name.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "fit_kwargs_by_estimator = {\n",
      "    \"transformer\": {\n",
      "        \"output_dir\": \"test/data/output/\",\n",
      "        \"fp16\": False,\n",
      "    }\n",
      "}\n",
      "```\n",
      "- `mlflow_logging` - boolean, default=True | Whether to log the training results to mlflow.\n",
      "  This requires mlflow to be installed and to have an active mlflow run.\n",
      "  FLAML will create nested runs.\n",
      "\n",
      "#### config\\_history\n",
      "\n",
      "```python\n",
      "@property\n",
      "def config_history() -> dict\n",
      "```\n",
      "\n",
      "A dictionary of iter->(estimator, config, time),\n",
      "storing the best estimator, config, and the time when the best\n",
      "model is updated each time.\n",
      "\n",
      "#### model\n",
      "\n",
      "```python\n",
      "@property\n",
      "def model()\n",
      "```\n",
      "\n",
      "An object with `predict()` and `predict_proba()` method (for\n",
      "classification), storing the best trained model.\n",
      "\n",
      "#### best\\_model\\_for\\_estimator\n",
      "\n",
      "```python\n",
      "def best_model_for_estimator(estimator_name: str)\n",
      "```\n",
      "\n",
      "Return the best model found for a particular estimator.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `estimator_name` - a str of the estimator's name.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  An object storing the best model for estimator_name.\n",
      "  If `model_history` was set to False during fit(), then the returned model\n",
      "  is untrained unless estimator_name is the best estimator.\n",
      "  If `model_history` was set to True, then the returned model is trained.\n",
      "\n",
      "#### best\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_estimator()\n",
      "```\n",
      "\n",
      "A string indicating the best estimator found.\n",
      "\n",
      "#### best\\_iteration\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_iteration()\n",
      "```\n",
      "\n",
      "An integer of the iteration number where the best\n",
      "config is found.\n",
      "\n",
      "#### best\\_config\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config()\n",
      "```\n",
      "\n",
      "A dictionary of the best configuration.\n",
      "\n",
      "#### best\\_config\\_per\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config_per_estimator()\n",
      "```\n",
      "\n",
      "A dictionary of all estimators' best configuration.\n",
      "\n",
      "#### best\\_loss\\_per\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_loss_per_estimator()\n",
      "```\n",
      "\n",
      "A dictionary of all estimators' best loss.\n",
      "\n",
      "#### best\\_loss\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_loss()\n",
      "```\n",
      "\n",
      "A float of the best loss found.\n",
      "\n",
      "#### best\\_result\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_result()\n",
      "```\n",
      "\n",
      "Result dictionary for model trained with the best config.\n",
      "\n",
      "#### metrics\\_for\\_best\\_config\n",
      "---\n",
      "sidebar_label: ts_model\n",
      "title: automl.time_series.ts_model\n",
      "---\n",
      "\n",
      "## Prophet Objects\n",
      "\n",
      "```python\n",
      "class Prophet(TimeSeriesEstimator)\n",
      "```\n",
      "\n",
      "The class for tuning Prophet.\n",
      "\n",
      "## ARIMA Objects\n",
      "\n",
      "```python\n",
      "class ARIMA(StatsModelsEstimator)\n",
      "```\n",
      "\n",
      "The class for tuning ARIMA.\n",
      "\n",
      "## SARIMAX Objects\n",
      "\n",
      "```python\n",
      "class SARIMAX(StatsModelsEstimator)\n",
      "```\n",
      "\n",
      "The class for tuning SARIMA.\n",
      "\n",
      "## HoltWinters Objects\n",
      "\n",
      "```python\n",
      "class HoltWinters(StatsModelsEstimator)\n",
      "```\n",
      "\n",
      "The class for tuning Holt Winters model, aka 'Triple Exponential Smoothing'.\n",
      "\n",
      "## TS\\_SKLearn Objects\n",
      "\n",
      "```python\n",
      "class TS_SKLearn(TimeSeriesEstimator)\n",
      "```\n",
      "\n",
      "The class for tuning SKLearn Regressors for time-series forecasting\n",
      "\n",
      "## LGBM\\_TS Objects\n",
      "\n",
      "```python\n",
      "class LGBM_TS(TS_SKLearn)\n",
      "```\n",
      "\n",
      "The class for tuning LGBM Regressor for time-series forecasting\n",
      "\n",
      "## XGBoost\\_TS Objects\n",
      "\n",
      "```python\n",
      "class XGBoost_TS(TS_SKLearn)\n",
      "```\n",
      "\n",
      "The class for tuning XGBoost Regressor for time-series forecasting\n",
      "\n",
      "## RF\\_TS Objects\n",
      "\n",
      "```python\n",
      "class RF_TS(TS_SKLearn)\n",
      "```\n",
      "\n",
      "The class for tuning Random Forest Regressor for time-series forecasting\n",
      "\n",
      "## ExtraTrees\\_TS Objects\n",
      "\n",
      "```python\n",
      "class ExtraTrees_TS(TS_SKLearn)\n",
      "```\n",
      "\n",
      "The class for tuning Extra Trees Regressor for time-series forecasting\n",
      "\n",
      "## XGBoostLimitDepth\\_TS Objects\n",
      "\n",
      "```python\n",
      "class XGBoostLimitDepth_TS(TS_SKLearn)\n",
      "```\n",
      "\n",
      "The class for tuning XGBoost Regressor with unlimited depth for time-series forecasting\n",
      "\n",
      "\n",
      "\n",
      "new_automl = AutoML()\n",
      "new_automl.fit(X_train, y_train, starting_points=starting_points)\n",
      "```\n",
      "  \n",
      "- `seed` - int or None, default=None | The random seed for hpo.\n",
      "- `n_concurrent_trials` - [Experimental] int, default=1 | The number of\n",
      "  concurrent trials. When n_concurrent_trials > 1, flaml performes\n",
      "  [parallel tuning](../../Use-Cases/Task-Oriented-AutoML#parallel-tuning)\n",
      "  and installation of ray or spark is required: `pip install flaml[ray]`\n",
      "  or `pip install flaml[spark]`. Please check\n",
      "  [here](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
      "  for more details about installing Spark.\n",
      "- `keep_search_state` - boolean, default=False | Whether to keep data needed\n",
      "  for model search after fit(). By default the state is deleted for\n",
      "  space saving.\n",
      "- `preserve_checkpoint` - boolean, default=True | Whether to preserve the saved checkpoint\n",
      "  on disk when deleting automl. By default the checkpoint is preserved.\n",
      "- `early_stop` - boolean, default=False | Whether to stop early if the\n",
      "  search is considered to converge.\n",
      "- `force_cancel` - boolean, default=False | Whether to forcely cancel the PySpark job if overtime.\n",
      "- `append_log` - boolean, default=False | Whetehr to directly append the log\n",
      "  records to the input log file if it exists.\n",
      "- `auto_augment` - boolean, default=True | Whether to automatically\n",
      "  augment rare classes.\n",
      "- `min_sample_size` - int, default=MIN_SAMPLE_TRAIN | the minimal sample\n",
      "  size when sample=True.\n",
      "- `use_ray` - boolean or dict.\n",
      "  If boolean: default=False | Whether to use ray to run the training\n",
      "  in separate processes. This can be used to prevent OOM for large\n",
      "  datasets, but will incur more overhead in time.\n",
      "  If dict: the dict contains the keywords arguments to be passed to\n",
      "  [ray.tune.run](https://docs.ray.io/en/latest/tune/api_docs/execution.html).\n",
      "- `use_spark` - boolean, default=False | Whether to use spark to run the training\n",
      "  in parallel spark jobs. This can be used to accelerate training on large models\n",
      "  and large datasets, but will incur more overhead in time and thus slow down\n",
      "  training in some cases.\n",
      "- `free_mem_ratio` - float between 0 and 1, default=0. The free memory ratio to keep during training.\n",
      "- `metric_constraints` - list, default=[] | The list of metric constraints.\n",
      "  Each element in this list is a 3-tuple, which shall be expressed\n",
      "  in the following format: the first element of the 3-tuple is the name of the\n",
      "  metric, the second element is the inequality sign chosen from \">=\" and \"<=\",\n",
      "  and the third element is the constraint value. E.g., `('precision', '>=', 0.9)`.\n",
      "  Note that all the metric names in metric_constraints need to be reported via\n",
      "  the metrics_to_log dictionary returned by a customized metric function.\n",
      "  The customized metric function shall be provided via the `metric` key word argument\n",
      "  of the fit() function or the automl constructor.\n",
      "  Find examples in this [test](https://github.com/microsoft/FLAML/tree/main/test/automl/test_constraints.py).\n",
      "  If `pred_time_limit` is provided as one of keyword arguments to fit() function or\n",
      "  the automl constructor, flaml will automatically (and under the hood)\n",
      "  add it as an additional element in the metric_constraints. Essentially 'pred_time_limit'\n",
      "  specifies a constraint about the prediction latency constraint in seconds.\n",
      "- `custom_hp` - dict, default=None | The custom search space specified by user\n",
      "  Each key is the estimator name, each value is a dict of the custom search space for that estimator. Notice the\n",
      "  domain of the custom search space can either be a value of a sample.Domain object.\n",
      "  \n",
      "  \n",
      "  \n",
      "```python\n",
      "custom_hp = {\n",
      "    \"transformer_ms\": {\n",
      "        \"model_path\": {\n",
      "            \"domain\": \"albert-base-v2\",\n",
      "        },\n",
      "        \"learning_rate\": {\n",
      "            \"domain\": tune.choice([1e-4, 1e-5]),\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "- `time_col` - for a time series task, name of the column containing the timestamps. If not\n",
      "  provided, defaults to the first column of X_train/X_val\n",
      "  \n",
      "- `cv_score_agg_func` - customized cross-validation scores aggregate function. Default to average metrics across folds. If specificed, this function needs to\n",
      "  have the following input arguments:\n",
      "  \n",
      "  * val_loss_folds: list of floats, the loss scores of each fold;\n",
      "  * log_metrics_folds: list of dicts/floats, the metrics of each fold to log.\n",
      "  \n",
      "  This function should return the final aggregate result of all folds. A float number of the minimization objective, and a dictionary as the metrics to log or None.\n",
      "  E.g.,\n",
      "  \n",
      "```python\n",
      "def cv_score_agg_func(val_loss_folds, log_metrics_folds):\n",
      "    metric_to_minimize = sum(val_loss_folds)/len(val_loss_folds)\n",
      "    metrics_to_log = None\n",
      "    for single_fold in log_metrics_folds:\n",
      "        if metrics_to_log is None:\n",
      "            metrics_to_log = single_fold\n",
      "        elif isinstance(metrics_to_log, dict):\n",
      "            metrics_to_log = {k: metrics_to_log[k] + v for k, v in single_fold.items()}\n",
      "        else:\n",
      "            metrics_to_log += single_fold\n",
      "    if metrics_to_log:\n",
      "        n = len(val_loss_folds)\n",
      "        metrics_to_log = (\n",
      "            {k: v / n for k, v in metrics_to_log.items()}\n",
      "            if isinstance(metrics_to_log, dict)\n",
      "            else metrics_to_log / n\n",
      "        )\n",
      "    return metric_to_minimize, metrics_to_log\n",
      "```\n",
      "  \n",
      "- `skip_transform` - boolean, default=False | Whether to pre-process data prior to modeling.\n",
      "- `mlflow_logging` - boolean, default=None | Whether to log the training results to mlflow.\n",
      "  Default value is None, which means the logging decision is made based on\n",
      "  AutoML.__init__'s mlflow_logging argument.\n",
      "  This requires mlflow to be installed and to have an active mlflow run.\n",
      "  FLAML will create nested runs.\n",
      "- `fit_kwargs_by_estimator` - dict, default=None | The user specified keywords arguments, grouped by estimator name.\n",
      "  For TransformersEstimator, available fit_kwargs can be found from\n",
      "  [TrainingArgumentsForAuto](nlp/huggingface/training_args).\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "fit_kwargs_by_estimator = {\n",
      "    \"transformer\": {\n",
      "        \"output_dir\": \"test/data/output/\",\n",
      "        \"fp16\": False,\n",
      "    },\n",
      "    \"tft\": {\n",
      "        \"max_encoder_length\": 1,\n",
      "        \"min_encoder_length\": 1,\n",
      "        \"static_categoricals\": [],\n",
      "        \"static_reals\": [],\n",
      "        \"time_varying_known_categoricals\": [],\n",
      "        \"time_varying_known_reals\": [],\n",
      "        \"time_varying_unknown_categoricals\": [],\n",
      "        \"time_varying_unknown_reals\": [],\n",
      "        \"variable_groups\": {},\n",
      "        \"lags\": {},\n",
      "    }\n",
      "}\n",
      "```\n",
      "  \n",
      "- `**fit_kwargs` - Other key word arguments to pass to fit() function of\n",
      "  the searched learners, such as sample_weight. Below are a few examples of\n",
      "  estimator-specific parameters:\n",
      "- `period` - int | forecast horizon for all time series forecast tasks.\n",
      "- `gpu_per_trial` - float, default = 0 | A float of the number of gpus per trial,\n",
      "  only used by TransformersEstimator, XGBoostSklearnEstimator, and\n",
      "  TemporalFusionTransformerEstimator.\n",
      "- `group_ids` - list of strings of column names identifying a time series, only\n",
      "  used by TemporalFusionTransformerEstimator, required for\n",
      "  'ts_forecast_panel' task. `group_ids` is a parameter for TimeSeriesDataSet object\n",
      "  from PyTorchForecasting.\n",
      "  For other parameters to describe your dataset, refer to\n",
      "  [TimeSeriesDataSet PyTorchForecasting](https://pytorch-forecasting.readthedocs.io/en/stable/api/pytorch_forecasting.data.timeseries.TimeSeriesDataSet.html).\n",
      "  To specify your variables, use `static_categoricals`, `static_reals`,\n",
      "  `time_varying_known_categoricals`, `time_varying_known_reals`,\n",
      "  `time_varying_unknown_categoricals`, `time_varying_unknown_reals`,\n",
      "  `variable_groups`. To provide more information on your data, use\n",
      "  `max_encoder_length`, `min_encoder_length`, `lags`.\n",
      "- `log_dir` - str, default = \"lightning_logs\" | Folder into which to log results\n",
      "  for tensorboard, only used by TemporalFusionTransformerEstimator.\n",
      "- `max_epochs` - int, default = 20 | Maximum number of epochs to run training,\n",
      "  only used by TemporalFusionTransformerEstimator.\n",
      "- `batch_size` - int, default = 64 | Batch size for training model, only\n",
      "  used by TemporalFusionTransformerEstimator.\n",
      "\n",
      "\n",
      "---\n",
      "sidebar_label: ts_data\n",
      "title: automl.time_series.ts_data\n",
      "---\n",
      "\n",
      "## TimeSeriesDataset Objects\n",
      "\n",
      "```python\n",
      "@dataclass\n",
      "class TimeSeriesDataset()\n",
      "```\n",
      "\n",
      "#### to\\_univariate\n",
      "\n",
      "```python\n",
      "def to_univariate() -> Dict[str, \"TimeSeriesDataset\"]\n",
      "```\n",
      "\n",
      "Convert a multivariate TrainingData  to a dict of univariate ones\n",
      "@param df:\n",
      "@return:\n",
      "\n",
      "#### fourier\\_series\n",
      "\n",
      "```python\n",
      "def fourier_series(feature: pd.Series, name: str)\n",
      "```\n",
      "\n",
      "Assume feature goes from 0 to 1 cyclically, transform that into Fourier\n",
      "@param feature: input feature\n",
      "@return: sin(2pi*feature), cos(2pi*feature)\n",
      "\n",
      "## DataTransformerTS Objects\n",
      "\n",
      "```python\n",
      "class DataTransformerTS()\n",
      "```\n",
      "\n",
      "Transform input time series training data.\n",
      "\n",
      "#### fit\n",
      "\n",
      "```python\n",
      "def fit(X: Union[DataFrame, np.array], y)\n",
      "```\n",
      "\n",
      "Fit transformer.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `X` - A numpy array or a pandas dataframe of training data.\n",
      "- `y` - A numpy array or a pandas series of labels.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "- `X` - Processed numpy array or pandas dataframe of training data.\n",
      "- `y` - Processed numpy array or pandas series of labels.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to ragproxyagent):\n",
      "\n",
      "To build a time series forecasting model for stock price using FLAML, you can use the following steps:\n",
      "\n",
      "1. Install FLAML library if not already installed:\n",
      "```\n",
      "pip install flaml[notebook,timeseries]\n",
      "```\n",
      "\n",
      "2. Import the necessary libraries and methods:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from flaml import AutoML\n",
      "```\n",
      "\n",
      "3. Load and preprocess your data. Ensure that the first column is the timestamp column (datetime type), and other columns are exogenous variables (categorical or numeric). Label column should be stock price:\n",
      "\n",
      "```python\n",
      "# Load your data (assuming it's in a CSV file)\n",
      "data = pd.read_csv(\"your_data.csv\")\n",
      "\n",
      "# Convert the timestamp column to datetime format (replace 'timestamp' with the name of your timestamp column)\n",
      "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
      "```\n",
      "\n",
      "4. Split the data into training and testing datasets:\n",
      "\n",
      "```python\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "data_train, data_test = train_test_split(data, shuffle=False, test_size=0.2)\n",
      "```\n",
      "\n",
      "5. Set up the FLAML AutoML instance and fit the time series model:\n",
      "\n",
      "```python\n",
      "automl = AutoML()\n",
      "\n",
      "automl.fit(\n",
      "    dataframe=data_train,\n",
      "    label=\"stock_price\",  # Replace with your label column name (stock price)\n",
      "    task=\"ts_forecast\",\n",
      "    time_budget=600  # Set the time budget for AutoML to find the best model (e.g., 600 seconds)\n",
      ")\n",
      "```\n",
      "\n",
      "6. Make predictions on the test data:\n",
      "\n",
      "```python\n",
      "predictions = automl.predict(data_test.loc[:, data_test.columns != 'stock_price'])\n",
      "```\n",
      "\n",
      "Now you have your time series forecasting model for stock price, and you have made predictions using it.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mragproxyagent\u001b[0m (to assistant):\n",
      "\n",
      "set time budget to 2 mins\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to ragproxyagent):\n",
      "\n",
      "To set the time budget to 2 minutes, you can simply adjust the `time_budget` parameter in the `fit()` function:\n",
      "\n",
      "```python\n",
      "automl.fit(\n",
      "    dataframe=data_train,\n",
      "    label=\"stock_price\",  # Replace with your label column name (stock price)\n",
      "    task=\"ts_forecast\",\n",
      "    time_budget=120  # Set the time budget to 2 minutes (120 seconds)\n",
      ")\n",
      "```\n",
      "\n",
      "Now the AutoML instance will search for the best model within a 2-minute time budget.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# reset the assistant. Always reset the assistant before starting a new conversation.\n",
    "assistant.reset()\n",
    "\n",
    "# set `human_input_mode` to be `ALWAYS`, so the agent will ask for human input at every step.\n",
    "ragproxyagent.human_input_mode = \"ALWAYS\"\n",
    "code_problem = \"how to build a time series forecasting model for stock price using FLAML?\"\n",
    "ragproxyagent.initiate_chat(assistant, problem=code_problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4\n",
    "\n",
    "Use RetrieveChat to answer a question and ask for human-in-loop feedbacks.\n",
    "\n",
    "Problem: Is there a function named `tune_automl` in FLAML?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_ids:  [['doc_35', 'doc_14', 'doc_40', 'doc_13', 'doc_51', 'doc_58', 'doc_20', 'doc_26', 'doc_34', 'doc_22', 'doc_11', 'doc_59', 'doc_3', 'doc_56', 'doc_47', 'doc_53', 'doc_19', 'doc_28', 'doc_32', 'doc_46']]\n",
      "\u001b[32mAdding doc_id doc_35 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_14 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_40 to context.\u001b[0m\n",
      "\u001b[33mragproxyagent\u001b[0m (to assistant):\n",
      "\n",
      "You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user. You should follow the following steps to answer a question:\n",
      "Step 1, you estimate the user's intent based on the question and context. The intent can be a code generation task or\n",
      "a question answering task.\n",
      "Step 2, you reply based on the intent.\n",
      "You should leverage the context provided by the user as much as possible. If you need more context, you should reply\n",
      "\"UPDATE CONTEXT\".\n",
      "For code generation task, you must obey the following rules:\n",
      "Rule 1. You MUST NOT install any packages because all the packages needed are already installed.\n",
      "Rule 2. You must follow the formats below to write your code:\n",
      "```language\n",
      "# your code\n",
      "```\n",
      "\n",
      "For question answering task, you must give as short an answer as possible.\n",
      "\n",
      "User's question is: Is there a function named `tune_automl` in FLAML?\n",
      "\n",
      "Context is: \n",
      "new_automl = AutoML()\n",
      "new_automl.fit(X_train, y_train, starting_points=starting_points)\n",
      "```\n",
      "  \n",
      "- `seed` - int or None, default=None | The random seed for hpo.\n",
      "- `n_concurrent_trials` - [Experimental] int, default=1 | The number of\n",
      "  concurrent trials. When n_concurrent_trials > 1, flaml performes\n",
      "  [parallel tuning](../../Use-Cases/Task-Oriented-AutoML#parallel-tuning)\n",
      "  and installation of ray or spark is required: `pip install flaml[ray]`\n",
      "  or `pip install flaml[spark]`. Please check\n",
      "  [here](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
      "  for more details about installing Spark.\n",
      "- `keep_search_state` - boolean, default=False | Whether to keep data needed\n",
      "  for model search after fit(). By default the state is deleted for\n",
      "  space saving.\n",
      "- `preserve_checkpoint` - boolean, default=True | Whether to preserve the saved checkpoint\n",
      "  on disk when deleting automl. By default the checkpoint is preserved.\n",
      "- `early_stop` - boolean, default=False | Whether to stop early if the\n",
      "  search is considered to converge.\n",
      "- `force_cancel` - boolean, default=False | Whether to forcely cancel Spark jobs if the\n",
      "  search time exceeded the time budget.\n",
      "- `append_log` - boolean, default=False | Whetehr to directly append the log\n",
      "  records to the input log file if it exists.\n",
      "- `auto_augment` - boolean, default=True | Whether to automatically\n",
      "  augment rare classes.\n",
      "- `min_sample_size` - int, default=MIN_SAMPLE_TRAIN | the minimal sample\n",
      "  size when sample=True.\n",
      "- `use_ray` - boolean or dict.\n",
      "  If boolean: default=False | Whether to use ray to run the training\n",
      "  in separate processes. This can be used to prevent OOM for large\n",
      "  datasets, but will incur more overhead in time.\n",
      "  If dict: the dict contains the keywords arguments to be passed to\n",
      "  [ray.tune.run](https://docs.ray.io/en/latest/tune/api_docs/execution.html).\n",
      "- `use_spark` - boolean, default=False | Whether to use spark to run the training\n",
      "  in parallel spark jobs. This can be used to accelerate training on large models\n",
      "  and large datasets, but will incur more overhead in time and thus slow down\n",
      "  training in some cases. GPU training is not supported yet when use_spark is True.\n",
      "  For Spark clusters, by default, we will launch one trial per executor. However,\n",
      "  sometimes we want to launch more trials than the number of executors (e.g., local mode).\n",
      "  In this case, we can set the environment variable `FLAML_MAX_CONCURRENT` to override\n",
      "  the detected `num_executors`. The final number of concurrent trials will be the minimum\n",
      "  of `n_concurrent_trials` and `num_executors`.\n",
      "- `free_mem_ratio` - float between 0 and 1, default=0. The free memory ratio to keep during training.\n",
      "- `metric_constraints` - list, default=[] | The list of metric constraints.\n",
      "  Each element in this list is a 3-tuple, which shall be expressed\n",
      "  in the following format: the first element of the 3-tuple is the name of the\n",
      "  metric, the second element is the inequality sign chosen from \">=\" and \"<=\",\n",
      "  and the third element is the constraint value. E.g., `('val_loss', '<=', 0.1)`.\n",
      "  Note that all the metric names in metric_constraints need to be reported via\n",
      "  the metrics_to_log dictionary returned by a customized metric function.\n",
      "  The customized metric function shall be provided via the `metric` key word\n",
      "  argument of the fit() function or the automl constructor.\n",
      "  Find an example in the 4th constraint type in this [doc](../../Use-Cases/Task-Oriented-AutoML#constraint).\n",
      "  If `pred_time_limit` is provided as one of keyword arguments to fit() function or\n",
      "  the automl constructor, flaml will automatically (and under the hood)\n",
      "  add it as an additional element in the metric_constraints. Essentially 'pred_time_limit'\n",
      "  specifies a constraint about the prediction latency constraint in seconds.\n",
      "- `custom_hp` - dict, default=None | The custom search space specified by user.\n",
      "  It is a nested dict with keys being the estimator names, and values being dicts\n",
      "  per estimator search space. In the per estimator search space dict,\n",
      "  the keys are the hyperparameter names, and values are dicts of info (\"domain\",\n",
      "  \"init_value\", and \"low_cost_init_value\") about the search space associated with\n",
      "  the hyperparameter (i.e., per hyperparameter search space dict). When custom_hp\n",
      "  is provided, the built-in search space which is also a nested dict of per estimator\n",
      "  search space dict, will be updated with custom_hp. Note that during this nested dict update,\n",
      "  the per hyperparameter search space dicts will be replaced (instead of updated) by the ones\n",
      "  provided in custom_hp. Note that the value for \"domain\" can either be a constant\n",
      "  or a sample.Domain object.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "custom_hp = {\n",
      "     \"transformer_ms\": {\n",
      "         \"model_path\": {\n",
      "             \"domain\": \"albert-base-v2\",\n",
      "         },\n",
      "         \"learning_rate\": {\n",
      "             \"domain\": tune.choice([1e-4, 1e-5]),\n",
      "         }\n",
      "     }\n",
      " }\n",
      "```\n",
      "- `skip_transform` - boolean, default=False | Whether to pre-process data prior to modeling.\n",
      "- `fit_kwargs_by_estimator` - dict, default=None | The user specified keywords arguments, grouped by estimator name.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "fit_kwargs_by_estimator = {\n",
      "    \"transformer\": {\n",
      "        \"output_dir\": \"test/data/output/\",\n",
      "        \"fp16\": False,\n",
      "    }\n",
      "}\n",
      "```\n",
      "- `mlflow_logging` - boolean, default=True | Whether to log the training results to mlflow.\n",
      "  This requires mlflow to be installed and to have an active mlflow run.\n",
      "  FLAML will create nested runs.\n",
      "\n",
      "#### config\\_history\n",
      "\n",
      "```python\n",
      "@property\n",
      "def config_history() -> dict\n",
      "```\n",
      "\n",
      "A dictionary of iter->(estimator, config, time),\n",
      "storing the best estimator, config, and the time when the best\n",
      "model is updated each time.\n",
      "\n",
      "#### model\n",
      "\n",
      "```python\n",
      "@property\n",
      "def model()\n",
      "```\n",
      "\n",
      "An object with `predict()` and `predict_proba()` method (for\n",
      "classification), storing the best trained model.\n",
      "\n",
      "#### best\\_model\\_for\\_estimator\n",
      "\n",
      "```python\n",
      "def best_model_for_estimator(estimator_name: str)\n",
      "```\n",
      "\n",
      "Return the best model found for a particular estimator.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `estimator_name` - a str of the estimator's name.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  An object storing the best model for estimator_name.\n",
      "  If `model_history` was set to False during fit(), then the returned model\n",
      "  is untrained unless estimator_name is the best estimator.\n",
      "  If `model_history` was set to True, then the returned model is trained.\n",
      "\n",
      "#### best\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_estimator()\n",
      "```\n",
      "\n",
      "A string indicating the best estimator found.\n",
      "\n",
      "#### best\\_iteration\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_iteration()\n",
      "```\n",
      "\n",
      "An integer of the iteration number where the best\n",
      "config is found.\n",
      "\n",
      "#### best\\_config\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config()\n",
      "```\n",
      "\n",
      "A dictionary of the best configuration.\n",
      "\n",
      "#### best\\_config\\_per\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_config_per_estimator()\n",
      "```\n",
      "\n",
      "A dictionary of all estimators' best configuration.\n",
      "\n",
      "#### best\\_loss\\_per\\_estimator\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_loss_per_estimator()\n",
      "```\n",
      "\n",
      "A dictionary of all estimators' best loss.\n",
      "\n",
      "#### best\\_loss\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_loss()\n",
      "```\n",
      "\n",
      "A float of the best loss found.\n",
      "\n",
      "#### best\\_result\n",
      "\n",
      "```python\n",
      "@property\n",
      "def best_result()\n",
      "```\n",
      "\n",
      "Result dictionary for model trained with the best config.\n",
      "\n",
      "#### metrics\\_for\\_best\\_config\n",
      "from flaml import BlendSearch\n",
      "algo = BlendSearch(metric='val_loss', mode='min',\n",
      "        space=search_space,\n",
      "        low_cost_partial_config=low_cost_partial_config)\n",
      "for i in range(10):\n",
      "    analysis = tune.run(compute_with_config,\n",
      "        search_alg=algo, use_ray=False)\n",
      "    print(analysis.trials[-1].last_result)\n",
      "```\n",
      "  \n",
      "- `verbose` - 0, 1, 2, or 3. If ray or spark backend is used, their verbosity will be\n",
      "  affected by this argument. 0 = silent, 1 = only status updates,\n",
      "  2 = status and brief trial results, 3 = status and detailed trial results.\n",
      "  Defaults to 2.\n",
      "- `local_dir` - A string of the local dir to save ray logs if ray backend is\n",
      "  used; or a local dir to save the tuning log.\n",
      "- `num_samples` - An integer of the number of configs to try. Defaults to 1.\n",
      "- `resources_per_trial` - A dictionary of the hardware resources to allocate\n",
      "  per trial, e.g., `{'cpu': 1}`. It is only valid when using ray backend\n",
      "  (by setting 'use_ray = True'). It shall be used when you need to do\n",
      "  [parallel tuning](../../Use-Cases/Tune-User-Defined-Function#parallel-tuning).\n",
      "- `config_constraints` - A list of config constraints to be satisfied.\n",
      "  e.g., ```config_constraints = [(mem_size, '<=', 1024**3)]```\n",
      "  \n",
      "  mem_size is a function which produces a float number for the bytes\n",
      "  needed for a config.\n",
      "  It is used to skip configs which do not fit in memory.\n",
      "- `metric_constraints` - A list of metric constraints to be satisfied.\n",
      "  e.g., `['precision', '>=', 0.9]`. The sign can be \">=\" or \"<=\".\n",
      "- `max_failure` - int | the maximal consecutive number of failures to sample\n",
      "  a trial before the tuning is terminated.\n",
      "- `use_ray` - A boolean of whether to use ray as the backend.\n",
      "- `use_spark` - A boolean of whether to use spark as the backend.\n",
      "- `log_file_name` - A string of the log file name. Default to None.\n",
      "  When set to None:\n",
      "  if local_dir is not given, no log file is created;\n",
      "  if local_dir is given, the log file name will be autogenerated under local_dir.\n",
      "  Only valid when verbose > 0 or use_ray is True.\n",
      "- `lexico_objectives` - dict, default=None | It specifics information needed to perform multi-objective\n",
      "  optimization with lexicographic preferences. When lexico_objectives is not None, the arguments metric,\n",
      "  mode, will be invalid, and flaml's tune uses CFO\n",
      "  as the `search_alg`, which makes the input (if provided) `search_alg' invalid.\n",
      "  This dictionary shall contain the following fields of key-value pairs:\n",
      "  - \"metrics\":  a list of optimization objectives with the orders reflecting the priorities/preferences of the\n",
      "  objectives.\n",
      "  - \"modes\" (optional): a list of optimization modes (each mode either \"min\" or \"max\") corresponding to the\n",
      "  objectives in the metric list. If not provided, we use \"min\" as the default mode for all the objectives.\n",
      "  - \"targets\" (optional): a dictionary to specify the optimization targets on the objectives. The keys are the\n",
      "  metric names (provided in \"metric\"), and the values are the numerical target values.\n",
      "  - \"tolerances\" (optional): a dictionary to specify the optimality tolerances on objectives. The keys are the metric names (provided in \"metrics\"), and the values are the absolute/percentage tolerance in the form of numeric/string.\n",
      "  E.g.,\n",
      "```python\n",
      "lexico_objectives = {\n",
      "    \"metrics\": [\"error_rate\", \"pred_time\"],\n",
      "    \"modes\": [\"min\", \"min\"],\n",
      "    \"tolerances\": {\"error_rate\": 0.01, \"pred_time\": 0.0},\n",
      "    \"targets\": {\"error_rate\": 0.0},\n",
      "}\n",
      "```\n",
      "  We also support percentage tolerance.\n",
      "  E.g.,\n",
      "```python\n",
      "lexico_objectives = {\n",
      "    \"metrics\": [\"error_rate\", \"pred_time\"],\n",
      "    \"modes\": [\"min\", \"min\"],\n",
      "    \"tolerances\": {\"error_rate\": \"5%\", \"pred_time\": \"0%\"},\n",
      "    \"targets\": {\"error_rate\": 0.0},\n",
      "}\n",
      "```\n",
      "- `force_cancel` - boolean, default=False | Whether to forcely cancel the PySpark job if overtime.\n",
      "- `n_concurrent_trials` - int, default=0 | The number of concurrent trials when perform hyperparameter\n",
      "  tuning with Spark. Only valid when use_spark=True and spark is required:\n",
      "  `pip install flaml[spark]`. Please check\n",
      "  [here](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
      "  for more details about installing Spark. When tune.run() is called from AutoML, it will be\n",
      "  overwritten by the value of `n_concurrent_trials` in AutoML. When <= 0, the concurrent trials\n",
      "  will be set to the number of executors.\n",
      "- `**ray_args` - keyword arguments to pass to ray.tune.run().\n",
      "  Only valid when use_ray=True.\n",
      "\n",
      "## Tuner Objects\n",
      "\n",
      "```python\n",
      "class Tuner()\n",
      "```\n",
      "\n",
      "Tuner is the class-based way of launching hyperparameter tuning jobs compatible with Ray Tune 2.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `trainable` - A user-defined evaluation function.\n",
      "  It takes a configuration as input, outputs a evaluation\n",
      "  result (can be a numerical value or a dictionary of string\n",
      "  and numerical value pairs) for the input configuration.\n",
      "  For machine learning tasks, it usually involves training and\n",
      "  scoring a machine learning model, e.g., through validation loss.\n",
      "- `param_space` - Search space of the tuning job.\n",
      "  One thing to note is that both preprocessor and dataset can be tuned here.\n",
      "- `tune_config` - Tuning algorithm specific configs.\n",
      "  Refer to ray.tune.tune_config.TuneConfig for more info.\n",
      "- `run_config` - Runtime configuration that is specific to individual trials.\n",
      "  If passed, this will overwrite the run config passed to the Trainer,\n",
      "  if applicable. Refer to ray.air.config.RunConfig for more info.\n",
      "  \n",
      "  Usage pattern:\n",
      "  \n",
      "  .. code-block:: python\n",
      "  \n",
      "  from sklearn.datasets import load_breast_cancer\n",
      "  \n",
      "  from ray import tune\n",
      "  from ray.data import from_pandas\n",
      "  from ray.air.config import RunConfig, ScalingConfig\n",
      "  from ray.train.xgboost import XGBoostTrainer\n",
      "  from ray.tune.tuner import Tuner\n",
      "  \n",
      "  def get_dataset():\n",
      "  data_raw = load_breast_cancer(as_frame=True)\n",
      "  dataset_df = data_raw[\"data\"]\n",
      "  dataset_df[\"target\"] = data_raw[\"target\"]\n",
      "  dataset = from_pandas(dataset_df)\n",
      "  return dataset\n",
      "  \n",
      "  trainer = XGBoostTrainer(\n",
      "  label_column=\"target\",\n",
      "  params={},\n",
      "- `datasets={\"train\"` - get_dataset()},\n",
      "  )\n",
      "  \n",
      "  param_space = {\n",
      "- `\"scaling_config\"` - ScalingConfig(\n",
      "  num_workers=tune.grid_search([2, 4]),\n",
      "  resources_per_worker={\n",
      "- `\"CPU\"` - tune.grid_search([1, 2]),\n",
      "  },\n",
      "  ),\n",
      "  # You can even grid search various datasets in Tune.\n",
      "  # \"datasets\": {\n",
      "  #     \"train\": tune.grid_search(\n",
      "  #         [ds1, ds2]\n",
      "  #     ),\n",
      "  # },\n",
      "- `\"params\"` - {\n",
      "- `\"objective\"` - \"binary:logistic\",\n",
      "- `\"tree_method\"` - \"approx\",\n",
      "- `\"eval_metric\"` - [\"logloss\", \"error\"],\n",
      "- `\"eta\"` - tune.loguniform(1e-4, 1e-1),\n",
      "- `\"subsample\"` - tune.uniform(0.5, 1.0),\n",
      "- `\"max_depth\"` - tune.randint(1, 9),\n",
      "  },\n",
      "  }\n",
      "  tuner = Tuner(trainable=trainer, param_space=param_space,\n",
      "  run_config=RunConfig(name=\"my_tune_run\"))\n",
      "  analysis = tuner.fit()\n",
      "  \n",
      "  To retry a failed tune run, you can then do\n",
      "  \n",
      "  .. code-block:: python\n",
      "  \n",
      "  tuner = Tuner.restore(experiment_checkpoint_dir)\n",
      "  tuner.fit()\n",
      "  \n",
      "  ``experiment_checkpoint_dir`` can be easily located near the end of the\n",
      "  console output of your first failed run.\n",
      "\n",
      "\n",
      "\n",
      "new_automl = AutoML()\n",
      "new_automl.fit(X_train, y_train, starting_points=starting_points)\n",
      "```\n",
      "  \n",
      "- `seed` - int or None, default=None | The random seed for hpo.\n",
      "- `n_concurrent_trials` - [Experimental] int, default=1 | The number of\n",
      "  concurrent trials. When n_concurrent_trials > 1, flaml performes\n",
      "  [parallel tuning](../../Use-Cases/Task-Oriented-AutoML#parallel-tuning)\n",
      "  and installation of ray or spark is required: `pip install flaml[ray]`\n",
      "  or `pip install flaml[spark]`. Please check\n",
      "  [here](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)\n",
      "  for more details about installing Spark.\n",
      "- `keep_search_state` - boolean, default=False | Whether to keep data needed\n",
      "  for model search after fit(). By default the state is deleted for\n",
      "  space saving.\n",
      "- `preserve_checkpoint` - boolean, default=True | Whether to preserve the saved checkpoint\n",
      "  on disk when deleting automl. By default the checkpoint is preserved.\n",
      "- `early_stop` - boolean, default=False | Whether to stop early if the\n",
      "  search is considered to converge.\n",
      "- `force_cancel` - boolean, default=False | Whether to forcely cancel the PySpark job if overtime.\n",
      "- `append_log` - boolean, default=False | Whetehr to directly append the log\n",
      "  records to the input log file if it exists.\n",
      "- `auto_augment` - boolean, default=True | Whether to automatically\n",
      "  augment rare classes.\n",
      "- `min_sample_size` - int, default=MIN_SAMPLE_TRAIN | the minimal sample\n",
      "  size when sample=True.\n",
      "- `use_ray` - boolean or dict.\n",
      "  If boolean: default=False | Whether to use ray to run the training\n",
      "  in separate processes. This can be used to prevent OOM for large\n",
      "  datasets, but will incur more overhead in time.\n",
      "  If dict: the dict contains the keywords arguments to be passed to\n",
      "  [ray.tune.run](https://docs.ray.io/en/latest/tune/api_docs/execution.html).\n",
      "- `use_spark` - boolean, default=False | Whether to use spark to run the training\n",
      "  in parallel spark jobs. This can be used to accelerate training on large models\n",
      "  and large datasets, but will incur more overhead in time and thus slow down\n",
      "  training in some cases.\n",
      "- `free_mem_ratio` - float between 0 and 1, default=0. The free memory ratio to keep during training.\n",
      "- `metric_constraints` - list, default=[] | The list of metric constraints.\n",
      "  Each element in this list is a 3-tuple, which shall be expressed\n",
      "  in the following format: the first element of the 3-tuple is the name of the\n",
      "  metric, the second element is the inequality sign chosen from \">=\" and \"<=\",\n",
      "  and the third element is the constraint value. E.g., `('precision', '>=', 0.9)`.\n",
      "  Note that all the metric names in metric_constraints need to be reported via\n",
      "  the metrics_to_log dictionary returned by a customized metric function.\n",
      "  The customized metric function shall be provided via the `metric` key word argument\n",
      "  of the fit() function or the automl constructor.\n",
      "  Find examples in this [test](https://github.com/microsoft/FLAML/tree/main/test/automl/test_constraints.py).\n",
      "  If `pred_time_limit` is provided as one of keyword arguments to fit() function or\n",
      "  the automl constructor, flaml will automatically (and under the hood)\n",
      "  add it as an additional element in the metric_constraints. Essentially 'pred_time_limit'\n",
      "  specifies a constraint about the prediction latency constraint in seconds.\n",
      "- `custom_hp` - dict, default=None | The custom search space specified by user\n",
      "  Each key is the estimator name, each value is a dict of the custom search space for that estimator. Notice the\n",
      "  domain of the custom search space can either be a value of a sample.Domain object.\n",
      "  \n",
      "  \n",
      "  \n",
      "```python\n",
      "custom_hp = {\n",
      "    \"transformer_ms\": {\n",
      "        \"model_path\": {\n",
      "            \"domain\": \"albert-base-v2\",\n",
      "        },\n",
      "        \"learning_rate\": {\n",
      "            \"domain\": tune.choice([1e-4, 1e-5]),\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "- `time_col` - for a time series task, name of the column containing the timestamps. If not\n",
      "  provided, defaults to the first column of X_train/X_val\n",
      "  \n",
      "- `cv_score_agg_func` - customized cross-validation scores aggregate function. Default to average metrics across folds. If specificed, this function needs to\n",
      "  have the following input arguments:\n",
      "  \n",
      "  * val_loss_folds: list of floats, the loss scores of each fold;\n",
      "  * log_metrics_folds: list of dicts/floats, the metrics of each fold to log.\n",
      "  \n",
      "  This function should return the final aggregate result of all folds. A float number of the minimization objective, and a dictionary as the metrics to log or None.\n",
      "  E.g.,\n",
      "  \n",
      "```python\n",
      "def cv_score_agg_func(val_loss_folds, log_metrics_folds):\n",
      "    metric_to_minimize = sum(val_loss_folds)/len(val_loss_folds)\n",
      "    metrics_to_log = None\n",
      "    for single_fold in log_metrics_folds:\n",
      "        if metrics_to_log is None:\n",
      "            metrics_to_log = single_fold\n",
      "        elif isinstance(metrics_to_log, dict):\n",
      "            metrics_to_log = {k: metrics_to_log[k] + v for k, v in single_fold.items()}\n",
      "        else:\n",
      "            metrics_to_log += single_fold\n",
      "    if metrics_to_log:\n",
      "        n = len(val_loss_folds)\n",
      "        metrics_to_log = (\n",
      "            {k: v / n for k, v in metrics_to_log.items()}\n",
      "            if isinstance(metrics_to_log, dict)\n",
      "            else metrics_to_log / n\n",
      "        )\n",
      "    return metric_to_minimize, metrics_to_log\n",
      "```\n",
      "  \n",
      "- `skip_transform` - boolean, default=False | Whether to pre-process data prior to modeling.\n",
      "- `mlflow_logging` - boolean, default=None | Whether to log the training results to mlflow.\n",
      "  Default value is None, which means the logging decision is made based on\n",
      "  AutoML.__init__'s mlflow_logging argument.\n",
      "  This requires mlflow to be installed and to have an active mlflow run.\n",
      "  FLAML will create nested runs.\n",
      "- `fit_kwargs_by_estimator` - dict, default=None | The user specified keywords arguments, grouped by estimator name.\n",
      "  For TransformersEstimator, available fit_kwargs can be found from\n",
      "  [TrainingArgumentsForAuto](nlp/huggingface/training_args).\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "fit_kwargs_by_estimator = {\n",
      "    \"transformer\": {\n",
      "        \"output_dir\": \"test/data/output/\",\n",
      "        \"fp16\": False,\n",
      "    },\n",
      "    \"tft\": {\n",
      "        \"max_encoder_length\": 1,\n",
      "        \"min_encoder_length\": 1,\n",
      "        \"static_categoricals\": [],\n",
      "        \"static_reals\": [],\n",
      "        \"time_varying_known_categoricals\": [],\n",
      "        \"time_varying_known_reals\": [],\n",
      "        \"time_varying_unknown_categoricals\": [],\n",
      "        \"time_varying_unknown_reals\": [],\n",
      "        \"variable_groups\": {},\n",
      "        \"lags\": {},\n",
      "    }\n",
      "}\n",
      "```\n",
      "  \n",
      "- `**fit_kwargs` - Other key word arguments to pass to fit() function of\n",
      "  the searched learners, such as sample_weight. Below are a few examples of\n",
      "  estimator-specific parameters:\n",
      "- `period` - int | forecast horizon for all time series forecast tasks.\n",
      "- `gpu_per_trial` - float, default = 0 | A float of the number of gpus per trial,\n",
      "  only used by TransformersEstimator, XGBoostSklearnEstimator, and\n",
      "  TemporalFusionTransformerEstimator.\n",
      "- `group_ids` - list of strings of column names identifying a time series, only\n",
      "  used by TemporalFusionTransformerEstimator, required for\n",
      "  'ts_forecast_panel' task. `group_ids` is a parameter for TimeSeriesDataSet object\n",
      "  from PyTorchForecasting.\n",
      "  For other parameters to describe your dataset, refer to\n",
      "  [TimeSeriesDataSet PyTorchForecasting](https://pytorch-forecasting.readthedocs.io/en/stable/api/pytorch_forecasting.data.timeseries.TimeSeriesDataSet.html).\n",
      "  To specify your variables, use `static_categoricals`, `static_reals`,\n",
      "  `time_varying_known_categoricals`, `time_varying_known_reals`,\n",
      "  `time_varying_unknown_categoricals`, `time_varying_unknown_reals`,\n",
      "  `variable_groups`. To provide more information on your data, use\n",
      "  `max_encoder_length`, `min_encoder_length`, `lags`.\n",
      "- `log_dir` - str, default = \"lightning_logs\" | Folder into which to log results\n",
      "  for tensorboard, only used by TemporalFusionTransformerEstimator.\n",
      "- `max_epochs` - int, default = 20 | Maximum number of epochs to run training,\n",
      "  only used by TemporalFusionTransformerEstimator.\n",
      "- `batch_size` - int, default = 64 | Batch size for training model, only\n",
      "  used by TemporalFusionTransformerEstimator.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to ragproxyagent):\n",
      "\n",
      "There is no function named `tune_automl` in FLAML. However, you can perform AutoML tuning using the `AutoML()` class and the `fit()` method, as shown in the context you provided.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mragproxyagent\u001b[0m (to assistant):\n",
      "\n",
      "update context\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to ragproxyagent):\n",
      "\n",
      "UPDATE CONTEXT\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32mUpdating context and resetting conversation.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_13 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_51 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_58 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_20 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_26 to context.\u001b[0m\n",
      "\u001b[33mragproxyagent\u001b[0m (to assistant):\n",
      "\n",
      "You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user. You should follow the following steps to answer a question:\n",
      "Step 1, you estimate the user's intent based on the question and context. The intent can be a code generation task or\n",
      "a question answering task.\n",
      "Step 2, you reply based on the intent.\n",
      "You should leverage the context provided by the user as much as possible. If you need more context, you should reply\n",
      "\"UPDATE CONTEXT\".\n",
      "For code generation task, you must obey the following rules:\n",
      "Rule 1. You MUST NOT install any packages because all the packages needed are already installed.\n",
      "Rule 2. You must follow the formats below to write your code:\n",
      "```language\n",
      "# your code\n",
      "```\n",
      "\n",
      "For question answering task, you must give as short an answer as possible.\n",
      "\n",
      "User's question is: Is there a function named `tune_automl` in FLAML?\n",
      "\n",
      "Context is: ---\n",
      "sidebar_label: tune\n",
      "title: tune.tune\n",
      "---\n",
      "\n",
      "## ExperimentAnalysis Objects\n",
      "\n",
      "```python\n",
      "class ExperimentAnalysis(EA)\n",
      "```\n",
      "\n",
      "Class for storing the experiment results.\n",
      "\n",
      "#### report\n",
      "\n",
      "```python\n",
      "def report(_metric=None, **kwargs)\n",
      "```\n",
      "\n",
      "A function called by the HPO application to report final or intermediate\n",
      "results.\n",
      "\n",
      "**Example**:\n",
      "\n",
      "  \n",
      "```python\n",
      "import time\n",
      "from flaml import tune\n",
      "\n",
      "def compute_with_config(config):\n",
      "    current_time = time.time()\n",
      "    metric2minimize = (round(config['x'])-95000)**2\n",
      "    time2eval = time.time() - current_time\n",
      "    tune.report(metric2minimize=metric2minimize, time2eval=time2eval)\n",
      "\n",
      "analysis = tune.run(\n",
      "    compute_with_config,\n",
      "    config={\n",
      "        'x': tune.lograndint(lower=1, upper=1000000),\n",
      "        'y': tune.randint(lower=1, upper=1000000)\n",
      "    },\n",
      "    metric='metric2minimize', mode='min',\n",
      "    num_samples=1000000, time_budget_s=60, use_ray=False)\n",
      "\n",
      "print(analysis.trials[-1].last_result)\n",
      "```\n",
      "  \n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `_metric` - Optional default anonymous metric for ``tune.report(value)``.\n",
      "  (For compatibility with ray.tune.report)\n",
      "- `**kwargs` - Any key value pair to be reported.\n",
      "  \n",
      "\n",
      "**Raises**:\n",
      "\n",
      "  StopIteration (when not using ray, i.e., _use_ray=False):\n",
      "  A StopIteration exception is raised if the trial has been signaled to stop.\n",
      "  SystemExit (when using ray):\n",
      "  A SystemExit exception is raised if the trial has been signaled to stop by ray.\n",
      "\n",
      "#### run\n",
      "\n",
      "```python\n",
      "def run(evaluation_function, config: Optional[dict] = None, low_cost_partial_config: Optional[dict] = None, cat_hp_cost: Optional[dict] = None, metric: Optional[str] = None, mode: Optional[str] = None, time_budget_s: Union[int, float] = None, points_to_evaluate: Optional[List[dict]] = None, evaluated_rewards: Optional[List] = None, resource_attr: Optional[str] = None, min_resource: Optional[float] = None, max_resource: Optional[float] = None, reduction_factor: Optional[float] = None, scheduler=None, search_alg=None, verbose: Optional[int] = 2, local_dir: Optional[str] = None, num_samples: Optional[int] = 1, resources_per_trial: Optional[dict] = None, config_constraints: Optional[List[Tuple[Callable[[dict], float], str, float]]] = None, metric_constraints: Optional[List[Tuple[str, str, float]]] = None, max_failure: Optional[int] = 100, use_ray: Optional[bool] = False, use_spark: Optional[bool] = False, use_incumbent_result_in_evaluation: Optional[bool] = None, log_file_name: Optional[str] = None, lexico_objectives: Optional[dict] = None, force_cancel: Optional[bool] = False, n_concurrent_trials: Optional[int] = 0, **ray_args, ,)\n",
      "```\n",
      "\n",
      "The function-based way of performing HPO.\n",
      "\n",
      "**Example**:\n",
      "\n",
      "  \n",
      "```python\n",
      "import time\n",
      "from flaml import tune\n",
      "\n",
      "def compute_with_config(config):\n",
      "    current_time = time.time()\n",
      "    metric2minimize = (round(config['x'])-95000)**2\n",
      "    time2eval = time.time() - current_time\n",
      "    tune.report(metric2minimize=metric2minimize, time2eval=time2eval)\n",
      "    # if the evaluation fails unexpectedly and the exception is caught,\n",
      "    # and it doesn't inform the goodness of the config,\n",
      "    # return {}\n",
      "    # if the failure indicates a config is bad,\n",
      "    # report a bad metric value like np.inf or -np.inf\n",
      "    # depending on metric mode being min or max\n",
      "\n",
      "analysis = tune.run(\n",
      "    compute_with_config,\n",
      "    config={\n",
      "        'x': tune.lograndint(lower=1, upper=1000000),\n",
      "        'y': tune.randint(lower=1, upper=1000000)\n",
      "    },\n",
      "    metric='metric2minimize', mode='min',\n",
      "    num_samples=-1, time_budget_s=60, use_ray=False)\n",
      "\n",
      "print(analysis.trials[-1].last_result)\n",
      "```\n",
      "  \n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `evaluation_function` - A user-defined evaluation function.\n",
      "  It takes a configuration as input, outputs a evaluation\n",
      "  result (can be a numerical value or a dictionary of string\n",
      "  and numerical value pairs) for the input configuration.\n",
      "  For machine learning tasks, it usually involves training and\n",
      "  scoring a machine learning model, e.g., through validation loss.\n",
      "- `config` - A dictionary to specify the search space.\n",
      "- `low_cost_partial_config` - A dictionary from a subset of\n",
      "  controlled dimensions to the initial low-cost values.\n",
      "  e.g., ```{'n_estimators': 4, 'max_leaves': 4}```\n",
      "  \n",
      "- `cat_hp_cost` - A dictionary from a subset of categorical dimensions\n",
      "  to the relative cost of each choice.\n",
      "  e.g., ```{'tree_method': [1, 1, 2]}```\n",
      "  i.e., the relative cost of the\n",
      "  three choices of 'tree_method' is 1, 1 and 2 respectively\n",
      "- `metric` - A string of the metric name to optimize for.\n",
      "- `mode` - A string in ['min', 'max'] to specify the objective as\n",
      "  minimization or maximization.\n",
      "- `time_budget_s` - int or float | The time budget in seconds.\n",
      "- `points_to_evaluate` - A list of initial hyperparameter\n",
      "  configurations to run first.\n",
      "- `evaluated_rewards` _list_ - If you have previously evaluated the\n",
      "  parameters passed in as points_to_evaluate you can avoid\n",
      "  re-running those trials by passing in the reward attributes\n",
      "  as a list so the optimiser can be told the results without\n",
      "  needing to re-compute the trial. Must be the same or shorter length than\n",
      "  points_to_evaluate.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "points_to_evaluate = [\n",
      "    {\"b\": .99, \"cost_related\": {\"a\": 3}},\n",
      "    {\"b\": .99, \"cost_related\": {\"a\": 2}},\n",
      "]\n",
      "evaluated_rewards = [3.0]\n",
      "```\n",
      "  \n",
      "  means that you know the reward for the first config in\n",
      "  points_to_evaluate is 3.0 and want to inform run().\n",
      "  \n",
      "- `resource_attr` - A string to specify the resource dimension used by\n",
      "  the scheduler via \"scheduler\".\n",
      "- `min_resource` - A float of the minimal resource to use for the resource_attr.\n",
      "- `max_resource` - A float of the maximal resource to use for the resource_attr.\n",
      "- `reduction_factor` - A float of the reduction factor used for incremental\n",
      "  pruning.\n",
      "- `scheduler` - A scheduler for executing the experiment. Can be None, 'flaml',\n",
      "  'asha' (or  'async_hyperband', 'asynchyperband') or a custom instance of the TrialScheduler class. Default is None:\n",
      "  in this case when resource_attr is provided, the 'flaml' scheduler will be\n",
      "  used, otherwise no scheduler will be used. When set 'flaml', an\n",
      "  authentic scheduler implemented in FLAML will be used. It does not\n",
      "  require users to report intermediate results in evaluation_function.\n",
      "  Find more details about this scheduler in this paper\n",
      "  https://arxiv.org/pdf/1911.04706.pdf).\n",
      "  When set 'asha', the input for arguments \"resource_attr\",\n",
      "  \"min_resource\", \"max_resource\" and \"reduction_factor\" will be passed\n",
      "  to ASHA's \"time_attr\",  \"max_t\", \"grace_period\" and \"reduction_factor\"\n",
      "  respectively. You can also provide a self-defined scheduler instance\n",
      "  of the TrialScheduler class. When 'asha' or self-defined scheduler is\n",
      "  used, you usually need to report intermediate results in the evaluation\n",
      "  function via 'tune.report()'.\n",
      "  If you would like to do some cleanup opearation when the trial is stopped\n",
      "  by the scheduler, you can catch the `StopIteration` (when not using ray)\n",
      "  or `SystemExit` (when using ray) exception explicitly,\n",
      "  as shown in the following example.\n",
      "  Please find more examples using different types of schedulers\n",
      "  and how to set up the corresponding evaluation functions in\n",
      "  test/tune/test_scheduler.py, and test/tune/example_scheduler.py.\n",
      "```python\n",
      "def easy_objective(config):\n",
      "    width, height = config[\"width\"], config[\"height\"]\n",
      "    for step in range(config[\"steps\"]):\n",
      "        intermediate_score = evaluation_fn(step, width, height)\n",
      "        try:\n",
      "            tune.report(iterations=step, mean_loss=intermediate_score)\n",
      "        except (StopIteration, SystemExit):\n",
      "            # do cleanup operation here\n",
      "            return\n",
      "```\n",
      "- `search_alg` - An instance/string of the search algorithm\n",
      "  to be used. The same instance can be used for iterative tuning.\n",
      "  e.g.,\n",
      "  \n",
      "```python\n",
      "---\n",
      "sidebar_label: task\n",
      "title: automl.task.task\n",
      "---\n",
      "\n",
      "## Task Objects\n",
      "\n",
      "```python\n",
      "class Task(ABC)\n",
      "```\n",
      "\n",
      "Abstract base class for a machine learning task.\n",
      "\n",
      "Class definitions should implement abstract methods and provide a non-empty dictionary of estimator classes.\n",
      "A Task can be suitable to be used for multiple machine-learning tasks (e.g. classification or regression) or be\n",
      "implemented specifically for a single one depending on the generality of data validation and model evaluation methods\n",
      "implemented. The implementation of a Task may optionally use the training data and labels to determine data and task\n",
      "specific details, such as in determining if a problem is single-label or multi-label.\n",
      "\n",
      "FLAML evaluates at runtime how to behave exactly, relying on the task instance to provide implementations of\n",
      "operations which vary between tasks.\n",
      "\n",
      "#### \\_\\_init\\_\\_\n",
      "\n",
      "```python\n",
      "def __init__(task_name: str, X_train: Optional[Union[np.ndarray, DataFrame, psDataFrame]] = None, y_train: Optional[Union[np.ndarray, DataFrame, Series, psSeries]] = None)\n",
      "```\n",
      "\n",
      "Constructor.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `task_name` - String name for this type of task. Used when the Task can be generic and implement a number of\n",
      "  types of sub-task.\n",
      "- `X_train` - Optional. Some Task types may use the data shape or features to determine details of their usage,\n",
      "  such as in binary vs multilabel classification.\n",
      "- `y_train` - Optional. Some Task types may use the data shape or features to determine details of their usage,\n",
      "  such as in binary vs multilabel classification.\n",
      "\n",
      "#### \\_\\_str\\_\\_\n",
      "\n",
      "```python\n",
      "def __str__() -> str\n",
      "```\n",
      "\n",
      "Name of this task type.\n",
      "\n",
      "#### evaluate\\_model\\_CV\n",
      "\n",
      "```python\n",
      "@abstractmethod\n",
      "def evaluate_model_CV(config: dict, estimator: \"flaml.automl.ml.BaseEstimator\", X_train_all: Union[np.ndarray, DataFrame, psDataFrame], y_train_all: Union[np.ndarray, DataFrame, Series, psSeries], budget: int, kf, eval_metric: str, best_val_loss: float, log_training_metric: bool = False, fit_kwargs: Optional[dict] = {}) -> Tuple[float, float, float, float]\n",
      "```\n",
      "\n",
      "Evaluate the model using cross-validation.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `config` - configuration used in the evaluation of the metric.\n",
      "- `estimator` - Estimator class of the model.\n",
      "- `X_train_all` - Complete training feature data.\n",
      "- `y_train_all` - Complete training target data.\n",
      "- `budget` - Training time budget.\n",
      "- `kf` - Cross-validation index generator.\n",
      "- `eval_metric` - Metric name to be used for evaluation.\n",
      "- `best_val_loss` - Best current validation-set loss.\n",
      "- `log_training_metric` - Bool defaults False. Enables logging of the training metric.\n",
      "- `fit_kwargs` - Additional kwargs passed to the estimator's fit method.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  validation loss, metric value, train time, prediction time\n",
      "\n",
      "#### validate\\_data\n",
      "\n",
      "```python\n",
      "@abstractmethod\n",
      "def validate_data(automl: \"flaml.automl.automl.AutoML\", state: \"flaml.automl.state.AutoMLState\", X_train_all: Union[np.ndarray, DataFrame, psDataFrame, None], y_train_all: Union[np.ndarray, DataFrame, Series, psSeries, None], dataframe: Union[DataFrame, None], label: str, X_val: Optional[Union[np.ndarray, DataFrame, psDataFrame]] = None, y_val: Optional[Union[np.ndarray, DataFrame, Series, psSeries]] = None, groups_val: Optional[List[str]] = None, groups: Optional[List[str]] = None)\n",
      "```\n",
      "\n",
      "Validate that the data is suitable for this task type.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `automl` - The AutoML instance from which this task has been constructed.\n",
      "- `state` - The AutoMLState instance for this run.\n",
      "- `X_train_all` - The complete data set or None if dataframe is supplied.\n",
      "- `y_train_all` - The complete target set or None if dataframe is supplied.\n",
      "- `dataframe` - A dataframe constaining the complete data set with targets.\n",
      "- `label` - The name of the target column in dataframe.\n",
      "- `X_val` - Optional. A data set for validation.\n",
      "- `y_val` - Optional. A target vector corresponding to X_val for validation.\n",
      "- `groups_val` - Group labels (with matching length to y_val) or group counts (with sum equal to length of y_val)\n",
      "  for validation data. Need to be consistent with groups.\n",
      "- `groups` - Group labels (with matching length to y_train) or groups counts (with sum equal to length of y_train)\n",
      "  for training data.\n",
      "  \n",
      "\n",
      "**Raises**:\n",
      "\n",
      "- `AssertionError` - The data provided is invalid for this task type and configuration.\n",
      "\n",
      "#### prepare\\_data\n",
      "\n",
      "```python\n",
      "@abstractmethod\n",
      "def prepare_data(state: \"flaml.automl.state.AutoMLState\", X_train_all: Union[np.ndarray, DataFrame, psDataFrame], y_train_all: Union[np.ndarray, DataFrame, Series, psSeries, None], auto_augment: bool, eval_method: str, split_type: str, split_ratio: float, n_splits: int, data_is_df: bool, sample_weight_full: Optional[List[float]] = None)\n",
      "```\n",
      "\n",
      "Prepare the data for fitting or inference.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `automl` - The AutoML instance from which this task has been constructed.\n",
      "- `state` - The AutoMLState instance for this run.\n",
      "- `X_train_all` - The complete data set or None if dataframe is supplied. Must\n",
      "  contain the target if y_train_all is None\n",
      "- `y_train_all` - The complete target set or None if supplied in X_train_all.\n",
      "- `auto_augment` - If true, task-specific data augmentations will be applied.\n",
      "- `eval_method` - A string of resampling strategy, one of ['auto', 'cv', 'holdout'].\n",
      "- `split_type` - str or splitter object, default=\"auto\" | the data split type.\n",
      "  * A valid splitter object is an instance of a derived class of scikit-learn\n",
      "  [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold)\n",
      "  and have ``split`` and ``get_n_splits`` methods with the same signatures.\n",
      "  Set eval_method to \"cv\" to use the splitter object.\n",
      "  * Valid str options depend on different tasks.\n",
      "  For classification tasks, valid choices are\n",
      "  [\"auto\", 'stratified', 'uniform', 'time', 'group']. \"auto\" -> stratified.\n",
      "  For regression tasks, valid choices are [\"auto\", 'uniform', 'time'].\n",
      "  \"auto\" -> uniform.\n",
      "  For time series forecast tasks, must be \"auto\" or 'time'.\n",
      "  For ranking task, must be \"auto\" or 'group'.\n",
      "- `split_ratio` - A float of the valiation data percentage for holdout.\n",
      "- `n_splits` - An integer of the number of folds for cross - validation.\n",
      "- `data_is_df` - True if the data was provided as a DataFrame else False.\n",
      "- `sample_weight_full` - A 1d arraylike of the sample weight.\n",
      "  \n",
      "\n",
      "**Raises**:\n",
      "\n",
      "- `AssertionError` - The configuration provided is invalid for this task type and data.\n",
      "\n",
      "#### decide\\_split\\_type\n",
      "\n",
      "```python\n",
      "@abstractmethod\n",
      "def decide_split_type(split_type: str, y_train_all: Union[np.ndarray, DataFrame, Series, psSeries, None], fit_kwargs: dict, groups: Optional[List[str]] = None) -> str\n",
      "```\n",
      "\n",
      "Choose an appropriate data split type for this data and task.\n",
      "\n",
      "If split_type is 'auto' then this is determined based on the task type and data.\n",
      "If a specific split_type is requested then the choice is validated to be appropriate.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `split_type` - Either 'auto' or a task appropriate split type.\n",
      "- `y_train_all` - The complete set of targets.\n",
      "- `fit_kwargs` - Additional kwargs passed to the estimator's fit method.\n",
      "- `groups` - Optional. Group labels (with matching length to y_train) or groups counts (with sum equal to length\n",
      "  of y_train) for training data.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  The determined appropriate split type.\n",
      "  \n",
      "\n",
      "**Raises**:\n",
      "\n",
      "- `AssertionError` - The requested split_type is invalid for this task, configuration and data.\n",
      "\n",
      "#### preprocess\n",
      "\n",
      "```python\n",
      "@abstractmethod\n",
      "def preprocess(X: Union[np.ndarray, DataFrame, psDataFrame], transformer: Optional[\"flaml.automl.data.DataTransformer\"] = None) -> Union[np.ndarray, DataFrame]\n",
      "```\n",
      "\n",
      "Preprocess the data ready for fitting or inference with this task type.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `X` - The data set to process.\n",
      "- `transformer` - A DataTransformer instance to be used in processing.\n",
      "  \n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  The preprocessed data set having the same type as the input.\n",
      "\n",
      "#### default\\_estimator\\_list\n",
      "\n",
      "```python\n",
      "@abstractmethod\n",
      "def default_estimator_list(estimator_list: Union[List[str], str] = \"auto\", is_spark_dataframe: bool = False) -> List[str]\n",
      "```\n",
      "\n",
      "Return the list of default estimators registered for this task type.\n",
      "\n",
      "If 'auto' is provided then the default list is returned, else the provided list will be validated given this task\n",
      "type.\n",
      "\n",
      "**Arguments**:\n",
      "---\n",
      "sidebar_label: estimator\n",
      "title: default.estimator\n",
      "---\n",
      "\n",
      "#### flamlize\\_estimator\n",
      "\n",
      "```python\n",
      "def flamlize_estimator(super_class, name: str, task: str, alternatives=None)\n",
      "```\n",
      "\n",
      "Enhance an estimator class with flaml's data-dependent default hyperparameter settings.\n",
      "\n",
      "**Example**:\n",
      "\n",
      "  \n",
      "```python\n",
      "import sklearn.ensemble as ensemble\n",
      "RandomForestRegressor = flamlize_estimator(\n",
      "    ensemble.RandomForestRegressor, \"rf\", \"regression\"\n",
      ")\n",
      "```\n",
      "  \n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `super_class` - an scikit-learn compatible estimator class.\n",
      "- `name` - a str of the estimator's name.\n",
      "- `task` - a str of the task type.\n",
      "- `alternatives` - (Optional) a list for alternative estimator names. For example,\n",
      "  ```[(\"max_depth\", 0, \"xgboost\")]``` means if the \"max_depth\" is set to 0\n",
      "  in the constructor, then look for the learned defaults for estimator \"xgboost\".\n",
      "\n",
      "\n",
      "---\n",
      "sidebar_label: space\n",
      "title: tune.space\n",
      "---\n",
      "\n",
      "#### is\\_constant\n",
      "\n",
      "```python\n",
      "def is_constant(space: Union[Dict, List]) -> bool\n",
      "```\n",
      "\n",
      "Whether the search space is all constant.\n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  A bool of whether the search space is all constant.\n",
      "\n",
      "#### define\\_by\\_run\\_func\n",
      "\n",
      "```python\n",
      "def define_by_run_func(trial, space: Dict, path: str = \"\") -> Optional[Dict[str, Any]]\n",
      "```\n",
      "\n",
      "Define-by-run function to create the search space.\n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  A dict with constant values.\n",
      "\n",
      "#### unflatten\\_hierarchical\n",
      "\n",
      "```python\n",
      "def unflatten_hierarchical(config: Dict, space: Dict) -> Tuple[Dict, Dict]\n",
      "```\n",
      "\n",
      "Unflatten hierarchical config.\n",
      "\n",
      "#### add\\_cost\\_to\\_space\n",
      "\n",
      "```python\n",
      "def add_cost_to_space(space: Dict, low_cost_point: Dict, choice_cost: Dict)\n",
      "```\n",
      "\n",
      "Update the space in place by adding low_cost_point and choice_cost.\n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  A dict with constant values.\n",
      "\n",
      "#### normalize\n",
      "\n",
      "```python\n",
      "def normalize(config: Dict, space: Dict, reference_config: Dict, normalized_reference_config: Dict, recursive: bool = False)\n",
      "```\n",
      "\n",
      "Normalize config in space according to reference_config.\n",
      "\n",
      "Normalize each dimension in config to [0,1].\n",
      "\n",
      "#### indexof\n",
      "\n",
      "```python\n",
      "def indexof(domain: Dict, config: Dict) -> int\n",
      "```\n",
      "\n",
      "Find the index of config in domain.categories.\n",
      "\n",
      "#### complete\\_config\n",
      "\n",
      "```python\n",
      "def complete_config(partial_config: Dict, space: Dict, flow2, disturb: bool = False, lower: Optional[Dict] = None, upper: Optional[Dict] = None) -> Tuple[Dict, Dict]\n",
      "```\n",
      "\n",
      "Complete partial config in space.\n",
      "\n",
      "**Returns**:\n",
      "\n",
      "  config, space.\n",
      "\n",
      "\n",
      "---\n",
      "sidebar_label: variant_generator\n",
      "title: tune.searcher.variant_generator\n",
      "---\n",
      "\n",
      "## TuneError Objects\n",
      "\n",
      "```python\n",
      "class TuneError(Exception)\n",
      "```\n",
      "\n",
      "General error class raised by ray.tune.\n",
      "\n",
      "#### generate\\_variants\n",
      "\n",
      "```python\n",
      "def generate_variants(unresolved_spec: Dict, constant_grid_search: bool = False, random_state: \"RandomState\" = None) -> Generator[Tuple[Dict, Dict], None, None]\n",
      "```\n",
      "\n",
      "Generates variants from a spec (dict) with unresolved values.\n",
      "There are two types of unresolved values:\n",
      "Grid search: These define a grid search over values. For example, the\n",
      "following grid search values in a spec will produce six distinct\n",
      "variants in combination:\n",
      "\"activation\": grid_search([\"relu\", \"tanh\"])\n",
      "\"learning_rate\": grid_search([1e-3, 1e-4, 1e-5])\n",
      "Lambda functions: These are evaluated to produce a concrete value, and\n",
      "can express dependencies or conditional distributions between values.\n",
      "They can also be used to express random search (e.g., by calling\n",
      "into the `random` or `np` module).\n",
      "\"cpu\": lambda spec: spec.config.num_workers\n",
      "\"batch_size\": lambda spec: random.uniform(1, 1000)\n",
      "Finally, to support defining specs in plain JSON / YAML, grid search\n",
      "and lambda functions can also be defined alternatively as follows:\n",
      "\"activation\": {\"grid_search\": [\"relu\", \"tanh\"]}\n",
      "\"cpu\": {\"eval\": \"spec.config.num_workers\"}\n",
      "Use `format_vars` to format the returned dict of hyperparameters.\n",
      "\n",
      "**Yields**:\n",
      "\n",
      "  (Dict of resolved variables, Spec object)\n",
      "\n",
      "#### grid\\_search\n",
      "\n",
      "```python\n",
      "def grid_search(values: List) -> Dict[str, List]\n",
      "```\n",
      "\n",
      "Convenience method for specifying grid search over a value.\n",
      "\n",
      "**Arguments**:\n",
      "\n",
      "- `values` - An iterable whose parameters will be gridded.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to ragproxyagent):\n",
      "\n",
      "There is no `tune_automl` function in FLAML. However, FLAML provides the `tune.run` function for hyperparameter optimization. You can find its usage in the given context.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# reset the assistant. Always reset the assistant before starting a new conversation.\n",
    "assistant.reset()\n",
    "\n",
    "# set `human_input_mode` to be `ALWAYS`, so the agent will ask for human input at every step.\n",
    "ragproxyagent.human_input_mode = \"ALWAYS\"\n",
    "qa_problem = \"Is there a function named `tune_automl` in FLAML?\"\n",
    "ragproxyagent.initiate_chat(assistant, problem=qa_problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5\n",
    "\n",
    "Use RetrieveChat to answer questions for [NaturalQuestion](https://ai.google.com/research/NaturalQuestions) dataset.\n",
    "\n",
    "We'll first create a new document collection based on all the context corpus, then we select some questions and answer them with RetrieveChat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file = \"https://huggingface.co/datasets/thinkall/NaturalQuestionsQA/resolve/main/corpus.txt\"\n",
    "\n",
    "# Create a new collection for NaturalQuestions dataset\n",
    "ragproxyagent = RetrieveUserProxyAgent(\n",
    "    name=\"ragproxyagent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    retrieve_config={\n",
    "        \"docs_path\": corpus_file,\n",
    "        \"chunk_token_size\": 4900,\n",
    "        \"model\": config_list[0][\"model\"],\n",
    "        \"client\": chromadb.PersistentClient(path=\"/tmp/chromadb\"),\n",
    "        \"collection_name\": \"natural-questions\",\n",
    "        \"chunk_mode\": \"one_line\",\n",
    "        \"embedding_model\": \"all-MiniLM-L6-v2\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what is non controlling interest on balance sheet', 'how many episodes are in chicago fire season 4', 'who sings love will keep us alive by the eagles', 'who is the leader of the ontario pc party', 'where did the last name keith come from']\n",
      "[[\"the portion of a subsidiary corporation 's stock that is not owned by the parent corporation\"], ['23'], ['Timothy B. Schmit'], ['Patrick Walter Brown'], ['from Keith in East Lothian , Scotland', \"from a nickname , derived from the Middle High German kīt , a word meaning `` sprout '' , `` offspring ''\"]]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# queries_file = \"https://huggingface.co/datasets/thinkall/NaturalQuestionsQA/resolve/main/queries.jsonl\"\n",
    "first_5_queries = \"\"\"{\"_id\": \"ce2342e1feb4e119cb273c05356b33309d38fa132a1cbeac2368a337e38419b8\", \"text\": \"what is non controlling interest on balance sheet\", \"metadata\": {\"answer\": [\"the portion of a subsidiary corporation 's stock that is not owned by the parent corporation\"]}}\n",
    "{\"_id\": \"3a10ff0e520530c0aa33b2c7e8d989d78a8cd5d699201fc4b13d3845010994ee\", \"text\": \"how many episodes are in chicago fire season 4\", \"metadata\": {\"answer\": [\"23\"]}}\n",
    "{\"_id\": \"8a19db28aa9be7dbcab290077d4a3e320d87e8badce1f7417f56f3720e527696\", \"text\": \"who sings love will keep us alive by the eagles\", \"metadata\": {\"answer\": [\"Timothy B. Schmit\"]}}\n",
    "{\"_id\": \"06758a4918650a3f27398ff0520d4121c6d9cacfab3efcd84ddb83d2caa460ae\", \"text\": \"who is the leader of the ontario pc party\", \"metadata\": {\"answer\": [\"Patrick Walter Brown\"]}}\n",
    "{\"_id\": \"d4a88ef2f705da63ced53932695505a2fc44879bafe6fd1224ffef9e9a590ad6\", \"text\": \"where did the last name keith come from\", \"metadata\": {\"answer\": [\"from Keith in East Lothian , Scotland\", \"from a nickname , derived from the Middle High German k\\u012bt , a word meaning `` sprout '' , `` offspring ''\"]}}\n",
    "\"\"\"\n",
    "queries = [json.loads(line) for line in first_5_queries.split(\"\\n\") if line]\n",
    "questions = [q[\"text\"] for q in queries]\n",
    "answers = [q[\"metadata\"][\"answer\"] for q in queries]\n",
    "print(questions)\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>>>>>>>>>>>  Below are outputs of Case 1  <<<<<<<<<<<<\n",
      "\n",
      "\n",
      "doc_ids:  [['doc_0', 'doc_155', 'doc_19']]\n",
      "\u001b[32mAdding doc_id doc_0 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_155 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_155 to context.\u001b[0m\n",
      "\u001b[33mragproxyagent\u001b[0m (to assistant):\n",
      "\n",
      "You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user. You should follow the following steps to answer a question:\n",
      "Step 1, you estimate the user's intent based on the question and context. The intent can be a code generation task or\n",
      "a question answering task.\n",
      "Step 2, you reply based on the intent.\n",
      "You should leverage the context provided by the user as much as possible. If you need more context, you should reply\n",
      "\"UPDATE CONTEXT\".\n",
      "For code generation task, you must obey the following rules:\n",
      "Rule 1. You MUST NOT install any packages because all the packages needed are already installed.\n",
      "Rule 2. You must follow the formats below to write your code:\n",
      "```language\n",
      "# your code\n",
      "```\n",
      "\n",
      "For question answering task, you must give as short an answer as possible.\n",
      "\n",
      "User's question is: what is non controlling interest on balance sheet\n",
      "\n",
      "Context is: <P> In accounting , minority interest ( or non-controlling interest ) is the portion of a subsidiary corporation 's stock that is not owned by the parent corporation . The magnitude of the minority interest in the subsidiary company is generally less than 50 % of outstanding shares , or the corporation would generally cease to be a subsidiary of the parent . </P>\n",
      "<Table> <Tr> <Th colspan=\"4\"> Leading foreign holders of US Treasury securities as of August 2017 </Th> </Tr> <Tr> <Th> Country </Th> <Th> Billions of dollars ( est . ) </Th> <Th> Ratio of owned US debt to 2016 GDP ( est . ) </Th> <Th> Percent change since August 2016 </Th> </Tr> <Tr> <Td> China </Td> <Td> 1,200.5 </Td> <Td> 6 % </Td> <Td> + 1 % </Td> </Tr> <Tr> <Td> Japan </Td> <Td> 1,101.7 </Td> <Td> 22 % </Td> <Td> − 4 % </Td> </Tr> <Tr> <Td> Ireland </Td> <Td> 307.2 </Td> <Td> 105 % </Td> <Td> + 15 % </Td> </Tr> <Tr> <Td> Brazil </Td> <Td> 273.6 </Td> <Td> 15 % </Td> <Td> + 7 % </Td> </Tr> <Tr> <Td> Cayman Islands </Td> <Td> 260.0 </Td> <Td> n / a </Td> <Td> − 2 % </Td> </Tr> <Tr> <Td> Switzerland </Td> <Td> 248.3 </Td> <Td> 38 % </Td> <Td> + 4 % </Td> </Tr> <Tr> <Td> United Kingdom </Td> <Td> 225.4 </Td> <Td> 9 % </Td> <Td> + 10 % </Td> </Tr> <Tr> <Td> Luxembourg </Td> <Td> 213.4 </Td> <Td> 359 % </Td> <Td> − 3 % </Td> </Tr> <Tr> <Td> Hong Kong </Td> <Td> 197.3 </Td> <Td> 62 % </Td> <Td> + 3 % </Td> </Tr> <Tr> <Td> Taiwan </Td> <Td> 180.4 </Td> <Td> 34 % </Td> <Td> -- 5 % </Td> </Tr> <Tr> <Td> Others </Td> <Td> 2,061.9 </Td> <Td> n / a </Td> <Td> + 1 % </Td> </Tr> <Tr> <Th> Grand total </Th> <Th> 6,269.7 </Th> <Th> n / a </Th> <Th> + 1 % </Th> </Tr> </Table>\n",
      "<P> The name -- elevator pitch -- reflects the idea that it should be possible to deliver the summary in the time span of an elevator ride , or approximately thirty seconds to two minutes . </P>\n",
      "<P> SAARC was founded in Dhaka on 8 December 1985 . Its secretariat is based in Kathmandu , Nepal . The organization promotes development of economic and regional integration . It launched the South Asian Free Trade Area in 2006 . SAARC maintains permanent diplomatic relations at the United Nations as an observer and has developed links with multilateral entities , including the European Union . </P>\n",
      "<P> Seth MacFarlane voices three of the show 's main characters : Peter Griffin , Brian Griffin , and Stewie Griffin . MacFarlane chose to voice these characters himself , believing it would be easier to portray the voices he had already envisioned than for someone else to attempt it . MacFarlane drew inspiration for the voice of Peter from a security guard he overheard talking while attending the Rhode Island School of Design . Stewie 's voice was based on the voice of English actor Rex Harrison , especially his performance in the 1964 musical drama film My Fair Lady . MacFarlane uses his own voice while portraying Brian . </P>\n",
      "<P> The cup is an English unit of volume , most commonly associated with cooking and serving sizes . It is traditionally equal to half a liquid pint in either US customary units or the British imperial system but is now separately defined in terms of the metric system at values between ⁄ and ⁄ of a liter . Because actual drinking cups may differ greatly from the size of this unit , standard measuring cups are usually used instead . </P>\n",
      "<Table> <Tr> <Th> Year </Th> <Th> Coach </Th> <Th> Super Bowl </Th> <Th> Location </Th> <Th> Opponent </Th> <Th> Score </Th> <Th> Record </Th> </Tr> <Tr> <Td> 1981 </Td> <Td> Bill Walsh </Td> <Td> XVI </Td> <Td> Pontiac , Michigan </Td> <Td> Cincinnati Bengals </Td> <Td> 26 -- 21 </Td> <Td> 16 -- 3 </Td> </Tr> <Tr> <Td> 1984 </Td> <Td> Bill Walsh </Td> <Td> XIX </Td> <Td> Stanford , California </Td> <Td> Miami Dolphins </Td> <Td> 38 -- 16 </Td> <Td> 18 -- 1 </Td> </Tr> <Tr> <Td> 1988 </Td> <Td> Bill Walsh </Td> <Td> XXIII </Td> <Td> Miami </Td> <Td> Cincinnati Bengals </Td> <Td> 20 -- 16 </Td> <Td> 13 -- 6 </Td> </Tr> <Tr> <Td> 1989 </Td> <Td> George Seifert </Td> <Td> XXIV </Td> <Td> New Orleans </Td> <Td> Denver Broncos </Td> <Td> 55 -- 10 </Td> <Td> 17 -- 2 </Td> </Tr> <Tr> <Td> 1994 </Td> <Td> George Seifert </Td> <Td> XXIX </Td> <Td> Miami </Td> <Td> San Diego Chargers </Td> <Td> 49 -- 26 </Td> <Td> 16 -- 3 </Td> </Tr> <Tr> <Td colspan=\"5\"> Total Super Bowls won : </Td> <Td colspan=\"2\"> 5 </Td> </Tr> </Table>\n",
      "<P> `` Would I Lie to You ? '' is an R&B song by American duo Charles & Eddie . Written by Mike Leeson and Peter Vale and produced by Josh Deutsch , `` Would I Lie to You ? '' was the debut single by the pop - soul duo , and it proved to be their biggest hit . A major international success , it reached number one on the UK Singles Chart for two weeks in November 1992 , and was also number one in New Zealand , Germany and Austria . It was a top five hit in several other European countries while in Australia and Canada it went to number 3 . The single became a Top 20 hit in the US , peaking at number 13 on the Billboard Hot 100 and it enjoyed award - winning sales , earning a platinum record in the UK , a gold record in both Germany and Austria and silver record award in France . </P>\n",
      "<P> The Lord of the Rings is a film series consisting of three high fantasy adventure films directed by Peter Jackson . They are based on the novel The Lord of the Rings by J.R.R. Tolkien . The films are subtitled The Fellowship of the Ring ( 2001 ) , The Two Towers ( 2002 ) and The Return of the King ( 2003 ) . They are a New Zealand - American venture produced by WingNut Films and The Saul Zaentz Company and distributed by New Line Cinema . </P>\n",
      "<Table> <Tr> <Th> NYHA Class </Th> <Th> Symptoms </Th> </Tr> <Tr> <Td> </Td> <Td> Cardiac disease , but no symptoms and no limitation in ordinary physical activity , e.g. no shortness of breath when walking , climbing stairs etc . </Td> </Tr> <Tr> <Td> II </Td> <Td> Mild symptoms ( mild shortness of breath and / or angina ) and slight limitation during ordinary activity . </Td> </Tr> <Tr> <Td> III </Td> <Td> Marked limitation in activity due to symptoms , even during less - than - ordinary activity , e.g. walking short distances ( 20 -- 100 m ) . Comfortable only at rest . </Td> </Tr> <Tr> <Td> IV </Td> <Td> Severe limitations . Experiences symptoms even while at rest . Mostly bedbound patients . </Td> </Tr> </Table>\n",
      "<P> Spanish moss ( Tillandsia usneoides ) is an epiphytic flowering plant that often grows upon larger trees in tropical and subtropical climates , native to much of Mexico , Bermuda , the Bahamas , Central America , South America , the southern United States , and the West Indies as well as being naturalized in Queensland ( Australia ) known as `` grandpas beard '' and in French Polynesia . In the United States from where it is most known , it is commonly found on the southern live oak ( Quercus virginiana ) and bald - cypress ( Taxodium distichum ) in the lowlands , swamps , and savannas of the southeastern United States from Texas and Florida north through southern Arkansas . </P>\n",
      "<Table> <Tr> <Td> Best Picture <Ul> <Li> Titanic -- James Cameron and Jon Landau , producers <Ul> <Li> As Good as It Gets -- James L. Brooks , Bridgit Johnson and Kristi Zea , producers </Li> <Li> The Full Monty -- Uberto Pasolini , producer </Li> <Li> Good Will Hunting -- Lawrence Bender , producer </Li> <Li> L.A. Confidential -- Arnon Milchan , Curtis Hanson and Michael Nathanson , producers </Li> </Ul> </Li> </Ul> </Td> <Td> Best Director <Ul> <Li> James Cameron -- Titanic <Ul> <Li> Peter Cattaneo -- The Full Monty </Li> <Li> Gus Van Sant -- Good Will Hunting </Li> <Li> Curtis Hanson -- L.A. Confidential </Li> <Li> Atom Egoyan -- The Sweet Hereafter </Li> </Ul> </Li> </Ul> </Td> </Tr> <Tr> <Td> Best Actor <Ul> <Li> Jack Nicholson -- As Good as It Gets as Melvin Udall <Ul> <Li> Matt Damon -- Good Will Hunting as Will Hunting </Li> <Li> Robert Duvall -- The Apostle as Euliss `` Sonny '' Dewey , a.k.a. `` The Apostle E.F. '' </Li> <Li> Peter Fonda -- Ulee 's Gold as Ulysses `` Ulee '' Jackson </Li> <Li> Dustin Hoffman -- Wag the Dog as Stanley Motss </Li> </Ul> </Li> </Ul> </Td> <Td> Best Actress <Ul> <Li> Helen Hunt -- As Good as It Gets as Carol Connelly <Ul> <Li> Helena Bonham Carter -- The Wings of the Dove as Kate Croy </Li> <Li> Julie Christie -- Afterglow as Phyllis Mann </Li> <Li> Judi Dench -- Mrs Brown as Queen Victoria </Li> <Li> Kate Winslet -- Titanic as Rose DeWitt Bukater </Li> </Ul> </Li> </Ul> </Td> </Tr> <Tr> <Td> Best Supporting Actor <Ul> <Li> Robin Williams -- Good Will Hunting as Dr. Sean Maguire <Ul> <Li> Robert Forster -- Jackie Brown as Max Cherry </Li> <Li> Anthony Hopkins -- Amistad as John Quincy Adams </Li> <Li> Greg Kinnear -- As Good as It Gets as Simon Bishop </Li> <Li> Burt Reynolds -- Boogie Nights as Jack Horner </Li> </Ul> </Li> </Ul> </Td> <Td> Best Supporting Actress <Ul> <Li> Kim Basinger -- L.A. Confidential as Lynn Bracken <Ul> <Li> Joan Cusack -- In & Out as Emily Montgomery </Li> <Li> Minnie Driver -- Good Will Hunting as Skylar </Li> <Li> Julianne Moore -- Boogie Nights as Amber Waves / Maggie </Li> <Li> Gloria Stuart -- Titanic as Rose Dawson Calvert </Li> </Ul> </Li> </Ul> </Td> </Tr> <Tr> <Td> Best Original Screenplay / Screenplay Written Directly for the Screen <Ul> <Li> Good Will Hunting -- Matt Damon and Ben Affleck <Ul> <Li> As Good as It Gets -- Mark Andrus and James L. Brooks </Li> <Li> Boogie Nights -- Paul Thomas Anderson </Li> <Li> Deconstructing Harry -- Woody Allen </Li> <Li> The Full Monty -- Simon Beaufoy </Li> </Ul> </Li> </Ul> </Td> <Td> Best Screenplay Based on Material Previously Produced or Published <Ul> <Li> L.A. Confidential -- Brian Helgeland and Curtis Hanson from the novel by James Ellroy <Ul> <Li> Donnie Brasco -- Paul Attanasio based on the book Donnie Brasco : My Undercover Life in the Mafia by Joseph D. Pistone with Richard Woodley </Li> <Li> The Sweet Hereafter -- Atom Egoyan adapted from the novel by Russell Banks </Li> <Li> Wag the Dog -- David Mamet and Hilary Henkin from the novel American Hero by Larry Beinhart </Li> <Li> The Wings of the Dove -- Hossein Amini adapted from the novel by Henry James </Li> </Ul> </Li> </Ul> </Td> </Tr> <Tr> <Td> Best Foreign Language Film <Ul> <Li> Karakter ( Netherlands ) in Dutch -- Mike van Diem <Ul> <Li> Beyond Silence ( Germany ) in German -- Caroline Link </Li> <Li> Four Days in September ( Brazil ) in Portuguese -- Bruno Barreto </Li> <Li> Secrets of the Heart ( Spain ) in Spanish -- Montxo Armendáriz </Li> <Li> The Thief ( Russia ) in Russian -- Pavel Chukhray </Li> </Ul> </Li> </Ul> </Td> </Tr> <Tr> <Td> Best Documentary Feature <Ul> <Li> The Long Way Home -- Rabbi Marvin Hier and Richard Trank <Ul> <Li> 4 Little Girls -- Spike Lee and Sam Pollard </Li> <Li> Ayn Rand : A Sense of Life -- Michael Paxton </Li> <Li> Colors Straight Up -- Michèle Ohayon and Julia Schachter </Li> <Li> Waco : The Rules of Engagement -- Dan Gifford and William Gazecki </Li> </Ul> </Li> </Ul> </Td> <Td> Best Documentary Short Subject <Ul> <Li> A Story of Healing -- Donna Dewey and Carol Pasternak <Ul> <Li> Alaska : Spirit of the Wild -- George Casey and Paul Novros </Li> <Li> Amazon -- Kieth Merrill and Jonathan Stern </Li> <Li> Family Video Diaries : Daughter of the Bride -- Terri Randall </Li> <Li> Still Kicking : The Fabulous Palm Springs Follies -- Mel Damski and Andrea Blaugrund </Li> </Ul> </Li> </Ul> </Td> </Tr> <Tr> <Td> Best Live Action Short Film <Ul> <Li> Visas\n",
      "<P> The Impeachment of Andrew Johnson occurred in 1868 , when the United States House of Representatives resolved to impeach President Andrew Johnson , adopting eleven articles of impeachment detailing his `` high crimes and misdemeanors , '' in accordance with Article Two of the United States Constitution . The House 's primary charge against Johnson was violation of the Tenure of Office Act , passed by the U.S. Congress in March 1867 , over the president 's veto . Specifically , he had removed from office Edwin M. Stanton , the Secretary of War -- whom the Act was largely designed to protect -- and attempted to replace him with Brevet Major General Lorenzo Thomas ( Earlier , while Congress was not in session , Johnson had suspended Stanton and appointed General Ulysses S. Grant as secretary of war ad interim ) . </P>\n",
      "<P> Jaffa Cakes are biscuit - sized cakes introduced by McVitie and Price in the UK in 1927 and named after Jaffa oranges . The most common form of Jaffa cakes are circular , 2 ⁄ inches ( 54 mm ) in diameter and have three layers : a Genoise sponge base , a layer of orange flavoured jam and a coating of chocolate . Jaffa cakes are also available as bars or in small packs , and in larger and smaller sizes . The original Jaffa Cakes come in packs of 12 , 24 or 36 . </P>\n",
      "<Table> Jaffa Cakes <Tr> <Td colspan=\"2\"> A Jaffa Cake cut in half </Td> </Tr> <Tr> <Th> Alternative names </Th> <Td> Jaffa </Td> </Tr> <Tr> <Th> Type </Th> <Td> Cake </Td> </Tr> <Tr> <Th> Place of origin </Th> <Td> United Kingdom </Td> </Tr> <Tr> <Th> Region or state </Th> <Td> All Regions </Td> </Tr> <Tr> <Th> Created by </Th> <Td> McVitie and Price </Td> </Tr> <Tr> <Th> Main ingredients </Th> <Td> Sponge cake , orange - flavoured jam , chocolate </Td> </Tr> <Tr> <Th> Variations </Th> <Td> Various limited edition flavours ( Lemon and lime , strawberry , black currant ) </Td> </Tr> <Tr> <Td colspan=\"2\"> Cookbook : Jaffa Cakes Media : Jaffa Cakes </Td> </Tr> </Table>\n",
      "<P> In 1983 , Richard Stallman , founder of the Free Software Foundation , set forth plans of a complete Unix - like operating system , called GNU , composed entirely of free software . In September of that year , Stallman published a manifesto in Dr. Dobb 's Journal detailing his new project publicly , outlining his vision of free software . Software development work began in January 1984 . By 1991 , the GNU mid-level portions of the operating system were almost complete , and the upper level could be supplied by the X Window System , but the lower level ( kernel , device drivers , system - level utilities and daemons ) was still mostly lacking . The GNU kernel was called GNU Hurd . The Hurd followed an ambitious design which proved unexpectedly difficult to implement and has only been marginally usable . </P>\n",
      "<P> Because McVitie 's did not trademark the name `` Jaffa Cakes '' , other biscuit manufacturers and supermarkets have made similar products under the same name . The product 's classification as a cake or biscuit was part of a VAT tribunal in 1991 , with the court finding in McVitie 's favour that the Jaffa cake should be considered a cake for tax purposes . In 2012 they were ranked the best selling cake or biscuit in the United Kingdom . </P>\n",
      "<P> The geopolitical divisions in Europe that created a concept of East and West originated in the Roman Empire . The Eastern Mediterranean was home to the highly urbanized cultures that had Greek as their common language ( owing to the older empire of Alexander the Great and of the Hellenistic successors ) , whereas the West was much more rural in its character and more readily adopted Latin as its common language . After the fall of the Western Roman Empire , Western and Central Europe were substantially cut off from the East where Byzantine Greek culture and Eastern Christianity became founding influences in the Arab / Muslim world and among the Eastern and Southern Slavic peoples . Roman Catholic Western and Central Europe , as such , maintained a distinct identity particularly as it began to redevelop during the Renaissance . Even following the Protestant Reformation , Protestant Europe continued to see itself as more tied to Roman Catholic Europe than other parts of the perceived civilized world . </P>\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to ragproxyagent):\n",
      "\n",
      "Non-controlling interest, also known as minority interest, refers to the portion of a subsidiary corporation's stock not owned by the parent corporation. It is typically less than 50% of the outstanding shares, or the subsidiary would not be considered a subsidiary of the parent corporation. On the balance sheet, non-controlling interest represents the ownership stake in a subsidiary held by other investors, not the parent company.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      ">>>>>>>>>>>>  Below are outputs of Case 2  <<<<<<<<<<<<\n",
      "\n",
      "\n",
      "doc_ids:  [['doc_1', 'doc_181', 'doc_222']]\n",
      "\u001b[32mAdding doc_id doc_1 to context.\u001b[0m\n",
      "\u001b[33mragproxyagent\u001b[0m (to assistant):\n",
      "\n",
      "You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user. You should follow the following steps to answer a question:\n",
      "Step 1, you estimate the user's intent based on the question and context. The intent can be a code generation task or\n",
      "a question answering task.\n",
      "Step 2, you reply based on the intent.\n",
      "You should leverage the context provided by the user as much as possible. If you need more context, you should reply\n",
      "\"UPDATE CONTEXT\".\n",
      "For code generation task, you must obey the following rules:\n",
      "Rule 1. You MUST NOT install any packages because all the packages needed are already installed.\n",
      "Rule 2. You must follow the formats below to write your code:\n",
      "```language\n",
      "# your code\n",
      "```\n",
      "\n",
      "For question answering task, you must give as short an answer as possible.\n",
      "\n",
      "User's question is: how many episodes are in chicago fire season 4\n",
      "\n",
      "Context is: <P> The fourth season of Chicago Fire , an American drama television series with executive producer Dick Wolf , and producers Derek Haas , Michael Brandt , and Matt Olmstead , was ordered on February 5 , 2015 , by NBC , and premiered on October 13 , 2015 and concluded on May 17 , 2016 . The season contained 23 episodes . </P>\n",
      "<P> `` Love Will Keep Us Alive '' is a song written by Jim Capaldi , Paul Carrack , and Peter Vale , and produced by the Eagles , Elliot Scheiner , and Rob Jacobs . It was first performed by the Eagles in 1994 , during their `` Hell Freezes Over '' reunion tour , with lead vocals by bassist Timothy B. Schmit . </P>\n",
      "<P> Patrick Walter Brown MPP ( born May 26 , 1978 ) is a Canadian politician who is the leader of the Progressive Conservative Party of Ontario and Ontario 's Leader of the Official Opposition . Brown was a federal Conservative member of the House of Commons of Canada from 2006 - 15 representing the riding of Barrie . </P>\n",
      "<P> The surname Keith has several origins . In some cases it is derived from Keith in East Lothian , Scotland . In other cases the surname is originated from a nickname , derived from the Middle High German kīt , a word meaning `` sprout '' , `` offspring '' . </P>\n",
      "<P> Panning can also be used in an audio mixer to reduce or reverse the stereo width of a stereo signal . For instance , the left and right channels of a stereo source can be panned straight up , that is sent equally to both the left output and the right output of the mixer , creating a dual mono signal . </P>\n",
      "<Li> Jason Marsden as Maximillan `` Max '' Goof , Goofy 's insecure teenage son . </Li>\n",
      "<P> According to Unfinished Tales , at the start of the War of the Elves and Sauron , Celebrimbor gave Narya together with the Ring Vilya to Gil - galad , High King of the Noldor . Gil - galad entrusted Narya to his lieutenant Círdan , Lord of the Havens of Mithlond , who kept it after Gil - galad 's death . According to The Lord of the Rings , Gil - galad received only Vilya , while Círdan received Narya from the very beginning along with Galadriel receiving Nenya from the start . </P>\n",
      "<P> Tappan Zee Constructors began construction in 2013 . The north span officially opened to westbound traffic on August 26 , 2017 ; it also opened to eastbound traffic on October 6 , 2017 . Tappan Zee Constructors then began demolishing the old bridge . Eastbound traffic will be switched to the south span upon its completion . Both spans are expected to be operational by June 15 , 2018 . </P>\n",
      "<P> In 26 August 2016 , Olympics 2016 bronze medallist Sakshi Malik was made brand ambassador for BBBP . </P>\n",
      "<P> A market economy is an economic system where decisions regarding investment , production , and distribution are based on the interplay of supply and demand , which determines the prices of goods and services . The major defining characteristic of a market economy is that investment decisions , or the allocation of producer good , are primarily made through capital and financial markets . This is contrasted with a planned economy , where investment and production decisions are embodied in an integrated plan of production established by a state or other organizational body that controls the factors of production . </P>\n",
      "<P> Disparate impact in United States labor law refers to practices in employment , housing , and other areas that adversely affect one group of people of a protected characteristic more than another , even though rules applied by employers or landlords are formally neutral . Although the protected classes vary by statute , most federal civil rights laws protect based on race , color , religion , national origin , and sex as protected traits , and some laws include disability status and other traits as well . </P>\n",
      "<P> Christopher Allen Lloyd ( born October 22 , 1938 ) is an American actor , voice actor , and comedian . He is best known for his roles as Emmett `` Doc '' Brown in the Back to the Future trilogy , Judge Doom in Who Framed Roger Rabbit ( 1988 ) , Merlock the Magician in DuckTales the Movie : Treasure of the Lost Lamp ( 1990 ) , Uncle Fester in The Addams Family ( 1991 ) and its sequel Addams Family Values ( 1993 ) , and Grigori Rasputin in Anastasia ( 1997 ) . </P>\n",
      "<P> `` Fishin ' in the Dark '' is a song written by Wendy Waldman and Jim Photoglo and recorded by American country music group The Nitty Gritty Dirt Band . It was released in June 1987 as the second single from their album Hold On . It reached number - one on the U.S. and Canadian country charts . It was the band 's third number - one single on the U.S. country music charts and the second in Canada . After it became available for download , it has sold over a million digital copies by 2015 . It was certified Platinum by the RIAA on September 12 , 2014 . </P>\n",
      "<P> Most episodes feature a storyline taking place in the present ( 2016 -- 2018 , contemporaneous with airing ) and a storyline taking place at a set time in the past ; but some episodes are set in one time period or use multiple flashback time periods . Flashbacks often focus on Jack and Rebecca c. 1980 both before and after their babies ' birth , or on the family when the Big Three are children ( at least ages 8 -- 10 ) or adolescents ; these scenes usually take place in Pittsburgh , where the Big Three are born and raised . Various other time periods and locations have also served a settings . As adults , Kate lives in Los Angeles , Randall and his family are in New Jersey , and Kevin relocates from Los Angeles to New York City . </P>\n",
      "<Table> <Tr> <Th colspan=\"2\"> Patrick Brown MPP </Th> </Tr> <Tr> <Td colspan=\"2\"> </Td> </Tr> <Tr> <Td colspan=\"2\"> </Td> </Tr> <Tr> <Th colspan=\"2\"> Leader of the Opposition in Ontario </Th> </Tr> <Tr> <Td colspan=\"2\"> Incumbent </Td> </Tr> <Tr> <Td colspan=\"2\"> Assumed office September 14 , 2015 </Td> </Tr> <Tr> <Th> Preceded by </Th> <Td> Jim Wilson </Td> </Tr> <Tr> <Th colspan=\"2\"> Leader of the Ontario PC Party </Th> </Tr> <Tr> <Td colspan=\"2\"> Incumbent </Td> </Tr> <Tr> <Td colspan=\"2\"> Assumed office May 9 , 2015 </Td> </Tr> <Tr> <Th> Preceded by </Th> <Td> Jim Wilson ( interim ) </Td> </Tr> <Tr> <Th colspan=\"2\"> Member of the Ontario Provincial Parliament for Simcoe North </Th> </Tr> <Tr> <Td colspan=\"2\"> Incumbent </Td> </Tr> <Tr> <Td colspan=\"2\"> Assumed office September 3 , 2015 </Td> </Tr> <Tr> <Th> Preceded by </Th> <Td> Garfield Dunlop </Td> </Tr> <Tr> <Th colspan=\"2\"> Member of the Canadian Parliament for Barrie </Th> </Tr> <Tr> <Td colspan=\"2\"> In office January 23 , 2006 -- May 13 , 2015 </Td> </Tr> <Tr> <Th> Preceded by </Th> <Td> Aileen Carroll </Td> </Tr> <Tr> <Th> Succeeded by </Th> <Td> Riding Abolished </Td> </Tr> <Tr> <Td colspan=\"2\"> </Td> </Tr> <Tr> <Th colspan=\"2\"> Personal details </Th> </Tr> <Tr> <Th> </Th> <Td> Patrick Walter Brown ( 1978 - 05 - 26 ) May 26 , 1978 ( age 39 ) Toronto , Ontario </Td> </Tr> <Tr> <Th> Political party </Th> <Td> Progressive Conservative Party of Ontario </Td> </Tr> <Tr> <Th> Other political affiliations </Th> <Td> Conservative Party of Canada </Td> </Tr> <Tr> <Th> Relations </Th> <Td> Joe Tascona ( uncle ) </Td> </Tr> <Tr> <Th> Residence </Th> <Td> Barrie , Ontario </Td> </Tr> <Tr> <Th> Education </Th> <Td> St. Michael 's College School </Td> </Tr> <Tr> <Th> Alma mater </Th> <Td> University of Windsor ( LL. B . ) University of Toronto ( B.A. ) </Td> </Tr> <Tr> <Th> Profession </Th> <Td> Lawyer </Td> </Tr> </Table>\n",
      "<P> Panning is the distribution of a sound signal ( either monaural or stereophonic pairs ) into a new stereo or multi-channel sound field determined by a pan control setting . A typical physical recording console has a pan control for each incoming source channel . A pan control or pan pot ( short for `` panoramic potentiometer '' ) is an analog knob or slider with a position indicator which can range continuously from the 8 o'clock when fully left to the 4 o'clock position fully right . Audio mixing software replaces pan pots with on - screen virtual knobs or sliders which function identically to the physical counterparts . </P>\n",
      "<P> The first five seasons of Prison Break have been released on DVD and Blu - ray in Regions 1 , 2 , and 4 . Each DVD boxed set includes all of the broadcast episodes from that season , the associated special episode , commentary from cast and crew , and profiles of various parts of Prison Break , such as Fox River State Penitentiary or the tattoo . Prison Break is also available online , including iTunes , Amazon Video , and Netflix . After the premiere of the second season of Prison Break , Fox began online streaming of the prior week 's episode , though it originally restricted viewing to the United States . </P>\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to ragproxyagent):\n",
      "\n",
      "There are 23 episodes in Chicago Fire season 4.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(f\"\\n\\n>>>>>>>>>>>>  Below are outputs of Case {i+1}  <<<<<<<<<<<<\\n\\n\")\n",
    "\n",
    "    # reset the assistant. Always reset the assistant before starting a new conversation.\n",
    "    assistant.reset()\n",
    "\n",
    "    # set `human_input_mode` to be `NEVER`\n",
    "    ragproxyagent.human_input_mode = \"NEVER\"\n",
    "    qa_problem = questions[i]\n",
    "    ragproxyagent.initiate_chat(assistant, problem=qa_problem, n_results=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flaml_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
