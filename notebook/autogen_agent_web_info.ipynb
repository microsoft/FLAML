{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/FLAML/blob/main/notebook/autogen_agent_web_info.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interactive LLM Agent Dealing with Web Info\n",
    "\n",
    "FLAML offers an experimental feature of interactive LLM agents, which can be used to solve various tasks with human or automatic feedback, including tasks that require using tools via code.\n",
    "\n",
    "In this notebook, we demonstrate how to use `AssistantAgent` and `UserProxyAgent` to perform tasks which require acquiring info from the web:\n",
    "* discuss a paper based on its URL.\n",
    "* discuss about stock market.\n",
    "\n",
    "Here `AssistantAgent` is an LLM-based agent that can write Python code (in a Python coding block) for a user to execute for a given task. `UserProxyAgent` is an agent which serves as a proxy for a user to execute the code written by `AssistantAgent`. By setting `human_input_mode` properly, the `UserProxyAgent` can also prompt the user for feedback to `AssistantAgent`. For example, when `human_input_mode` is set to \"ALWAYS\", the `UserProxyAgent` will always prompt the user for feedback. When user feedback is provided, the `UserProxyAgent` will directly pass the feedback to `AssistantAgent` without doing any additional steps. When no user feedback is provided, the `UserProxyAgent` will execute the code written by `AssistantAgent` directly and return the execution results (success or failure and corresponding outputs) to `AssistantAgent`.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "FLAML requires `Python>=3.8`. To run this notebook example, please install flaml with the [autogen] option:\n",
    "```bash\n",
    "pip install flaml[autogen]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T23:40:52.317406Z",
     "iopub.status.busy": "2023-02-13T23:40:52.316561Z",
     "iopub.status.idle": "2023-02-13T23:40:52.321193Z",
     "shell.execute_reply": "2023-02-13T23:40:52.320628Z"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install flaml[autogen]==2.0.0rc3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_openai_aoai`](https://microsoft.github.io/FLAML/docs/reference/autogen/oai/openai_utils#config_list_openai_aoai) function tries to create a list of configurations using Azure OpenAI endpoints and OpenAI endpoints. It assumes the api keys and api bases are stored in the corresponding environment variables or local txt files:\n",
    "\n",
    "- OpenAI API key: os.environ[\"OPENAI_API_KEY\"] or `openai_api_key_file=\"key_openai.txt\"`.\n",
    "- Azure OpenAI API key: os.environ[\"AZURE_OPENAI_API_KEY\"] or `aoai_api_key_file=\"key_aoai.txt\"`. Multiple keys can be stored, one per line.\n",
    "- Azure OpenAI API base: os.environ[\"AZURE_OPENAI_API_BASE\"] or `aoai_api_base_file=\"base_aoai.txt\"`. Multiple bases can be stored, one per line.\n",
    "\n",
    "It's OK to have only the OpenAI API key, or only the Azure OpenAI API key + base. If you open this notebook in colab, you can upload your files by clicking the file icon on the left panel and then choose \"upload file\" icon.\n",
    "\n",
    "The following code excludes openai endpoints from the config list.\n",
    "Change to `exclude=\"aoai\"` to exclude Azure OpenAI, or remove the `exclude` argument to include both.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import oai\n",
    "\n",
    "config_list = oai.config_list_openai_aoai(exclude=\"openai\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Agents\n",
    "\n",
    "We construct the assistant agent and the user proxy agent. We specify `human_input_mode` as \"TERMINATE\" in the user proxy agent, which will ask for feedback when it receives a \"TERMINATE\" signal from the assistant agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml.autogen.agent import AssistantAgent, UserProxyAgent\n",
    "\n",
    "# create an AssistantAgent instance named \"assistant\"\n",
    "assistant = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    request_timeout=600,\n",
    "    seed=42,\n",
    "    config_list=config_list,\n",
    "    model=\"gpt-4-32k\",  # modify if the endpoint you use doesn't support this model\n",
    ")\n",
    "# create a UserProxyAgent instance named \"user\"\n",
    "user = UserProxyAgent(\n",
    "    name=\"user\",\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    work_dir='web',\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Task: Paper Talk from URL\n",
    "\n",
    "We invoke the `receive()` method of the coding agent to start the conversation. When you run the cell below, you will be prompted to provide feedback after the coding agent sends a \"TERMINATE\" signal in the end of the message. If you don't provide any feedback (by pressing Enter directly), the conversation will finish. Before the \"TERMINATE\" signal, the user proxy agent will try to execute the code suggested by the coding agent on behalf of the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user (to assistant):\n",
      "\n",
      "\n",
      "Who should read this paper: https://arxiv.org/abs/2306.01337\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to user):\n",
      "\n",
      "I will need to check the abstract of the paper to determine who should read it. Let me do that for you.\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "url = \"https://arxiv.org/abs/2306.01337\"\n",
      "response = requests.get(url)\n",
      "soup = BeautifulSoup(response.text, \"html.parser\")\n",
      "abstract = soup.find(\"blockquote\", {\"class\": \"abstract\"}).text.strip()\n",
      "\n",
      "print(\"Abstract:\", abstract)\n",
      "```\n",
      "\n",
      "Please run the above Python code to fetch the abstract of the paper. Based on the abstract, we can determine who should read it.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED. USING AUTO REPLY FOR THE USER...\n",
      "user (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Abstract: Abstract:  Employing Large Language Models (LLMs) to address mathematical problems is an\n",
      "intriguing research endeavor, considering the abundance of math problems\n",
      "expressed in natural language across numerous science and engineering fields.\n",
      "While several prior works have investigated solving elementary mathematics\n",
      "using LLMs, this work explores the frontier of using GPT-4 for solving more\n",
      "complex and challenging math problems. We evaluate various ways of using GPT-4.\n",
      "Some of them are adapted from existing work, and one is MathChat, a\n",
      "conversational problem-solving framework newly proposed in this work. We\n",
      "perform the evaluation on difficult high school competition problems from the\n",
      "MATH dataset, which shows the advantage of the proposed conversational\n",
      "approach.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to user):\n",
      "\n",
      "Based on the abstract, the paper is about using Large Language Models, specifically GPT-4, to solve complex mathematical problems. The paper introduces a conversational problem-solving framework called MathChat and evaluates its performance on challenging high school competition problems from the MATH dataset.\n",
      "\n",
      "The paper should be of interest to the following groups:\n",
      "\n",
      "1. Researchers and practitioners working in the field of artificial intelligence, specifically natural language processing and language models.\n",
      "2. Professionals interested in the application of AI for solving mathematical problems.\n",
      "3. Educators and instructors focused on teaching mathematics and incorporating AI-based solutions into teaching methodologies.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# the assistant receives a message from the user, which contains the task description\n",
    "assistant.receive(\n",
    "    \"\"\"\n",
    "Who should read this paper: https://arxiv.org/abs/2306.01337\n",
    "\"\"\",\n",
    "    user\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Task: Chat about Stock Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user (to assistant):\n",
      "\n",
      "What date is today? Which big tech stock has the largest year-to-date gain this year? How much is the gain?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to user):\n",
      "\n",
      "First, let's find out today's date. Please execute the following Python code:\n",
      "\n",
      "```python\n",
      "import datetime\n",
      "\n",
      "today = datetime.date.today()\n",
      "print(\"Today's date:\", today)\n",
      "```\n",
      "\n",
      "Once we know today's date, let's find out which big tech stock has the largest year-to-date gain. I will provide a code to search for this information. This task requires the `yfinance` package. Install it by running:\n",
      "\n",
      "```sh\n",
      "pip install yfinance\n",
      "```\n",
      "\n",
      "Next, execute the following Python code:\n",
      "\n",
      "```python\n",
      "import yfinance as yf\n",
      "\n",
      "big_tech_stocks = [\"AAPL\", \"GOOGL\", \"AMZN\", \"MSFT\", \"FB\"]\n",
      "max_gain = 0\n",
      "max_gain_stock = \"\"\n",
      "\n",
      "for stock_symbol in big_tech_stocks:\n",
      "    stock_data = yf.download(stock_symbol, start=f\"{today.year}-01-01\", end=today)\n",
      "    year_start_price = stock_data[\"Close\"][0]\n",
      "    current_price = stock_data[\"Close\"][-1]\n",
      "    gain_percentage = (current_price - year_start_price) / year_start_price * 100\n",
      "\n",
      "    if gain_percentage > max_gain:\n",
      "        max_gain = gain_percentage\n",
      "        max_gain_stock = stock_symbol\n",
      "\n",
      "print(\"The big tech stock with the largest year-to-date gain is\", max_gain_stock)\n",
      "print(f\"The gain is {max_gain:.2f}%\")\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED. USING AUTO REPLY FOR THE USER...\n",
      "user (to assistant):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Today's date: 2023-07-10\n",
      "\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: yfinance in /home/vscode/.local/lib/python3.9/site-packages (0.2.18)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.9/site-packages (from yfinance) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (1.23.5)\n",
      "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.9/site-packages (from yfinance) (2.28.1)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: lxml>=4.9.1 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (4.9.2)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.9/site-packages (from yfinance) (2022.6)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (2.3.8)\n",
      "Requirement already satisfied: cryptography>=3.3.2 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (38.0.4)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (4.11.1)\n",
      "Requirement already satisfied: html5lib>=1.1 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/vscode/.local/lib/python3.9/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.3.2.post1)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/vscode/.local/lib/python3.9/site-packages (from cryptography>=3.3.2->yfinance) (1.15.1)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.9/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /home/vscode/.local/lib/python3.9/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/site-packages (from requests>=2.26->yfinance) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests>=2.26->yfinance) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests>=2.26->yfinance) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests>=2.26->yfinance) (2022.9.24)\n",
      "Requirement already satisfied: pycparser in /home/vscode/.local/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=3.3.2->yfinance) (2.21)\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/FLAML/notebook/web/tmp_code_dad672c8a5e8e3b25c27c3bd8085848d.py\", line 8, in <module>\n",
      "    stock_data = yf.download(stock_symbol, start=f\"{today.year}-01-01\", end=today)\n",
      "NameError: name 'today' is not defined\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to user):\n",
      "\n",
      "I apologize for the oversight. It seems that the `today` variable from the previous code block is not accessible in the current code block. Let's modify the code to include fetching today's date in the same code block. Please execute the following Python code:\n",
      "\n",
      "```python\n",
      "import datetime\n",
      "import yfinance as yf\n",
      "\n",
      "today = datetime.date.today()\n",
      "print(\"Today's date:\", today)\n",
      "\n",
      "big_tech_stocks = [\"AAPL\", \"GOOGL\", \"AMZN\", \"MSFT\", \"FB\"]\n",
      "max_gain = 0\n",
      "max_gain_stock = \"\"\n",
      "\n",
      "for stock_symbol in big_tech_stocks:\n",
      "    stock_data = yf.download(stock_symbol, start=f\"{today.year}-01-01\", end=today)\n",
      "    year_start_price = stock_data[\"Close\"][0]\n",
      "    current_price = stock_data[\"Close\"][-1]\n",
      "    gain_percentage = (current_price - year_start_price) / year_start_price * 100\n",
      "\n",
      "    if gain_percentage > max_gain:\n",
      "        max_gain = gain_percentage\n",
      "        max_gain_stock = stock_symbol\n",
      "\n",
      "print(\"The big tech stock with the largest year-to-date gain is\", max_gain_stock)\n",
      "print(f\"The gain is {max_gain:.2f}%\")\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED. USING AUTO REPLY FOR THE USER...\n",
      "user (to assistant):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/FLAML/notebook/web/tmp_code_0d5c40281daaf2e5e5430a5b89413be7.py\", line 13, in <module>\n",
      "    year_start_price = stock_data[\"Close\"][0]\n",
      "  File \"/usr/local/lib/python3.9/site-packages/pandas/core/series.py\", line 978, in __getitem__\n",
      "    return self._values[key]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to user):\n",
      "\n",
      "I apologize for the error. It seems that there is an issue with the stock data retrieved. Let's add a check to ensure that the stock data is available before processing it. Please execute the following modified Python code:\n",
      "\n",
      "```python\n",
      "import datetime\n",
      "import yfinance as yf\n",
      "\n",
      "today = datetime.date.today()\n",
      "print(\"Today's date:\", today)\n",
      "\n",
      "big_tech_stocks = [\"AAPL\", \"GOOGL\", \"AMZN\", \"MSFT\", \"FB\"]\n",
      "max_gain = 0\n",
      "max_gain_stock = \"\"\n",
      "\n",
      "for stock_symbol in big_tech_stocks:\n",
      "    stock_data = yf.download(stock_symbol, start=f\"{today.year}-01-01\", end=today)\n",
      "    \n",
      "    if not stock_data.empty:\n",
      "        year_start_price = stock_data[\"Close\"][0]\n",
      "        current_price = stock_data[\"Close\"][-1]\n",
      "        gain_percentage = (current_price - year_start_price) / year_start_price * 100\n",
      "\n",
      "        if gain_percentage > max_gain:\n",
      "            max_gain = gain_percentage\n",
      "            max_gain_stock = stock_symbol\n",
      "    else:\n",
      "        print(f\"Unable to retrieve data for stock {stock_symbol}\")\n",
      "\n",
      "print(\"The big tech stock with the largest year-to-date gain is\", max_gain_stock)\n",
      "print(f\"The gain is {max_gain:.2f}%\")\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED. USING AUTO REPLY FOR THE USER...\n",
      "user (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Today's date: 2023-07-10\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- FB: No timezone found, symbol may be delisted\n",
      "Unable to retrieve data for stock FB\n",
      "The big tech stock with the largest year-to-date gain is AAPL\n",
      "The gain is 52.46%\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to user):\n",
      "\n",
      "Today's date is 2023-07-10. The big tech stock with the largest year-to-date gain is AAPL (Apple Inc.) with a gain of 52.46%. Please note that there was an issue retrieving the data for the stock FB (Facebook). It is possible that the symbol has been delisted or there is a temporary issue with the data source.\n",
      "\n",
      "If you have any other questions or need further assistance, please let me know.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "user (to assistant):\n",
      "\n",
      "Replace FB with Meta\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to user):\n",
      "\n",
      "Sure, let's replace \"FB\" with \"META\" in the stock list and run the modified code again to find the largest year-to-date gain.\n",
      "\n",
      "```python\n",
      "import datetime\n",
      "import yfinance as yf\n",
      "\n",
      "today = datetime.date.today()\n",
      "print(\"Today's date:\", today)\n",
      "\n",
      "big_tech_stocks = [\"AAPL\", \"GOOGL\", \"AMZN\", \"MSFT\", \"META\"]\n",
      "max_gain = 0\n",
      "max_gain_stock = \"\"\n",
      "\n",
      "for stock_symbol in big_tech_stocks:\n",
      "    stock_data = yf.download(stock_symbol, start=f\"{today.year}-01-01\", end=today)\n",
      "    \n",
      "    if not stock_data.empty:\n",
      "        year_start_price = stock_data[\"Close\"][0]\n",
      "        current_price = stock_data[\"Close\"][-1]\n",
      "        gain_percentage = (current_price - year_start_price) / year_start_price * 100\n",
      "\n",
      "        if gain_percentage > max_gain:\n",
      "            max_gain = gain_percentage\n",
      "            max_gain_stock = stock_symbol\n",
      "    else:\n",
      "        print(f\"Unable to retrieve data for stock {stock_symbol}\")\n",
      "\n",
      "print(\"The big tech stock with the largest year-to-date gain is\", max_gain_stock)\n",
      "print(f\"The gain is {max_gain:.2f}%\")\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED. USING AUTO REPLY FOR THE USER...\n",
      "user (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Today's date: 2023-07-10\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "The big tech stock with the largest year-to-date gain is META\n",
      "The gain is 132.91%\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to user):\n",
      "\n",
      "Today's date is 2023-07-10. The big tech stock with the largest year-to-date gain is META (Meta Platforms Inc., formerly known as Facebook) with a gain of 132.91%. If you have any other questions or need further assistance, please let me know.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "user (to assistant):\n",
      "\n",
      "Add NVDA and TESLA\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to user):\n",
      "\n",
      "Let's add \"NVDA\" (Nvidia Corporation) and \"TSLA\" (Tesla, Inc.) to the stock list and run the modified code again to find the largest year-to-date gain.\n",
      "\n",
      "```python\n",
      "import datetime\n",
      "import yfinance as yf\n",
      "\n",
      "today = datetime.date.today()\n",
      "print(\"Today's date:\", today)\n",
      "\n",
      "big_tech_stocks = [\"AAPL\", \"GOOGL\", \"AMZN\", \"MSFT\", \"META\", \"NVDA\", \"TSLA\"]\n",
      "max_gain = 0\n",
      "max_gain_stock = \"\"\n",
      "\n",
      "for stock_symbol in big_tech_stocks:\n",
      "    stock_data = yf.download(stock_symbol, start=f\"{today.year}-01-01\", end=today)\n",
      "    \n",
      "    if not stock_data.empty:\n",
      "        year_start_price = stock_data[\"Close\"][0]\n",
      "        current_price = stock_data[\"Close\"][-1]\n",
      "        gain_percentage = (current_price - year_start_price) / year_start_price * 100\n",
      "\n",
      "        if gain_percentage > max_gain:\n",
      "            max_gain = gain_percentage\n",
      "            max_gain_stock = stock_symbol\n",
      "    else:\n",
      "        print(f\"Unable to retrieve data for stock {stock_symbol}\")\n",
      "\n",
      "print(\"The big tech stock with the largest year-to-date gain is\", max_gain_stock)\n",
      "print(f\"The gain is {max_gain:.2f}%\")\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED. USING AUTO REPLY FOR THE USER...\n",
      "user (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Today's date: 2023-07-10\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "The big tech stock with the largest year-to-date gain is NVDA\n",
      "The gain is 196.91%\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "assistant (to user):\n",
      "\n",
      "Today's date is 2023-07-10. The big tech stock with the largest year-to-date gain, including \"NVDA\" (Nvidia Corporation) and \"TSLA\" (Tesla, Inc.), is NVDA with a gain of 196.91%. If you have any other questions or need further assistance, please let me know.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# it is suggested to reset the assistant to clear the state if the new task is not related to the previous one.\n",
    "assistant.reset()\n",
    "assistant.receive(\n",
    "    \"\"\"What date is today? Which big tech stock has the largest year-to-date gain this year? How much is the gain?\"\"\",\n",
    "    user,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2d910cfd2d2a4fc49fc30fbbdc5576a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "454146d0f7224f038689031002906e6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e4ae2b6f5a974fd4bafb6abb9d12ff26",
        "IPY_MODEL_577e1e3cc4db4942b0883577b3b52755",
        "IPY_MODEL_b40bdfb1ac1d4cffb7cefcb870c64d45"
       ],
       "layout": "IPY_MODEL_dc83c7bff2f241309537a8119dfc7555",
       "tabbable": null,
       "tooltip": null
      }
     },
     "577e1e3cc4db4942b0883577b3b52755": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2d910cfd2d2a4fc49fc30fbbdc5576a7",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_74a6ba0c3cbc4051be0a83e152fe1e62",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "6086462a12d54bafa59d3c4566f06cb2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74a6ba0c3cbc4051be0a83e152fe1e62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7d3f3d9e15894d05a4d188ff4f466554": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b40bdfb1ac1d4cffb7cefcb870c64d45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f1355871cc6f4dd4b50d9df5af20e5c8",
       "placeholder": "​",
       "style": "IPY_MODEL_ca245376fd9f4354af6b2befe4af4466",
       "tabbable": null,
       "tooltip": null,
       "value": " 1/1 [00:00&lt;00:00, 44.69it/s]"
      }
     },
     "ca245376fd9f4354af6b2befe4af4466": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dc83c7bff2f241309537a8119dfc7555": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e4ae2b6f5a974fd4bafb6abb9d12ff26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6086462a12d54bafa59d3c4566f06cb2",
       "placeholder": "​",
       "style": "IPY_MODEL_7d3f3d9e15894d05a4d188ff4f466554",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "f1355871cc6f4dd4b50d9df5af20e5c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
