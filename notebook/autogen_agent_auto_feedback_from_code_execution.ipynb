{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/FLAML/blob/main/notebook/autogen_agent_auto_feedback_from_code_execution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interactive LLM Agent with Auto Feedback from Code Execution\n",
    "\n",
    "FLAML offers an experimental feature of interactive LLM agents, which can be used to solve various tasks with human or automatic feedback, including tasks that require using tools via code.\n",
    "\n",
    "In this notebook, we demonstrate how to use `AssistantAgent` and `UserProxyAgent` to write code and execute the code. Here `AssistantAgent` is an LLM-based agent that can write Python code (in a Python coding block) for a user to execute for a given task. `UserProxyAgent` is an agent which serves as a proxy for the human user to execute the code written by `AssistantAgent`, or automatically execute the code. Depending on the setting of `human_input_mode` and `max_consecutive_auto_reply`, the `UserProxyAgent` either solicits feedback from the human user or uses auto-feedback based on the result of code execution. For example, when `human_input_mode` is set to \"ALWAYS\", the `UserProxyAgent` will always prompt the user for feedback. When user feedback is provided, the `UserProxyAgent` will directly pass the feedback to `AssistantAgent` without doing any additional steps. When no user feedback is provided, the `UserProxyAgent` will execute the code written by `AssistantAgent` directly and return the execution results (success or failure and corresponding outputs) to `AssistantAgent`.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "FLAML requires `Python>=3.7`. To run this notebook example, please install flaml with the [autogen] option:\n",
    "```bash\n",
    "pip install flaml[autogen]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T23:40:52.317406Z",
     "iopub.status.busy": "2023-02-13T23:40:52.316561Z",
     "iopub.status.idle": "2023-02-13T23:40:52.321193Z",
     "shell.execute_reply": "2023-02-13T23:40:52.320628Z"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install flaml[autogen]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_gpt4_gpt35`](https://microsoft.github.io/FLAML/docs/reference/autogen/oai/openai_utils#config_list_gpt4_gpt35) function tries to create a list of gpt-4 and gpt-3.5 configurations using Azure OpenAI endpoints and OpenAI endpoints. It assumes the api keys and api bases are stored in the corresponding environment variables or local txt files:\n",
    "\n",
    "- OpenAI API key: os.environ[\"OPENAI_API_KEY\"] or `openai_api_key_file=\"key_openai.txt\"`.\n",
    "- Azure OpenAI API key: os.environ[\"AZURE_OPENAI_API_KEY\"] or `aoai_api_key_file=\"key_aoai.txt\"`. Multiple keys can be stored, one per line.\n",
    "- Azure OpenAI API base: os.environ[\"AZURE_OPENAI_API_BASE\"] or `aoai_api_base_file=\"base_aoai.txt\"`. Multiple bases can be stored, one per line.\n",
    "\n",
    "It's OK to have only the OpenAI API key, or only the Azure OpenAI API key + base.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import oai\n",
    "\n",
    "config_list = oai.config_list_from_models(model_list=[\"gpt-4\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The config list looks like the following:\n",
    "```python\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your OpenAI API key here>',\n",
    "    },  # only if OpenAI API key is found\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your first Azure OpenAI API key here>',\n",
    "        'api_base': '<your first Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-03-15-preview',\n",
    "    },  # only if the at least one Azure OpenAI API key is found\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your second Azure OpenAI API key here>',\n",
    "        'api_base': '<your second Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-03-15-preview',\n",
    "    },  # only if the second Azure OpenAI API key is found\n",
    "    {\n",
    "        'model': 'gpt-3.5-turbo',\n",
    "        'api_key': '<your OpenAI API key here>',\n",
    "    },  # only if OpenAI API key is found\n",
    "    {\n",
    "        'model': 'gpt-3.5-turbo',\n",
    "        'api_key': '<your first Azure OpenAI API key here>',\n",
    "        'api_base': '<your first Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-03-15-preview',\n",
    "    },  # only if the at least one Azure OpenAI API key is found\n",
    "    {\n",
    "        'model': 'gpt-3.5-turbo',\n",
    "        'api_key': '<your second Azure OpenAI API key here>',\n",
    "        'api_base': '<your second Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-03-15-preview',\n",
    "    },  # only if the second Azure OpenAI API key is found\n",
    "]\n",
    "```\n",
    "\n",
    "You can directly override it if the above function returns an empty list, i.e., it doesn't find the keys in the specified locations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Task: Write Code to Draw a Plot\n",
    "\n",
    "In the example below, let's see how to use the agents in FLAML to write a python script and execute the script. This process involves constructing a `AssistantAgent` to serve as the assistant, along with a `UserProxyAgent` that acts as a proxy for the human user. In this example demonstrated below, when constructing the `UserProxyAgent`,  we select the `human_input_mode` to \"NEVER\". This means that the `UserProxyAgent` will not solicit feedback from the human user. It stops replying when the limit defined by `max_consecutive_auto_reply` is reached, or when `is_termination_msg()` returns true for the received message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**** assistant received message from user ****\n",
      "\n",
      "Plot a rocket and save the plot to a file named 'rocket.svg'\n",
      "\n",
      "**** user received message from assistant ****\n",
      "\n",
      "To plot a rocket and save it to an SVG file, you'll need to install the `matplotlib` library if you haven't already:\n",
      "\n",
      "```bash\n",
      "pip install matplotlib\n",
      "```\n",
      "\n",
      "Now, use the code snippet below to plot a simple rocket and save it as 'rocket.svg':\n",
      "```python\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "def plot_rocket():\n",
      "    plt.figure(figsize=(4, 10))\n",
      "    \n",
      "    # Rocket body\n",
      "    plt.plot([0, 0], [0, 8], 'b-', linewidth=12)\n",
      "    \n",
      "    # Rocket head\n",
      "    plt.plot([-0.5, 0, 0.5], [8, 9, 8], 'b-', linewidth=12, solid_capstyle='round')\n",
      "    \n",
      "    # Rocket fins\n",
      "    plt.plot([0, -1.5], [2, 0], 'b-', linewidth=4, solid_capstyle='round')\n",
      "    plt.plot([0, 1.5], [2, 0], 'b-', linewidth=4, solid_capstyle='round')\n",
      "    \n",
      "    plt.xlim(-2, 2)\n",
      "    plt.ylim(0, 9.5)\n",
      "    plt.gca().set_aspect('equal', adjustable='box')\n",
      "    plt.axis('off')\n",
      "    \n",
      "    plt.savefig('rocket.svg', format='svg')\n",
      "\n",
      "plot_rocket()\n",
      "```\n",
      "This code will create a simple rocket plot and save it as 'rocket.svg'. Please execute the code and let me know if the rocket plot is saved successfully.\n",
      "\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED. USING AUTO REPLY FOR THE USER...\n",
      "\n",
      "**** assistant received message from user ****\n",
      "\n",
      "user (to assistant):\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "\n",
      "**** user received message from assistant ****\n",
      "\n",
      "Great! The rocket plot has been successfully created and saved as 'rocket.svg'. If you have any further requests or tasks, feel free to ask. Otherwise, have a great day!\n",
      "TERMINATE\n"
     ]
    }
   ],
   "source": [
    "from flaml.autogen.agent.assistant_agent import AssistantAgent\n",
    "from flaml.autogen.agent.user_proxy_agent import UserProxyAgent\n",
    "\n",
    "# create an assistant which is essentially a AssistantAgent instance named \"coding_agent\"\n",
    "assistant = AssistantAgent(\"assistant\", request_timeout=600, seed=42, config_list=config_list)\n",
    "# create a UserProxyAgent instance named \"user\"\n",
    "user = UserProxyAgent(\n",
    "    \"user\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    is_termination_msg=lambda x: x.rstrip().endswith(\"TERMINATE\") or x.rstrip().endswith('\"TERMINATE\".'),\n",
    "    work_dir=\".\",\n",
    ")\n",
    "# the assistant receives a message from the user, which contains the task description\n",
    "assistant.receive(\n",
    "    \"\"\"Plot a rocket and save the plot to a file named 'rocket.svg'\"\"\",\n",
    "    user,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example above involves code execution. In FLAML, code execution is triggered automatically by the `UserProxyAgent` when it detects an executable code block in a received message and no human user input is provided. This process occurs in a designated working directory, using a Docker container by default. Unless a specific directory is specified, FLAML defaults to the `flaml/autogen/extensions` directory. Users have the option to specify a different working directory by setting the `work_dir` argument when constructing a new instance of the `UserProxyAgent`.\n",
    "\n",
    "Let's display the generated figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" xmlns=\"http://www.w3.org/2000/svg\" width=\"288pt\" height=\"720pt\" viewBox=\"0 0 288 720\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-06-01T04:14:40.122729</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 720  L 288 720  L 288 0  L 0 0  z \" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"line2d_1\">\n",
       "    <path d=\"M 147.6 628.65  L 147.6 182.25  \" clip-path=\"url(#p72448343b1)\" style=\"fill: none; stroke: #0000ff; stroke-width: 12; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_2\">\n",
       "    <path d=\"M 119.7 182.25  L 147.6 126.45  L 175.5 182.25  \" clip-path=\"url(#p72448343b1)\" style=\"fill: none; stroke: #0000ff; stroke-width: 12; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_3\">\n",
       "    <path d=\"M 147.6 517.05  L 63.9 628.65  \" clip-path=\"url(#p72448343b1)\" style=\"fill: none; stroke: #0000ff; stroke-width: 4; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_4\">\n",
       "    <path d=\"M 147.6 517.05  L 231.3 628.65  \" clip-path=\"url(#p72448343b1)\" style=\"fill: none; stroke: #0000ff; stroke-width: 4; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p72448343b1\">\n",
       "   <rect x=\"36\" y=\"98.55\" width=\"223.2\" height=\"530.1\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# uncomment the following to render the svg file\n",
    "# from IPython.display import SVG, display\n",
    "\n",
    "# display(SVG(\"rocket.svg\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Task: Use Code to Check Stock Price Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**** assistant received message from user ****\n",
      "\n",
      "What date is today? Which S&P stock has the largest year-to-date gain in 2023? How much is the gain\n",
      "\n",
      "**** user received message from assistant ****\n",
      "\n",
      "To get today's date, you can use the following code:\n",
      "\n",
      "```python\n",
      "from datetime import datetime\n",
      "\n",
      "today = datetime.now().strftime(\"%Y-%m-%d\")\n",
      "print(f\"Today's date is {today}\")\n",
      "```\n",
      "\n",
      "As for fetching the S&P stock with the largest year-to-date gain in 2023, we first need to check the stock data. Run the code below to install the necessary library:\n",
      "\n",
      "```python\n",
      "!pip install yfinance\n",
      "```\n",
      "\n",
      "Once the library is installed, use the following code to retrieve the S&P 500 stock data:\n",
      "\n",
      "```python\n",
      "import yfinance as yf\n",
      "import pandas as pd\n",
      "from datetime import datetime\n",
      "\n",
      "def get_sp500_tickers():\n",
      "    table = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
      "    return table['Symbol'].tolist()\n",
      "\n",
      "def ytd_stock_gains(year):\n",
      "    start_date = f\"{year}-01-01\"\n",
      "    end_date = datetime.now().strftime(\"%Y-%m-%d\") if year == datetime.now().year else f\"{year}-12-31\"\n",
      "\n",
      "    tickers = get_sp500_tickers()\n",
      "\n",
      "    max_gain = 0\n",
      "    max_ticker = \"\"\n",
      "\n",
      "    for ticker in tickers:\n",
      "        stock = yf.Ticker(ticker)\n",
      "        hist = stock.history(start=start_date, end=end_date)\n",
      "\n",
      "        if len(hist) > 0:\n",
      "            start_price = hist.iloc[0]['Close']\n",
      "            end_price = hist.iloc[-1]['Close']\n",
      "            gain = (end_price - start_price) / start_price * 100\n",
      "\n",
      "            if gain > max_gain:\n",
      "                max_gain = gain\n",
      "                max_ticker = ticker\n",
      "        else:\n",
      "            print(f\"Error: No historical data for {ticker}\")\n",
      "\n",
      "    return max_ticker, max_gain\n",
      "\n",
      "largest_gain_ticker, largest_gain_value = ytd_stock_gains(2023)\n",
      "print(f\"The S&P stock with the largest year-to-date gain in 2023 is {largest_gain_ticker} with a gain of {largest_gain_value:.2f}%.\")\n",
      "```\n",
      "\n",
      "Keep in mind that first it fetches all S&P 500 stock symbols, then it loops through the list of stock symbols, fetching the historical price data and calculating the year-to-date gain for each stock. The script takes time to run and may exceed some rate limits for the API. If you run into errors, try again after a few minutes or perhaps implement a rate-limiting process like using `time.sleep()` to wait between fetching historical data.\n",
      "\n",
      "Please note that this code block does not run properly in AI Dungeon; however, you may run it in any Python environment on your local computer or cloud-based service like Google Colab.\n",
      "\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED. USING AUTO REPLY FOR THE USER...\n",
      "\n",
      "**** assistant received message from user ****\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output:   File \"/workspaces/FLAML/notebook/tmp_code_594fe356b9f2b4e2a63fea4383994a74.py\", line 1\n",
      "    !pip install yfinance\n",
      "    ^\n",
      "SyntaxError: invalid syntax\n",
      "\n",
      "user (to assistant):\n",
      "\n",
      "**** user received message from assistant ****\n",
      "\n",
      "I apologize for the confusion. I forgot that we cannot run shell commands directly in the code block provided. Please install the `yfinance` library using your command prompt or terminal by executing the following line:\n",
      "\n",
      "```\n",
      "pip install yfinance\n",
      "```\n",
      "\n",
      "Once you have installed the `yfinance` library, you can then run the second code block I provided for fetching the S&P 500 stock data and calculating the largest year-to-date gain in 2023.\n",
      "\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED. USING AUTO REPLY FOR THE USER...\n",
      "\n",
      "**** assistant received message from user ****\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: yfinance in /home/vscode/.local/lib/python3.9/site-packages (0.2.18)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (2.3.8)\n",
      "Requirement already satisfied: cryptography>=3.3.2 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (41.0.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (4.12.2)\n",
      "Requirement already satisfied: pytz>=2022.5 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (2023.3)\n",
      "Requirement already satisfied: requests>=2.26 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (2.28.2)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (1.5.3)\n",
      "Requirement already satisfied: lxml>=4.9.1 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (4.9.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (1.24.3)\n",
      "Requirement already satisfied: html5lib>=1.1 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (1.1)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in /home/vscode/.local/lib/python3.9/site-packages (from yfinance) (1.4.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/vscode/.local/lib/python3.9/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/vscode/.local/lib/python3.9/site-packages (from cryptography>=3.3.2->yfinance) (1.15.1)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.9/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /home/vscode/.local/lib/python3.9/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/vscode/.local/lib/python3.9/site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests>=2.26->yfinance) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests>=2.26->yfinance) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/vscode/.local/lib/python3.9/site-packages (from requests>=2.26->yfinance) (1.26.16)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests>=2.26->yfinance) (3.4)\n",
      "Requirement already satisfied: pycparser in /home/vscode/.local/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=3.3.2->yfinance) (2.21)\n",
      "\n",
      "\n",
      "**** user received message from assistant ****\n",
      "\n",
      "Great! Now that the `yfinance` library is installed, you can run the Python code I provided earlier to fetch the S&P 500 stock data and calculate the largest year-to-date gain in 2023.\n",
      "\n",
      "```python\n",
      "import yfinance as yf\n",
      "import pandas as pd\n",
      "from datetime import datetime\n",
      "\n",
      "def get_sp500_tickers():\n",
      "    table = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
      "    return table['Symbol'].tolist()\n",
      "\n",
      "def ytd_stock_gains(year):\n",
      "    start_date = f\"{year}-01-01\"\n",
      "    end_date = datetime.now().strftime(\"%Y-%m-%d\") if year == datetime.now().year else f\"{year}-12-31\"\n",
      "\n",
      "    tickers = get_sp500_tickers()\n",
      "\n",
      "    max_gain = 0\n",
      "    max_ticker = \"\"\n",
      "\n",
      "    for ticker in tickers:\n",
      "        stock = yf.Ticker(ticker)\n",
      "        hist = stock.history(start=start_date, end=end_date)\n",
      "\n",
      "        if len(hist) > 0:\n",
      "            start_price = hist.iloc[0]['Close']\n",
      "            end_price = hist.iloc[-1]['Close']\n",
      "            gain = (end_price - start_price) / start_price * 100\n",
      "\n",
      "            if gain > max_gain:\n",
      "                max_gain = gain\n",
      "                max_ticker = ticker\n",
      "        else:\n",
      "            print(f\"Error: No historical data for {ticker}\")\n",
      "\n",
      "    return max_ticker, max_gain\n",
      "\n",
      "largest_gain_ticker, largest_gain_value = ytd_stock_gains(2023)\n",
      "print(f\"The S&P stock with the largest year-to-date gain in 2023 is {largest_gain_ticker} with a gain of {largest_gain_value:.2f}%.\")\n",
      "```\n",
      "\n",
      "Please note that this code block might not run as intended in AI Dungeon; however, you may run it in any Python environment on your local computer or cloud-based service like Google Colab.\n",
      "\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED. USING AUTO REPLY FOR THE USER...\n",
      "\n",
      "**** assistant received message from user ****\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: Got error from yahoo api for ticker BRK.B, Error: {'code': 'Not Found', 'description': 'No data found, symbol may be delisted'}\n",
      "- BRK.B: No timezone found, symbol may be delisted\n",
      "Error: No historical data for BRK.B\n",
      "BF.B: No data found for this date range, symbol may be delisted\n",
      "Error: No historical data for BF.B\n",
      "The S&P stock with the largest year-to-date gain in 2023 is NVDA with a gain of 164.34%.\n",
      "\n",
      "\n",
      "**** user received message from assistant ****\n",
      "\n",
      "Great! The code fetched the S&P 500 stock data and calculated the largest year-to-date gain in 2023 successfully. The output shows that the S&P stock with the largest gain in 2023 is NVDA (NVIDIA Corporation) with a gain of 164.34%. Please note that data may change over time, and the result might be different if you run the code later.\n",
      "\n",
      "If you have any other questions or need further assistance, feel free to ask. If not, you can end this task by replying with \"TERMINATE\".\n"
     ]
    }
   ],
   "source": [
    "# it is suggested to reset the assistant to clear the state if the new task is not related to the previous one.\n",
    "assistant.reset()\n",
    "assistant.receive(\n",
    "    \"\"\"What date is today? Which S&P stock has the largest year-to-date gain in 2023? How much is the gain\"\"\",\n",
    "    user,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the feedback is auto generated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2d910cfd2d2a4fc49fc30fbbdc5576a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "454146d0f7224f038689031002906e6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e4ae2b6f5a974fd4bafb6abb9d12ff26",
        "IPY_MODEL_577e1e3cc4db4942b0883577b3b52755",
        "IPY_MODEL_b40bdfb1ac1d4cffb7cefcb870c64d45"
       ],
       "layout": "IPY_MODEL_dc83c7bff2f241309537a8119dfc7555",
       "tabbable": null,
       "tooltip": null
      }
     },
     "577e1e3cc4db4942b0883577b3b52755": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2d910cfd2d2a4fc49fc30fbbdc5576a7",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_74a6ba0c3cbc4051be0a83e152fe1e62",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "6086462a12d54bafa59d3c4566f06cb2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74a6ba0c3cbc4051be0a83e152fe1e62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7d3f3d9e15894d05a4d188ff4f466554": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b40bdfb1ac1d4cffb7cefcb870c64d45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f1355871cc6f4dd4b50d9df5af20e5c8",
       "placeholder": "​",
       "style": "IPY_MODEL_ca245376fd9f4354af6b2befe4af4466",
       "tabbable": null,
       "tooltip": null,
       "value": " 1/1 [00:00&lt;00:00, 44.69it/s]"
      }
     },
     "ca245376fd9f4354af6b2befe4af4466": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dc83c7bff2f241309537a8119dfc7555": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e4ae2b6f5a974fd4bafb6abb9d12ff26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6086462a12d54bafa59d3c4566f06cb2",
       "placeholder": "​",
       "style": "IPY_MODEL_7d3f3d9e15894d05a4d188ff4f466554",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "f1355871cc6f4dd4b50d9df5af20e5c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
