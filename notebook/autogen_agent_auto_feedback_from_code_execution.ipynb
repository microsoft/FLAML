{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/FLAML/blob/main/notebook/autogen_agent_auto_feedback_from_code_execution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interactive LLM Agent with Auto Feedback from Code Execution\n",
    "\n",
    "FLAML offers an experimental feature of interactive LLM agents, which can be used to solve various tasks, including coding and math problem-solving.\n",
    "\n",
    "In this notebook, we demonstrate how to use `AssistantAgent` and `UserProxyAgent` to write code and execute the code. Here `AssistantAgent` is an LLM-based agent that can write Python code (in a Python coding block) for a user to execute for a given task. `UserProxyAgent` is an agent which serves as a proxy for the human user to execute the code written by `AssistantAgent`, or automatically execute the code. Depending on the setting of `human_input_mode` and `max_consecutive_auto_reply`, the `UserProxyAgent` either solicits feedback from the human user or uses auto-feedback based on the result of code execution. For example, when `human_input_mode` is set to \"ALWAYS\", the `UserProxyAgent` will always prompt the user for feedback. When user feedback is provided, the `UserProxyAgent` will directly pass the feedback to `AssistantAgent` without doing any additional steps. When no user feedback is provided, the `UserProxyAgent` will execute the code written by `AssistantAgent` directly and return the execution results (success or failure and corresponding outputs) to `AssistantAgent`.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "FLAML requires `Python>=3.7`. To run this notebook example, please install flaml with the [autogen] option:\n",
    "```bash\n",
    "pip install flaml[autogen]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T23:40:52.317406Z",
     "iopub.status.busy": "2023-02-13T23:40:52.316561Z",
     "iopub.status.idle": "2023-02-13T23:40:52.321193Z",
     "shell.execute_reply": "2023-02-13T23:40:52.320628Z"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install flaml[autogen]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_gpt4_gpt35`](https://microsoft.github.io/FLAML/docs/reference/autogen/oai/openai_utils#config_list_gpt4_gpt35) function tries to create a list of gpt-4 and gpt-3.5 configurations using Azure OpenAI endpoints and OpenAI endpoints. It assumes the api keys and api bases are stored in the corresponding environment variables or local txt files:\n",
    "\n",
    "- OpenAI API key: os.environ[\"OPENAI_API_KEY\"] or `openai_api_key_file=\"key_openai.txt\"`.\n",
    "- Azure OpenAI API key: os.environ[\"AZURE_OPENAI_API_KEY\"] or `aoai_api_key_file=\"key_aoai.txt\"`. Multiple keys can be stored, one per line.\n",
    "- Azure OpenAI API base: os.environ[\"AZURE_OPENAI_API_BASE\"] or `aoai_api_base_file=\"base_aoai.txt\"`. Multiple bases can be stored, one per line.\n",
    "\n",
    "It's OK to have only the OpenAI API key, or only the Azure OpenAI API key + base.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import oai\n",
    "\n",
    "config_list = oai.config_list_gpt4_gpt35()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The config list looks like the following:\n",
    "```python\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your OpenAI API key here>',\n",
    "    },  # only if OpenAI API key is found\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your first Azure OpenAI API key here>',\n",
    "        'api_base': '<your first Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-03-15-preview',\n",
    "    },  # only if the at least one Azure OpenAI API key is found\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your second Azure OpenAI API key here>',\n",
    "        'api_base': '<your second Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-03-15-preview',\n",
    "    },  # only if the second Azure OpenAI API key is found\n",
    "    {\n",
    "        'model': 'gpt-3.5-turbo',\n",
    "        'api_key': '<your OpenAI API key here>',\n",
    "    },  # only if OpenAI API key is found\n",
    "    {\n",
    "        'model': 'gpt-3.5-turbo',\n",
    "        'api_key': '<your first Azure OpenAI API key here>',\n",
    "        'api_base': '<your first Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-03-15-preview',\n",
    "    },  # only if the at least one Azure OpenAI API key is found\n",
    "    {\n",
    "        'model': 'gpt-3.5-turbo',\n",
    "        'api_key': '<your second Azure OpenAI API key here>',\n",
    "        'api_base': '<your second Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-03-15-preview',\n",
    "    },  # only if the second Azure OpenAI API key is found\n",
    "]\n",
    "```\n",
    "\n",
    "You can directly override it if the above function returns an empty list, i.e., it doesn't find the keys in the specified locations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Task: Write Code to Draw a Plot\n",
    "\n",
    "In the example below, let's see how to use the agents in FLAML to write a python script and execute the script. This process involves constructing a `AssistantAgent` to serve as the assistant, along with a `UserProxyAgent` that acts as a proxy for the human user. In this example demonstrated below, when constructing the `UserProxyAgent`,  we select the `human_input_mode` to \"NEVER\". This means that the `UserProxyAgent` will not solicit feedback from the human user. It stops replying when the limit defined by `max_consecutive_auto_reply` is reached, or when `is_termination_msg()` returns true for the received message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**** assistant received message from user ****\n",
      "\n",
      "Plot a rocket and save the plot to a file named 'rocket.svg'\n",
      "\n",
      "**** user received message from assistant ****\n",
      "\n",
      "```python\n",
      "# filename: plot_rocket.py\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "def draw_rocket():\n",
      "    rocket_base = plt.Rectangle((0, 0), 1, 4, fc='gray')\n",
      "    rocket_cone = plt.Polygon([[0, 4], [0.5, 5.5], [1, 4]], fc='red')\n",
      "    rocket_fin_1 = plt.Polygon([[0, 2], [-0.5, 1], [0, 0]], fc='blue')\n",
      "    rocket_fin_2 = plt.Polygon([[1, 2], [1.5, 1], [1, 0]], fc='blue')\n",
      "\n",
      "    fig, ax = plt.subplots()\n",
      "    ax.add_patch(rocket_base)\n",
      "    ax.add_patch(rocket_cone)\n",
      "    ax.add_patch(rocket_fin_1)\n",
      "    ax.add_patch(rocket_fin_2)\n",
      "\n",
      "    plt.xlim(-2, 3)\n",
      "    plt.ylim(-1, 6)\n",
      "    plt.axis('equal')\n",
      "    plt.axis('off')\n",
      "\n",
      "    plt.savefig('rocket.svg')\n",
      "    plt.show()\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    draw_rocket()\n",
      "```\n",
      "Please save the above code in a file named `plot_rocket.py` and then execute it with the following command:\n",
      "\n",
      "```sh\n",
      "python plot_rocket.py\n",
      "```\n",
      "\n",
      "This will generate a file called `rocket.svg` containing the rocket plot.\n",
      "\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED. USING AUTO REPLY FOR THE USER...\n",
      "\n",
      "**** assistant received message from user ****\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: Figure(640x480)\n",
      "\n",
      "\n",
      "**** user received message from assistant ****\n",
      "\n",
      "Great! The code executed successfully, and you should now have a file named 'rocket.svg' containing the rocket plot. Let me know if you need any further assistance.\n",
      "\n",
      "TERMINATE\n"
     ]
    }
   ],
   "source": [
    "from flaml.autogen.agent.assistant_agent import AssistantAgent\n",
    "from flaml.autogen.agent.user_proxy_agent import UserProxyAgent\n",
    "\n",
    "# create an assistant which is essentially a AssistantAgent instance named \"coding_agent\"\n",
    "assistant = AssistantAgent(\"assistant\", request_timeout=600, seed=42, config_list=config_list)\n",
    "# create a UserProxyAgent instance named \"user\"\n",
    "user = UserProxyAgent(\n",
    "    \"user\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    is_termination_msg=lambda x: x.rstrip().endswith(\"TERMINATE\") or x.rstrip().endswith('\"TERMINATE\".'),\n",
    "    work_dir=\".\",\n",
    ")\n",
    "# the assistant receives a message from the user, which contains the task description\n",
    "assistant.receive(\n",
    "    \"\"\"Plot a rocket and save the plot to a file named 'rocket.svg'\"\"\",\n",
    "    user,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example above involves code execution. In FLAML, code execution is triggered automatically by the `UserProxyAgent` when it detects an executable code block in a received message and no human user input is provided. This process occurs in a designated working directory, using a Docker container by default. Unless a specific directory is specified, FLAML defaults to the `flaml/autogen/extensions` directory. Users have the option to specify a different working directory by setting the `work_dir` argument when constructing a new instance of the `UserProxyAgent`.\n",
    "\n",
    "Let's display the generated figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" xmlns=\"http://www.w3.org/2000/svg\" width=\"460.8pt\" height=\"345.6pt\" viewBox=\"0 0 460.8 345.6\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-06-01T22:24:00.184858</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 345.6  L 460.8 345.6  L 460.8 0  L 0 0  z \" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 214.167273 295.488  L 258.152727 295.488  L 258.152727 119.546182  L 214.167273 119.546182  z \" clip-path=\"url(#p95ddd458d6)\" style=\"fill: #808080\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 214.167273 119.546182  L 236.16 53.568  L 258.152727 119.546182  z \" clip-path=\"url(#p95ddd458d6)\" style=\"fill: #ff0000\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 214.167273 207.517091  L 192.174545 251.502545  L 214.167273 295.488  z \" clip-path=\"url(#p95ddd458d6)\" style=\"fill: #0000ff\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 258.152727 207.517091  L 280.145455 251.502545  L 258.152727 295.488  z \" clip-path=\"url(#p95ddd458d6)\" style=\"fill: #0000ff\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p95ddd458d6\">\n",
       "   <rect x=\"57.6\" y=\"41.472\" width=\"357.12\" height=\"266.112\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# uncomment the following to render the svg file\n",
    "# from IPython.display import SVG, display\n",
    "\n",
    "# display(SVG(\"rocket.svg\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Task: Use Code to Check Stock Price Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**** assistant received message from user ****\n",
      "\n",
      "What date is today? Which big tech stock has the largest year-to-date gain in 2023? How much is the gain?\n",
      "\n",
      "**** user received message from assistant ****\n",
      "\n",
      "To get today's date, you can use the following Python code:\n",
      "\n",
      "```python\n",
      "from datetime import datetime\n",
      "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
      "print(f\"Today's date is {today}\")\n",
      "```\n",
      "\n",
      "However, I am an AI language model and don't have real-time access to live stock market data. You can use financial websites or stock market applications to determine which big tech stock has the largest year-to-date gain in 2023 and find out the gain amount. You can also use Python with some libraries such as `yfinance` or `pandas-datareader` to fetch financial data, but it requires an internet connection to fetch real-time data.\n",
      "\n",
      "Let's find today's date first. Run the code above to get the current date.\n",
      "\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED. USING AUTO REPLY FOR THE USER...\n",
      "\n",
      "**** assistant received message from user ****\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: Today's date is 2023-06-01\n",
      "\n",
      "\n",
      "**** user received message from assistant ****\n",
      "\n",
      "Thank you for providing the current date. Based on the provided date, we can now proceed with fetching stock data for big tech stocks. To check which big tech stock has the largest year-to-date gain, you can use the following Python code with the `yfinance` library. If you don't have the yfinance library installed, you can install it with this command:\n",
      "\n",
      "```sh\n",
      "pip install yfinance\n",
      "```\n",
      "\n",
      "Once you have installed yfinance, you can run the following Python code:\n",
      "\n",
      "```python\n",
      "import yfinance as yf\n",
      "import pandas as pd\n",
      "\n",
      "# Define the big tech stock tickers\n",
      "stocks = ['AAPL', 'GOOGL', 'AMZN', 'MSFT', 'FB']\n",
      "\n",
      "# Fetch the stock data\n",
      "start_date = '2023-01-01'\n",
      "data = yf.download(tickers=stocks, start=start_date)\n",
      "\n",
      "# Calculate the year-to-date gains\n",
      "today_close_prices = data['Adj Close'].iloc[-1]\n",
      "first_day_close_prices = data['Adj Close'].iloc[0]\n",
      "gains = (today_close_prices - first_day_close_prices) / first_day_close_prices * 100\n",
      "\n",
      "# Find the stock with the largest gain\n",
      "largest_gain_stock = gains.idxmax()\n",
      "largest_gain_value = gains[largest_gain_stock]\n",
      "\n",
      "print(f\"{largest_gain_stock} has the largest year-to-date gain of {largest_gain_value:.2f}% as of {today}\")\n",
      "```\n",
      "\n",
      "This code will fetch the year-to-date data for the specified stock tickers and calculate the percentage gains. It will then output the stock with the largest gain and its gain percentage as of the provided date.\n",
      "\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED. USING AUTO REPLY FOR THE USER...\n",
      "\n",
      "**** assistant received message from user ****\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: Traceback (most recent call last):\n",
      "  File \"/workspaces/FLAML/notebook/tmp_code_28a6141bc111a58e6a41abcba15bdbcb.py\", line 20, in <module>\n",
      "    print(f\"{largest_gain_stock} has the largest year-to-date gain of {largest_gain_value:.2f}% as of {today}\")\n",
      "NameError: name 'today' is not defined\n",
      "\n",
      "\n",
      "**** user received message from assistant ****\n",
      "\n",
      "My apologies for the error. I mistakenly used the variable `today` without including the code snippet to define it. Let's fix the error by adding the `today` variable back as shown below:\n",
      "\n",
      "```python\n",
      "import yfinance as yf\n",
      "import pandas as pd\n",
      "from datetime import datetime\n",
      "\n",
      "# Define the big tech stock tickers\n",
      "stocks = ['AAPL', 'GOOGL', 'AMZN', 'MSFT', 'FB']\n",
      "\n",
      "# Fetch the stock data\n",
      "start_date = '2023-01-01'\n",
      "data = yf.download(tickers=stocks, start=start_date)\n",
      "\n",
      "# Calculate the year-to-date gains\n",
      "today_close_prices = data['Adj Close'].iloc[-1]\n",
      "first_day_close_prices = data['Adj Close'].iloc[0]\n",
      "gains = (today_close_prices - first_day_close_prices) / first_day_close_prices * 100\n",
      "\n",
      "# Find the stock with the largest gain\n",
      "largest_gain_stock = gains.idxmax()\n",
      "largest_gain_value = gains[largest_gain_stock]\n",
      "\n",
      "# Get today's date\n",
      "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
      "\n",
      "print(f\"{largest_gain_stock} has the largest year-to-date gain of {largest_gain_value:.2f}% as of {today}\")\n",
      "```\n",
      "\n",
      "Please run the updated code to get the stock with the largest year-to-date gain and its gain percentage.\n",
      "\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED. USING AUTO REPLY FOR THE USER...\n",
      "\n",
      "**** assistant received message from user ****\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "[*********************100%***********************]  5 of 5 completed\n",
      "\n",
      "1 Failed download:\n",
      "- FB: No timezone found, symbol may be delisted\n",
      "AAPL has the largest year-to-date gain of 44.41% as of 2023-06-01\n",
      "\n",
      "\n",
      "**** user received message from assistant ****\n",
      "\n",
      "It seems that the ticker symbol for Meta Platforms Inc., formerly known as Facebook, has changed from \"FB\" to \"META\" or \"MVRS\". The ticker \"FB\" appears to be delisted. To avoid the \"Failed download\" error message, you can update the code with the new ticker symbol:\n",
      "\n",
      "```python\n",
      "import yfinance as yf\n",
      "import pandas as pd\n",
      "from datetime import datetime\n",
      "\n",
      "# Define the big tech stock tickers\n",
      "stocks = ['AAPL', 'GOOGL', 'AMZN', 'MSFT', 'META']\n",
      "\n",
      "# Fetch the stock data\n",
      "start_date = '2023-01-01'\n",
      "data = yf.download(tickers=stocks, start=start_date)\n",
      "\n",
      "# Calculate the year-to-date gains\n",
      "today_close_prices = data['Adj Close'].iloc[-1]\n",
      "first_day_close_prices = data['Adj Close'].iloc[0]\n",
      "gains = (today_close_prices - first_day_close_prices) / first_day_close_prices * 100\n",
      "\n",
      "# Find the stock with the largest gain\n",
      "largest_gain_stock = gains.idxmax()\n",
      "largest_gain_value = gains[largest_gain_stock]\n",
      "\n",
      "# Get today's date\n",
      "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
      "\n",
      "print(f\"{largest_gain_stock} has the largest year-to-date gain of {largest_gain_value:.2f}% as of {today}\")\n",
      "```\n",
      "\n",
      "However, based on your previous output, Apple Inc. (AAPL) has the largest year-to-date gain of 44.41% as of June 1, 2023. You can run the updated code to include the new ticker symbol for Meta Platforms Inc., but the result may still be the same. \n",
      "\n",
      "Please, let me know if you need further assistance.\n",
      "\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED. USING AUTO REPLY FOR THE USER...\n",
      "\n",
      "**** assistant received message from user ****\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "[*********************100%***********************]  5 of 5 completed\n",
      "META has the largest year-to-date gain of 118.54% as of 2023-06-01\n",
      "\n",
      "\n",
      "**** user received message from assistant ****\n",
      "\n",
      "Great! Based on the updated code, Meta Platforms Inc. (META) has the largest year-to-date gain of 118.54% as of June 1, 2023. If you need more assistance or have any other questions, feel free to ask.\n",
      "\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED. USING AUTO REPLY FOR THE USER...\n",
      "\n",
      "**** assistant received message from user ****\n",
      "\n",
      "\n",
      "\n",
      "**** user received message from assistant ****\n",
      "\n",
      "TERMINATE\n"
     ]
    }
   ],
   "source": [
    "# it is suggested to reset the assistant to clear the state if the new task is not related to the previous one.\n",
    "assistant.reset()\n",
    "assistant.receive(\n",
    "    \"\"\"What date is today? Which big tech stock has the largest year-to-date gain in 2023? How much is the gain?\"\"\",\n",
    "    user,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the feedback is auto generated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2d910cfd2d2a4fc49fc30fbbdc5576a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "454146d0f7224f038689031002906e6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e4ae2b6f5a974fd4bafb6abb9d12ff26",
        "IPY_MODEL_577e1e3cc4db4942b0883577b3b52755",
        "IPY_MODEL_b40bdfb1ac1d4cffb7cefcb870c64d45"
       ],
       "layout": "IPY_MODEL_dc83c7bff2f241309537a8119dfc7555",
       "tabbable": null,
       "tooltip": null
      }
     },
     "577e1e3cc4db4942b0883577b3b52755": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2d910cfd2d2a4fc49fc30fbbdc5576a7",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_74a6ba0c3cbc4051be0a83e152fe1e62",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "6086462a12d54bafa59d3c4566f06cb2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74a6ba0c3cbc4051be0a83e152fe1e62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7d3f3d9e15894d05a4d188ff4f466554": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b40bdfb1ac1d4cffb7cefcb870c64d45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f1355871cc6f4dd4b50d9df5af20e5c8",
       "placeholder": "​",
       "style": "IPY_MODEL_ca245376fd9f4354af6b2befe4af4466",
       "tabbable": null,
       "tooltip": null,
       "value": " 1/1 [00:00&lt;00:00, 44.69it/s]"
      }
     },
     "ca245376fd9f4354af6b2befe4af4466": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dc83c7bff2f241309537a8119dfc7555": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e4ae2b6f5a974fd4bafb6abb9d12ff26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6086462a12d54bafa59d3c4566f06cb2",
       "placeholder": "​",
       "style": "IPY_MODEL_7d3f3d9e15894d05a4d188ff4f466554",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "f1355871cc6f4dd4b50d9df5af20e5c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
