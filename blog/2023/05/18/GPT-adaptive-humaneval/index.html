<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v0.0.0-4193">
<link rel="alternate" type="application/rss+xml" href="/FLAML/blog/rss.xml" title="FLAML RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/FLAML/blog/atom.xml" title="FLAML Atom Feed">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" integrity="sha384-Um5gpz1odJg5Z4HAmzPtgZKdTBHZdw8S29IecapCSB31ligYPhHQZMIlWLYQGVoc" crossorigin="anonymous"><title data-react-helmet="true">Achieve More, Pay Less - Use GPT-4 Smartly | FLAML</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://microsoft.github.io//FLAML/blog/2023/05/18/GPT-adaptive-humaneval"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_tag" content="default"><meta data-react-helmet="true" property="og:title" content="Achieve More, Pay Less - Use GPT-4 Smartly | FLAML"><meta data-react-helmet="true" name="description" content="An adaptive way of using GPT-3.5 and GPT-4 outperforms GPT-4 in both coding success rate and inference cost"><meta data-react-helmet="true" property="og:description" content="An adaptive way of using GPT-3.5 and GPT-4 outperforms GPT-4 in both coding success rate and inference cost"><meta data-react-helmet="true" property="og:type" content="article"><meta data-react-helmet="true" property="article:published_time" content="2023-05-18T00:00:00.000Z"><meta data-react-helmet="true" property="article:author" content="https://www.linkedin.com/in/chi-wang-49b15b16/"><meta data-react-helmet="true" property="article:tag" content="LLM,GPT,research"><link data-react-helmet="true" rel="shortcut icon" href="/FLAML/img/flaml_logo.ico"><link data-react-helmet="true" rel="canonical" href="https://microsoft.github.io//FLAML/blog/2023/05/18/GPT-adaptive-humaneval"><link data-react-helmet="true" rel="alternate" href="https://microsoft.github.io//FLAML/blog/2023/05/18/GPT-adaptive-humaneval" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://microsoft.github.io//FLAML/blog/2023/05/18/GPT-adaptive-humaneval" hreflang="x-default"><link rel="stylesheet" href="/FLAML/assets/css/styles.a35b243d.css">
<link rel="preload" href="/FLAML/assets/js/runtime~main.597cf7c4.js" as="script">
<link rel="preload" href="/FLAML/assets/js/main.ced98023.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_OuoZ">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/FLAML/"><div class="navbar__logo"><img src="/FLAML/img/flaml_logo_fill.svg" alt="FLAML" class="themedImage_TMUO themedImage--light_4Vu1"><img src="/FLAML/img/flaml_logo_fill.svg" alt="FLAML" class="themedImage_TMUO themedImage--dark_uzRr"></div><b class="navbar__title">FLAML</b></a><a class="navbar__item navbar__link" href="/FLAML/docs/Getting-Started">Docs</a><a class="navbar__item navbar__link" href="/FLAML/docs/reference/automl/automl">SDK</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/FLAML/blog">Blog</a><a class="navbar__item navbar__link" href="/FLAML/docs/FAQ">FAQ</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/microsoft/FLAML" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_iYfV toggle_2i4l toggleDisabled_xj38"><div class="toggleTrack_t-f2" role="button" tabindex="-1"><div class="toggleTrackCheck_mk7D"><span class="toggleIcon_pHJ9">ðŸŒœ</span></div><div class="toggleTrackX_dm8H"><span class="toggleIcon_pHJ9">ðŸŒž</span></div><div class="toggleTrackThumb_W6To"></div></div><input type="checkbox" class="toggleScreenReader_h9qa" aria-label="Switch between dark and light mode"></div><div class="navbar__search searchBarContainer_I7kZ"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_Zg7X searchBarLoadingRing_J5Ez"><div></div><div></div><div></div><div></div></div><div class="searchHintContainer_CDc6"><kbd class="searchHint_2RRg">ctrl</kbd><kbd class="searchHint_2RRg">K</kbd></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-post-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_q+wC thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_9G5K margin-bottom--md">Recent posts</div><ul class="sidebarItemList_6T4b"><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/FLAML/blog/2023/07/14/Local-LLMs">Use flaml.autogen for Local LLMs</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/FLAML/blog/2023/06/28/MathChat">MathChat - An Conversational Framework to Solve Math Problems</a></li><li class="sidebarItem_cjdF"><a aria-current="page" class="sidebarItemLink_zyXk sidebarItemLinkActive_wcJs" href="/FLAML/blog/2023/05/18/GPT-adaptive-humaneval">Achieve More, Pay Less - Use GPT-4 Smartly</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/FLAML/blog/2023/05/07/1M-milestone">Surpassing 1 Million Downloads - A Retrospective and a Look into the Future</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/FLAML/blog/2023/04/21/LLM-tuning-math">Does Model and Inference Parameter Matter in LLM Applications? - A Case Study for MATH</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="blogPostTitle_d4p0" itemprop="headline">Achieve More, Pay Less - Use GPT-4 Smartly</h1><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2023-05-18T00:00:00.000Z" itemprop="datePublished">May 18, 2023</time> Â· <!-- -->8 min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/chi-wang-49b15b16/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://github.com/sonichi.png" alt="Chi Wang"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/chi-wang-49b15b16/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Chi Wang</span></a></div><small class="avatar__subtitle" itemprop="description">Principal Researcher at Microsoft Research</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img alt="An adaptive way of using GPT-3.5 and GPT-4 outperforms GPT-4 in both coding success rate and inference cost" src="/FLAML/assets/images/humaneval-b2718b0b15d76b8fc59a4094e1bd684c.png"></p><p><strong>TL;DR:</strong></p><ul><li><strong>A case study using the HumanEval benchmark shows that an adaptive way of using multiple GPT models can achieve both much higher accuracy (from 68% to 90%) and lower inference cost (by 18%) than using GPT-4 for coding.</strong></li></ul><p>GPT-4 is a big upgrade of foundation model capability, e.g., in code and math, accompanied by a much higher (more than 10x) price per token to use over GPT-3.5-Turbo. On a code completion benchmark, <a href="https://huggingface.co/datasets/openai_humaneval" target="_blank" rel="noopener noreferrer">HumanEval</a>, developed by OpenAI, GPT-4 can successfully solve 68% tasks while GPT-3.5-Turbo does 46%. It is possible to increase the success rate of GPT-4 further by generating multiple responses or making multiple calls. However, that will further increase the cost, which is already nearly 20 times of using GPT-3.5-Turbo and with more restricted API call rate limit. Can we achieve more with less?</p><p>In this blog post, we will explore a creative, adaptive way of using GPT models which leads to a big leap forward.</p><h2 class="anchor anchorWithStickyNavbar_y2LR" id="observations">Observations<a aria-hidden="true" class="hash-link" href="#observations" title="Direct link to heading">â€‹</a></h2><ul><li>GPT-3.5-Turbo can alrady solve 40%-50% tasks. For these tasks if we never use GPT-4, we can save nearly 40-50% cost.</li><li>If we use the saved cost to generate more responses with GPT-4 for the remaining unsolved tasks, it is possible to solve some more of them while keeping the amortized cost down.</li></ul><p>The obstacle of leveraging these observations is that we do not know <em>a priori</em> which tasks can be solved by the cheaper model, which tasks can be solved by the expensive model, and which tasks can be solved by paying even more to the expensive model.</p><p>To overcome that obstacle, one may want to predict which task requires what model to solve and how many responses are required for each task. Let&#x27;s look at one example code completion task:</p><div class="codeBlockContainer_J+bg language-python"><div class="codeBlockContent_csEI python"><pre tabindex="0" class="prism-code language-python codeBlock_rtdJ thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#bfc7d5"><span class="token keyword" style="font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(130, 170, 255)">vowels_count</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">&quot;&quot;&quot;Write a function vowels_count which takes a string representing</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    a word as input and returns the number of vowels in the string.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    Vowels in this case are &#x27;a&#x27;, &#x27;e&#x27;, &#x27;i&#x27;, &#x27;o&#x27;, &#x27;u&#x27;. Here, &#x27;y&#x27; is also a</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    vowel, but only when it is at the end of the given word.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="display:inline-block;color:rgb(195, 232, 141)"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    Example:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    &gt;&gt;&gt; vowels_count(&quot;abcde&quot;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    2</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    &gt;&gt;&gt; vowels_count(&quot;ACEDY&quot;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    3</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    &quot;&quot;&quot;</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>Can we predict whether GPT-3.5-Turbo can solve this task or do we need to use GPT-4? My first guess is that GPT-3.5-Turbo can get it right because the instruction is fairly straightforward. Yet, it turns out that GPT-3.5-Turbo does not consistently get it right, if we only give it one chance. It&#x27;s not obvious (but an interesting research question!) how to predict the performance without actually trying.</p><p>What else can we do? We notice that:
<strong>It&#x27;s &quot;easier&quot; to verify a given solution than finding a correct solution from scratch.</strong></p><p>Some simple example test cases are provided in the docstr. If we already have a response generated by a model, we can use those test cases to filter wrong implementations, and either use a more powerful model or generate more responses, until the result passes the example test cases. Moreover, this step can be automated by asking GPT-3.5-Turbo to generate assertion statements from the examples given in the docstr (a simpler task where we can place our bet) and executing the code.</p><h2 class="anchor anchorWithStickyNavbar_y2LR" id="solution">Solution<a aria-hidden="true" class="hash-link" href="#solution" title="Direct link to heading">â€‹</a></h2><p>Combining these observations, we can design a solution with two intuitive ideas:</p><ul><li>Make use of auto-generated feedback, i.e., code execution results, to filter responses.</li><li>Try inference configurations one by one, until one response can pass the filter.</li></ul><p><img alt="Design" src="/FLAML/assets/images/design-88630f6d8d95f1e31ef5ce79e81aab54.png"></p><p>This solution works adaptively without knowing or predicting which task fits which configuration. It simply tries multiple configurations one by one, starting from the cheapest configuration. Note that one configuration can generate multiple responses (by setting the inference parameter n larger than 1). And different configurations can use the same model and different inference parameters such as n and temperature. Only one response is returned and evaluated per task.</p><p>An implementation of this solution is provided in <a href="/FLAML/docs/reference/autogen/code_utils#implement">flaml.autogen</a>. It uses the following sequence of configurations:</p><ol><li>GPT-3.5-Turbo, n=1, temperature=0</li><li>GPT-3.5-Turbo, n=7, temperature=1, stop=<!-- -->[&quot;\nclass&quot;, &quot;\ndef&quot;, &quot;\nif&quot;, &quot;\nprint&quot;]</li><li>GPT-4, n=1, temperature=0</li><li>GPT-4, n=2, temperature=1, stop=<!-- -->[&quot;\nclass&quot;, &quot;\ndef&quot;, &quot;\nif&quot;, &quot;\nprint&quot;]</li><li>GPT-4, n=1, temperature=1, stop=<!-- -->[&quot;\nclass&quot;, &quot;\ndef&quot;, &quot;\nif&quot;, &quot;\nprint&quot;]</li></ol><h2 class="anchor anchorWithStickyNavbar_y2LR" id="experiment-results">Experiment Results<a aria-hidden="true" class="hash-link" href="#experiment-results" title="Direct link to heading">â€‹</a></h2><p>The first figure in this blog post shows the success rate and average inference cost of the adaptive solution compared with default GPT-4.
The inference cost includes the cost for generating the assertions in our solution. The generated assertions are not always correct, and programs that pass/fail the generated assertions are not always right/wrong. Despite of that, the adaptive solution can increase the success rate (referred to as pass@1 in the literature) from 68% to 90%, while reducing the cost by 18%.</p><p>Here are a few examples of function definitions which are solved by different configurations in the portfolio.</p><ol><li>Solved by GPT-3.5-Turbo, n=1, temperature=0</li></ol><div class="codeBlockContainer_J+bg language-python"><div class="codeBlockContent_csEI python"><pre tabindex="0" class="prism-code language-python codeBlock_rtdJ thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#bfc7d5"><span class="token keyword" style="font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(130, 170, 255)">compare</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">game</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain">guess</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">&quot;&quot;&quot;I think we all remember that feeling when the result of some long-awaited</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    event is finally known. The feelings and thoughts you have at that moment are</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    definitely worth noting down and comparing.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    Your task is to determine if a person correctly guessed the results of a number of matches.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    You are given two arrays of scores and guesses of equal length, where each index shows a match.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    Return an array of the same length denoting how far off each guess was. If they have guessed correctly,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    the value is 0, and if not, the value is the absolute difference between the guess and the score.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="display:inline-block;color:rgb(195, 232, 141)"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="display:inline-block;color:rgb(195, 232, 141)"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    example:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="display:inline-block;color:rgb(195, 232, 141)"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    compare([1,2,3,4,5,1],[1,2,3,4,2,-2]) -&gt; [0,0,0,0,3,3]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    compare([0,5,0,0,0,4],[4,1,1,0,0,-2]) -&gt; [4,4,1,0,0,6]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    &quot;&quot;&quot;</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><ol start="2"><li>Solved by GPT-3.5-Turbo, n=7, temperature=1, stop=<!-- -->[&quot;\nclass&quot;, &quot;\ndef&quot;, &quot;\nif&quot;, &quot;\nprint&quot;]<!-- -->: the <code>vowels_count</code> function presented earlier.</li><li>Solved by GPT-4, n=1, temperature=0:</li></ol><div class="codeBlockContainer_J+bg language-python"><div class="codeBlockContent_csEI python"><pre tabindex="0" class="prism-code language-python codeBlock_rtdJ thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#bfc7d5"><span class="token keyword" style="font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(130, 170, 255)">string_xor</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(130, 170, 255)">str</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> b</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(130, 170, 255)">str</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"> </span><span class="token operator" style="color:rgb(137, 221, 255)">-</span><span class="token operator" style="color:rgb(137, 221, 255)">&gt;</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(130, 170, 255)">str</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">&quot;&quot;&quot; Input are two strings a and b consisting only of 1s and 0s.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    Perform binary XOR on these inputs and return result also as a string.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    &gt;&gt;&gt; string_xor(&#x27;010&#x27;, &#x27;110&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    &#x27;100&#x27;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    &quot;&quot;&quot;</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><ol start="4"><li>Solved by GPT-4, n=2, temperature=1, stop=<!-- -->[&quot;\nclass&quot;, &quot;\ndef&quot;, &quot;\nif&quot;, &quot;\nprint&quot;]<!-- -->:</li></ol><div class="codeBlockContainer_J+bg language-python"><div class="codeBlockContent_csEI python"><pre tabindex="0" class="prism-code language-python codeBlock_rtdJ thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#bfc7d5"><span class="token keyword" style="font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(130, 170, 255)">is_palindrome</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">string</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(130, 170, 255)">str</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"> </span><span class="token operator" style="color:rgb(137, 221, 255)">-</span><span class="token operator" style="color:rgb(137, 221, 255)">&gt;</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(130, 170, 255)">bool</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">&quot;&quot;&quot; Test if given string is a palindrome &quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token keyword" style="font-style:italic">return</span><span class="token plain"> string </span><span class="token operator" style="color:rgb(137, 221, 255)">==</span><span class="token plain"> string</span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token operator" style="color:rgb(137, 221, 255)">-</span><span class="token number" style="color:rgb(247, 140, 108)">1</span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(130, 170, 255)">make_palindrome</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">string</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(130, 170, 255)">str</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"> </span><span class="token operator" style="color:rgb(137, 221, 255)">-</span><span class="token operator" style="color:rgb(137, 221, 255)">&gt;</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(130, 170, 255)">str</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">&quot;&quot;&quot; Find the shortest palindrome that begins with a supplied string.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    Algorithm idea is simple:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    - Find the longest postfix of supplied string that is a palindrome.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    - Append to the end of the string reverse of a string prefix that comes before the palindromic suffix.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    &gt;&gt;&gt; make_palindrome(&#x27;&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    &#x27;&#x27;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    &gt;&gt;&gt; make_palindrome(&#x27;cat&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    &#x27;catac&#x27;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    &gt;&gt;&gt; make_palindrome(&#x27;cata&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    &#x27;catac&#x27;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    &quot;&quot;&quot;</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><ol start="5"><li>Solved by GPT-4, n=1, temperature=1, stop=<!-- -->[&quot;\nclass&quot;, &quot;\ndef&quot;, &quot;\nif&quot;, &quot;\nprint&quot;]<!-- -->:</li></ol><div class="codeBlockContainer_J+bg language-python"><div class="codeBlockContent_csEI python"><pre tabindex="0" class="prism-code language-python codeBlock_rtdJ thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#bfc7d5"><span class="token keyword" style="font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(130, 170, 255)">sort_array</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">arr</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    In this Kata, you have to sort an array of non-negative integers according to</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    number of ones in their binary representation in ascending order.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    For similar number of ones, sort based on decimal value.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="display:inline-block;color:rgb(195, 232, 141)"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    It must be implemented like this:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    &gt;&gt;&gt; sort_array([1, 5, 2, 3, 4]) == [1, 2, 3, 4, 5]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    &gt;&gt;&gt; sort_array([-2, -3, -4, -5, -6]) == [-6, -5, -4, -3, -2]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    &gt;&gt;&gt; sort_array([1, 0, 2, 3, 4]) [0, 1, 2, 3, 4]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">    &quot;&quot;&quot;</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>The last problem is an example with wrong example test cases in the original definition. It misleads the adaptive solution because a correct implementation is regarded as wrong and more trials are made. The last configuration in the sequence returns the right implementation, even though it does not pass the auto-generated assertions. This example demonstrates that:</p><ul><li>Our adaptive solution has a certain degree of fault tolerance.</li><li>The success rate and inference cost for the adaptive solution can be further improved if correct example test cases are used.</li></ul><p>It is worth noting that the reduced inference cost is the amortized cost over all the tasks. For each individual task, the cost can be either larger or smaller than directly using GPT-4. This is the nature of the adaptive solution: The cost is in general larger for difficult tasks than that for easy tasks.</p><p>An example notebook to run this experiment can be found at: <a href="https://github.com/microsoft/FLAML/blob/v1.2.1/notebook/research/autogen_code.ipynb" target="_blank" rel="noopener noreferrer">https://github.com/microsoft/FLAML/blob/v1.2.1/notebook/research/autogen_code.ipynb</a></p><h2 class="anchor anchorWithStickyNavbar_y2LR" id="discussion">Discussion<a aria-hidden="true" class="hash-link" href="#discussion" title="Direct link to heading">â€‹</a></h2><p>Our solution is quite simple to implement using a generic interface offered in <a href="https://microsoft.github.io/autogen/docs/Use-Cases/enhanced_inference#logic-error" target="_blank" rel="noopener noreferrer"><code>flaml.autogen</code></a>, yet the result is quite encouraging.</p><p>While the specific way of generating assertions is application-specific, the main ideas are general in LLM operations:</p><ul><li>Generate multiple responses to select - especially useful when selecting a good response is relatively easier than generating a good response at one shot.</li><li>Consider multiple configurations to generate responses - especially useful when:<ul><li>Model and other inference parameter choice affect the utility-cost tradeoff; or</li><li>Different configurations have complementary effect.</li></ul></li></ul><p>A <a href="/FLAML/blog/2023/04/21/LLM-tuning-math">previous blog post</a> provides evidence that these ideas are relevant in solving math problems too.
<code>flaml.autogen</code> uses a technique <a href="https://arxiv.org/abs/2303.04673" target="_blank" rel="noopener noreferrer">EcoOptiGen</a> to support inference parameter tuning and model selection.</p><p>There are many directions of extensions in research and development:</p><ul><li>Generalize the way to provide feedback.</li><li>Automate the process of optimizing the configurations.</li><li>Build adaptive agents for different applications.</li></ul><p><em>Do you find this approach applicable to your use case? Do you have any other challenge to share about LLM applications? Do you like to see more support or research of LLM optimization or automation? Please join our <a href="https://discord.gg/Cppx2vSPVP" target="_blank" rel="noopener noreferrer">Discord</a> server for discussion.</em></p><h2 class="anchor anchorWithStickyNavbar_y2LR" id="for-further-reading">For Further Reading<a aria-hidden="true" class="hash-link" href="#for-further-reading" title="Direct link to heading">â€‹</a></h2><ul><li><a href="https://microsoft.github.io/autogen/" target="_blank" rel="noopener noreferrer">Documentation</a> about <code>flaml.autogen</code> and <a href="https://arxiv.org/abs/2303.04673" target="_blank" rel="noopener noreferrer">Research paper</a>.</li><li><a href="/FLAML/blog/2023/04/21/LLM-tuning-math">Blog post</a> about a related study for math.</li></ul></div><footer class="row docusaurus-mt-lg blogPostDetailsFull_xD8n"><div class="col"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/FLAML/blog/tags/llm">LLM</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/FLAML/blog/tags/gpt">GPT</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/FLAML/blog/tags/research">research</a></li></ul></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/FLAML/blog/2023/06/28/MathChat"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">Â« <!-- -->MathChat - An Conversational Framework to Solve Math Problems</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/FLAML/blog/2023/05/07/1M-milestone"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Surpassing 1 Million Downloads - A Retrospective and a Look into the Future<!-- --> Â»</div></a></div></nav></main><div class="col col--2"><div class="tableOfContents_vrFS thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#observations" class="table-of-contents__link toc-highlight">Observations</a></li><li><a href="#solution" class="table-of-contents__link toc-highlight">Solution</a></li><li><a href="#experiment-results" class="table-of-contents__link toc-highlight">Experiment Results</a></li><li><a href="#discussion" class="table-of-contents__link toc-highlight">Discussion</a></li><li><a href="#for-further-reading" class="table-of-contents__link toc-highlight">For Further Reading</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items"><li class="footer__item"><a href="https://discord.gg/Cppx2vSPVP" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2025 FLAML Authors. Built with Docusaurus.</div></div></div></footer></div>
<script src="/FLAML/assets/js/runtime~main.597cf7c4.js"></script>
<script src="/FLAML/assets/js/main.ced98023.js"></script>
</body>
</html>